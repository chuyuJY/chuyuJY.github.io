# 操作系统


[toc]

## 一、进程、线程、协程

> #### 问：什么是系统调用？

进程的运行分为两个级别：

1. **用户态(user mode)**：用户态运行的进程可以直接读取用户程序的数据。
2. **系统态(kernel mode)**：系统态运行的进程几乎可以访问计算机的任何资源，不受限制。

用户写的程序基本上都运行在用户态，若想调用与**系统级资源**有关的操作，则必须通过**系统调用**向操作系统请求。

这些系统调用按功能大致可分为如下几类：

- **设备管理：**完成设备的请求或释放，以及设备启动等功能。
- **文件管理：**完成文件的读、写、创建及删除等功能。
- **进程控制：**完成进程的创建、撤销、阻塞及唤醒等功能。
- **进程通信：**完成进程之间的消息传递或信号传递等功能。
- **内存管理：**完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

> #### 问：进程、线程、协程的区别？:star::star::star:

|              | 进程                                                         | 线程                                               | 协程                                                         |
| ------------ | ------------------------------------------------------------ | -------------------------------------------------- | ------------------------------------------------------------ |
| **定义**     | 拥有资源的基本单位                                           | 独立调度的基本单位                                 | 用户态的轻量级线程，线程内部调度的基本单位                   |
| 切换情况     | 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 | 保存和设置程序计数器、少量寄存器和栈的内容         | 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复         |
| 切换者       | 操作系统                                                     | 操作系统                                           | 用户                                                         |
| 切换过程     | 用户态->内核态->用户态                                       | 用户态->内核态->用户态                             | 用户态(没有陷入内核)                                         |
| 调用栈       | 内核栈和用户栈                                               | 内核栈和用户栈                                     | 用户栈                                                       |
| 拥有资源     | CPU资源、内存资源、文件资源和句柄等                          | 程序计数器、寄存器、栈和状态字                     | 拥有自己的寄存器上下文和栈                                   |
| 并发性       | 不同进程之间切换实现并发，各自占有CPU实现并行                | 一个进程内部的多个线程并发执行                     | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| **系统开销** | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 | 切换时只需保存和设置少量寄存器内容，因此开销很小   | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| **通信方面** | 进程间通信需要借助操作系统                                   | 线程间可以直接读写进程数据段(如全局变量)来进行通信 | 共享内存、消息队列                                           |

进程的执行体->线程，线程的执行体->协程。

每个**进程**拥有独立的**虚拟地址空间**，也就是有**独立的页表**，因此创建大量进程时会造成内存开销显著；操作系统进行进程调度时，需要**切换虚拟地址空间**，也就会切换页表。CPU 通过 MMU 将逻辑地址转到物理地址，为了减少访存次数设置了 TLB，而只有一个 TLB，因此进程切换会造成 TLB 失效，进而地址转换效率降低。而**线程切换不需要切换虚拟地址空间**，**因此出现线程**。

**多线程**下，进程拥有的资源是被所有线程共享的，但每个线程拥有**自己**的**内核数据结构**、**内核栈**和**用户栈**。为什么要分别拥有两个栈呢？对于内核来讲，所有用户代码都被视为不安全的，操作系统不允许用户态代码访问内核数据，线程进入内核态后执行的是内核提供的代码，若跟用户态共用一个栈就会留下安全漏洞(栈上数据可能会被用户程序非法读取)，因此要给内核态单独分配栈。

**线程切换**时，无需切换虚拟地址空间，也就无需切换页表，TLB 缓存也就不会失效，只需要切换自己拥有的寄存器和栈，因此性能显著提升。

**==为什么要有协程呢？==**

线程的切换，是抢占式的，依然需要操作系统参与，假如并发量不断增大，线程数量达到百万级别时需要大量线程，但是每个线程只需执行很短的时间片，这样的切换就显得很笨重。

也就是说，**一方面**，线程的内核数据结构、内核栈和用户栈会**占用大量内存**；**另一方面**，线程是**操作系统基于时间片策略**进行调度的，在如此庞大的线程数量下，为了尽量降低延迟，线程每次得以运行的**时间片会被压缩**，造成线程切换频率的大幅提高。线程切换过于频繁时，**调度会占用大量CPU资源**，造成性能下降。

问题明了：

- **要节省内存空间**，让主流服务器能轻松装载百万级的轻量线程；
- **要降低调度代价**，切换起来更加轻快。

**协程是通过主动让出的**，**调度无需通过操作系统**，而是由用户程序管理，这就降低了调度代价。**并且协程只有一个用户栈，一个线程的内存在MB级别，而协程只需要KB级别**，这就节省了内存空间。

| 任务抽象 |   上下文    |
| :------: | :---------: |
|   进程   |     PCB     |
|   线程   |     TCB     |
|   协程   | use-defined |

---

==**函数和协程的区别？**==

**函数可以看成一个特殊的协程**。函数的调用其实就是：

- 调用者主动让出CPU，创建函数栈帧，转而执行调用函数；
- `return`时再销毁被调函数栈帧，被调函数主动让出CPU；
- 返回继续执行调用者函数。

这个过程中，**只有函数调用时，被调函数才拥有CPU；只有函数结束时，被调函数才会主动让出**。但是，**协程可以多次拥有CPU、多次主动让出CPU**。这就是最大的区别。

> #### 问：线程之间共享的资源有哪些？

可以先分析一下，哪些资源是线程私有的：

- 栈
- 程序计数器
- 函数运行使用的寄存器
- 栈指针

以上可以统称为**线程上下文**。

那除此之外，其余的就应该是**共享的**了：

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/fduyofm926.png" alt="img" style="zoom:50%;" />

- **代码区**

线程之间共享代码区，**这就意味着程序中的任何一个函数都可以放到线程中去执行，不存在某个函数只能被特定线程执行的情况**。

- **数据区**

用来存储全局变量。**数据区中的全局变量有且仅有一个实例，所有的线程都可以访问到该全局变量**。

- **堆区**

**只要知道变量的地址，也就是指针，任何一个线程都可以访问指针指向的数据**，因此堆区也是线程共享的属于进程的资源。

- **栈区**

上边说了，栈区是私有的。但是！！！尽管是私有的，但如果一个线程拿到了另一个线程内部变量的地址，那么照样是可以修改它的！！！**理应是私有的，但没有什么保护措施，导致还算是共有的**。

- **动态链接库**

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/emf9tx3mjv.png" alt="img" style="zoom:67%;" />

> #### 问：为什么线程切换比进程切换快呢？

每个进程都拥有一个自己的**虚拟地址空间**，并且独立于其他进程的地址空间。**而进程切换会涉及到虚拟地址空间的切换**

**虚拟地址**转换为物理地址需要两个东西：**CPU 上的 MMU** 和 **内存中的页表**，为了减少访问内存的次数，设计了**快表**(页表缓存)。

由于**进程切换会涉及到虚拟地址空间的切换**，这就**导致内存中的页表也需要进行切换**，一个进程对应一个页表是不假，**但是 CPU 中的 TLB 只有一个**啊！页表切换后这个 TLB 就失效了。这样，TLB 在一段时间内肯定是无法被命中的，操作系统就必须去访问内存，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢。

而**线程切换不需要切换虚拟地址空间**，也就不存在这个问题了。

> #### 问：进程有哪些状态？

- **创建状态(new)**：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)**：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)**：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(waiting)**：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)**：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

---

以上为基础状态，但是**大量进程阻塞时，也会占用内存**，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。

所以需要新的状态-**挂起态**，来**描述进程没有占用实际的物理内存空间的情况**。

**挂起状态**可以分为两种：

- **阻塞挂起状态**：进程在外存（硬盘）并等待某个事件的出现；
- **就绪挂起状态**：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

> #### 问：进程间的通信方式？

- **管道**：管道的实质是一个内核**缓冲区**，进程以**先进先出**的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。**管道只能承载无格式字节流以及缓冲区大小受限**；
- **消息队列**：消息队列是**消息的链表**，**具有特定的格式**，存放在内存中并由消息队列标识符标识。**消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，并且**存在用户态与内核态之间的数据拷贝开销**因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程；
- **共享内存**：使得**多个进程可以访问同一块内存空间**，不同进程可以及时看到对方进程中对共享内存中数据的更新。**这种方式需要依靠某种同步操作，如互斥锁和信号量等。**可以说这是**最有用的进程间通信方式**。
- **信号量**：信号量是一个计数器，用于多进程对共享数据的访问，**信号量的意图在于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。
  - 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
  - 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程。

- **信号**：信号是Linux系统中用于进程间互相通信或者操作的一种**异步通信机制**，信号可以**在任何时候**发给某一进程，而无需知道该进程的状态。(**和信号量完全没关系！！**)。比如：
  - `Ctrl+C`产生`Sigint`信号，表示终止进程；
  - `kill pid`终止进程。

- **套接字**：主要用于在客户端和服务器之间**通过网络**进行通信。

> #### 问：进程调度算法有哪些？

- **先到先服务(FCFS)调度算法**：从就绪队列中，按照进入队列的顺序对线程分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法**：从就绪队列中，选出一个估计**运行时间最短**的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法**：时间片轮转调度是一种最古老，最简单，**最公平且使用最广**的算法，又称 RR(Round robin)调度。**每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。**
  - 时间片的长度如何设置？一般来说，时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。
    - 如果时间片设得**太短会导致过多的进程上下文切换**，降低了 CPU 效率；
    - 如果**设得太长又可能引起对短作业进程的响应时间变长**。

- **优先级调度**：**为每个进程分配优先级**，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。
- **多级反馈队列调度算法**：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

==详解**多级反馈队列调度算法**：==

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么**需要切换 100 次**。

多级队列是为这种需要连续执行多个时间片的进程考虑，它**设置了多个队列**，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。

这种方式下，之前的进程**只需要切换 7 次**。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是**时间片轮转调度算法**和**优先级调度算法**的结合。

![img](https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/202205220000527.png)

## 二、同步、锁

> #### 问：线程间的同步方式？

- **互斥锁(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。
- **信号量(Semaphore)**：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
- **事件(Event)**：Wait/Notify：通过**通知**的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

> #### 问：都有哪些锁？

- **互斥锁：**一次只能一个线程拥有互斥锁，其他线程只有等待，**加锁失败就让出CPU**；
- **自旋锁：**如果进/线程无法取得锁，进/线程**不会立刻放弃CPU时间片**，而是**一直循环尝试获取锁(忙等待)**，直到获取为止；
- **读写锁：**多个读者可同时获得，但写者互斥，若有写者，则读者必须等待；

**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**因为线程上下文切换的代价相比自旋锁来说也很大。

> #### 问：乐观锁与悲观锁是啥？

- **悲观锁：**互斥锁、自旋锁、读写锁都属于悲观锁。悲观锁做事比较悲观，它认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。
- **乐观锁：**乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作**。

乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**比如在线文档、Git等。

> #### 问：什么是死锁？

死锁：两个或多个线程由于相互等待对方占有的资源而永远被阻塞的情况。

> #### 问：产生死锁的四个必要条件？

- **互斥条件：**一个资源每次只能被一个进程使用。

- **请求与保持条件：**一个进程因请求资源而阻塞时，对已获得的资源保持不放。

- **不剥夺条件：**进程已获得的资源，在末使用完之前，不能被强行剥夺。

- **循环等待条件：**若干进程之间形成一种头尾相接的循环等待资源关系。

> #### 问：解决死锁的方法？

1. **预防：**采用某种策略，**限制并发进程对资源的请求**；

- 破坏**请求与保持**：进程必须在执行前就申请到它所需要的全部资源，并且直到它所要的资源都得到满足之后才开始执行；
- 破坏**循环等待**：所有的资源被分成了多个层次，一个进程得到某一层次的资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源；

2. **避免：**系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**：**银行家算法**。
3. **检测：**当死锁发生时，能够检测死锁的发生，并精确地确定与死锁有关的进程和资源；
4. **解除：**检测到死锁的进程，释放其持有的资源。

## 三、内存管理

操作系统的内存管理主要**负责内存的分配与回收**。

> #### 问：内存管理机制有哪些？

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。

- **连续分配管理**是指为一个用户程序分配一个连续的内存空间，常见的如**分区管理方式(块式管理)**。
- **非连续分配管理**允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1. **块式管理**：固定分区和动态分区。前者容易有内部碎片，后者有外部碎片。**过程：前者**将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块。**后者**按照进程大小划分块，按照首次适应算法分配。
2. **页式管理**：**把内存分为大小相等且固定的一页一页的形式**，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，**减少了碎片**。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理**：页式管理是从计算机角度出发设计的，对用户完全透明，而段式管理则是从用户角度出发设计的。**将进程的逻辑空间划分为代码段、数据段、栈段、堆段等**，段内的内存空间是连续的，段外的内存空间是不连续的。通过段表对应逻辑地址和物理地址。
4. **段页式管理**：段页式管理机制结合了段式管理和页式管理的优点。简单来说**段页式管理机制就是把主存先分成若干段，每个段又分成若干页。**每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号。

> #### 问：页式管理中，虚拟地址和物理地址怎么转换？

**页号**和**页内偏移**。

页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**。**基地址**与**页内偏移**的组合就形成了**物理内存**地址。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/7884f4d8db4949f7a5bb4bbd0f452609.png" alt="img" style="zoom: 50%;" />

> #### 问：多级页表有啥用？

把存储大量页表项的页表，再次分页。

引入多级页表的主要目的是为了避免把**全部页表项**一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于**时间换空间**的典型场景。

比如，32位系统，虚拟地址空间共有 4GB，假设一个页的大小是 4KB(2^12)，那么就有大约 1024 * 1024 (2^20) 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。**可以划分成二级页表**，第一级是1024个页表项，每个页表项对应一个页面，这个页面中又有1024个页表项，**这样的好处就是**：当查找时，首先通过一级页表找到二级页面，然后将指向的页面调入内存，然后找到页表项。也就是说内存中只需要存储用到的页面即可。这将大大减少需要调入内存的页表项总数。

如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= `0.804MB`，这对比单级页表的 `4MB` 是不是一个巨大的节约？

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230505220636912.png" alt="image-20230505220636912" style="zoom: 50%;" />

对于 64位系统，通常采用四级页表。

> #### 问：快表(TLB) 是啥？

**快表(TLB)：**将最常访问的**页表项**存储到访问速度更快的Cache中。

因为若把页表全部放入内存，存取一条数据至少要访问两次内存，第一次先访问页表找到数据对应的物理地址，第二次再从该地址存取数据。**对于多级页表，需要访问内存的次数会更多。**

而若命中快表，则**只需要一次访存**。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230505220934007.png" alt="image-20230505220934007" style="zoom: 40%;" />

> #### 问：段页式内存管理的实现？

- 先将**程序划分为多个有逻辑意义的段**：栈段、堆段、BSS段、数据段、代码段，也就是分段机制；
- 接着再把**每个段划分为多个页**，也就是对分段划分出来的连续空间，再划分固定大小的页；

地址结构就由**段号、段内页号和页内位移**三部分组成：

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/8904fb89ae0c49c4b0f2f7b5a0a7b099.png" alt="img" style="zoom: 50%;" />

段页式地址变换中要得到物理地址须经过**三次内存**访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

> #### 问：虚拟地址空间是啥？有啥用？

**虚拟地址空间**是程序中使用的内存地址，实际访问时通过 **`内存管理单元(MMU)`** 和 **内存中的页表** 转化为物理地址。==实际上并不存在。==

**每个进程都拥有一个自己的虚拟地址空间，并且独立于其他进程的地址空间**。虚拟地址空间**将不同进程的虚拟地址和不同内存的物理地址映射起来**。

**虚拟地址空间**主要是为了：

- **避免直接操作物理地址**。可能会对操作系统造成影响；
- **不同进程使用的虚拟地址彼此隔离**。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存；
- **易移植性**。可以屏蔽操作系统物理地址的差别。
- 可以使用一系列**相邻**的虚拟地址来访问物理内存中**不相邻**的大内存缓冲区。

> #### 问：虚拟内存是啥？虚拟内存管理有啥用？

**虚拟内存**是一种逻辑上扩充物理内存的技术，就是将硬盘的一部分作为内存来使用。==是实际存在的。==

---

虚拟内存技术基于一个非常重要的原理，**局部性原理**：

1）**时间局部性**：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环）

2）**空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的）

基于这个局部性原理：

- 在一个程序装入内存的时候，可以只将这个程序中**很快会用到的部分装入内存**，暂时用不到的部分仍然留在外存（磁盘），并且程序可以正常执行；
- 而在程序执行过程中，当 CPU 所需要的信息不在内存中的时候，由操作系统负责将所需信息从外存（磁盘）**调入内存**，然后继续执行程序；
- 如果调入内存的时候内存空间不够，由操作系统负责将内存中**暂时用不到的信息换出到外存**。

---

**虚拟内存管理**主要是为了：

- 逻辑上扩大实际的物理内存。(就这一个)

> #### 问：虚拟内存的技术实现？页面置换算法有哪些？

- **请求分页管理**（页式虚存系统）
- **请求分段管理**（段式虚存系统）
- **请求段页式管理**（段页式虚存系统）

以**请求分页管理**为例：**请求掉页、缺页中断、页面置换**。

- 在程序执行过程中，当所访问的页不在内存时，会产生一个**缺页中断**，操作系统将内存中缺失的页面从磁盘**调入内存**；

  - 若此时有空闲的块，就调入空闲的块；
  - 若无空闲的块，就需要先淘汰掉某页。

- 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到磁盘（操作系统要提供**页面置换**的功能， 将暂时用不到的页面换出磁盘）。

  - **FIFO 算法**，先入先淘汰；
  - **LRU 算法**，效率很高，但实现复杂；
  - **Clock 算法**，效率近似 LRU，但实现简单点

  **改进型的 CLOCK 算法**步骤如下：

  **两个标志位：**访问位和修改位

  1. 从指针的当前位置开始，扫描循环队列。**在这次扫描过程中，对访问位不做任何修改**。选择遇到的第一个是第 0 类 “未被访问，未被修改 (Referenced bit = 0，Modified bit = 0)” 的页面用于替换
2. 如果第 1 步失败，则重新扫描，查找第一个是 “未被访问，被修改 (Referenced bit = 0，Modified bit = 1)” 的页面用于替换。**在这次扫描过程中，对每个跳过的页面，和简单的 CLOCK 算法一样，把它的访问位设置成 0**
  3. 如果第 2 步失败，指针将回到它的最初位置，并且集合中所有页面的访问位都已经被设置为 0 了。重复第 1 步，并且如果有必要，重复第 2 步。这样一定可以找到供替换的页面。


## 四、文件系统（未）



## 五、网络系统

### 网络请求处理

黑马视频 redis 最后。

#### 阻塞IO (Bloking IO)

先讲讲**阻塞 IO** 的数据接收流程：

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230404220247663.png" alt="image-20230404220247663" style="zoom:50%;" />

1. 服务端进程 A 通过 socket() 函数**陷入内核态**进行 socket 系统调用，该内核函数会创建 **socket 内核对象**，包含两个重要数据结构：**等待队列**和**接收队列**。
   - 等待队列：存放服务端进程A的**进程描述符**和**回调函数**；
   - 接收队列：存放网卡接收到的该 socket **要处理的数据**。
2. 进程 A 调用 recv() 函数接收数据，会进入到 **recvfrom() 系统调用函数**，发现 socket 的**接收队列**没有它要接收的数据到达时，**进程 A 会让出 CPU，进入阻塞状态，**进程 A 的进程描述符和它被唤醒用到的回调函数 callback func 会组成一个结构体，称为**等待队列项**，放入 socket 的**等待队列**；
3. 客户端的发送数据到达服务端的网卡；
4. 网卡首先会将网络传输过来的数据通过 DMA 控制程序复制到**内存**环形缓冲区 RingBuffer 中；
5. 网卡向 CPU 发出**硬中断**；
6. CPU 收到了硬中断后，为了避免过度占用 CPU 处理网络设备请求导致其他设备如鼠标和键盘的消息无法被处理，会调用网络驱动注册的中断处理函数，进行简单快速处理后向内核中断进程 ksoftirqd 发出**软中断**，就释放 CPU，由软中断进程处理复杂耗时的网络设备请求逻辑；
7. **内核中断进程 ksoftirqd** 收到软中断信号后，会将网卡复制到内存的数据，根据数据报文的 IP 和端口号，将其**拷贝到对应 socket 的接收队列**；
8. 并通过进程等待队列中的回调函数，**唤醒**要处理该数据的进程 A，进程 A 会进入 CPU 的运行队列，等待获取 CPU 执行数据处理逻辑；
9. 进程 A 获取 CPU 后，会回到之前调用 **recvfrom() 函数**时阻塞的位置继续执行，这时发现 socket 内核空间的等待队列上有数据，会**在内核态**将内核空间的 socket 等待队列的数据**拷贝到用户空间**，然后才会**回到用户态**执行进程的用户程序，从而真的解除阻塞。

---

**==阻塞 IO 模型==**如下：

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230404221521244.png" alt="image-20230404221521244" style="zoom:50%;" />

**会出现的问题：**

1. 进程在 recv 的时候大概率会被阻塞掉，导致**第一次进程切换**；
2. 当数据到达服务端的网卡、并**从网卡复制到内核空间** socket 的数据接收队列时，进程会被唤醒，**第二次进程切换**。此时还需要将数据**从内核态复制到用户态**，也就是**数据复制会出现两次**；
3. **一个进程同时只能等待一条连接**，如果有很多并发，则需要很多进程。

**总结：**一次数据到达会进行**两次进程切换，**一次数据读取有**两次阻塞**(出现在**两次等待数据拷贝**时)，**单进程只能对单连接**。

#### 非阻塞IO (Nonbloking IO)

非阻塞的 Recv() 的效果是：如果没有**数据从网卡到达内核 socket 的等待队列**时，**系统调用会直接返回，而不是阻塞的等待**。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230405111128201.png" alt="image-20230405111128201" style="zoom:50%;" />

也就是说，**非阻塞 IO**，只是将**等待数据从网卡到达 socket 内核空间这一部分变成了非阻塞的**：

- 用户进程调用 recvfrom() 会**重复**发送请求检查数据是否到达内核空间(**CPU忙等待**)，如果没有到，则立即返回，**重复这个过程**，不会阻塞。
- 当数据已经到达内核空间的 socket 的等待队列后，**用户进程依然要等待 recvfrom() 函数将数据从内核空间拷贝到用户空间**，才会从 recvfrom() 系统调用函数中返回。

**总结：**非阻塞 IO 模型将“**两处阻塞**”变成了“**一处阻塞**”，但依然存在“**两次进程切换，一处阻塞，单进程对单连接**”的问题。

==花里胡哨的，没什么用，数据没来还不停的问，有什么用？==

maybe 类似自旋锁的作用？

#### IO多路复用 (IO Multiplexing)

IO 多路复用可以解决“**两次进程切换，单进程对单连接**”的问题。

通过一个进程处理多个 TCP 连接，只处理有数据到达的连接。当然，如果要监听的所有连接都没有数据到达，进程还是会进入阻塞状态，直到某个连接有数据到达时被回调函数唤醒。

==问题就在于**如何发现哪个连接的数据到达了？**==

### 详解select、poll、epoll

先说明几个重要的概念：

- **文件描述符 fd**：是一个从 0 开始的非负整数，**进程使用文件描述符来标识一个打开的文件**。Linux 中一切皆文件。系统为每个进程维护了一个**文件描述符表**，**表示该进程打开文件的记录表**，文件描述符实际就是这张表中的索引。
- **文件描述符集 fd_set：**select 函数参数中的 fd_set 类型表示文件描述符的集合，fd_set 的每一位来表示一个文件描述符。比如，当 select 返回 fd_set = 00010011 时，表示文件描述符 1、2、5 已经就绪。
- **Socket**：用于不同进程间的通信。**操作系统将 Socket 映射到进程的一个文件描述符上**，进程就可以通过读写这个文件描述符来进行通信。**通过 Socket 通信，实际上就是通过文件描述符 fd 读写文件**。

**IO 多路复用**：利用**单个进程**来**同时监听多个 fd**，并**在某个 fd 可读、可写时得到通知**，从而避免无效的等待。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230412221118984.png" alt="image-20230412221118984" style="zoom:50%;" />

#### select

**select 实现多路复用的方式**：将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写，接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

所以，对于 select 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里，而且还会发生 **2 次「拷贝」文件描述符集合**，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

看个例子：

1. 服务器进程 A 启动的时候，要监听的连接的 socket 文件描述符是 3、4、5；
2. 如果这三个连接**均没有数据到达网卡**，则进程 A 会让出 CPU，**进入阻塞状态**；同时会将**进程 A 的进程描述符**和被唤醒时用到的**回调函数**组成等待队列项**加入到 socket 对象 3、4、5 的进程等待队列**中。注意，**select 调用时**，fdsr 文件描述符集**会从用户空间拷贝到内核空间**；

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230405145858134.png" alt="image-20230405145858134" style="zoom:50%;" />

3. 当**网卡接收到数据**，然后网卡通过中断信号通知 CPU 有数据到达，执行中断程序，**中断程序主要做了两件事**：

- 将网络数据**写入到对应 socket 的数据接收队列**里面；
- **唤醒队列中的等待进程 A**，重新将进程 A 放入 CPU 的运行队列中；

4. 假设连接 3、5 有数据到达网卡，注意，这时 **select 调用结束时**，fdsr 文件描述符集**会从内核空间拷贝到用户空间**：
5. 进程 A 需要**遍历 fd_set**，获取就绪的文件描述符。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230405150454268.png" alt="image-20230405150454268" style="zoom:50%;" />

**select 的缺点：**

- **性能开销大**
  - 调用 select 时会陷入内核，这时需要将参数中的 fd_set 从**用户空间拷贝到内核空间**；select 执行完后，还需要将 fd_set 从**内核空间拷贝回用户空间**，高并发场景下这样的拷贝会消耗极大资源；（epoll 优化为不拷贝）
  - 进程被唤醒后，不知道哪些连接已就绪，**需要遍历**拷贝过来的 fd_set 的每一位；（epoll 优化为异步事件通知）
- **同时能监听的文件描述符太少**
  - **受限于 sizeof(fd_set) 的大小**，在编译内核时就确定了且无法更改。一般是 32 位操作系统是 1024，64 位是 2048。（poll、epoll 优化为适应链表方式）

#### poll

和 select 类似，**只是描述 fd 集合的方式不同**：poll 使用 pollfd 结构而非 select 的 fd_set 结构。

**基于链表存储，无最大数量限制**，因此解决了 select 的第二个缺点。

#### epoll

epoll 是对 select 和 poll 的巨大改进：

- 解决了 **select 中 fd_set 不断重复拷贝到内核**的问题：使用**红黑树**在内核中存储**一份**文件描述符集合，**每个文件描述符只需在添加时传入内核一次**，无需每次都重新传入；
- 通过**事件**的发生触发**回调函数**，存储就绪的文件描述符列表，而不是通过轮询的方式；
- **使用队列存储就绪的文件描述符**，且会按需返回就绪的文件描述符，**无须再次遍历**。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230413175430874.png" alt="image-20230413175430874" style="zoom:33%;" />

**主要涉及3个函数：**

```c
// 创建一个 eventpoll 内核对象
int epoll_create(int size);  

// 将连接的socket对象添加到 eventpoll 对象中，epoll_event是要监听的事件
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);

// 等待连接 socket 的数据是否到达
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

##### epoll_create

epoll_create 函数会创建一个**内核对象 eventpoll**，把它关联到当前进程的已打开文件列表中。主要包含3个成员：

```c
struct eventpoll {
    struct rb_root rbr;        // 红黑树，管理用户进程下添加进来的所有 socket 连接
 	struct list_head rdllist;  // 数据就绪的文件描述符都会放到这里
    wait_queue_head_t wq;      // 等待队列链表，存放阻塞的进程
        ......
}
```

- rbr：一棵红黑树，管理**所有要监听的 socket 连接**，增删改的时间复杂度是 `O(logn)`；
- rdllist：**就绪的描述符的链表**。当某个 socket 注册事件触发时，通过注册的回调函数将就绪的 socket 放到 rdllist 链表里；
- wq：等待队列，如当前进程要等待数据，就会把**当前进程描述符**和**回调函数**构造成一个**等待队列项**，放入当前 wq 等待队列。

##### epoll_ctl

epoll_ctl 函数有三个功能：**增、删、改**。主要负责**把 socket 连接注册到 eventpoll 对象里**，会做三件事：

- 创建一个 epitem 对象，主要包含两个字段：socket 的文件描述符、所属的 eventpoll 对象的指针；
- 将一个数据到达时用到的**回调函数**添加到 socket 的**进程等待队列**中；
- 将第 1 步创建的 epitem 对象**插入**红黑树。

##### epoll_wait

- 当 eventpoll 监控的 socket 对象有数据到达时，会通过 socket 进程等待队列中的**回调函数**唤醒红黑树中的节点 epitem，并将其添加到**就绪队列 rdllist** 中；
- 检查 eventpoll 对象的进程等待队列上是否有等待项，通过**回调函数**唤醒这个进程，进行数据的处理；
- 进程唤醒后，把 rdllist 中**就绪的事件列表**拷贝到用户空间。

> #### 问：I/O 多路复用是啥？有啥用？实现原理？:star:

IO多路复用是一种同步的IO模型。这里的I/O通常指网络I/O，也指Socket通信。

可以实现**多个请求复用一个进程**。利用IO多路复用模型，**可以实现一个线程监视多个文件句柄**；一旦某个文件句柄就绪，就能够通知到对应应用程序进行相应的读写操作；没有文件句柄就绪时就会**阻塞应用程序**，从而释放出CPU资源。

有三种实现方式：

- **select：**首先将所有的socket都放到一组**文件描述符**中，然后调入**内核**，内核通过**轮询**检查是否有网络事件发生。

  - 若检查到事件发生，就将**整组文件描述符**调入**用户态**，然后用户程序**再次轮询**，对有事件发生的进行处理。
  - 这种方式，一共**轮询两次**，并且需要**两次拷贝文件描述符**。并且有数量限制，1024个；

- **poll：**和`select`没啥区别，只不过没有数量限制，因为改成了**用链表存储**。

- ==**epoll：**==

  - epoll 在**内核**里使用**「红黑树」**来关注进程所有**待检测的事件**。红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。epoll 因为在内核维护了红黑树，可以保存所有待检测的事件，不需要像 select/poll 在每次操作时都传入整个事件集合，只需要传入**一个**待检测的事件，减少了内核和用户空间大量的数据拷贝和内存分配。
  - epoll 使用**事件驱动**的机制，内核里**维护了一个链表来记录就绪事件**，当某个 socket 有事件发生时，通过**回调函数**内核会将其加入到这个**就绪事件列表**中，当调用 `epoll_wait()` 函数时，**只会返回有事件发生的文件描述符**，m不需要像 select/poll 那样轮询扫描整个事件集合，大大提高了检测的效率。

  <img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/epoll.png" alt="img" style="zoom:50%;" />

**epoll 最大的优点是：**

- 避免了**轮询**所有的文件描述符，采用**回调函数**定向通知程序要处理的事件，大大提高了CPU执行效率。
- 在内核中**维护红黑树**，避免文件描述符集的拷贝过程。

#### 事件通知机制

> #### 问：epoll 支持哪几种事件通知机制？

epoll 支持两种事件触发模式，分别是**边缘触发(*ET*)**和**水平触发(*LT*)**。

- **LT**：当被监控的 FD 有数据可读时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，直至数据处理完成。**Epoll 的默认模式**。
- **ET**：当被监控的 FD 有数据可读时，**服务器端只会从 epoll_wait 中苏醒一次**，不管数据是否处理完成，因此要保证一次性将内核缓冲区的数据读取完；

**ET** 的效率要比 LT 高，但是实现起来比较复杂，因为**要保证一次读完所有的数据**，要注意采用**非阻塞的读取**，也就是读不到数据了也返回，不然会一直阻塞在这里等待数据。

LT 可能会有**惊群现象**。

#### 基于 epoll 的服务端模型

Redis 就跟这个类似。

![image-20230414163402528](https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414163402528.png)

## 六、Linux

#### 查看进程

```bash
ps aux | grep 进程名
ps -ef | grep 进程名
```

`ps aux` 和 `ps -ef` 命令都可以用于显示当前系统中运行的进程列表，但它们的输出格式略有不同。

- `ps aux` 命令的输出格式是以用户为主导的，它显示了所有进程的详细信息，包括进程的用户、进程 ID、CPU 占用率、内存占用率等。其中，`a` 选项表示显示所有进程，`u` 选项表示显示详细信息，`x` 选项表示同时显示没有控制终端的进程。

- `ps -ef` 命令的输出格式是以进程为主导的，它显示了所有进程的简要信息，包括进程的用户、进程 ID、父进程 ID、启动时间、命令等。其中，`e` 选项表示显示所有进程，`f` 选项表示显示进程的详细信息，包括父进程 ID、进程状态等。

因此，`ps aux` 输出的信息比 `ps -ef` 更详细，但也更复杂，而 `ps -ef` 输出的信息则更为简洁。在实际使用中，可以根据自己的需要选择使用哪个命令。

#### 查看 socket

```bash
$ netstat
$ ss	# 推荐
```

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414194118907.png" alt="image-20230414194118907" style="zoom:50%;" />

输出的内容都差不多，都包含了 socket 的状态（*State*）、接收队列（*Recv-Q*）、发送队列（*Send-Q*）、本地地址（*Local Address*）、远端地址（*Foreign Address*）、进程 PID 和进程名称（*PID/Program name*）等。

**接收队列（*Recv-Q*）**和**发送队列（*Send-Q*）**比较特殊，在不同的 socket 状态。它们表示的含义是不同的。

当 socket 状态处于 `Established`时：

- ***Recv-Q*** 表示 socket **接收缓冲区**中还没有被应用程序读取的字节数；
- ***Send-Q*** 表示 socket 发送缓冲区中还没有被远端主机确认的字节数；

而当 socket 状态处于 `Listen` 时：

- *Recv-Q* 表示全连接队列的长度；
- *Send-Q* 表示全连接队列的最大长度；

#### 日志分析

用一个大概几万条记录的 nginx **日志文件** `access.log` 作为案例，看看如何分析出「用户信息」。

##### 准备工作

**查看日志文件的大小**：

```bash
$ ls -lh 日志名
```

如果日志文件大小非常大，最好不要在线上环境做，下面的 `access.log`就只有 6.5 MB：

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414194931567.png" alt="image-20230414194931567" style="zoom:50%;" />

如果日志量太大，**`cat`命令会非常影响性能**，导致性能抖动；最好先用`scp`命令将日志文件传输到闲置的服务器再分析。

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414195124270.png" alt="image-20230414195124270" style="zoom:50%;" />

##### 慎用`cat`

`cat`读取文件时，文件中有多少数据，它就读多少，**不适用于大文件**。**应使用`less`命令读取大文件的内容**，因为 `less` 并不会加载整个文件，而是**按需加载**：先是输出一小页的内容，当要往下看的时候，才会继续加载。

若要看日志最新的内容，**应使用`tail`命令**：

```bash
$ tail -n 5 access.log   # 查看 access.log 最新的 5 条数据
$ tail -f  				 # 实时查看日志
```

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414200617101.png" alt="image-20230414200617101" style="zoom:50%;" />

##### PV 分析

**PV(Page View)：指页面的访问量(点击次数)**。比如大多数博客平台，点击一次页面，阅读量就加 1，所以说 PV 的数量并不代表真实的用户数量，只是**点击量**。

分析 PV 比较容易，因为**有多少行日志记录就有多少 PV**，可以使用：

```bash
$ wc -l access.log	# 输出 access.log 有多少行
49903 access.log
```

##### PV 分组

根据**访问时间**进行分组，比如按天分组，得到每天的访问量。根据日志记录的格式，时间在第 4 列，可以利用`awk`构造过滤语句：

```bash
$ awk '{print $4}' access.log
```

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414201039734.png" alt="image-20230414201039734" style="zoom:50%;" />

但包含了时分秒，**进一步过滤出年月日**，使用`awk`的`substr`，从第 2 个字符开始，截取 11 个字符：

```bash
$ awk '{print substr($4, 2, 11)}' access.log
```

但没排序，**进一步排序**，使用`sort`，然后使用`uniq -c`进行统计：

```bash
$ awk '{print substr($4, 2, 11)}' access.log | sort | uniq -c
```

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414201442555.png" alt="image-20230414201442555" style="zoom:50%;" />

注意，**使用 `uniq -c` 命令前，先要进行 `sort` 排序**，因为 uniq 去重的原理是比较相邻的行，然后除去第二行和该行的后续副本。

##### UV 分析

**UV(Uniq Visitor)：指访问人数**。比如公众号的阅读量就是以 UV 统计的，不管单个用户点击了多少次，最终**只算 1 次阅读量**。

`access.log`中没有用户信息，可以用 `IP`地址 近似统计：

```bash
$ awk '{print $1}' access.log | sort | uniq | wc -l
```

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414201840781.png" alt="image-20230414201840781" style="zoom:50%;" />

该命令的输出结果是 2589，也就说明 UV 的量为 2589。

- `awk '{print $1}' access.log`，取日志的第 1 列内容，客户端的 IP 地址正是第 1 列；
- `sort`，对信息排序；
- `uniq`，去除重复的记录；
- `wc -l`，查看记录条数；

##### UV 分组

**按天分组**分析每天的 UV 数量。命令较多，分开来看：

1. 过滤出 「日期 + IP地址」

```bash
$ awk '{print substr($4, 2, 11) " " $1}' access.log | sort | uniq 
```

- `awk` 将第 4 列的日期和第 1 列的客户端 IP 地址过滤出来，并用空格拼接起来；
- `sort` 对 `awk` 输出的内容进行排序；
- 接着用 `uniq` 去除重复的记录，也就说 `日期 IP` 相同的行就只保留一个；

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414202528091.png" alt="image-20230414202528091" style="zoom:50%;" />

2. 统计次数，在上述命令后拼接：`awk '{uv[$1]++;next}END{for (day in uv) print day, uv[day]}'`

```bash
$ awk '{print substr($4, 2, 11) " " $1}' access.log | sort | uniq | awk '{uv[$1]++;next}END{for (day in uv) print day, uv[day]}'
```

- `awk` 本身是「逐行」进行处理的，当执行完一行后，我们可以用 `next` 关键字来告诉 `awk` 跳转到下一行，把下一行作为输入；

- 对每一行输入，`awk` 会根据第 1 列的字符串(也就是日期)进行累加，这样相同日期的 ip 地址，就会累加起来，作为当天的 uv 数量；

- 之后的 `END` 关键字代表一个触发器，就是当前面的输入全部完成后，才会执行 `END {}` 中的语句，通过 for 遍历 uv 中所有的 key，打印出按天分组的 uv 数量。

##### 终端类型分析

`access.log` 日志最末尾关于 `User Agent` 的信息，主要是客户端访问服务器使用的工具：手机、浏览器等。

可利用这些信息，分析不同终端类型分别有多少。

User Agent 的信息在日志里的第 12 列

```bash
$ awk '{print $12}' access.log | sort | uniq -c | sort -rn
```

- `awk` 过滤出第 12 列的内容；
- `sort` 排序；
- `uniq -c` 去重并统计；
- `sort -rn`(*r 表示逆向排序， n 表示按数值排序*)，对统计的结果排序

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414204531299.png" alt="image-20230414204531299" style="zoom:50%;" />

##### 分析 TOP3 请求

获取到访问路径最频繁的 TOP3。

```bash
$ awk '{print $7}' access.log | sort | uniq -c | sort -rn | head -n 3
```

<img src="https://chuyu-typora.oss-cn-hangzhou.aliyuncs.com/image/image-20230414204939468.png" alt="image-20230414204939468" style="zoom:50%;" />


[{"categories":["面试","项目"],"content":"[toc] ","date":"2023-08-01","objectID":"/trlab/:0:0","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"一、智能问答系统 背景：传统站内搜索系统基于关键字匹配，在面向：特定领域知识库、技术图谱、产品说明、企业/学校生活指南等业务场景时，缺少对用户问题理解和答案二次处理能力。 大语言模型（Large Language Model, LLM）通过其对自然语言理解和生成的能力，可以猜测用户意图，并对原始知识点进行提炼、汇总、整合，进而生成更贴切的答案。 现有的大语言模型如 ChatGPT， 知识库仅覆盖至 2021 年 9 月前的信息，无法参考训练数据集未包含的信息及之后出现的新信息。 本文探索通过 LLM，打造 特定领域知识（Domain-specific Knowledge）问答系统🤖。 ","date":"2023-08-01","objectID":"/trlab/:1:0","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"1.1 需求分析 在 Web 端，实现一个可以在特定领域与用户对话的智能问答系统🤖。具体需求分析如下： graph ss(智能问答系统) --\u003e 中英文问答 ss --\u003e 特定领域 ss --\u003e 支持上下文 ss --\u003e 避免编造答案 通过问答的形式，和用户交互，同时支持中文和英文； 问题的回答需要参考站内提供的特定领域的原始信息； 支持上下文。用户的问题可能与历史会话相关，需要从历史回答提取上下文； 回答准确。ChatGPT 很擅长在不擅长的领域“表现”的很擅长，要尽量避免这种情况！ 由于 LLM 无法参考预训练数据集之外的数据，因此实现上述需求的关键就在于：如何向 LLM 反馈特定领域的知识库。 ","date":"2023-08-01","objectID":"/trlab/:1:1","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"1.2 方案分析 通过调研，业界主流的方案有两种。 Fine-Tunning💰👍 Fine-Tunning：对开源的 LLM 进行全面或部分的微调，采用 fine-tune 或者 LoRA 技术。业界已经不少 chatgpt 的平替方案都支持微调，比如： 清华大学于 2023.03 提出的 ChatGLM 支持中英双语，具有 62 亿参数，可以在消费级显卡上部署，INT4 量化级别下最低只需要 6GB 显存。 Alpaca 是在 Meta 提出的 LLaMA 7B 模型基础上微调的结果。原生的 Alpaca 对中文的支持并不好，不过已经业界也做了些扩充中文词表的开源方案。 优点： 能使 LLM “彻底记住”特定的领域知识，从而在拥有特定知识背景的条件下进交流； 采用私有部署，适合用于一些尚未公开的公司内部知识，不会造成信息泄露。 缺点： 资源消耗非常大。消耗的资源量虽然相对大模型预训练减少，但还是不容小觑的。比如 Alpaca 的微调，据作者介绍他们使用 8 个 显存 80GB A100 ，花费了 3 个小时。如果领域支持频繁更新，且需要需要较高的实时性，显然是无法满足要求的。 需要构建特定预训练语料库。高质量训练数据集的构建需要精心设计，开销也是不容忽视的。 微调的结果不一定符合预期。 Embedding⭐ Embedding：通过嵌入模型，将特定知识转化为向量 Embedding，然后将这些向量存入相应的向量数据库中。在查询阶段，通过相似度查询，匹配出关联的 topK 结果，然后将这些结果提供给 LLM，生成相应的答案。 优点： 成本低； 优秀的正确度和精确度； 缺点： 可能存在数据泄露的风险； 可嵌入的文本有长度限制，可能会有丢失部分上下文的风险。 Model Maximum text length gpt-3.5-turbo 4,096(~5 pages) gpt-4 8,192(~10 pages) gpt-4-32k 32,768(~40 pages) 参考链接： Question answering using embeddings-based search ","date":"2023-08-01","objectID":"/trlab/:1:2","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"1.3 整体流程 准备领域知识库（每个文档需要一次） 收集文本信息：通过指定数据源获取原始文本信息； 分块（Chunk）：根据 Token 限制，将长文本拆分成短文本； 嵌入（Embedding）：通过 OpenAI API 获取每块文本的嵌入信息 Embedding； 存储：将 Embedding 保存在向量数据库，推荐使用Milvus。 搜索（每次查询需要一次） 给定一个用户查询请求，通过 OpenAI API 生成该问题对应的 Embedding； 从向量数据库中查询与该问题对应 Embedding 最相似的 TopN 个文本，并按照相似度排序； 询问（每次查询需要一次） 将前置背景信息、历史问答、查询问题、相似文本插入到一个 Complection 发送给 ChatGPT； 返回 ChatGPT 的回答并进行处理。 ","date":"2023-08-01","objectID":"/trlab/:1:3","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"1.4 关键实现 以下功能均通过 Go 实现。 ","date":"2023-08-01","objectID":"/trlab/:1:4","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"准备知识库 获取原始信息 这里的文本来源主要是：https://trlab.com/ 可以通过 Go 的爬虫框架 Colly 写一个简易的脚本，爬取文章和 FAQS。此处直接从接口获取： func CrawArticles(url string, object any) { c := colly.NewCollector() c.OnRequest(func(r *colly.Request) { fmt.Println(\"Visiting\", r.URL) }) c.OnResponse(func(response *colly.Response) { if err := json.Unmarshal(response.Body, object); err != nil { logger.ZapLogger.Error(err.Error()) return } }) c.Visit(url) } CrawArticles() 参数为一个接口地址 url 和接收对象 object，会将获取的信息按照 object 格式进行解析。 Tokenizer Token：LLM 理解语言的基本单元，通过将文本分解为 Token 来理解和处理文本。单词和 Token 不是一一对应的，比如 goodness 就由good、ness 两个 Token 组成。中文通常先转换为 Unicode 或 UTF-8 编码，再转换成 Token。 Tokenizer：分词器，将文本分成一个个词元，保证各个词元拥有相对完整和独立的语义，以供后续任务比如 Embedding 使用。此处选用Tiktoken，有多种编码方法可选，如：r50k_base，p50k_base，cl100k_base 等。面向 OpenAI 的 gpt-4，gpt-3.5-turbo 和 text-embedding-ada-002 模型通常使用 cl100k_base 编码方法。 了解文本中的 Token 数量，既可以告诉你字符串是否太长而超出了模型处理能力，也可以查看 OpenAI 的 API 费用（按照token计费）。 OpenAI 官方提供了一个在线分词工具，根据工具提供的分词结果看，1 个中文词语会分解为 2/3 个 Token。 OpenAI 按照 token 数目收费，并且每个 embedding-model 和 gpt-model 对 token 数目都有限制，超出部分会被截断。注意：长度是指通过 Tokenizer 计算出的 token长度，而非文本字符串的长度。 比如 text-embedding-ada-002 采用的 cl100k_base 的 max token 为 8191，而 gpt-3.5-turbo 单次询问的 max token 为 4096。 EMBEDDING MODEL TOKENIZER MAX INPUT TOKENS OUTPUT DIMENSIONS text-embedding-ada-002 cl100k_base 8191 1536 GPT MODEL MAX TOKENS gpt-3.5-turbo 4,096 tokens (~5 pages) gpt-3.5-turbo-16k 16,384 tokens（~20 pages） gpt-4 8,192 tokens (~10 pages) gpt-4-32k 32,768 tokens (~40 pages) 官方文档提供了 Python 计算 Token 的方法，此处提供 Go 的版本： // CountMessagesTokens based on \"How_to_count_tokens_with_tiktoken.ipynb\" func CountMessagesTokens(model string, messages ...openai.ChatCompletionMessage) (numTokens int) { tkm, err := tiktoken.EncodingForModel(model) if err != nil { err = fmt.Errorf(\"encoding for model: %v\", err) log.Println(err) return } var tokensPerMessage, tokensPerName int switch model { case \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k-0613\", \"gpt-4-0314\", \"gpt-4-32k-0314\", \"gpt-4-0613\", \"gpt-4-32k-0613\": tokensPerMessage = 3 tokensPerName = 1 case \"gpt-3.5-turbo-0301\": tokensPerMessage = 4 // every message follows \u003c|start|\u003e{role/name}\\n{content}\u003c|end|\u003e\\n tokensPerName = -1 // if there's a name, the role is omitted default: if strings.Contains(model, \"gpt-3.5-turbo\") { //logger.ZapLogger.Warn(\"warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\") return CountMessagesTokens(\"gpt-3.5-turbo-0613\", messages...) } else if strings.Contains(model, \"gpt-4\") { //logger.ZapLogger.Warn(\"warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\") return CountMessagesTokens(\"gpt-4-0613\", messages...) } else { err = fmt.Errorf(\"num_tokens_from_messages() is not implemented for model %s. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\", model) logger.ZapLogger.Error(err.Error()) return } } for _, message := range messages { numTokens += tokensPerMessage numTokens += len(tkm.Encode(message.Content, nil, nil)) numTokens += len(tkm.Encode(message.Role, nil, nil)) numTokens += len(tkm.Encode(message.Name, nil, nil)) if message.Name != \"\" { numTokens += tokensPerName } } numTokens += 3 // every reply is primed with \u003c|start|\u003eassistant\u003c|message|\u003e return numTokens } 安全分片 安全分片：将原始知识库拆分为若干个独立、较短的知识点⭐每个知识点会作为问答的最小记录，与问题进行匹配。 分片时有如下可参考的原则： 原始内容在编写、组织时最好原子化、正交化。对于树状结构的知识点，可以按层级关系表示，最好不要混为一谈。比如倚天剑可能基础属性，也有适合的打法，偏向的英雄天赋，那么三者应该独立描述，而不要混杂在一起； 可以在原始语料中设计明确的分片标记，简化处理过程； 基本的分片方式，粒度从细到粗可以使用：标点符号、段落、章节等。分片粒度过细，知识点会比较零碎影响了相互间的关系；分片粒度过粗，在匹配时可能会携带冗余信息，另外对 Embedding、处理、索引的效率也有影响。 分片要使用 Tokenizer，原始文本经过分词然后再进行 Embedding，分片大小需要考虑分词之后生成的 Token 数量。基本目标是：分片不能破坏知识点的完整性，生成的分片对应的 Token 数量应该在预设范围内，不要过小或过大。 此处按照限制的 Token 最大长度，切割 string 类型的文本信息： // ChunkedTokens encodes a string into tokens and then breaks it up into chunks func ChunkedTokens(text string, model string, chunkLength int) [][]int { if chunkLength \u003c 1 { logger.ZapLogger.Error(\"chunkLength must be at least one\") return nil } return Batched(","date":"2023-08-01","objectID":"/trlab/:1:5","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"1.5 应用效果 前置文本 Question Who is the President of the United States? Compare the GC of Java and Go. When will Apple release new products? 知识库 Question What is a secondary market? What is NFT? What is rhizome? What are the steps to purchase an NFT artwork? 中英文 Question What are the steps to purchase an NFT artwork? 购买一个 NFT 艺术品有哪些步骤？ 回答格式 TRLab is a platform for discovering and collecting NFT (Non-Fungible Token) art from the world’s leading artists. They aim to elevate the NFT landscape by showcasing NFT art from renowned artists and exclusive collaborations. TRLab has a strong curatorial mission and leverages its connections with the art world to provide a platform for artists, collectors, and art lovers to engage with NFT art.\\n\\nThe team at TRLab believes in the long-lasting potential of NFTs to fundamentally change art ownership, collecting, royalties, and provenance. They offer a robust transaction platform, a production studio to assist artists in creating digital and NFT works of art, a concierge team to assist collectors, and a social community to engage art enthusiasts [1].\\n\\nThe name \"TRLab\" comes from \"Tabula Rasa,\" a Latin expression meaning \"blank slate.\" It signifies that everyone is born as a blank slate, free of judgment. TRLab sees NFTs as a blank slate where the value is given by the creator, and they aim to be at the forefront of the evolution of the creative industries in the information age [1].\\n\\nThe founding members of TRLab include Dragonfly Capital, Xin Li-Cohen (Non-executive Deputy Chairman of Christie’s), and the founders of Rockbund Art Museum, Artsy, and ART021 [1].\\n\\nTRLab has also collaborated with artists and authors to create unique NFT projects, such as the collaboration with authors Stanley Qiufan Chen and Kai-Fu Lee for the release of their book \"AI 2041: Ten Visions For Our Future\" [3] and the collaboration with David Ariew and Tatler China for the release of the magazine cover featuring an NFT artwork [4].\\n\\nOverall, TRLab aims to redefine the NFT art space and provide a platform for artists and collectors to engage with and explore the potential of NFTs in the art world. ","date":"2023-08-01","objectID":"/trlab/:1:6","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"1.6 改进方向 对于文本分片，有可能出现语义丢失现象，比如： 小明的爱好有很多，\u003cfont color = “blue\"\u003e比如：乒乓球，羽毛球，跑步。 如果问题是“小明的爱好？”，那么就无法匹配到。 需要调研与 LLM 对应的语义分片工具，在尽可能保证句子语义完整的前提下根据 ChunkSize 进行分片，比如按照完整语义进行回溯。 对不同语种的支持，由于材料是英文，无法通过已有接口进行不同语种间的相似度匹配。 上下文中，下文的文本匹配不会携带上文，Embedding 方式的缺陷，比如： Question What is rhizome? When was it created? 参考文章： openai-cookbook https://hackernoon.com/how-to-customize-an-openai-chatbot-with-embedding https://mp.weixin.qq.com/s/MpF9xBHYjgnCHNkFn1AsOA https://mp.weixin.qq.com/s/movaNCWjJGBaes6KxhpYpg ","date":"2023-08-01","objectID":"/trlab/:1:7","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"二、拼字游戏 ","date":"2023-08-01","objectID":"/trlab/:2:0","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"2.1 需求分析 类似于https://sculpture.co/game，实现拼字游戏。具体需求分析如下： graph id1(拼字游戏) id1 --\u003e 相邻字符串可拼接 id1 --\u003e 可包含空格 id1 --\u003e 不区分字符位置 id1 --\u003e 确保可拼接成原字符串 ","date":"2023-08-01","objectID":"/trlab/:2:1","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["面试","项目"],"content":"2.2 整体流程 将原始字符串 word 进行拆分 两种情况： 下一个字符不为 的字符，单独划分； 下一个字符为 的字符，合并下一个字符。 type WordGame struct { Word string WordParts []string } func NewWordGame(word string) *WordGame { wg := \u0026WordGame{Word: word} for i := 0; i \u003c len(wg.Word); i++ { if i \u003c len(wg.Word)-1 \u0026\u0026 wg.Word[i+1] == ' ' { wg.WordParts = append(wg.WordParts, wg.Word[i:i+2]) i++ // 跳过 ' ' } else { wg.WordParts = append(wg.WordParts, string(wg.Word[i])) } } return wg } 拼接字符串 该函数的参数为：currentIndex，currentPos，touchedIndex，touchedPos，分别代表选中字符串的下标，选中字符串的摆放位置，靠近字符串的下标，靠近字符串的摆放位置。 判断所选的两个字符串是否能拼接，主要就是看： 原字符串是否包含了拼接后的子串； 拼接完成后的 wordParts 是否还能拼接回原字符串，这是为了避免相同字符串的影响。 第一步相当于剪枝，因为第二步通过回溯，时间复杂度较高。 func (wg *WordGame) TryConnect(currentIndex, currentPos, touchedIndex, touchedPos int) { // 判断输入是否合法 if currentIndex == touchedIndex || currentIndex \u003c 0 || touchedIndex \u003c 0 || currentIndex \u003e= len(wg.WordParts) || touchedIndex \u003e= len(wg.WordParts) || currentPos^touchedPos \u003e= 0 { fmt.Println(\"invalid input\") return } // 设置拼接字符串的位置 var leftPart, rightPart string if currentPos \u003e 0 { leftPart, rightPart = wg.WordParts[currentIndex], wg.WordParts[touchedIndex] } else { leftPart, rightPart = wg.WordParts[touchedIndex], wg.WordParts[currentIndex] } // 判断是否可以拼接 temp := wg.WordParts[currentIndex] wg.WordParts[currentIndex] = leftPart + rightPart // 此处交换是为了节省内存和时间，否则需要重新开辟 Slice 并拷贝原数据 wg.WordParts[touchedIndex], wg.WordParts[len(wg.WordParts)-1] = wg.WordParts[len(wg.WordParts)-1], wg.WordParts[touchedIndex] // 首先判断是否含有拼接成的字符串(剪枝)，然后判断拼接之后的 wordParts 是否还可以组成 word ok := strings.Contains(wg.Word, wg.WordParts[currentIndex]) \u0026\u0026 isValid(wg.Word, wg.WordParts[:len(wg.WordParts)-1]) wg.WordParts[touchedIndex], wg.WordParts[len(wg.WordParts)-1] = wg.WordParts[len(wg.WordParts)-1], wg.WordParts[touchedIndex] if ok { // 若可以拼接，则删除原来的两个字符串，添加新的字符串 wg.WordParts = append(wg.WordParts[:touchedIndex], wg.WordParts[touchedIndex+1:]...) fmt.Println(\"combine success\") } else { // 若不可以拼接，则恢复原来的字符串 wg.WordParts[currentIndex] = temp fmt.Println(\"combine failed\") } // 打印当前的 wordParts wg.printWordParts() } 判断拼接后的 wordParts 是否能拼接成原字符串： // 判断 wordParts 是否可以组成 word func isValid(s string, wordParts []string) bool { var backTrack func(s string, start int) bool backTrack = func(s string, start int) bool { // 匹配完毕 if s == \"\" { return true } flag := false for i := start; i \u003c len(wordParts); i++ { // 回溯 if strings.HasPrefix(s, wordParts[i]) { // 当前子串是 s 的前缀 // 此处交换是为了递归时重复使用子串 wordParts[i], wordParts[start] = wordParts[start], wordParts[i] flag = backTrack(s[len(wordParts[start]):], start+1) wordParts[i], wordParts[start] = wordParts[start], wordParts[i] } // 若成立，则直接返回 if flag { break } } return flag } return backTrack(s, 0) } 测试 单元测试： 测试用例满足需求分析中的要求。随机生成要操作的下标，检测是否可以拼接回原字符串。 func TestWordGame_TryConnect(t *testing.T) { tests := []struct { name string word string }{ {\"friendship\", \"friendship\"}, {\"ababab\", \"ababab\"}, {\"testwordgame\", \"testwordgame\"}, {\"test blank word\", \"test blank word\"}, {\"pairs and nicole\", \"pairs and nicole\"}, {\"hello world\", \"hello world\"}, {\"ababa abb aab\", \"ababa abb aab\"}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { wg := NewWordGame(tt.word) cnt := 0 for len(wg.WordParts) \u003e 1 \u0026\u0026 cnt \u003c= 1000 { cnt++ currentIndex, touchedIndex := rand.Intn(len(wg.WordParts)), rand.Intn(len(wg.WordParts)) fmt.Println(\"currentIndex:\", currentIndex, \"touchedIndex:\", touchedIndex) wg.TryConnect(currentIndex, 1, touchedIndex, -1) // 默认位置 } require.Equal(t, wg.Word, wg.WordParts[0]) }) } } 性能测试： 随机生成长度为 n 的字符串，每 5 个字符插入一个 ，观察随字符串长度上升，对性能的影响。 注意：测试时，避免打印日志，否则频繁地 IO 会严重降低效率。 func BenchmarkWordGame_TryConnect(b *testing.B) { for i := 0; i \u003c b.N; i++ { wg := NewWordGame(randomString(30)) cnt := 0 for len(wg.WordParts) \u003e 1 \u0026\u0026 cnt \u003c= 1000 { cnt++ currentIndex, touchedIndex := rand.Intn(len(wg.WordParts)), rand.Intn(len(wg.WordParts)) wg.TryConnect(currentIndex, 1, touchedIndex, -1) } } } const letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" func randomString(n int) string { b := make([]byte, n) for","date":"2023-08-01","objectID":"/trlab/:2:2","tags":["实习","项目","ChatGPT"],"title":"实习-Trlab","uri":"/trlab/"},{"categories":["关于"],"content":" Name Chuyu Education Southeast University Research Direction Blockchain \u0026 Golang QQ 1205667742 Mail jyzhangis12@gmail.com Phone +86 15237174980 ","date":"2023-07-27","objectID":"/about/about/:0:0","tags":["关于"],"title":"About Me","uri":"/about/about/"},{"categories":["通用"],"content":"[toc] ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:0:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"一、基本流程 拉取最新代码——创建分支——提交分支至云端——分支代码完成后查看状态——将代码添加至暂存区——本地提交代码——推送至云端——切换为主分支——合并子分支代码——推送至云端——删除分支 ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:1:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"二、执行命令 在主分支拉取最新代码：git pull 基于主分支创建并且切换到新的子分支（没有这个分支就会新建）：git checkout -b 分支名 先把新的子分支推送到云端仓库，因为此时云端没有这个分支。如果有则忽略此步骤：git push -u origin 分支名 然后创建对应文件，开始写代码 将修改过的文件全部添加到暂存区：git add . 将代码保存到本地仓库：git commit -m \"完成了分类功能开发\" 将本地代码推送到云端：git push 切换到主分支：git checkout master 拉取最新代码：git pull 如果上一步骤存在更新，则进行变基操作即处理冲突（第四步），如果没有，则进行下一步 切换到主分支，合并代码：git merge 分支名 把主分支推送到云端: git push 删除本地的分支：git branch -d 分支名 删除云端的分支：git push origin --delete 分支名 ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:2:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"三、常用 git 命令 初始化一个 git 仓库：git init 查看状态：git status 添加所有修改：git add -A 提交修改：git commit -m \"提交说明\" 查看提交历史，按字母 q(uit) 退出：git log 查看没 add 的不同：git diff(erence) 查看本地分支：git branch 查看所有分支：git branch -a 删除未合并代码分支：git branch -D 分支名 拉取本地不存在的远程分支：git checkout -b 本地分支名 origin/远程分支名 与远程仓库关联：git remote add origin 地址 ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:3:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"四、解决冲突 pre-1: 在基准分支（主分支）上接取最新的代码 git pull pre-2: 切换到自己的分支上 git checkout 分支名 git rebase dev 解决冲突（需要和团队之间商量） git add -A git rebase --continue 重复 2，3，4 直到 reabase 完成,会出现 applying 字样 有可能本地自己的分支和远程分支还有冲突，这时候需要 git pull origin qh/home 之后，解决冲突再 push 即可 ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:4:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"五、git 的语义化 commit chore：add Oyster build script（其他修改, 比如构建流程, 依赖管理） docs：explain hat wobble（更改文档） feat：add beta sequence（新增了一个功能） fix：remove broken confirmation message（修复了一个 bug） refactor：share logic between 4d3d3d3 and flarhgunnstow（代码重构，既不修复错误也不添加功能） style：convert tabs to spaces（不影响代码含义的变化（空白、格式化、缺少分号等，注意不是 css 修改）） test：ensure Tayne retains clothing（测试用例修改） ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:5:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"六、git merge 和 git rebase 的区别 ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:6:0","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"merge merge 特点：⾃动创建⼀个新的 commit 如果合并的时候遇到冲突，仅需要修改后重新 commit 优点：记录了真实的 commit 情况，包括每个分⽀的详情 缺点：因为每次 merge 会⾃动产⽣⼀个 merge commit，所以在使⽤⼀些 git 的 GUI tools，特别是 commit ⽐较频繁时，看到分支很杂乱。 ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:6:1","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"rebase rebase 特点：会合并之前的 commit 历史 优点：得到更简洁的项目历史，去掉了 merge commit 缺点：如果合并出现代码问题不容易定位，因为 re-write 了 history 总结：因此，当需要保留详细的合并信息的时候建议使⽤ git merge，特别是需要将分支合并进入 master 分支时；当发现自己修改某个功能时，频繁进⾏了 git commit 提交时，发现其实过多的提交信息没有必要时，可以尝试 git rebase. ","date":"2023-07-23","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:6:2","tags":["Git","计算机基础"],"title":"Git-代码冲突","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":["通用"],"content":"一、微服务 ","date":"2023-07-03","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:0","tags":["微服务"],"title":"微服务基础知识 ","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["通用"],"content":"1.1 微服务技术栈 先给出微服务的架构： 分类： ","date":"2023-07-03","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:1","tags":["微服务"],"title":"微服务基础知识 ","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["通用"],"content":"1.2 认识微服务 单体架构：将业务的所有功能集中在一个项目中开发，打包成一个部署。 优点：架构简单，部署成本低； 缺点：耦合度太高，不适合大型项目。 微服务架构的特征： 单一职责：微服务拆分的粒度更小，每一个服务都对应唯一的业务能力，做到单一职责，避免重复业务开发； 面向服务：微服务对外暴露业务接口，允许远程调用； 隔离性强：各服务做好隔离、容错、降级等，避免服务挂了对其他服务产生影响。 ","date":"2023-07-03","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:2","tags":["微服务"],"title":"微服务基础知识 ","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["通用"],"content":"二、gRPC ","date":"2023-07-03","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:0","tags":["微服务"],"title":"微服务基础知识 ","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["通用"],"content":"概述 gRPC 是谷歌推出的一个开源、高性能的 RPC 框架。默认情况下使用 protoBuf 进行序列化和反序列化，并基于 HTTP/2 传输报文，带来诸如多请求复用一个 TCP 连接(所谓的多路复用)、双向流、流控、头部压缩等特性。 在 gRPC 中，开发者可以像调用本地方法一样，通过 gRPC 的客户端调用远程机器上 gRPC 服务的方法。gRPC 客户端封装了 HTTP/2 协议数据帧的打包、以及网络层的通信细节，把复杂留给框架自己，把便捷提供给用户。 gRPC 基于这样的一个设计理念： 定义一个服务，及其被远程调用的方法(方法名称、入参、出参)，在 gRPC 服务端实现这个方法的业务逻辑，并在 gRPC 服务端处理来自远程客户端对这个 RPC 方法的调用； 在 gRPC 客户端也拥有这个 RPC 方法的存根(stub)。gRPC 的客户端和服务端都可以用任何支持 gRPC 的语言来实现，例如一个 gRPC 服务端可以是 C++ 语言编写的，以供 Ruby 语言的 gRPC 客户端和 JAVA 语言的 gRPC 客户端调用，如下图所示： gRPC 默认使用 ProtoBuf 对请求/响应进行序列化和反序列化，这使得传输的请求体和响应体比 JSON 等序列化方式包体更小、更轻量。 gRPC 基于 HTTP/2 协议传输报文，HTTP/2 具有多路复用、头部压缩等特性，基于 HTTP/2 的帧设计，实现了多个请求复用一个 TCP 连接，基本解决了 HTTP/1.1 的队头阻塞问题，相对 HTTP/1.1 带来了巨大的性能提升。 ","date":"2023-07-03","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:1","tags":["微服务"],"title":"微服务基础知识 ","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["通用"],"content":"协议格式 gRPC 基于 HTTP/2/协议进行通信，使用 ProtoBuf 序列化与反序列化，gRPC 的协议格式如下图： gRPC 协议在 HTTP 协议的基础上，对 HTTP/2 的帧的**有效包体(Frame Payload)**做了进一步编码：gRPC 包头(5 字节)+gRPC 变长包头，其中： 5 字节的 gRPC 包头：1 字节的压缩标志(compress flag) 和 4 字节的 gRPC 包头长度； gRPC 包体长度是变长的，是一串二进制流：使用指定序列化方式(通常是 ProtoBuf)序列化成字节流，再使用指定的压缩算法对序列化的字节流压缩而成的。如果对序列化字节流进行了压缩，gRPC 包头的压缩标志为 1。 ","date":"2023-07-03","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:2","tags":["微服务"],"title":"微服务基础知识 ","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":["通用"],"content":" 前言：Protobuf 的编码是基于变种的 Base 128。因此，按照 Base 64 --\u003e Base 128 --\u003e Protobuf 的顺序来学习比较好~ 原文链接 ","date":"2023-06-21","objectID":"/13-protobuf/:0:0","tags":["序列化"],"title":"Protobuf浅析","uri":"/13-protobuf/"},{"categories":["通用"],"content":"一、Base 64 计算机之间传输数据时，数据本质上是一串字节流。由于不同机器采用的字符集不同等原因，我们并不能保证目标机器能够正确地“理解”字节流。 先看看 Base 64 如何工作，假设这里有 4 个字节，代表要传输的二进制数据： 首先将这个字节流按每 6 个 bit 为一组进行分组，剩下少于 6 bits 的低位补 0； 然后在每一组 6 bits 的高位补两个 0； 对照 Base 64 table，字节流可以用 ognC0w 来表示。另外，Base 64 编码是按照 6 bits 为一组进行编码，每 3 个字节的原始数据要用 4 个字节来储存，编码后的长度要为 4 的整数倍，不足 4 字节的部分要使用 pad 补齐，所以最终的编码结果为ognC0w==。 Base 64 编码之后所有字节均可以用数字、字母、+、/、= 进行表示，这些都是可以被正常显示的 ascii 字符，即**“安全”的字节**。绝大部分的计算机和操作系统都对 ascii 有着良好的支持，保证了编码之后的字节流能被正确地复制、传播、解析。 Base 64 存在的问题就是：编码后的每一个字节的最高两位总是 0，在不考虑 pad 的情况下，有效 bit 只占 bit 总数的 75%，造成大量的空间浪费。 ","date":"2023-06-21","objectID":"/13-protobuf/:1:0","tags":["序列化"],"title":"Protobuf浅析","uri":"/13-protobuf/"},{"categories":["通用"],"content":"二、Base 128 因此，Base 128 的大致实现思路是：将字节流按 7 bits 进行分组，然后低位补 0。 但问题来了，Base 64 实际上用了 2^6^+1 个 ascii 字符，按照这个思路 Base 128 需要使用 2^7^+1 个 ascii 个字符，但是 ascii 字符一共只有 128 个。另外，即使不考虑 pad，ascii 中包含了一些不可以正常打印的控制字符，编码之后的字符还可能包含会被不同操作系统转换的换行符号(10 和 13)。因此，Base 64 至今依然没有被 Base 128 替代。 ","date":"2023-06-21","objectID":"/13-protobuf/:2:0","tags":["序列化"],"title":"Protobuf浅析","uri":"/13-protobuf/"},{"categories":["通用"],"content":"三、Base 128 Varints Protocol Buffers 所用的编码方式就是 Base 128 Varints。(按照小端模式讨论) 编码/解码 对于编码后的每个字节，低 7 位用于储存数据，最高位用来标识当前字节是否是当前整数的最后一个字节，称为最高有效位（most significant bit, msb）。msb 为 1 时，代表着后面还有数据；msb 为 0 时代表着当前字节是当前整数的最后一个字节。 如何将使用 Base 128 Varints 对整数进行编码： 将数据按每 7 bits 一组拆分 逆序每一个组(因为小端) 添加 msb 如何将使用 Base 128 Varints 对整数进行解码： 去除 msb 将字节流逆序(msb 为 0 的字节储存原始数据的高位部分，小端模式) 最后拼接所有的 bits。 300 (0b 10 0101100)编码： 解码： protobuf 的 varints 最多可以编码 8 字节的数据，这是因为绝大部分的现代计算机最高支持处理 64 位的整型。 ","date":"2023-06-21","objectID":"/13-protobuf/:3:0","tags":["序列化"],"title":"Protobuf浅析","uri":"/13-protobuf/"},{"categories":["通用"],"content":"四、Protobuf Protocol Buffers 所用的编码方式就是 Base 128 Varints。(按照小端模式讨论) 数据类型 protobuf 支持的数据类型(wire type)： 当实际使用 protobuf 进行编码时，经过了两步处理： 将 编程语言的数据结构 转化为 wire type。 根据不同的 wire type 使用对应的方法编码。前文所提到的 Base 128 Varints 用来编码 varint 类型的数据，其他 wire type 则使用其他编码方式。 部分数据类型到 wire type 的转换规则： 有符号整型 采用 ZigZag 编码来将 sint32 和 sint64 转换为 wire type 0。下面是 ZigZag 编码的规则（注意是算术位移）： n * 2 // when n \u003e= 0 -n * 2 - 1 // when n \u003c 0 一些例子： 定长数据(64-bit) 直接采用小端模式储存，不作转换。 字符串 以字符串\"testing\"为例： 编码后的 value 分为两部分： 蓝色，表示字符串采用 UTF-8 编码后字节流的长度(bytes)，采用 Base 128 Varints 进行编码。 白色，字符串用 UTF-8 编码后的字节流。 消息结构 Protobuf 采用 proto3 作为 DSL 来描述其支持的消息结构。 syntax = \"proto3\"; message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; } 设想一下这样一个场景：数据的发送方在业务迭代之后需要在消息内携带更多的字段，而有的接收方并没有更新自己的 proto 文件。要保持较好的兼容性，接收方需要分辨出哪些字段是自己可以识别的，哪些是不能识别的新增字段。要做到这一点，发送方在编码消息时还必须附带每个字段的 key，客户端读取到未知的 key 时，可以直接跳过对应的 value。 proto3 中每一个字段后面都有一个 = x，比如： string query = 1; 这里的等号并不是用于赋值，而是给每一个字段指定一个 ID，称为 field number。消息内同一层次字段的 field number 必须各不相同。 上面所说的 key，在 protobuf 源码中被称为 tag。tag 由 field number 和 type 两部分组成： field number 左移 3 bits 在最低 3 bits 写入 wire type 一个生成 tag 的例子： Go 版本 Protobuf 中生成 tag 的源码： func EncodeTag(num Number, typ Type) uint64 { return uint64(num)\u003c\u003c3 | uint64(typ\u00267) } 源码中生成的 tag 是 uint64，代表着 field number 可以使用 61 个 bit 吗？并非如此。事实上，==tag 的长度不能超过 32 bits==，意味着 field number 的最大取值为 2^29^-1 (536870911)。而且在这个范围内，有一些数是不能被使用的： 0：protobuf 规定 field number 必须为正整数。 19000 到 19999： protobuf 仅供内部使用的保留位。 理解了生成 tag 的规则之后，不难得出以下结论： field number 不必从 1 开始，可以从合法范围内的任意数字开始。 不同字段间的 field number 不必连续，只要合法且不同即可。 当修改 proto 文件时，需要注意⭐： field number 一旦被分配了就不应该被更改，除非你能保证所有的接收方都能更新到最新的 proto 文件； 由于 tag 中不携带 field name 信息，更改 field name 并不会改变消息的结构。发送方认为的 apple 到接受方可能会被识别成 pear。双方把字段读取成哪个名字完全由双方自己的 proto 文件决定，只要字段的 wire type 和 field number 相同即可。 最后再来个复杂例子(能看明白就算会了~)： 嵌套消息 wire type 2不仅支持 string，也支持 embedded messages。 对于嵌套消息： 首先要将被嵌套的消息进行编码成字节流； 然后就可以像处理 UTF-8 编码的字符串一样处理这些字节流：在字节流前面加入使用 Base 128 Varints 编码的长度即可。 能看明白就是胜利！😉 字段顺序 Proto 文件中定义字段的顺序与最终编码结果的字段顺序无关，两者有可能相同也可能不同。 任何 Protobuf 的实现都应该保证字段以任意顺序编码的结果都能被解码。 安全性 由于 Protobuf 序列化后就是一堆字节流，需要有原 Proto 声明文件才能反序列化，因此也具备一定的保密性。 对比JSON、XML XML、JSON 更注重数据结构化，关注人类可读性和语义表达能力； ProtoBuf 更注重数据序列化，关注效率、空间、速度，人类可读性差，语义表达能力不足（为保证极致的效率，会舍弃一部分元信息） ProtoBuf 的应用场景更为明确，XML、JSON 的应用场景更为丰富。 ","date":"2023-06-21","objectID":"/13-protobuf/:4:0","tags":["序列化"],"title":"Protobuf浅析","uri":"/13-protobuf/"},{"categories":["通用"],"content":" 问：什么是 JWT ？ JWT（JSON Web Token）是目前最流行的跨域认证解决方案，是一种基于 Token 的认证授权机制。从 JWT 的全称可以看出，JWT 本身也是 Token，一种规范化之后的 JSON 结构的 Token。 JWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息。这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。 JWT 本质上就是一组字符串，通过（.）切分成三个为 Base64 编码的部分： Header：描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型； Payload：用来存放实际需要传递的数据； Signature（签名）：服务器通过 Payload、Header 和私钥（Secret）使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。 JWT 通常是这样的：xxxxx.yyyyy.zzzzz。 示例： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9. eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ. SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c 你可以在 jwt.ioopen in new window 这个网站上对其 JWT 进行解码，解码之后得到的就是 Header、Payload、Signature 这三部分。 问：如何基于 JWT 进行身份验证？ 在基于 JWT 进行身份验证的的应用程序中，服务器通过 Payload、Header 和 Secret（密钥） 创建 JWT 并将 JWT 发送给客户端。客户端接收到 JWT 之后，会将其保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。 两点建议： 建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。 请求服务端并携带 JWT 的常见做法是将其放在 HTTP Header 的 Authorization 字段中（Authorization: Bearer Token）。 问：如何提高 JWT 的安全性？ JWT 存放在 localStorage 中而不是 Cookie 中，避免 CSRF 风险； 一定不要将隐私信息存放在 Payload 当中，因为它不加密； JWT 的过期时间不易过长。 问：JWT 为啥不会有 CSRF 攻击漏洞？ 一般情况下我们使用 JWT 的话，在我们登录成功获得 JWT 之后，一般会选择存放在 localStorage 中。前端的每一个请求后续都会附带上这个 JWT，整个过程压根不会涉及到 Cookie。因此，即使你点击了非法链接发送了请求到服务端，这个非法请求也是不会携带 JWT 的，所以这个请求将是非法的。 总结来说就一句话：使用 JWT 进行身份验证不需要依赖 Cookie ，因此可以避免 CSRF 攻击。 但是 XSS 依然会有。 问：JWT 重放攻击怎么防御？ JWT 过期时间设置的短点； 增加时间戳机制，但时间同步是个问题； 客户端每次需要携带服务端分发的随机数，随机数的维护是个问题； 客户端与服务端商量流水号，落后的序号将被认定为重放攻击，分布式场景下序号同步是个问题。 ","date":"2023-06-19","objectID":"/12-jwt%E8%AE%A4%E8%AF%81/:0:0","tags":["身份认证"],"title":"JWT认证","uri":"/12-jwt%E8%AE%A4%E8%AF%81/"},{"categories":["面试"],"content":"[toc] ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:0:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"一、概述 问：如何理解高并发系统？ 所谓设计高并发系统，就是设计一个系统，保证它整体可用的同时，能够处理很高的并发用户请求，能够承受很大的流量冲击。 我们要设计高并发的系统，那就需要处理好一些常见的系统瓶颈问题，如内存不足、磁盘空间不足，连接数不够，网络宽带不够等等，以应对突发的流量洪峰。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"分而治之，横向扩展 单个服务器的缺点： 抗住的流量请求是非常有限； 有单点的风险，挂了就寄了。 因此，可以分而治之，横向扩展。即，采用分布式部署的方式，部署多台服务器，把流量分流开，让每个服务器都承担一部分的并发和流量，提升整体系统的并发能力。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:1","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"微服务拆分（系统拆分） 所谓的微服务拆分，其实就是把一个单体的应用，按功能单一性，拆分为多个服务模块，这样就可以达到分摊请求流量的目的，提高了并发能力。比如一个电商系统，拆分为用户系统、订单系统、商品系统等等。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:2","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"分库分表 考虑将单机数据库，拆分为多个数据库或表。 详情参考： 分库分表经典15连问 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:3","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"池化技术 请求调用数据库时，都会先获取数据库的连接，然后依靠这个连接来查询数据，搞完收工，最后关闭连接，释放资源。如果我们不用数据库连接池的话，每次执行SQL，都要创建连接和销毁连接，这就会导致每个查询请求都变得更慢了，相应的，系统处理用户请求的能力就降低了。 因此，需要使用池化技术，即数据库连接池、HTTP 连接池、Redis 连接池等等。使用数据库连接池，可以避免每次查询都新建连接，减少不必要的资源开销，通过复用连接池，提高系统处理高并发请求的能力。 同理，我们使用线程池，也能让任务并行处理，更高效地完成任务。 面试必备：Java线程池解析 细数线程池的10个坑 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:4","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"读写分离 通常来说，一台单机的MySQL服务器，可以支持500左右的TPS和10000左右的QPS，即单机支撑的请求访问是有限的。 当请求量非常大的时候，对于实时性要求不高的读请求，都去读从库，写的请求或者实时性要求高的请求，才走主库。 面试必备：聊聊MySQL的主从 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:5","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"使用缓存 内存操作，显然更快，能支撑更高的并发量。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:6","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"CDN 什么是CDN？ Content Delivery Network/Content Distribution Network，翻译过来就是内容分发网络，它表示将静态资源分发到位于多个地理位置机房的服务器，可以做到数据就近访问，加速了静态资源的访问速度，因此让系统更好处理正常别的动态请求。 商品图片，icon等等静态资源，可以对页面做静态化处理，减少访问服务端的请求。如果用户分布在全国各地，有的在上海，有的在深圳，地域相差很远，网速也各不相同。为了让用户最快访问到页面，可以使用CDN。CDN可以让用户就近获取所需内容。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:7","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"消息队列 异步、削峰、解耦 搞一些双十一、双十二等运营活动时，需要避免流量暴涨，打垮应用系统的风险。因此一般会引入消息队列，来应对高并发的场景。 假设你的应用系统每秒最多可以处理2k个请求，每秒却有5k的请求过来，可以引入消息队列，应用系统每秒从消息队列拉2k请求处理得了。 有些伙伴担心这样可能会出现消息积压的问题： 首先，搞一些运营活动，不会每时每刻都那么多请求过来你的系统（除非有人恶意攻击），高峰期过去后，积压的请求可以慢慢处理； 其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面； ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:8","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"ElasticSearch 一般搜索功能都会用到它，它是一个分布式、高扩展、高实时的搜索与数据分析引擎，简称为ES。ES可以扩容方便，天然支撑高并发。当数据量大的时候，不用动不动就加机器扩容，分库等等，可以考虑用ES来支持简单的查询搜索、统计类的操作。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:9","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"降级熔断 熔断降级是保护系统的一种手段。当前互联网系统一般都是分布式部署的，而分布式系统中偶尔会出现某个基础服务不可用，最终导致整个系统不可用的情况, 这种现象被称为服务雪崩效应。 比如分布式调用链路A-\u003eB-\u003eC....，下图所示： 如果服务C出现问题，比如是因为慢SQL导致调用缓慢，那将导致B也会延迟，从而A也会延迟。堵住的A请求会消耗占用系统的线程、IO、CPU等资源。当请求A的服务越来越多，占用计算机的资源也越来越多，最终会导致系统瓶颈出现，造成其他的请求同样不可用，最后导致业务系统崩溃。 为了应对服务雪崩, 常见的做法是熔断和降级。最简单是加开关控制，当下游系统出问题时，开关打开降级，不再调用下游系统。还可以选用开源组件Hystrix来支持。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:10","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"限流 如果你的系统每秒扛住的请求是一千，如果一秒钟来了十万请求呢？换个角度就是说，高并发的时候，流量洪峰来了，超过系统的承载能力，怎么办呢？ 这时候，我们可以采取限流方案。就是为了保护系统，多余的请求，直接丢弃。 什么是限流：在计算机网络中，限流就是控制网络接口发送或接收请求的速率，它可防止DoS攻击和限制Web爬虫。限流，也称流量控制。是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定性。 可以使用Guava的RateLimiter单机版限流，也可以使用Redis分布式限流，还可以使用阿里开源组件sentinel限流。 面试的时候，你说到限流这块的话？面试官很大概率会问你限流的算法：面试必备：4种经典限流算法讲解 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:11","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"二、数据库 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"池化 原因：数据库的调用方式是先获取数据库的连接，然后依靠这条连接从数据库中查询数据，最后关闭连接释放数据库资源。这种调用方式下，每次执行 SQL 都需要重新建立连接，而建立连接的耗时可能要比执行sql的耗时还要高，因此采用池化技术。 做法：数据库连接池有两个最重要的配置：最小连接数和最大连接数，它们控制着从连接池中获取连接的流程： 如果当前连接池中的连接数小于最小连接数，则创建新的连接； 如果连接池中有空闲连接则复用空闲连接； 如果空闲池中没有空闲连接并且当前连接数小于最大连接数，则创建新的连接处理请求； 如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间等待旧的连接可用； 如果等待超过了这个设定时间则向用户抛出错误。 总结： 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。 池子中的对象需要在使用之前预先初始化完成，叫做连接池预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:1","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"主从读写分离 原因：其实，大部分系统的访问模型是读多写少，读写请求量的差距可能达到几个数量级。读写分离主要用来解决查询请求增多的问题。 关键技术： 主从复制； 访问哪个数据库。可基于代理选择。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:2","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"分库分表 原因：读写分离主要解决读请求增多的问题，而分库分表解决写请求增多、存储变多的问题。 关键技术： 垂直分片：可以解决单库数据存储问题，同时，单库的数据量降低，也能提高数据查询的性能。 水平分片：解决单库或单表数据存储问题，同时，单库或单表的数据量降低，也能提高数据查询的性能。 当分库分表之后，同一个逻辑表的数据被分布到多个库中，这时如果使用数据库自增字段作为主键，那么只能保证在这个库中是唯一的，无法保证全局的唯一性。那么假如设计用户系统的时候，使用自增 ID 作为用户 ID，就可能出现两个用户有两个相同的 ID，这是不可接受的，那么就需要生成全局唯一的 ID。 UUID 不建议使用 UUID 作为数据库主键，因为： ID 有序更利于索引数据的插入，而 UUID 是无序的，造成了多余的数据移动的开销； UUID 不具备业务含义； UUID 是由 32 个 16 进制数字组成的字符串(128位)，如果作为数据库主键使用比较耗费空间。 ==雪花算法(Snowflake)== Snowflake 的核心思想是将 64 位的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。可以自定义各字段代表的含义和位数。 原理知道了，那工程上是怎么实现呢？ 一种是嵌入到业务代码里，也就是分布在业务服务器中。 一种是作为独立的服务部署，这也就是我们常说的发号器服务。 Snowflake 算法设计的非常简单且巧妙，性能上也足够高效，同时也能够生成具有全局唯一性、单调递增性和有业务含义的 ID，但是它也有一些缺点： 其中最大的缺点就是它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止； 另外，如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。 这一点，也是我在实际项目中踩过的坑，而解决办法主要有两个： 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均； 生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量的均衡了。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:3","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"NoSQL // TODO ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:4","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"三、缓存 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"概述 什么是缓存？ 凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。内存和缓存之间不能划等号。 常见硬件组件的延时情况： 可以看到，做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms，所以，使用内存作为缓存的存储介质相比于以磁盘作为主要存储介质的数据库来说，性能上会提高多个数量级，同时也能够支撑更高的并发量。 缓存分类 日常开发中，常见的缓存主要就是静态缓存、分布式缓存、热点本地缓存这三种。 静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。 例如，我们在做一些内容管理系统的时候，后台会录入很多的文章，前台在网站上展示文章内容，就像新浪，网易这种门户网站一样。解决思路是：每篇文章在录入的时候渲染成静态页面，放置在所有的前端 Nginx 或者 Squid 等 Web 服务器上，这样用户在访问的时候会优先访问 Web 服务器上的静态页面，在对旧的文章执行一定的清理策略后，依然可以保证 99% 以上的缓存命中率。 静态缓存只能针对静态数据来缓存，对于动态请求就无能为力了，针对动态请求做缓存就需要分布式缓存了。 分布式缓存最典型的就是 Redis 了。 当遇到极端的热点数据查询时，分布式缓存也扛不住了，就要考虑热点本地缓存了。 热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。 本地缓存方案，如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询。 比如，电商系统的首页有一些推荐的商品，请求量很大，可以使用 Guava Cache 来将所有的推荐商品的信息缓存起来，并且设置每隔 30 秒重新从数据库中加载最新的所有商品。这样，在获取所有商品信息的时候可以调用 Loading Cache 的 get 方法，就可以优先从本地缓存中获取商品信息，如果本地缓存不存在，会使用 CacheLoader 中的逻辑从数据库中加载所有的商品。 缺点就是有时效性，不能实时读到最新的数据。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:1","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"缓存一致性 旁路缓存策略。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:2","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"高可用 主要选择的方案有客户端方案、中间代理层方案和服务端方案三大类： 客户端方案：在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。 中间代理层方案：在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。 服务端方案：Redis 2.4 版本后提出的 Redis Sentinel 方案。 客户端方案⭐ 在客户端方案中，需要关注缓存的写和读两个方面： 写数据时，需要把被写入缓存的数据分散到多个节点中，即进行数据分片，通常采用一致性哈希； 读数据时，可以利用多组的缓存来做容错，提升缓存系统的可用性。关于读数据，这里可以使用主从和多副本两种策略，两种策略是为了解决不同的问题而提出的。 中间代理层方案 虽然客户端方案已经能解决大部分的问题，但是只能在单一语言系统之间复用。例如微博使用 Java 语言实现了这么一套逻辑，再使用 PHP 就难以复用，需要重新写一套，很麻烦。而中间代理层的方案就可以解决这个问题。 所有缓存的读写请求都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能。 服务端方案⭐ Redis 在 2.4 版本中提出了 Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题，它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性，整体的架构如下图所示： 缓存穿透及解决 回种空值； 布隆过滤器； 分布式锁。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:3","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"CDN 分布式缓存主要对动态请求数据做了加速，但是系统中还存在着大量的静态资源请求： 对于移动 APP 来说，静态资源主要是图片、视频和流媒体信息。 对于 Web 网站来说，则包括了 JavaScript 文件，CSS 文件，静态 HTML 文件等等。 问：是否也可以使用分布式缓存来解决这个问题呢？ 不能！ 一般来说，图片和视频的大小会在几兆到几百兆之间，如果我们的应用服务器和分布式缓存都部署在北京的机房里，这时一个杭州的用户要访问缓存中的一个视频，那这个视频文件就需要从北京传输到杭州，期间会经过多个公网骨干网络，延迟很高，会让用户感觉视频打开很慢，严重影响到用户的使用体验。 所以，静态资源访问的关键点是就近访问，即北京用户访问北京的数据，杭州用户访问杭州的数据，这样才可以达到性能的最优。 你可能会说：「那我们在杭州也自建一个机房，让用户访问杭州机房的数据就好了呀。」可用户遍布在全国各地，有些应用可能还有国外的用户，我们不可能在每个地域都自建机房，这样成本太高了。 另外，单个视频和图片等静态资源很大，并且访问量又极高，如果使用业务服务器和分布式缓存来承担这些流量，无论是对于内网还是外网的带宽都会是很大的考验。 所以考虑在业务服务器的上层，增加一层特殊的缓存，用来承担绝大部分对于静态资源的访问，这一层特殊缓存的节点需要遍布在全国各地，这样可以让用户选择最近的节点访问。缓存的命中率也需要一定的保证，尽量减少访问资源存储源站的请求数量（回源请求），也就是用 CDN。 关键技术 内容分发网络(CDN，Content Delivery Network/Content Distribution Network)：简单来说，CDN 就是将静态的资源分发到位于多个地理位置机房中的服务器上，因此它能很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。 要搭建一个 CDN 系统需要考虑哪两点： 如何将用户的请求映射到 CDN 节点上； 如何根据用户的地理位置信息选择到比较近的节点。 CNAME 首先，我们考虑一下如何让用户的请求到达 CDN 节点，你可能会觉得，这很简单啊，只需要告诉用户 CDN 节点的 IP 地址，然后请求这个 IP 地址上面部署的 CDN 服务就可以了啊。但是这样会有一个问题：就是我们使用的是第三方厂商的 CDN 服务，CDN 厂商会给我们一个 CDN 的节点 IP，比如说这个 IP 地址是「111.202.34.130」，那么我们的电商系统中的图片的地址很可能是这样的：「http://111.202.34.130/1.jpg」，这个地址是要存储在数据库中的。 那么如果这个节点 IP 发生了变更怎么办？或者我们如果更改了 CDN 厂商怎么办？是不是要修改所有的商品的 url 域名呢？这就是一个比较大的工作量了。所以，我们要做的事情是 将第三方厂商提供的 IP 隐藏起来，给到用户的最好是一个本公司域名的子域名。 问：那么如何做到这一点呢？这就需要依靠 DNS 来帮我们解决域名映射的问题了。 域名系统(DNS，Domain Name System)：实际上就是一个存储域名和 IP 地址对应关系的分布式数据库。而域名解析的结果一般有两种： 一种叫做 A 记录，返回的是域名对应的 IP 地址； 另一种是 CNAME 记录，返回的是另一个域名。 也就是说当前域名的解析要跳转到另一个域名的解析上，实际上 www.baidu.com 域名的解析结果就是一个 CNAME 记录，域名的解析被跳转到 www.a.shifen.com 上了，正是利用 CNAME 记录来解决域名映射问题的。 问：具体是怎么解决的呢？举个例子。 比如你的公司的一级域名叫做 example.com，那么你可以给你的图片服务的域名定义为 img.example.com，然后将这个域名的解析结果的 CNAME 配置到 CDN 提供的域名上。 比如 ucloud 可能会提供一个域名是 80f21f91.cdn.ucloud.com.cn 这个域名。这样你的电商系统使用的图片地址可以是 http://img.example.com/1.jpg。 用户在请求这个地址时，DNS 服务器会将域名解析到 80f21f91.cdn.ucloud.com.cn 域名上，然后再将这个域名解析为 CDN 的节点 IP，这样就可以得到 CDN 上面的资源数据了。 问：DNS 域名解析的时间可能会有点久，怎么办呢？ 一个解决的思路是：在 APP 启动时，对需要解析的域名做预先解析，然后把解析的结果缓存到本地的一个 LRU 缓存里面。这样当我们要使用这个域名的时候，只需要从缓存中直接拿到所需要的 IP 地址就好了，如果缓存中不存在才会走整个 DNS 查询的过程。同时，为了避免 DNS 解析结果的变更造成缓存内数据失效，我们可以启动一个定时器，定期地更新缓存中的数据。 GSLB 全局负载均衡(GSLB，Global Server Load Balance)：主要是对于部署在不同地域的服务器之间做负载均衡，底层可能管理了很多的本地负载均衡组件。它有两方面的作用： 一方面，它是一种负载均衡服务器。负载均衡，顾名思义嘛，指的是让流量平均分配使得下面管理的服务器的负载更平均； 另一方面，它还需要保证流量流经的服务器与流量源头在地缘上是比较接近的。 GSLB 可以通过多种策略，来保证返回的 CDN 节点和用户尽量保证在同一地缘区域： 比如说可以将用户的 IP 地址按照地理位置划分为若干的区域，然后将 CDN 节点对应到一个区域上，然后根据用户所在区域来返回合适的节点； 也可以通过发送数据包测量 RTT 的方式来决定返回哪一个节点。 有了 GSLB 之后，节点的解析过程变成了下图中的样子： 当然，是否能够从 CDN 节点上获取到资源还取决于 CDN 的同步延时。 一般，会通过 CDN 厂商的接口将静态的资源写入到某一个 CDN 节点上 ，再由 CDN 内部的同步机制将资源分散同步到每个 CDN 节点，即使 CDN 内部网络经过了优化，这个同步的过程是有延时的，一旦我们无法从选定的 CDN 节点上获取到数据，我们就不得不从源站获取数据，而用户网络到源站的网络可能会跨越多个主干网，这样不仅性能上有损耗，也会消耗源站的带宽，带来更高的研发成本。所以，我们在使用 CDN 的时候需要关注 CDN 的命中率和源站的带宽情况。 小结 DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上； DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间； GSLB 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:4","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"四、消息队列 上面一直关注的是如何提升读请求的性能，但随着业务发展，可能会遇到一些存在高并发写请求的场景，其中秒杀抢购就是最典型的场景。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"应用场景 高并发写请求-削峰 秒杀场景： 秒杀开始前，用户查询的是少量的商品数据，属于查询的热点数据，可以采用缓存策略，将请求尽量挡在上层的缓存中，能被静态化的数据，比如说商城里的图片和视频数据，尽量做到静态化，这样就可以命中 CDN 节点缓存，减少 Web 服务器的查询量和带宽负担。Web 服务器比如 Nginx 可以直接访问分布式缓存节点，这样可以避免请求到达 Tomcat 等业务服务器。 秒杀开始后，用户瞬间向电商系统请求生成订单，扣减库存，用户的这些写操作都是不经过缓存直达数据库的。1 秒钟之内，有 1 万个数据库连接同时达到，系统的数据库濒临崩溃，寻找能够应对如此高并发的写请求方案迫在眉睫。 在秒杀场景下，短时间之内数据库的写流量会很高，那么依照我们以前的思路应该对数据做分库分表。如果已经做了分库分表，那么就需要扩展更多的数据库来应对更高的写流量。但是无论是分库分表，还是扩充更多的数据库，都会比较复杂，原因是你需要将数据库中的数据做迁移，这个时间就要按天甚至按周来计算了。 而在秒杀场景下，高并发的写请求并不是持续的，也不是经常发生的，而只有在秒杀活动开始后的几秒或者十几秒时间内才会存在。为了应对这十几秒的瞬间写高峰，就要花费几天甚至几周的时间来扩容数据库，再在秒杀之后花费几天的时间来做缩容，这无疑是得不偿失的。 所以，解决思路是：将秒杀请求暂存在消息队列中，然后业务服务器会响应用户「秒杀结果正在计算中」，释放了系统资源之后再处理其它用户的请求。 我们会在后台启动若干个队列处理程序，消费消息队列中的消息，再执行校验库存、下单等逻辑。因为只有有限个队列处理线程在执行，所以落入后端数据库上的并发请求是有限的。而请求是可以在消息队列中被短暂地堆积，当库存被消耗完之后，消息队列中堆积的请求就可以被丢弃了。 这就是消息队列在秒杀系统中最主要的作用：削峰填谷。也就是说它可以削平短暂的流量高峰，虽说堆积会造成请求被短暂延迟处理，但是只要我们时刻监控消息队列中的堆积长度，在堆积量超过一定量时，增加队列处理机数量，来提升消息的处理能力就好了，而且秒杀的用户对于短暂延迟知晓秒杀的结果，也是有一定容忍度的。 比如秒杀商品有 1000 件，处理一次购买请求的时间是 500ms，那么总共就需要 500s 的时间。这时，你部署 10 个队列处理程序，那么秒杀请求的处理时间就是 50s，也就是说用户需要等待 50s 才可以看到秒杀的结果，这是可以接受的。这时会并发 10 个请求到达数据库，并不会对数据库造成很大的压力。 业务流程-异步 在刚才提到的秒杀场景下，我们在处理购买请求时，需要 500ms。这时，你分析了一下整个的购买流程，发现这里面会有主要的业务逻辑，也会有次要的业务逻辑：比如说，主要的流程是生成订单、扣减库存；次要的流程可能是我们在下单购买成功之后会给用户发放优惠券，会增加用户的积分。假如发放优惠券的耗时是 50ms，增加用户积分的耗时也是 50ms，那么如果我们将发放优惠券、增加积分的操作放在另外一个队列处理机中执行，那么整个流程就缩短到了 400ms，性能提升了 20%，处理这 1000 件商品的时间就变成了 400s。如果我们还是希望能在 50s 之内看到秒杀结果的话，只需要部署 8 个队列程序就好了。 经过将一些业务流程异步处理之后，我们的秒杀系统部署结构也会有所改变： 系统模块-解耦 比如数据团队对你说，在秒杀活动之后想要统计活动的数据，借此来分析活动商品的受欢迎程度、购买者人群的特点以及用户对于秒杀互动的满意程度等等指标。而我们需要将大量的数据发送给数据团队，那么要怎么做呢？ 一个思路是：可以使用 HTTP 或者 RPC 的方式来同步地调用，也就是数据团队这边提供一个接口，我们实时将秒杀的数据推送给它，但是这样调用会有两个问题： 整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。 当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。 这时，我们可以考虑使用消息队列降低业务系统和数据系统的直接耦合度。 秒杀系统产生一条购买数据后，我们可以先把全部数据发送给消息队列，然后数据团队再订阅这个消息队列的话题，这样它们就可以接收到数据，然后再做过滤和处理了。秒杀系统在这样解耦合之后，数据系统的故障就不会影响到秒杀系统了，同时，当数据系统需要新的字段时，只需要解析消息队列中的消息，拿到需要的数据就好了。 异步处理、解耦合和削峰填谷 是消息队列在秒杀系统设计中起到的主要作用，其中， 削峰填谷可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和，但会造成请求处理的延迟； 异步处理可以简化业务流程中的步骤，提升系统性能； 解耦合可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统，可以提升系统的鲁棒性。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:1","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"避免重复消费 避免消息丢失 如果要保证消息只被消费一次，首先就要保证消息不会丢失。 消息丢失主要存在三个场景： 消息从生产者写入到消息队列的过程。 消息在消息队列中的存储场景。 消息被消费者消费的过程。 消息生产的过程中丢失 主要原因：网络抖动，消息有可能因为网络的错误而丢失。 解决方案：消息重传。当你发现发送超时后你就将消息重新发一次，但是你也不能无限制地重传消息。一般来说，如果不是消息队列发生故障，或者是到消息队列的网络断开了，重试 2～3 次就可以了。 消息队列中丢失 主要原因：为了减少消息存储时对磁盘的随机 I/O，Kafka 可以配置当达到某一时间间隔，或者累积一定的消息数量的时候再刷盘，也就是所说的异步刷盘。 解决方案：考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。 具体实现：Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份。Follower 中有一个特殊的集合叫做 ISR，当 Leader 故障时，会从 ISR 中新选举出来 Leader。Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。 由于消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个选项叫做 acks，当这个选项被设置为 all 时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送成功。这样，只有 Leader 和所有的 ISR 都挂了，消息才会丢失。 建议是： 如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是需要使用集群的方式来解决，可以配置当所有 ISR Follower 都接收到消息才返回成功。 如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个 Follower 就可以返回成功了。 消费过程中消息丢失 主要原因：一个消费者消费消息的进度是记录在消息队列集群中的，而消费的过程分为三步：接收消息、处理消息、更新消费进度。接收消息和处理消息的过程都可能会发生异常或者失败，比如说，消息接收时网络发生抖动，导致消息并没有被正确的接收到；处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，那么这条失败的消息就永远不会被处理了，也可以认为是丢失了。 解决方案：一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，比方说某一条消息在处理之后，消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。 避免重复消费 为了避免消息丢失，需要付出两方面的代价：一方面是性能的损耗；一方面可能造成消息重复消费。性能损耗还能接受，但消息重复消费可能就会造成严重错误，那么如何避免呢？ Kafka 出现消息重复消费的原因： 根本原因：已经消费的数据没有成功提交 offset。 Kafka 侧由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。 想要完全的避免消息重复的发生是很难做到的，因为网络的抖动、机器的宕机和处理的异常都是比较难以避免的，在工业上并没有成熟的方法，因此我们会把要求放宽，只要保证即使消费到了重复的消息，从消费的最终结果来看和只消费一次是等同的就好了，也就是保证在消息的生产和消费的过程是幂等的。 注：**幂等**指只执行一次操作和多次执行同一个操作，最终得到的结果是相同的 问：Kafka 如何保证消息不被重复消费？/如何实现幂等性，设计去重机制？ 生产端： 思路：Kafka 支持将 Producer 升级为幂等性 Producer，保证消息虽然可能在生产端重复生产，但是最终在消息队列存储时只会存储一份。 具体做法：给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID，消息队列的服务端会存储 \u003c 生产者 ID，最后一条消息 ID\u003e 的映射。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致，如果一致，就认为是重复的消息，服务端会自动丢弃。 消费端： 思路：可分为通用层和业务层。 具体做法： 通用层：可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息 ID，消息被处理之后，把这个 ID 存储在数据库中，在处理下一条消息之前，先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费； 业务层：利用乐观锁的方式来实现。这个机制是在消息中添加一个版本号，在生产消息时先查询数据的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，执行时也带上版本号。比如在消费第一条消息时，version 值为 1，SQL 可以执行成功，并且同时把 version 值改为了 2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:2","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"消息延迟/堆积 如何监控消息延迟 监控消息的延迟有两种方式： 使用消息队列提供的工具，通过监控消息的堆积来完成； 通过生成监控消息的方式来监控消息的延迟情况。 监控消息的堆积 首先需要从原理上了解，在消息队列中消费者的消费进度是多少，因为这样才方便计算当前的消费延迟是多少。比方说，生产者向队列中一共生产了 1000 条消息，某一个消费者消费进度是 900 条，那么这个消费者的消费延迟就是 100 条消息。 在 Kafka 中，消费者的消费进度在不同的版本上是不同的。 在 Kafka0.9 之前的版本中，消费进度是存储在 ZooKeeper 中的，消费者在消费消息的时候，先要从 ZooKeeper 中获取最新的消费进度，再从这个进度的基础上消费后面的消息。 在 Kafka0.9 版本之后，消费进度被迁入到 Kakfa 的一个专门的 topic 叫 __consumer_offsets 里面。 Kafka 也提供了一些工具来获取这个消费进度的信息，帮助实现自己的监控，比较推荐 JMX。Kafka 通过 JMX 暴露了消息堆积的数据，我在本地启动了一个 console consumer，然后使用 jconsole 连接这个 consumer，你就可以看到这个 consumer 的堆积数据了。 生成监控消息 具体做法： 先定义一种特殊的消息； 然后启动一个监控程序，将这个消息定时地循环写入到消息队列中。消息的内容可以是生成消息的时间戳，并且也会作为队列的消费者消费数据； 业务处理程序消费到这个消息时直接丢弃掉，而监控程序在消费到这个消息时，就可以和这个消息的生成时间做比较，如果时间差达到某一个阈值就可以向我们报警。 减少消息延迟 减少消息的处理延迟，需要在消费端和消息队列两个层面来完成。 消费端： 增加消费者的数量 在 Kafka 中，Topic 的 Partition 数量决定了消费的并行度，增加多余的消费者也是没用的。这是因为 Kafka 约定一个 Partition 只能被一个消费者消费。 优化消费代码 可以在 consumer 中提升处理消息的并行度，所以可以考虑使用多线程的方式来增加处理能力：你可以预先创建一个或者多个线程池，在接收到消息之后，把消息丢到线程池中来异步地处理，这样，原本串行的消费消息的流程就变成了并行的消费，可以提高消息消费的吞吐量，在并行处理的前提下，我们就可以在一次和消息队列的交互中多拉取几条数据，然后分配给多个线程来处理。 消息队列： 零拷贝 传统数据文件拷贝 操作系统将数据从磁盘拷贝到内核缓冲区； 应用程序通过系统调用将内核缓存区的数据拷贝到用户缓冲区； 应用程序将用户缓冲区的数据拷贝到内核的 Socket 缓冲区中； 操作系统将 Socket 缓冲区的数据拷贝到网卡缓冲区中，通过网卡发送给数据接收方。 总结：涉及 1 次内核态到用户态的数据拷贝和 1 次 用户态到内核态的数据拷贝。 零拷贝 操作系统提供了 Sendfile 函数，可以减少数据被拷贝的次数。使用了 Sendfile 之后，在内核缓冲区的数据不会被拷贝到用户缓冲区，而是直接被拷贝到 Socket 缓冲区，节省了一次拷贝的过程，提升了消息发送的性能。 操作系统将数据从磁盘拷贝到内核缓冲区； 系统调用 Sendfile 将数据的文件描述符直接被拷贝到 Socket 缓冲区(仅仅会拷贝一个描述符过去，不会拷贝数据到 Socket 缓存)； 操作系统将 Socket 缓冲区的数据拷贝到网卡缓冲区中，通过网卡发送给数据接收方。 总结：省略了两次不必要的数据拷贝： 从内核空间拷贝到用户空间； 从用户空间再次拷贝到内核空间。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:3","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"五、微服务 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"概述 为什么要使用微服务架构？ 一体化架构增加了研发的成本，抑制了研发效率的提升。 《人月神话》中曾经提到：一个团队内部沟通成本，和人员数量 n 有关，约等于 n(n-1)/2，也就是说随着团队人员的增加，沟通的成本呈指数级增长，一个 100 人的团队，需要沟通的渠道大概是 100（100-1）/2 = 4950。那么为了减少沟通成本，我们一般会把团队拆分成若干个小团队，每个小团队 5～7 人，负责一部分功能模块的开发和维护。 按照亚马逊 CEO，贝佐斯的「两个披萨」的理论，如果两个披萨不够你的团队吃，那么你的团队就太大了，需要拆分，所以一个小团队包括开发、运维、测试以 6～8 个人为最佳； 有的研发同学会认为最快的方式，不是询问其他团队是否有现成的，而是自己写一套，但是这种想法是不合适的，这样一来就会造成功能服务的重复开发。 由于代码部署在一起，每个人都向同一个代码库提交代码，代码冲突无法避免；同时，功能之间耦合严重，可能你只是更改了很小的逻辑，却导致其它功能不可用，从而在测试时需要对整体功能回归，延长了交付时间。 模块之间互相依赖，一个小团队中的成员犯了一个错误，就可能会影响到，其它团队维护的服务，对于整体系统稳定性影响很大。 一体化架构对于系统的运维也会有很大的影响。 在项目初期，你的代码可能只有几千行，构建一次只需要一分钟，那么你可以很敏捷灵活地频繁上线变更修复问题。但是当你的系统扩充到几十万行，甚至上百万行代码的时候，一次构建的过程，包括编译、单元测试、打包和上传到正式环境，花费的时间可能达到十几分钟，并且，任何小的修改，都需要构建整个项目，上线变更的过程非常不灵活。 这些问题，都可以用微服务来解决。 微服务拆分原则 单一服务内部功能的高内聚、低耦合。即，每个服务只完成自己职责之内的任务，对于不是自己职责的功能，交给其它服务来完成。 关注服务拆分的粒度，先粗略拆分，再逐渐细化。因为服务多了也会带来问题，像是服务个数的增加会增加运维的成本。再比如，原本一次请求只需要调用进程内的多个方法，现在则需要跨网络调用多个 RPC 服务，在性能上肯定会有所下降。推荐的做法是：拆分初期可以把服务粒度拆的粗一些，后面随着团队对于业务和微服务理解的加深，再考虑把服务粒度细化。比如说，对于一个社区系统来说，你可以先把和用户关系相关的业务逻辑，都拆分到用户关系服务中，之后，再把其中比如黑名单的逻辑独立成黑名单服务。 拆分的过程，要尽量避免影响产品的日常功能迭代，也就是说，要一边做产品功能迭代，一边完成服务化拆分。总不能停掉所有业务开发，全盘推翻重构完再上线吧？参考如下剥离顺序： 优先剥离比较独立的边界服务。从非核心的服务出发，减少拆分对现有业务的影响，也给团队一个练习、试错的机会； 要理清服务之间的调用关系，当两个服务存在依赖关系时，优先拆分被依赖的服务。比如，内容服务会依赖用户服务获取用户信息，互动服务会依赖内容服务，所以要按照先用户服务，再内容服务，最后互动服务的顺序来进行拆分。 服务接口的定义要具备可扩展性。服务拆分之后，由于服务是以独立进程的方式部署，所以服务之间通信，就不再是进程内部的方法调用，而是跨进程的网络通信了。在这种通信模型下需要注意，服务接口的定义要具备可扩展性，否则在服务变更时，会造成意想不到的错误。比如，某一个微服务的接口有三个参数，在一次业务需求开发中，组内的一个同学将这个接口的参数调整为了四个，接口被调用的地方也做了修改，结果上线这个服务后，却不断报错，无奈只能回滚。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:1","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"远程调用 当采用微服务架构之后，原本的 1 次请求，可能需要调用 4、5 次服务，如图。 那如何避免其带来的性能损耗呢？ 选择合适的网络模型，有针对性地调整网络参数，以优化网络传输性能； 选择合适的序列化方式，以提升封包、解包的性能。 如何提升网络传输性能？ 有很多方面： I/O 多路复用； 禁用 Nagle 算法。 要讲讲 Nagle 算法： tcp 协议的包头有 20 字节，ip 协议的包头也有 20 字节，如果仅仅传输 1 字节的数据，在网络上传输的就有 20 + 20 + 1 = 41 字节，其中真正有用的数据只有 1 个字节，这对效率和带宽是极大的浪费。所以在 1984 年的时候，John Nagle 提出了以他的名字命名的 Nagle 算法： 如果是连续的小数据包，大小没有一个 MSS（Maximum Segment Size，最大分段大小），并且还没有收到之前发送的数据包的 Ack 信息，那么这些小数据包就会在发送端暂存起来，直到小数据包累积到一个 MSS，或者收到一个 Ack 为止。 原本是为了减少不必要的网络传输，但是如果接收端开启了 DelayedACK（延迟 ACK 的发送，这样可以合并多个 ACK，提升网络传输效率），那就会发生，发送端发送第一个数据包后，接收端没有返回 ACK，这时发送端发送了第二个数据包，因为 Nagle 算法的存在，并且第一个发送包的 ACK 还没有返回，所以第二个包会暂存起来。而 DelayedACK 的超时时间，默认是 40ms，所以一旦到了 40ms，接收端回给发送端 ACK，那么发送端才会发送第二个包，这样就增加了延迟。 解决的方式非常简单：只要在 socket 上开启 tcp_nodelay 就好了，这个参数关闭了 Nagle 算法，这样发送端就不需要等到上一个发送包的 ACK 返回，直接发送新的数据包就好了。这对于强网络交互的场景来说非常的适用，基本上，如果你要自己实现一套网络框架，tcp_nodelay 这个参数最好是要开启的。 选择合适的序列化方法 一次 RPC 调用需要经历两次序列化、两次反序列化的过程，因此需要选择高效的序列化方法。 没啥要求的可以用 JSON，不然还得是 Protobuf。(原因详见 Protobuf 的 md) ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:2","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"服务注册与发现 注册中心 注册中心提供的功能： 其一是提供了服务地址的存储； 其二是当存储内容发生变化时，可以将变更的内容推送给客户端。 有了注册中心之后，服务节点的增加和减少对于客户端就是透明的。这样，除了可以实现不重启客户端，就能动态地变更服务节点以外，还可以实现优雅关闭的功能。 问：什么是优雅的关闭？注册中心怎么做到？ 优雅关闭是必须要考虑的问题。因为如果直接暴力地停止服务，那么已经发送给服务端的请求，来不及被处理就会被丢弃了，就会造成这部分请求失败，服务就会有波动。 所以，服务在退出的时候，都需要先停掉流量，再停止服务，这样服务的关闭才会更平滑。 对于 RPC 服务来说，可以先将 RPC 服务从注册中心的服务列表中删除掉，然后观察 RPC 服务端没有未处理的请求之后，再将服务端停掉。有了优雅关闭之后，RPC 服务端再重启的时候，就会减少对客户端的影响。 服务状态管理 一般有两种解决思路： 主动探测； 心跳模式； 主动探测 思路：RPC 服务打开一个端口，由注册中心每隔一段时间（比如 30 秒）探测这些端口是否可用，如果可用就认为服务仍然是正常的，否则就可以认为服务不可用，那么注册中心就可以把服务从列表里面删除了。 缺陷： 所有的 RPC 服务端都需要开放一个统一的端口给注册中心探测，但需要开放的端口很可能已经被占用，这样会造成 RPC 服务启动失败； 如果 RPC 服务实例比较多，那么每次探测的成本也会比较高，探测的时间也比较长，这样当一个服务不可用时，可能会有一段时间的延迟，才会被注册中心探测到。 因此，改进成了心跳模式。 心跳模式 大部分注册中心都采用心跳模式检测 RPC 服务是否存活。 思路： 首先，注册中心为每一个连接上来的 RPC 服务节点，记录最近续约的时间； 同时，注册中心会启动一个定时器，检测 RPC 服务节点的租约是否到期，租约到期就认为这个服务节点不可用 RPC 服务节点可以按照一定的时间间隔(比如 30 秒)，向注册中心发送心跳包续约； 注册中心收到心跳包之后，会更新这个节点的最近续约时间。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:3","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"分布式 Trace 慢请求问题如何排查？ 单体架构中的慢请求排查 为了应对多线程同时请求造成的日志混乱，可以在记录打点日志时，使用 requestId 将日志串起来，这样方便比较一次请求中的多个步骤的耗时情况； 使用静态代理的方式做切面编程，避免在业务代码中，加入大量打印耗时的日志的代码，减少了对于代码的侵入性，同时编译期的代码注入可以减少； 增加日志采样率，避免全量日志的打印； 为了避免在排查问题时，需要到多台服务器上搜索日志，可以使用消息队列，将日志集中起来放在了 Elasticsearch 中。 分布式 Trace 在单体架构中，单次请求的所有的耗时日志，都被记录在一台服务器上；而在微服务的场景下，单次请求可能跨越多个 RPC 服务，这就造成了，单次的请求的日志会分布在多个服务器上。 可以采用 traceId + spanId 这两个数据维度来记录服务之间的调用关系（这里 traceId 就是 requestId），也就是使用 traceId 串起单次请求，用 spanId 记录每一次 RPC 调用。 比如，请求从用户端过来，先到达 A 服务，A 服务会分别调用 B 和 C 服务，B 服务又会调用 D 和 E 服务。 那么 spanId 是何时生成的，又是如何传递的呢？ 首先，A 服务在发起 RPC 请求服务 B 前，先从线程上下文中获取当前的 traceId 和 spanId，然后，依据上面的逻辑生成本次 RPC 调用的 spanId，再将 spanId 和 traceId 序列化后，装配到请求体中，发送给服务方 B。 服务方 B 获取请求后，从请求体中反序列化出 spanId 和 traceId，同时设置到线程上下文中，以便给下次 RPC 调用使用。在服务 B 调用完成返回响应前，计算出服务 B 的执行时间发送给消息队列。 当然，在服务 B 中，你依然可以使用切面编程的方式，得到所有调用的数据库、缓存、HTTP 服务的响应时间，只是在发送给消息队列的时候，要加上当前线程上下文中的 spanId 和 traceId。 这样，无论是数据库等资源的响应时间，还是 RPC 服务的响应时间就都汇总到了消息队列中，在经过一些处理之后，最终被写入到 Elasticsearch 中以便给开发和运维同学查询使用。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:4","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"负载均衡 负载均衡服务大体上可以分为两大类：一类是代理类的负载均衡服务；另一类是客户端负载均衡服务。 代理类负载均衡服务典型的就是 NGINX 和 LVS，适用于普通的 Web 服务。但对于微服务架构来说，是不合适的。因为微服务架构中的服务节点存储在注册中心里，使用 LVS 就很难和注册中心交互，获取全量的服务节点列表。另外，一般微服务架构中，使用的是 RPC 协议而不是 HTTP 协议，所以 Nginx 也不能满足要求。 在 RPC 中，通常会使用另一类的负载均衡服务，客户端负载均衡服务，也就是把负载均衡的服务内嵌在 RPC 客户端中。 客户端负载均衡 客户端负载均衡服务，一般和客户端应用部署在一个进程中，提供多种选择节点的策略，最终为客户端应用提供一个最佳的，可用的服务端节点。思想：这类服务一般会结合注册中心来使用，注册中心提供服务节点的完整列表，客户端拿到列表之后使用负载均衡服务的策略选取一个合适的节点，然后将请求发到这个节点上。 负载均衡策略 负载均衡策略从大体上来看可以分为两类： 一类是静态策略，也就是说负载均衡服务器在选择服务节点时，不会参考后端服务的实际运行的状态。 一类是动态策略，也就是说负载均衡服务器会依据后端服务的一些负载特性，来决定要选择哪一个服务节点。 静态策略 轮询(RoundRobin，RR)：按照服务列表的顺序，逐个请求后端服务节点； 带权轮询：给节点加上权重值，比如给 8 核 8G 的机器配置权重为 2，那么就会给它分配双倍的流量； 一致性 Hash。 轮询和带有权重的轮询策略，能够将请求尽量平均地分配到后端服务节点上，也就能够做到对于负载的均衡分配，在没有更好的动态策略之前，应该优先使用这两种策略，比如 Nginx 就会优先使用轮询的策略。 动态策略 原理：负载均衡服务器会收集对后端服务节点的调用信息，比如从负载均衡器到服务节点的活跃连接数，或者是请求调用的响应时间，然后从中选择连接数最少的服务节点，或者响应时间最短的服务节点。 在实际开发中，优先考虑使用动态的策略。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:5","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"API 网关 API 网关是一种架构模式，它是将一些服务共有的功能整合在一起，独立部署为单独的一层，用来解决一些服务治理的问题。可以把它看作系统的边界，它可以对出入系统的流量做统一的管控。 网关分类 API 网关可以分为两类：一类叫做入口网关，一类叫做出口网关。 入口网关⭐ 入口网关部署在负载均衡服务器和应用服务器之间，主要有以下作用： 提供给客户端一个统一的请求接入地址，API 网关可以将用户的请求动态路由到不同的业务服务上，并且做一些必要的协议转换工作。比如，部署的微服务对外暴露的协议可能不同，有些还提供的是 HTTP 服务；有些已经完成 RPC 改造，对外暴露 RPC 服务。API 网关可以对客户端屏蔽这些服务的部署地址，以及协议的细节，给客户端的调用带来很大的便捷。 植入一些服务治理的策略，比如服务的熔断、降级，流量控制和分流等； API 网关可以嵌入中间件，比如用户认证和授权的实现等； API 网关可以给请求分配 Request ID，辅助进行日志记录，用于之前讲的分布式 Trace。 出口网关 不是重点。 在系统开发中，会依赖很多外部的第三方系统，出口网关就是负责调用这些外部第三方系统的。比如典型的例子：第三方账户登录、使用第三方工具支付等等。我们可以在应用服务器和第三方系统之间，部署出口网关，在出口网关中，对调用外部的 API 做统一的认证、授权，审计以及访问控制。 如何实现 // TODO：线程池 可以针对不同的服务使用不同的线程池，在线程池内部针对不同的接口设置配额 Tyk 是一种 Go 语言实现的轻量级 API 网关，有着丰富的插件资源，对于 Go 语言栈的团队来说，也是一种不错的选择。 引入网关 在服务层和客户端之间建立一层薄薄的 Web 层，主要做两件事： 聚合服务层接口数据。比如，商品详情页的接口，可能会聚合服务层中，获取商品信息、用户信息、店铺信息以及用户评论等多个服务接口的数据； 负责协议转换、限流、黑白名单等。比如将 HTTP 请求转换为 RPC 请求，并且对前端的流量做一些限制，对于某些请求添加设备 ID 的黑名单等等。 聚合服务接口数据，一般有两种解决思路： 独立出一组网关专门做服务聚合、超时控制方面的事情，我们一般把前一种网关叫做流量网关，后一种可以叫做业务网关； 抽取独立的服务层，专门做接口聚合的操作。这样服务层就大概分为原子服务层和聚合服务层。 接口数据聚合是业务操作，与其放在通用的网关层来实现，不如放在更贴近业务的服务层来实现，所以，我更倾向于第二种方案。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:6","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"跨地域分布式系统 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:7","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"六、维护 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:6:0","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"降级熔断 雪崩是如何发生的 雪崩：局部故障最终导致全局故障。 那么，为什么会发生雪崩呢？我们知道，系统在运行的时候是需要消耗一些资源的，包括 CPU、内存等系统资源，也包括执行业务逻辑的时候，需要的线程资源。 举个例子，一般在业务执行的容器内，都会定义一些线程池来分配执行任务的线程，比如在 Tomcat 这种 Web 容器的内部，定义了线程池来处理 HTTP 请求；RPC 框架也给 RPC 服务端初始化了线程池来处理 RPC 请求。 这些线程池中的线程资源是有限的，如果这些线程资源被耗尽，那么服务自然也就无法处理新的请求，服务提供方也就宕机了。比如，你的垂直电商系统有四个服务 A、B、C、D，A 调用 B，B 调用 C 和 D。其中，A、B、D 服务是系统的核心服务（像是电商系统中的订单服务、支付服务等等），C 是非核心服务（像反垃圾服务、审核服务）。 所以，一旦作为入口的 A 流量增加，你可能会考虑把 A、B 和 D 服务扩容，忽略 C。那么 C 就有可能因为无法承担这么大的流量，导致请求处理缓慢，进一步会让 B 在调用 C 的时候，B 中的请求被阻塞，等待 C 返回响应结果。这样一来，B 服务中被占用的线程资源就不能释放。 久而久之，B 就会因为线程资源被占满，无法处理后续的请求。那么从 A 发往 B 的请求，就会被放入 B 服务线程池的队列中，然后 A 调用 B 响应时间变长，进而拖垮 A 服务。你看，仅仅因为非核心服务 C 的响应时间变长，就可以导致整体服务宕机，这就是我们经常遇到的一种服务雪崩情况。 那么我们要如何避免出现上面这种情况呢？从刚刚的介绍中可以看到，因为服务调用方等待服务提供方的响应时间过长，它的资源被耗尽，才引发了级联反应，发生雪崩。 所以在分布式环境下，系统最怕的反而不是某一个服务或者组件宕机，而是最怕它响应缓慢，因为，某一个服务或者组件宕机也许只会影响系统的部分功能，但它响应一慢，就会出现雪崩拖垮整个系统。 解决的思路就是在检测到某一个服务的响应时间出现异常时，切断调用它的服务与它之间的联系，让服务的调用快速返回失败，从而释放这次请求持有的资源。这个思路也就是我们经常提到的降级和熔断机制。 熔断机制 服务治理中的熔断机制指的是在发起服务调用时，如果返回错误或者超时的次数超过一定阈值，则后续的请求不再发向远程服务而是暂时返回错误。 服务调用方为每一个调用的服务维护一个有限状态机，在这个状态机中会有三种状态：关闭（调用远程服务）、半打开（尝试调用远程服务）和打开（直接返回错误）： 当调用失败的次数累积到一定的阈值时，熔断状态从关闭态切换到打开态。一般在实现时，如果调用成功一次，就会重置调用失败次数。 当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时后，状态切换到半打开态。你也可以通过设置一个定时器，定期地探测服务是否恢复。 在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定的成功次数后，状态切换到关闭态；如果出现调用失败的情况，则切换到打开态。 降级机制 相比熔断来说，降级是一个更大的概念。因为它是站在整体系统负载的角度上，放弃部分非核心功能或者服务，保证整体的可用性的方法，是一种有损的系统容错方式。这样看来，熔断也是降级的一种，除此之外还有限流降级、开关降级等。 此处先介绍开关降级，限流降级单独讲。 开关降级指的是在代码中预先埋设一些开关，用来控制服务调用的返回值。比方说，开关关闭的时候正常调用远程服务，开关打开时则执行降级的策略。这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要通过配置中心动态更改开关的值，就可以实现不重启服务快速地降级远程服务了。 在设计开关降级预案的时候，首先要区分哪些是核心服务，哪些是非核心服务。因为我们只能针对非核心服务来做降级处理，然后就可以针对具体的业务，制定不同的降级策略了。列举一些常见场景下的降级策略： 针对读取数据的场景，我们一般采用的策略是直接返回降级数据。比如，如果数据库的压力比较大，我们在降级的时候，可以考虑只读取缓存的数据，而不再读取数据库中的数据；如果非核心接口出现问题，可以直接返回服务繁忙或者返回固定的降级数据。 对于一些轮询查询数据的场景，比如每隔 30 秒轮询获取未读数，可以降低获取数据的频率（将获取频率下降到 10 分钟一次）。 而对于写数据的场景，一般会考虑把同步写转换成异步写，这样可以牺牲一些数据一致性和实效性来保证系统的可用性。 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:6:1","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试"],"content":"限流 什么是限流？ 限流，也称流量控制。是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定性。限流会导致部分用户请求处理不及时或者被拒，这就影响了用户体验。所以一般需要在系统稳定和用户体验之间平衡一下。 限流算法 固定窗口算法 首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。 当次数少于限流阀值，就允许访问，并且计数器+1 当次数大于限流阀值，就拒绝访问。 当前的时间窗口过去之后，计数器清零。 假设单位时间是1秒，限流阀值为3。在单位时间1秒内，每来一个请求,计数器就加1，如果计数器累加的次数超过限流阀值3，后续的请求全部拒绝。等到1s结束后，计数器清0，重新开始计数。如下图： 缺陷：假设限流阀值为5个请求，单位时间窗口是1s，如果我们在单位时间内的前0.8-1s和1-1.2s，分别并发5个请求。虽然都没有超过阀值，但是如果算0.8-1.2s，则并发数高达10，已经超过单位时间1s不超过5阀值的定义啦。 滑动窗口算法 滑动窗口算法解决固定窗口临界值的问题。它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。 假设单位时间还是1s，滑动窗口算法把它划分为5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子。每格表示0.2s。每过0.2s，时间窗口就会往右滑动一格。然后呢，每个小周期，都有自己独立的计数器，如果请求是0.83s到达的，0.8~1.0s对应的计数器就会加1。 那滑动窗口是如何解决临界问题的？ 假设我们1s内的限流阀值还是5个请求，0.8~1.0s内（比如0.9s的时候）来了5个请求，落在黄色格子里。时间过了1.0s这个点之后，又来5个请求，落在紫色格子里。如果是固定窗口算法，是不会被限流的；但是滑动窗口的话，每过一个小周期，它会右移一个小格。过了1.0s这个点后，会右移一小格，当前的单位时间段是0.2~1.2s，这个区域的请求已经超过限定的5了，已触发限流啦，实际上，紫色格子的请求都被拒绝啦。 TIPS: 当滑动窗口的格子周期划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 缺陷：滑动窗口算法虽然解决了固定窗口的临界问题，但是一旦到达限流后，请求都会直接暴力被拒绝。酱紫我们会损失一部分请求，这其实对于产品来说，并不太友好。 漏桶算法 漏桶算法面对限流，就更加的柔性，不存在直接的粗暴拒绝。 它的原理很简单，可以认为就是注水漏水的过程：往漏桶中以任意速率流入水，以固定的速率流出水。当水超过桶的容量时，会被溢出，也就是被丢弃。因为桶容量是不变的，保证了整体的速率。 流入的水滴，可以看作是访问系统的请求，这个流入速率是不确定的。 桶的容量一般表示系统所能处理的请求数。 如果桶的容量满了，就达到限流的阀值，就会丢弃水滴（拒绝请求） 流出的水滴，是恒定过滤的，对应服务按照固定的速率处理请求。 在正常流量的时候，系统按照固定的速率处理请求，是我们想要的。但是面对突发流量的时候，漏桶算法还是循规蹈矩地处理请求，这就不是我们想看到的啦。流量变突发时，我们肯定希望系统尽量快点处理请求，提升用户体验嘛。 令牌桶算法 面对突发流量的时候，我们可以使用令牌桶算法限流。相比漏桶算法，可以调节速率。 令牌桶算法原理： 有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。 如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。 系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑； 如果拿不到令牌，就直接拒绝这个请求。 如果令牌发放的策略正确，这个系统即不会被拖垮，也能提高机器的利用率。 参考文章： 面试必备：4种经典限流算法讲解 参考文章： 高并发系统设计 40 问 字节三面：如何设计一个高并发系统 ","date":"2023-05-25","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:6:2","tags":["高并发系统"],"title":"高并发系统设计","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":["面试","项目"],"content":"[toc] ","date":"2023-05-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:0:0","tags":["项目"],"title":"个人项目","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":["面试","项目"],"content":"一、Gin 框架 问：为什么需要 Web框架？ net/http提供了基础的Web功能，即监听端口，映射静态路由，解析HTTP报文。一个实例： func main() { http.HandleFunc(\"/\", handler) http.HandleFunc(\"/count\", counter) log.Fatal(http.ListenAndServe(\"localhost:8000\", nil)) } func handler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"URL.Path = %q\\n\", r.URL.Path) } 但一些Web开发中简单的需求并不支持，需要手工实现： 动态路由：例如hello/:name，hello/*这类的规则。 鉴权：没有分组/统一鉴权的能力，需要在每个路由映射的handler中实现。 模板：没有统一简化的HTML机制。 统一入口 package http type Handler interface { ServeHTTP(w ResponseWriter, r *Request) } func ListenAndServe(address string, h Handler) error 其实就是，实现Handler接口，拦截所有的请求到咱们自己的处理逻辑。 解释一下：你可以看这点代码：http.ListenAndServe(\"localhost:8000\", nil)，后面是nil，其实http库会自动给个默认的DefaultServeMux，也就把所有的请求用这个处理了，所以第一件事就是拦截掉所有的请求！ ==路由映射==（动态路由有点问题吧，测试一下） func main() { r := gee.New() r.GET(\"/\", func(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \"URL.Path = %q\\n\", req.URL.Path) }) r.GET(\"/hello\", func(w http.ResponseWriter, req *http.Request) { for k, v := range req.Header { fmt.Fprintf(w, \"Header[%q] = %q\\n\", k, v) } }) r.Run(\":9999\") } 其实就是，把路由地址和对应的处理函数，存起来。 解释一下：这里最简单的办法是啥？不就是在r里边整个哈希表，把路由和处理函数分别当成key和val嘛？但是哈希表有一个弊端：只能支持静态路由。 支持动态路由，有很多方法： 正则表达式 前缀树、压缩前缀树(此处使用) 这里实现动态路由具备两个功能： 参数匹配:。例如 /p/:lang/doc，可以匹配 /p/c/doc 和 /p/go/doc； 通配*。例如 /static/*filepath，可以匹配/static/fav.ico，也可以匹配/static/js/jQuery.js，这种模式常用于静态服务器，能够递归地匹配子路径。 实现前缀树后，可以在router中对每一种类型的方法都维护一颗Trie。 对于动态路由传递的参数，可以放在Context中的Param里。 设计Context 设计上下文(Context)，封装 Request 和 Response，提供对 JSON、HTML 等返回类型的支持。 必要性： 对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter。但是这两个对象提供的接口粒度太细，比如我们要构造一个完整的响应，需要考虑消息头(Header)和消息体(Body)，而 Header 包含了状态码(StatusCode)，消息类型(ContentType)等几乎每次请求都需要设置的信息。因此，如果不进行有效的封装，那么框架的用户将需要写大量重复，繁杂的代码，而且容易出错。针对常用场景，能够高效地构造出 HTTP 响应是一个好的框架必须考虑的点。 示例： 封装前 obj = map[string]interface{}{ \"name\": \"geektutu\", \"password\": \"1234\", } w.Header().Set(\"Content-Type\", \"application/json\") w.WriteHeader(http.StatusOK) encoder := json.NewEncoder(w) if err := encoder.Encode(obj); err != nil { http.Error(w, err.Error(), 500) } VS 封装后： c.JSON(http.StatusOK, gee.H{ \"username\": c.PostForm(\"username\"), \"password\": c.PostForm(\"password\"), }) Context 还可以支撑其他功能。比如： **动态路由的参数：**将来解析动态路由/hello/:name，参数:name的值放在哪呢？ **中间件的参数与结果：**框架需要支持中间件，那中间件产生的信息放在哪呢？ Context 随着每一个请求的出现而产生，请求的结束而销毁，和当前请求强相关的信息都应由 Context 承载。 Context 就像一次会话的百宝箱，可以找到任何东西。 提供了访问Query和PostForm参数的方法； 提供了快速构造String/Data/JSON/HTML响应的方法。 package gee import ( \"encoding/json\" \"fmt\" \"net/http\" ) type H map[string]interface{} type Context struct { // origin objects W http.ResponseWriter Req *http.Request // req info Path string // 其实就是 pattern Method string // 请求方法 Params map[string]string // 存储Path传递的参数 // resp info StatusCode int // 响应码 // middleware handlers []HandlerFunc // 存储中间件 index int // 记录当前执行到第几个中间件 // engine pointer engine *Engine } func NewContext(w http.ResponseWriter, req *http.Request) *Context { return \u0026Context{ W: w, Req: req, Path: req.URL.Path, Method: req.Method, index: -1, } } // 获取传递的参数 func (c *Context) Param(key string) string { return c.Params[key] } // 获取Form的数据 func (c *Context) PostForm(key string) string { return c.Req.FormValue(key) } // 获取Query的数据 func (c *Context) Query(key string) string { return c.Req.URL.Query().Get(key) } func (c *Context) Status(code int) { c.StatusCode = code c.W.WriteHeader(code) } func (c *Context) SetHeader(key string, value string) { c.W.Header().Set(key, value) } func (c *Context) String(code int, format string, values ...interface{}) { c.SetHeader(\"Content-Type\", \"text/plain\") c.Status(code) c.W.Write([]byte(fmt.Sprintf(format, values...))) } func (c *Context) Data(code int, data []byte) { c.Status(code) c.W.Write(data) } func (c *Context) JSON(code int, obj interface{}) { c.SetHeader(\"Content-Type\", \"application/json\") c.Status(code) encoder := json.NewEncoder(c.W) if err := encoder.Encode(obj); err != nil { http.Error(c.W, err.Error(), 500) } } func (c *Context) HTML(code int, name string, data interface{}) { c.SetHeader(\"Content-Type\", \"text/html\") c.Status(code) i","date":"2023-05-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:1:0","tags":["项目"],"title":"个人项目","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":["面试","项目"],"content":"二、分布式缓存框架 仿照 groupCache 实现，最大的特点是没有删除、更新接口，只有Get接口。 问：为什么要设计分布式缓存机制？ 最简单的缓存就是用哈希表。但是会有以下问题： 内存不够了咋办，需要实现一个合理的缓存淘汰策略； 全局哈希表存在访问冲突，需要加锁，降低效率； 单机性能可能不够，单点故障的成本太高，分布式缓存可以增强系统鲁棒性。 … 问：支持那些特性？ 单机缓存和基于 HTTP 的分布式缓存； 最近最少访问(Least Recently Used, LRU) 缓存策略； 使用 Go 锁机制防止缓存击穿； 使用一致性哈希选择节点，实现负载均衡； 使用 protobuf 优化节点间二进制通信； 。。。 缓存策略 缓存肯定不能无限大，超过设置容量时需要有合理的淘汰策略。 常见的缓存策略： FIFO：队列嘛，先进先出，显然很不合理； LFU：按照使用次数排序，淘汰最少使用的； LRU：最近最少使用； 问：缓存大小是如何表示的？ 使用[]byte存储数据，其长度len()就是占用多少Byte。 问：数据存放格式？⭐ 缓存Cache由以下字段组成： type Cache struct { MaxEntries int OnEvicted func(key Key, value interface{}) ll *list.List // 真正存储 entry 指针的地方 cache map[interface{}]*list.Element // 存储 key - entry，用于快速找到 entry } type Key interface{} type entry struct { key Key value interface{} } 当要存储一对 key-value时，首先转换成 entry 对象，理论上 key 和 value 都是 interface{}，也就是支持所有类型。 插入时，若key之前不存在，就是插入；若已存在，就是更新： // Add adds a value to the cache. func (c *Cache) Add(key Key, value interface{}) { if c.cache == nil { c.cache = make(map[interface{}]*list.Element) c.ll = list.New() } if ee, ok := c.cache[key]; ok { c.ll.MoveToFront(ee) ee.Value.(*entry).value = value return } ele := c.ll.PushFront(\u0026entry{key, value}) // ll 中存储的其实是 entry 对象的指针 c.cache[key] = ele if c.MaxEntries != 0 \u0026\u0026 c.ll.Len() \u003e c.MaxEntries { c.RemoveOldest() } } 问：数据支持哪些操作？ 只支持 Get。 用户使用时，需要实现以下： 初始化的时候，就需要明确当 key miss 的时候，怎么获取到内容的手段，把这个手段配置好是前提； get 调用的时候，当 key miss 的时候，就会调用初始化的获取手段来获取数据，如果 hit 的话，那么就直接返回了。 问：这种只能 get ，不能更新 key 的缓存有啥用？有什么适用场景？ 比如你缓存一些静态文件，用文件 md5 作为 key，value 就是文件。这种场景就很适合用 groupcache 这种缓存，因为 key 对应的 value 不需要变。 参考文章： https://liqingqiya.github.io/groupcache/golang/%E7%BC%93%E5%AD%98/2020/05/10/groupcache.html 单机并发缓存 并发设计多协程，所以肯定需要一把互斥锁。 问：单机并发缓存是如何实现的？ 在lru外再封装一层，主要数据结构： type cache struct { mu sync.Mutex // 支持并发, 必须有锁 lru *lru.Cache cacheBytes int64 // 缓存容量 Byte } 为了区分不同类型的缓存，设置Group，负责与用户交互，控制缓存值存储和获取的流程： /* 是 接收 key --\u003e 检查是否被缓存 -----\u003e 返回缓存值 ⑴ | 否 是 |-----\u003e 是否应当从远程节点获取 -----\u003e 与远程节点交互 --\u003e 返回缓存值 ⑵ | 否 |-----\u003e 调用`回调函数`，获取值并添加到缓存 --\u003e 返回缓存值 ⑶ */ 问：若缓存不存在，怎么获取呢？ 分为从远程节点获取和**调用用户逻辑(回调函数)**获取。 这部分是回调函数的实现逻辑： 因为数据怎么获得、获得的来源是哪，应该是框架的用户需要考虑的，所以只需要开放一个回调函数接口即可。 **用户需要自定义一个GetterFunc类型的函数。**当缓存未命中时，就会调用此函数获取数据，获取之后会调用cache.put()更新缓存。 // Getter 未命中时从数据源获取数据 type Getter interface { Get(key string) ([]byte, error) // 回调函数 } // 函数类型实现某一个接口，称之为接口型函数。 // 方便使用者在调用时既能够传入函数作为参数，也能够传入实现了该接口的结构体作为参数。 // 是一个将函数转换为接口的技巧 type GetterFunc func(key string) ([]byte, error) // Get 实现Getter接口 func (f GetterFunc) Get(key string) ([]byte, error) { return f(key) } 这部分是从远程节点获取的实现逻辑： 一致性哈希 问：一致性哈希原理？有啥用？ 一致性哈希算法将 key 映射到 2^32^ 的空间中，将这个数字首尾相连，形成一个环。 计算节点/机器(通常使用节点的名称、编号和 IP 地址)的哈希值，放置在环上。 计算 key 的哈希值，放置在环上，顺时针寻找到的第一个节点，就是应选取的节点/机器。 环上有 peer2，peer4，peer6 三个节点，key11，key2，key27 均映射到 peer2，key23 映射到 peer4。此时，如果新增节点/机器 peer8，假设它新增位置如图所示，那么只有 key27 从 peer2 调整到 peer8，其余的映射均没有发生改变。 也就是说，一致性哈希算法，在新增/删除节点时，只需要重新定位该节点附近的一小部分数据，而不需要重新定位所有的节点。 问：怎么解决数据倾斜问题？ ==数据倾斜是什么？== **如果服务器的节点过少，容易引起 key 的倾斜。**例如上面例子中的 peer2，peer4，peer6 分布在环的上半部分，下半部分是空的。那么映射到环下半部分的 key 都会被分配给 peer2，key 过度向 peer2 倾斜，缓存节点间负载不均。 ==怎么解决？== **引入了虚拟节点：**一个真实节点对应多个虚拟节点。 假设 1 个真实节点对应 3 个虚拟节点，那么 peer1 对应的虚拟节点是 peer1-1、 peer1-2、 peer1-3（通常以添加编号的方式实现），其余节点也以相同的方式操作。 第一步，计算虚拟节点的 Hash 值，放置在环上。 第二步，计算 key 的 Hash 值，在环上顺时针寻找到应选取的虚拟节点，例如是 peer2-1，那么就对应真实节点 peer2。 **虚拟节点扩充了节点的数量，解决了节点较少的情况下数据容易倾斜的问题。**而且代价非常小，只需要增加一个字典(map)维护真实节点与虚拟节点的映射关系即可。 问：具体是如何实现的呢？ Go实现部分：https://geektutu.com/post/geecache-day4.html 就是： 定义一致性哈希的数据结构： type Hash func(data []byte) uint32 type Map struct { hash Hash // 可更换用户自定义的哈希函数，默认为crc32.ChecksumIEE() replicas int // 虚拟节点倍数，即一个真实节点对应replicas个虚拟节点 keys []int // 哈希环，存储每个节点的hash值 hashMap map[int]string // 节点哈希值 - 真实节点名称 } 如何添加真实/虚拟节点： func (m *Map) Add(keys ...string) { // keys是节点名称 for _, key := range keys { for i := 0; i \u003c m.replicas; i++ { // 每个真实节点都创建replicas个虚拟节点 hash := int(m.hash([]byte(strconv.Itoa(i) + key))) // 求 虚拟节点(\"i+key\") 的哈希值 m.keys = append(m.keys, hash) // 加入哈希环 m.hashMap[hash] = key // 虚拟节点 - 真实节点 } } sort.Ints(m.keys) // 排序 } 如何选择节点： func (m *Map) Get(key string) string { // key是查找键值","date":"2023-05-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:2:0","tags":["项目"],"title":"个人项目","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":["面试","项目"],"content":"三、Orm 框架 问：ORM 框架有什么用？ ORM 框架相当于对象和数据库中间的一个桥梁，借助 ORM 可以避免写繁琐的 SQL 语言，仅仅通过操作具体的对象，就能够完成对关系型数据库的操作。 问：设计 ORM 框架，需要关注哪些问题呢？ 如何屏蔽不同数据库之间的差异？ 如何从对象映射到数据库中的表结构/记录？ MySQL，PostgreSQL，SQLite 等数据库的 SQL 语句是有区别的，ORM 框架如何在开发者不感知的情况下适配多种数据库？ 如何实现：对象的字段发生改变，数据库表结构能够自动更新，即支持数据库自动迁移(migrate)？ 数据库支持的其他功能，如事务等，ORM 框架能实现哪些？ 简单的增删查改使用 ORM 替代 SQL 语句是没有问题的，但是也有很多特性难以用 ORM 替代，比如复杂的多表关联查询，ORM 也可能支持，但是基于性能的考虑，开发者自己写 SQL 语句很可能更高效。 问：你的 ORM 框架都实现了点啥？ 目前支持的特性有： 表的创建、删除、迁移。 记录的增删查改，查询条件的链式操作。 单一主键的设置(primary key)。 钩子(在创建/更新/删除/查找之前或之后)。 事务(transaction)。 数据库迁移。 为了轻量化，目前只支持轻量级数据库 SQLite。 问：项目结构是怎样的？各部分都实现了啥？ . |-- clause // 5. 生成sql语句 | |-- clause.go // 组合sql子句为完整句子 | `-- generator.go // 生成拼合用到的sql子句 |-- cmd | |-- gee.db | `-- main.go |-- dialect // 3. 抽象出各个数据库差异的部分 | |-- dialect.go // Go的数据类型 转换成 数据库的数据类型 | `-- sqlite3.go // 这是个示例：sqlite3的数据类型转换。要支持其他数据库，还需要添加对应数据库的 |-- geeorm.go // 2. 与用户交互的入口：交互前的准备工作（比如连接/测试），交互后的收尾工作（关闭连接） |-- schema // 4. 负责 对象 --\u003e 表 的转换 | `-- schema.go // schema就是存放 要转换成的表 的信息 `-- session // 1. 用来和数据库交互 |-- hooks.go // 钩子 |-- raw.go // 直接调用 SQL 语句进行原生交互的部分 |-- record.go // 用户直接调用的增删查改接口 |-- record_test.go |-- table.go // \"表\"的增删查 `-- transaction.go // 事务 表结构映射 问：怎么实现的从结构体对象到表的映射？ 在schema.go中。 在数据库中创建一张表需要哪些要素呢？ 表名(table name) —— 结构体名(struct name) 字段名和字段类型 —— 成员变量和类型。 额外的约束条件(例如非空、主键等) —— 成员变量的Tag（Go 语言通过 Tag 实现，Java、Python 等语言通过注解实现） 举一个实际的例子： type User struct { Name string `geeorm:\"PRIMARY KEY\"` Age int } 期望对应的 schema 语句： CREATE TABLE `User` (`Name` text PRIMARY KEY, `Age` integer); 主要问题是：如何通过任意类型的指针，得到其对应的结构体的信息。 所以 ORM 框架的实现需要依赖大量的 Reflect 操作： reflect.ValueOf() 获取接口对应的反射值。 reflect.Indirect() 获取指针指向的对象的反射值。 (reflect.Type).Name() 返回类名(字符串)。 (reflect.Type).Field(i) 获取第 i 个成员变量。 以上是一些基础知识。下面是映射流程： // 1. 要转换成的 // Schema 代表一张表 type Schema struct { Model interface{} // 被映射的对象 Name string // 表名 Fields []*Field // 所有的字段信息 FieldNames []string // 所有的字段名 fieldMap map[string]*Field // 映射 [字段名: *Field] } // Field 字段的信息 type Field struct { Name string // 字段名 Type string // 类型 Tag string // 约束条件 } // 2. 转换对象，示例 type User struct { name string `geeorm:\"primary\"` age int `geeorm:\"age\"` } 经过以下步骤，将User转换成数据库对象Schema： // 1. 得到该结构体的类型元数据 modelType := reflect.Indirect(reflect.ValueOf(dest)).Type() // 2. 建立Schema实例，也即映射到的表结构 schema := \u0026Schema{ Model: dest, Name: modelType.Name(), // 结构体的名称作为表名 fieldMap: make(map[string]*Field), } // 3. 得到该结构体所有的字段 for i := 0; i \u003c modelType.NumField(); i++ { p := modelType.Field(i) field := \u0026Field{ Name: p.Name, Type: d.DataTypeOf(reflect.Indirect(reflect.New(p.Type))), // 会通过reflect.Kind转换类型 } } // 4. 在tag中寻找约束条件，比如主键之类的 if v, ok := p.Tag.Lookup(\"geeorm\"); ok { field.Tag = v } // 5. 往Schema中添加结构体的字段 schema.Fields = append(schema.Fields, field) schema.FieldNames = append(schema.FieldNames, p.Name) schema.fieldMap[p.Name] = field 然后就可以用 schema 中的信息，在数据库中建表： // CreateTable 创建表 func (s *Session) CreateTable() error { table := s.RefTable() // table就是schema，也就是表的信息 var columns []string for _, field := range table.Fields { columns = append(columns, fmt.Sprintf(\"%s %s %s\", field.Name, field.Type, field.Tag)) } desc := strings.Join(columns, \",\") _, err := s.Raw(fmt.Sprintf(\"CREATE TABLE %s (%s);\", table.Name, desc)).Exec() return err } 插入、查询 问：如何实现带有条件的指令？ 通常select和insert等指令都会带有条件，以这俩为例。 带有条件的语句，**需要多个子句进行拼合！**毕竟你不能构造出所有组合出来的语句。 用户主要通过clause.go，构造最终的sql语句： // Type SQL 语句种类 type Type int const ( INSERT Type = iota VALUES SELECT LIMIT WHERE ORDERBY UPDATE DELETE COUNT ) // Clause 组合 SQL 独立语句为完整句子 type Clause struct { sql map[Type]string // SQL 语句 sqlVars map[Type][]interface{} // 参数 } // Set 按照SQL语句的Name和参数, 得到子句 func (c *Clause) Set(name Type, vars ...interface{}) { if c.sql == nil { c.sql = make(map[Type]string) c.sqlVars = make(map[Type][]interface{}) } sql, vars := generators[name](vars...) c.sql[name] = sql c.sqlVars[name] = vars } // Build 按照传入子句类型的顺序，构造最终的SQL语句 func (c *Clause) Build(orders ...Type) (string, []interface{}) { var sqls []string var vars []interface{} for _, order := range orders { if sql, ok := c.sql[order]; ok {","date":"2023-05-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:3:0","tags":["项目"],"title":"个人项目","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":["面试","项目"],"content":"四、负载均衡器 ","date":"2023-05-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:4:0","tags":["项目"],"title":"个人项目","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":["通用"],"content":" 前言：本文记录常见的负载均衡算法。 ","date":"2023-04-27","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:0","tags":["负载均衡","计算机基础"],"title":"负载均衡算法","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["通用"],"content":"1. Power of 2 random choice P2C算法是一种工业中运用较多的负载均衡算法，它的原理很简单，它有两条基本定律： 若请求IP为空，P2C均衡器将随机选择两个代理主机节点，最后选择其中负载量较小的节点； 若请求IP不为空，P2C均衡器通过对IP地址以及对IP地址加盐进行CRC32哈希计算，则会得到两个32bit的值，将其对主机数量进行取模，即CRC32(IP) % len(hosts) 、CRC32(IP + salt) % len(hosts)， 最后选择其中负载量较小的节点； ","date":"2023-04-27","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:1","tags":["负载均衡","计算机基础"],"title":"负载均衡算法","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["通用"],"content":"2. Least Load Least Load也就是最小负载算法，也是非常经典的负载均衡算法，在最小负载算法中，负载均衡器将请求定向到负载最小的目标主机中； 对于最小负载算法而言，如果把所有主机的负载值动态存入动态数组中，寻找负载最小节点的时间复杂度为O(N)，如果把主机的负载值维护成一个红黑树，那么寻找负载最小节点的时间复杂度为O(logN)，我们这里利用的数据结构叫做 斐波那契堆 ，寻找负载最小节点的时间复杂度为O(1)，感兴趣的小伙伴可以看看斐波那契堆的原理！ ","date":"2023-04-27","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:2","tags":["负载均衡","计算机基础"],"title":"负载均衡算法","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["通用"],"content":"3. 传统一致性哈希 一致性哈希算法是一种特殊的哈希算法，当哈希表改变大小时，平均只需要重新映射n/m个键值，其中n为哈希表键值的数量，m为哈希表槽的数量。 在一致性哈希负载均衡器中，一个集群由多个代理节点所组成，通过CRC32散列算法对代理主机节点的UUID或节点的IP地址进行计算，即**CRC32(IP)或CRC32(UUID)，**则会得到一组散列值，而这组散列值连成的环，称为哈希环。 当收到请求时，负载均衡器将请求的IP进行CRC32哈希计算进而得到一个散列值。如图所示，将代理主机节点和请求IP的哈希值映射到哈希环后，沿着哈希环顺时针方向查找，找到的第一个节点，即请求所被调度的代理节点。 通过对代理节点的哈希值按升序建立动态数组，即可在O(logN)时间复杂度的情况下通过二分搜索可以找到被调度的代理节点。 当代理节点数量越少时，越容易出现节点的哈希值在哈希环上分布不均匀的情况。而通过引入虚拟节点的方式可以解决一致性哈希算法负载不平衡的问题 。通过对代理主机的IP外加虚拟序号的形式作哈希计算。 如192.168.1.1的虚拟节点可能是192.168.1.1#1、192.168.1.1#2、192.168.1.1#3，我们需要把虚拟节点计算得到的CRC32值也映射到哈希环中。 下图的三个节点H1、H2、H3均匀两个虚拟节点： ","date":"2023-04-27","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:3","tags":["负载均衡","计算机基础"],"title":"负载均衡算法","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["通用"],"content":"4. 有界负载一致性哈希 Google提出的有界负载一致性哈希通过限制节点负载上限的方式解决了工作节点负载过高的问题。当节点负载过高时，有界负载一致性哈希算法通过转移热点的方式来提升集群整体的负载平衡性。 在有界负载一致性哈希算法中R 表示代理主机节点的总负载量，Tw 表示代理主机节点的数量，L 表示当前所有代理主机的平均负载量，即： α 表示代理主机所能执行的额外上限系数，M 则表示每个代理主机所能承受的最大负载量，即： 当α趋于0时，有界负载一致性哈希算法将会退化成最小负载算法 当α趋于正无穷时，算法会退化成普通性质的一致性哈希算法。 当请求IP的哈希值所调度的代理主机节点超过所能承受的最大负载量M 时，负载均衡器则会按顺时针选择第一个负载量小于M 值的代理主机节点： ","date":"2023-04-27","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:4","tags":["负载均衡","计算机基础"],"title":"负载均衡算法","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["Go","面试"],"content":" 前言：用来记录Go的语言特性，主要参考为B站《幼麟实验室》及《深度探索Go语言》。 一、基础知识 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:0:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.1 数据结构 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.1.1 String 编码：定长编码非常浪费内存，所以采用变长编码。**那么怎么划分边界呢？**最高几位空出来作为标识位，标记该字符占用几个字节。 这是 Go 默认的编码方式：UTF-8 编码： ==string的结构：== 一个起始地址：用来标记字符串起始位置；但是怎么找到结尾呢？C 是在字符串结尾处放个\\0，但这限制了内容不能出现这个字符，所以 Go 并不这样做； 一个字符串长度：用来标记该字符有多长(字节个数，而不是字符个数！)，这样就能够找到字符串在哪结束了。 Go 的字符串内容不能修改，所以 Go 的编译器会把定义好的字符串内容分配到只读内存段。可以通过[]byte()将字符串转换为字节slice，这样会为slice变量重新分配一段内存，并拷贝之前字符串的内容，可脱离只读内存的限制。 问：rune 和 byte 的区别？ 本质区别就是： type byte = uint8 type rune = int32 rune 等同于 int32，即4个字节长度，常用来处理 unicode 或 utf-8 字符。比如用来处理中文字符。 byte 等同于 uint8，即一个字节长度，常用来处理 ascii 字符(共128个)。 在go中修改字符串，需要先将字符串转化成数组，[]byte 或 []rune，然后再转换成 string 型。 str := \"你好 world\" // str[i] 其实是 byte for i := 0; i \u003c len(str); i++ { fmt.Printf(\"%c\", str[i]) // ä½\u0026nbsp;å¥½ world } // 使用range，其实是使用rune类型来编码的，rune类型用来表示utf8字符，一个rune字符由一个或多个byte组成。 for _, value := range str { fmt.Printf(\"%c\", value) // 你好 world } ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:1","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.1.2 Slice 1.1.2.1 数据结构 Slice 有三个部分： 元素存哪里(data) 存了多少个元素(len) 可以存多少个元素(cap) 例如： 若通过var ints []int或new创建数组，data是该数组的起始地址，但初始化为nil，len=0，cap=0，因为不会开辟底层内存给它； 若通过make([]int, 2, 5)创建数组，不仅会分配上述三部分，还会开辟一段内存作为它的底层数组； 1.1.2.2 append append可以为没有底层内存空间的Slice开辟一段内存，并赋值。 可以把不同的Slice关联到同一个数组，它们会共用底层数组，例如： 这三个Slice访问和修改的都是同一个底层数组，s1和s2若访问超过其len的元素，会产生访问越界。 上图中，若再给s2添加元素会怎样？这个底层数组是不能用了，得开辟新数组，原来的元素要拷贝过去，还要添加新元素，此时s2就不指向原底层数组了： 1.1.2.3 ==扩容规则== 当使用append添加元素，容量不够时，该怎么重新分配容量呢？ 预估扩容后的容量： 预估规则： oldLen*2 \u003c cap：旧容量*2 还是小于最少要分配的容量，那么就分配最少要分配的容量，此处为5； 否则：oldLen \u003c 1024时，直接 *2，oldLen \u003e= 1024时，就先扩 1/4。 **预估元素需要占用多大内存：**直接分配 预估容量 * 元素类型大小 内存可以嘛？不可以的！因为不一定有刚好一样大的预置规格的内存块。这就是第三步要做的事。 匹配到合适的内存规格：之前例子中，预估容量为 5，64位下就需要申请 40 字节内存，而最接近的内存规格为 48 字节。也就是能装 6 个该元素，所以 扩容后容量为 6。 分配完新的底层 Array 空间后，就把原 Array 中的数据拷贝到新的上面。 问：Slice 和 Array 有啥区别？ arr := [2]int{1, 2} // 声明了一个数组 sli := []int{1, 2} // 声明了一个Slice Array 长度是固定的；Slice 是动态数组，长度可变； Slice 是在 Array 基础上实现的，Slice有仨字段，首个就是对底层 Array 的引用，所以 Slice 是引用型。 在 C 语言中，数组变量是指向第一个元素的指针，但是 Go 语言中并不是。 由于值传递，数组进行赋值、传递时，实际上会复制整个数组： a := [...]int{1, 2, 3} // ... 会自动计算数组长度 b := a // 值拷贝，复制整个数组 a[0] = 100 fmt.Println(a, b) // [100 2 3] [1 2 3] // 为了避免复制数组，一般会传递指向数组的指针。 a := [...]int{1, 2, 3} b := \u0026a (*b)[0] = 100 fmt.Println(a, *b) // [100 2 3] [100 2 3] 问：Slice 的性能陷阱？ 大量内存得不到释放 在已有切片的基础上进行切片，不会创建新的底层数组。因为原来的底层数组没有发生变化，内存会一直占用，直到没有变量引用该数组。因此很可能出现这么一种情况，原切片由大量的元素构成，但是我们在原切片的基础上切片，虽然只使用了很小一段，但底层数组在内存中仍然占据了大量空间，得不到释放。比较推荐的做法，使用 copy 替代 re-slice。 // 1. 无法释放 origin，造成内存浪费 func lastNumsBySlice(origin []int) []int { return origin[len(origin)-2:] } // 2. 自动回收 origin，节省内存 func lastNumsByCopy(origin []int) []int { result := make([]int, 2) copy(result, origin[len(origin)-2:]) return result } ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:2","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.1.3 结构体与内存对齐 太强了，看视频吧去。拨云见日，茅塞顿开！ 1.1.3.1 访问内存 CPU是将内存地址通过地址总线传输给内存，内存准备好数据后通过数据总线传给CPU： 若想一次读取 8字节 的数据，就需要64位数据总线，这里的数据总线位数就是机器字长。如何能只传输一个地址，读取 8字节 数据呢？ 为了更高的访问效率，内存布局如下：就是8个chip排列在一起(每个chip由8个bank组成，即 1字节 内存)，共用同一个内存地址，各自寻找 1字节，然后组合起来成为 8字节： 所以每次访问内存都只能从起始地址%8==0处开始访问。 1.1.3.2 内存对齐 为了提高访问效率(保证一次读取)，编译器会把各种类型的数据安排到合适的地址，并占用合适的长度。 内存对齐要求数据存储起始地址，及占用的字节数都要是它对齐边界的倍数： 1.1.3.3 结构体对齐 共两个条件： 各成员要对齐边界； 结构体总内存大小 % 对齐边界 == 0。 可以看出，结构体各字段的顺序会影响结构体占用内存的大小。 ==为什么要有结构体总内存大小 % 对齐边界 == 0？== 如下情况，若不是整数倍的话，只有第一个T的内存是对齐的，第2个T就没有对齐。 问：什么是内存对齐？ 答：为了提高访问效率，编译器会把各种类型的数据安排到合适的地址，并占用合适的长度。内存对齐要求数据存储起始地址，及占用的字节数都要是它**==对其边界==的倍数**。 问：如何确定数据类型的对齐边界？ 机器字长是最大对齐边界，而数据类型的对齐边界是：min(类型大小, 最大对齐边界)。 ==为什么不统一按照最大对齐边界或类型大小分配呢？== 为了减少浪费，提高性能。 如果是int8类型，只占 1字节，若对齐到最大边界，就会浪费 7字节，所以对齐到 1字节 最合适； 如果是int64类型，占用 8字节，若对齐到 8字节，如下情况中就会浪费前面的 6字节，所以对齐到最大对齐边界最合适。 如果是结构体类型，对齐边界就是包含类型中最大的对齐边界。 问：为什么要内存对齐？ 有些CPU能访问任意地址，是因为做了处理：比如读1-8的内存：会先读0-7，只取1-7，再读8-15，只取8，组合起来就是1-8，但是这样会降低访问效率。为了避免这样读取，因此要内存对齐。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:3","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.1.4 Map 1.1.4.1 概述 Map主要由哈希函数和桶组成。 哈希函数用来实现key-value的映射，是决定哈希表的读写性能的关键，哈希函数映射的结果一定要尽可能均匀。如果使用结果分布较为均匀的哈希函数，那么哈希的增删改查的时间复杂度为 O(1)；但是如果哈希函数的结果分布不均匀，那么所有操作的时间复杂度可能会达到 O(n)。 桶用来解决哈希映射的冲突问题，常见方法有：开放寻址法和拉链法。 ==Point 1：== 因为哈希之后的地址空间通常远大于实际地址空间，因此需要对哈希值进行处理，常用有两种方法： 取模法：hash % m； 与运算(Go采用)：hash \u0026 (m-1)。这里m必须是2的整数次幂，这样可以确保不会出现空桶。 ==Point 2：== 上述对哈希值的操作会造成哈希冲突，因此需要对哈希冲突进行处理，常用有两种方法，如图所示： 开放寻址法： 写入：对当前元素进行哈希映射得到地址，若该地址空闲，可以直接填入；若已被占用，则需要将当前元素分配在该地址后的空闲地址； **读取：**若映射地址中存储元素的Key与当前元素的Key不同，则需要遍历该地址之后的地址空间，直到地址为空或找到目标Key。 拉链法（最常用）： 写入：对当前元素进行哈希映射得到地址，若该地址空闲，可以直接填入；若已被占用，则需要在链表的末尾追加新的键值对； **读取：**遍历映射地址的键值对链表，直到搜索到相同的Key(存在)或链表末尾(不存在)。 1.1.4.2 数据结构 runtime.hmap 是最核心的结构体： type hmap struct { count int // 记录 已存储键值对的数目 flags uint8 B uint8 // 记录 桶(buckets)的数目是2的多少次幂 noverflow uint16 // 记录 使用的溢出桶的数目 hash0 uint32 // 哈希的种子，为哈希函数的结果引入随机性 buckets unsafe.Pointer // 记录 桶的位置 oldbuckets unsafe.Pointer // 记录 扩容阶段旧桶的位置，大小是当前 buckets 的一半 nevacuate uintptr // 记录 扩容阶段旧桶迁移进度：下一个要进行迁移的旧桶编号 extra *mapextra // 记录 溢出桶相关信息 } // 记录溢出桶相关信息 type mapextra struct { overflow *[]*bmap // 记录 目前已被使用的溢出桶的地址 oldoverflow *[]*bmap // 记录 扩容阶段旧桶使用到的溢出桶的地址 nextOverflow *bmap // 下一个空闲溢出桶 } type bmap struct { topbits [8]uint8 // 每个topbit都是对应hash值的高8位，索引 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr // 溢出桶，布局与常规bmap相同，是为了减少扩容次数 } Go语言中，Map类型的变量本质上是一个指向hmap结构体的指针。 使用的桶的数据结构为bmap结构，每一个bmap都能存储8个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 extra.nextOverflow 中的桶存储溢出的数据。随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用更多溢出桶存储溢出的数据。 1.1.4.3 初始化 ==字面量：== Go语言中通过key: value的方法表示键值对，可以通过如下方式初始化： hash := map[string]int{ \"1\": 2, \"3\": 4, \"5\": 6, } 当**哈希表中的元素数量 \u003c= 25 **时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： hash := make(map[string]int, 3) hash[\"1\"] = 2 hash[\"3\"] = 4 hash[\"5\"] = 6 当**哈希表中的元素数量 \u003e 25 **时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： hash := make(map[string]int, 26) vstatk := []string{\"1\", \"2\", \"3\", ... ， \"26\"} vstatv := []int{1, 2, 3, ... , 26} for i := 0; i \u003c len(vstak); i++ { hash[vstatk[i]] = vstatv[i] } ==运行时：== 根据传入的B来确定需要创建的桶的数量： 若桶的数量 \u003c 2^4，此时认为数据量较小，使用溢出桶的概率较低，因此不创建溢出桶； 若桶的数量 \u003e 2^4，会额外创建2^(B-4)个溢出桶。 **注意：**正常桶和溢出桶在内存中的存储空间是连续的。 1.1.4.4 读写操作 ==访问：== 共有两种访问方式： v := hash[key] // =\u003e v := *mapaccess1(maptype, hash, \u0026key) v, ok := hash[key] // =\u003e v, ok := mapaccess2(maptype, hash, \u0026key) 赋值语句左侧接受参数的个数会决定使用的运行时方法： 当接受一个参数时，会使用 runtime.mapaccess1，该函数仅会返回一个指向目标值的指针（感觉这里的指针并不是一个地址，感觉还是目标值）； 当接受两个参数时，会使用 runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 bool 值。 查找过程⭐：哈希会依次遍历正常桶和溢出桶中的数据，它会先比较哈希的高 8 位和桶中存储的 tophash(==减少key的对比次数，缩小查找成本==)，后比较传入的和桶中的key(==因此key需要是可比较类型==)以加速数据的读写。 每一个桶都是一整片的内存空间，当发现桶中的 tophash 与传入键的 tophash 匹配之后，我们会通过指针和偏移量获取哈希中存储的键 keys[x] 并与 key 比较，如果两者相同就会获取目标值的指针 values[x] 并返回。 ==写入：== 首先会根据传入的key拿到对应的哈希和桶，然后通过遍历比较桶中存储的 tophash 和key的哈希， 如果当前键值对在哈希中存在，那么就会直接返回目标区域的内存地址； 如果当前键值对在哈希中不存在，哈希会为新键值对规划存储的内存地址并存入。 1.1.4.5 ⭐扩容 除了用散列均匀的哈希函数来提高读写性能，还可以通过对地址空间适时扩容减少哈希冲突以提高性能。 负载因子：count/(2^B)，即存储键值对的数目/桶的数目，用来判断是否需要进行扩容。不难理解，装载因子越大，哈希的读写性能就越差。 扩容规则： count/(2^B) \u003e 6.5 –\u003e 翻倍扩容(hamp.B++)； 使用了\"过多\"的溢出桶 -\u003e 等量扩容。 注：“过多” 指： 1. `B \u003c= 15`时，`noverflow \u003e= 2^B`； 1. `B \u003e 15`时，`noverflow \u003e= 2^15`。 **翻倍扩容：**会创建旧桶数目2倍的新桶，然后将旧桶中的键值对分流到对应的两个新桶中，b = hash(key) \u0026 (2^B-1)，(这个地方很有意思)。 等量扩容：所谓等量扩容就是创建和旧桶数目一样多的新桶，然后把原来的键值对迁移到新桶中。**这里有一个问题：**既然是等量的，那何必扩容呢？ **答：**当发生大规模删除操作时，旧桶中存放的键值对可能非常稀疏，因此为了紧凑内存，需要将这些键值对重新排列到新桶中。 ==Point 3== 扩容时，需要把旧桶中的数据迁移到新桶，但并不需要一次性迁移完。 渐进式扩容：把键值对迁移的时间分摊到多次哈希表操作中，可以避免瞬时的性能抖动。在哈希表每次进行读写操作时，如果检测到当前处于扩容阶段，就完成一部分键值对迁移任务，直到所有的旧桶迁移完毕。 **具体过程：**扩容时，字段oldbuckets指向旧桶，nevacuate记录下一个待迁移的旧桶。 个人觉得，Go本质上还是拉链法，但是它做了一些内存上的优化，以空间换时间，给每个桶预先分配可以放8个数据的空间，和传统的拉链法相比，好处就是不需要频繁的分配内存，同时在某些极限情况下，也可以节省一些空间，传统的拉链法还需要存放前后数据的指针，在64位机器上又是16个字节的开销，但是用数组的方式组织的话，就不需要存储前后的指针。如果一个桶里面存放了超过8个数据，还是需要另一个bmap来放多余的数，然后把两个bmap连接起来。我觉得对比一下，传统的拉链法就是一个节点只能放一个数据，而go是一个节点可以放8个数据，这8个数据是按照数组来组织的。 1.1.4.5 小结 Go 语言使用拉链法来解决哈希碰撞的问题实现了哈希表，它的访问、写入和删除等操作都在编译期间转换成了运行时的函数或者方法。哈希在每一个桶中存储键对应哈希的前 8 位，当对哈希进行操作时，这些 tophash 就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:4","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.1.5 sync.map 问：sync.map 和 mutex+map 有啥区别？sync.map 为啥要有俩 map(read+dirty)？一个不行吗？ 一个是不行的，你总不能读不加锁，写加锁吧？这样照样会有并发访问的问题(是会报错的)。但是如果是 read+dirty，就可以对 read 的所有操作都不加锁，对 dirty 的所有操作都要加锁，就可以避免并发问题。我觉得最关键的差别就是这个地方！也是很精妙的地方！ 参考文章： https://eddycjy.com/posts/go/sync-map/ https://mp.weixin.qq.com/s/vtvlye801ePWRY7RvtkDmA ⭐ 先来看看 sync.map 的底层数据结构： type Map struct { mu Mutex // 保护 dirty 和 read read atomic.Value // readOnly，只读类型，所以是并发安全的 dirty map[interface{}]*entry // 一个非线程安全的原始 map misses int // 计数作用。当读数据时，该字段不在 read 中，尝试从 dirty 中读取，不管是否在 dirty 中读取到数据，misses+1。当 misses 累计到 len(dirty) 时，会将 dirty 拷贝到 read 中，并将 dirty 清空，以此提升读性能。 } // read 的类型为 atomic.Value，它会通过 atomic.Value 的 Load 方法将其断言为 readOnly 对象 read, _ := m.read.Load().(readOnly) // m 为 sync.Map // read 的真实类型即是 readOnly type readOnly struct { m map[interface{}]*entry // read 中的 go 内置 map 类型，但是它不需要锁。 amended bool // 当 sync.Map.diry 中的包含了某些不在 m 中的 key 时，amended 的值为 true. } // map 存储的值类型是 *entry，它包含一个指针 p，指向用户存储的 value 值。 type entry struct { p unsafe.Pointer // *interface{} } mu：保护 dirty； read：存只读数据。读是并发安全的，但如果要更新 read，则需要加锁保护； dirty：包含最新写入的数据。当 misses 计数达到一定值，将其赋值给 read； misses：计数作用。当读数据时，该字段不在 read 中，尝试从 dirty 中读取，不管是否在 dirty 中读取到数据，misses+1。当 misses 累计到 len(dirty) 时，会将 dirty 拷贝到 read 中，并将 dirty 清空，以此提升读性能。 1.1.5.1 查询数据 Load(): 首先，从只读数据read中读取(因为不用加锁)，若有就直接返回，若无再继续往下； 若read没有，且dirty中有新数据，就会去dirty查找； 先加锁，然后再次检查read，若还没有，才真正去dirty查找，并且对miss计数器+1(无论是否找到)； 若miss的值 \u003e= dirty中的元素数量，就把dirty赋给read，因为穿透次数太多了，然后就可以把dirty置为空了。 func (m *Map) Load(key interface{}) (value interface{}, ok bool) { // 首先从 m.read 中通过 Load 方法得到 readOnly read, _ := m.read.Load().(readOnly) // 从 read 中的 map 中查找 key e, ok := read.m[key] // 如果 read 没有，并且 dirty 有新数据，那么去 dirty 中查找 if !ok \u0026\u0026 read.amended { m.mu.Lock() // 双重检查：避免在本次加锁的时候，有其他 goroutine 正好将 Map 中的 dirty 数据复制到了 read 中。 read, _ = m.read.Load().(readOnly) e, ok = read.m[key] // 如果 read 中还是不存在，并且 dirty 中有新数据 if !ok \u0026\u0026 read.amended { e, ok = m.dirty[key] // m 计数 +1 m.missLocked() } m.mu.Unlock() } if !ok { return nil, false } return e.load() // 返回指针指向的值 } func (m *Map) missLocked() { m.misses++ if m.misses \u003c len(m.dirty) { return } // 将dirty置给read，因为穿透概率太大了(原子操作，耗时很小) m.read.Store(readOnly{m: m.dirty}) m.dirty = nil // 清空 dirty m.misses = 0 // 重置 misses } 1.1.5.2 删除数据 Delete()： 首先，从只读数据read中读取，若有的话，就直接从read中\"删除\"(并非真的删除，只是标记一下)； 若read中没有，就获得锁，然后再检查一遍read，然后就从dirty中删除； func (m *Map) Delete(key interface{}) { // 读出 read，断言为readOnly 类型 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 如果 read 中没有，并且 dirty 中有新元素，那么就去 dirty 中去找。这里用到了 amended，当 read 与 dirty 不同时为 true，说明 dirty 中有 read 没有的数据。 if !ok \u0026\u0026 read.amended { m.mu.Lock() // 再检查一次，因为前文的判断和锁不是原子操作，防止期间发生了变化。 read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026\u0026 read.amended { // 直接删除 delete(m.dirty, key) } m.mu.Unlock() } if ok { // 如果 read 中存在该 key，则将该 value 赋值 nil(采用标记的方式删除！) e.delete() } } // 如果 read 中有该键，则从 read 中删除，其删除方式是通过原子操作 func (e *entry) delete() (hadValue bool) { for { p := atomic.LoadPointer(\u0026e.p) // 如果 p 指针为空，或者被标记清除 if p == nil || p == expunged { return false } // 通过原子操作，将 e.p 标记为 nil if atomic.CompareAndSwapPointer(\u0026e.p, p, nil) { return true } } } 1.1.5.3 增改数据 Store()： 首先，从只读数据read中获取该key，若存在，并且没有被标记删除，就尝试更新； 如果在read中不存在或已被标记删除，就在dirty中判断是否存在，若已存在，就尝试更新； 若在dirty中不存在，就加入dirty； func (m *Map) Store(key, value interface{}) { // 如果 m.read 中存在该键，且该键没有被标记删除(expunged) // 则尝试直接存储(见 entry 的 tryStore 方法) // 注意：如果 m.dirty 中也有该键(key 对应的 entry)，由于都是通过指针指向，所有 m.dirty 中也会保持最新 entry 值。 read, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) { return } // 如果不满足上述条件，即 read 不存在或者已经被标记删除 m.mu.Lock() read, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok { // read 存在该 key // 如果 entry 被标记 expunge，则表明 dirty 没有 key，可添加入 dirty，并更新 entry。 if e.unexpungeLocked() { // 加入 dirty 中，这儿是指针 m.dirty[key] = e } // 更新 entry 指向新的 value 地址 e.storeLocked(\u0026value) } else if e, ok := m.dirty[key]; ok { // read 不存在该 key，但 dirty 存在该 key，更新 e.storeLocked(\u0026value) } else { // read 和 dirty 都没有 // 如果 re","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:5","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2 语言基础 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.1 函数调用 1.2.1.1 栈帧布局 按照编程语言定义的函数，会被编译器编译为一堆机器指令，写入可执行文件，在运行时被加载到内存，位于虚拟地址空间的代码段。 当出现函数调用时，编译器就会对应生成一条call指令，程序执行到这条指令时，就会跳转到对应函数入口处执行，而每个函数最后都有一个ret指令，负责在函数调用结束后，跳转回调用处继续执行。 函数执行时需要足够的内存空间来存放局部变量、参数、返回值等数据，这些数据对应到虚拟地址空间的栈。 栈的执行顺序是从低地址到高地址，所有函数的栈帧格式都是统一的。执行到call指令会做两件事情： 首先是将下一条指令入栈，也即返回地址，当执行完调用函数就会跳转回这里； 然后会跳转到被调用函数入口处开始执行，这个过程是通过偏移量+栈指针sp完成的。 指令运行时，CPU用特定寄存器来存储运行时的栈基和栈指针，同时也有指令指针寄存器用来存放下一条要运行的指令。 Go语言中不是逐步扩张栈帧的，而是一次性分配。然后通过栈指针+偏移值使用栈帧。 ==Point：== 一次性分配栈帧主要是为了避免栈访问越界。 而Go语言编译器会在函数头部插入检测代码，当发现需要进行**“栈增长”**，就会另外分配一段足够大的栈空间，并把原来栈上的数据拷贝过来，同时释放原来那段栈空间。 **==call和ret指令==：**此处最好是看视频理解。 需要注意的是，可执行文件存放在代码段，所用的参数、变量等存放在栈空间，寄存器是指向栈空间的！ 1.2.1.2 传参与返回值 ==传值与传引用：== **传值：**函数调用时会对参数进行拷贝，被调用方和调用方两者持有不相关的两份数据； **传引用：**函数调用时会传递参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 不同语言会选择不同的方式传递参数，Go 语言选择了传值的方式，无论是传递基本类型、结构体还是指针，都会对传递的参数进行拷贝。 ==传参：== **过程：**下图swap函数并不能实现交换a, b的作用。 首先需要分配main的栈帧空间，即BP of main 和 SP of main中间的空间； 将main中的局部变量入栈； 从右至左依次将参数入栈(值拷贝)； call会将返回地址入栈，即return addr； 然后就是swap的栈帧了； 可以发现，执行交换操作只是对参数(同时也是swap的内部变量)进行操作，对main中原本的数据并不能造成影响，因此交换失败。 下图swap函数能实现交换a, b的作用。 前两步同上； 从右至左依次将参数入栈，这里同样是值拷贝，只不过值为a、b的地址； 交换时，是直接将addrA和addrB指向的数据进行交换，因此可以交换成功。 ==Point：== Go 语言中传指针也是传值。将指针作为参数传入某个函数时，函数内部会复制指针，也就是会同时出现两个指针指向原有的内存空间。因此，在传递数组或者内存占用非常大的结构体时，我们应该尽量使用指针作为参数类型来避免发生数据拷贝进而影响性能。 ==返回值：== 通常返回值是通过寄存器返回，但是Go支持返回多个返回值，也就是有可能返回值的数目大于寄存器个数，因此Go选择在栈上存储返回值。 **匿名返回值：**下图返回结果为1。 被调用函数执行完毕，ret会给返回值赋值，并执行defer函数，这里有一个问题：是先给返回值赋值还是先执行defer函数呢？ **答：**先给返回值赋值，再执行defer函数。 命名返回值： 和上边那个完全相同，只改动一个地方，返回结果为2。==这是因为被调用函数的返回值b一直在调用者栈帧中。== 参数空间分配： 若调用多个函数，将以最大的参数+返回值空间为标准来分配。如下图，将会按照B的参数+返回值空间进行分配，B执行完后，C的参数+返回值会从低地址到高地址进行分配，不满的空间就空着。 1.2.1.3 小结 Go 通过栈传递函数的参数和返回值，==参数和返回值居然是在调用者的栈帧中！！！==在调用函数之前会在栈上为返回值分配合适的内存空间，随后将入参从右到左按顺序压栈并拷贝参数，返回值会被存储到调用方预留好的栈空间上，我们可以简单总结出以下几条规则： 通过堆栈传递参数，入栈的顺序是从右到左，而参数的计算是从左到右； 函数返回值通过堆栈传递并由调用者预先分配内存空间； 调用函数时都是传值，接收方会对入参进行复制再计算； ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:1","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.2 闭包 函数，可以作为参数传递，可以做函数返回值，也可以绑定到变量。称这样的参数、返回值或变量为**function value**。 function value本质上是一个指针，但是并不直接指向函数指令入口，而是指向一个runtime.funcval的结构体，这个结构体里只有一个地址，就是这个二函数指令的入口地址。 将一个函数赋值给多个变量，这些变量会共用同一个funcval。 那么既然funcval中只有一个地址，为啥不直接使用这个地址呢？ 这是为了处理闭包。 闭包的一个示例： Go 语言中，闭包就是有捕获列表的Function Value。捕获列表中存储的值，通过funcval的地址+偏移量来获取。 ==闭包需要维持捕获变量在外层函数和内层函数中的一致性。== ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:2","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.3 方法 1.2.3.1 方法的本质 如果定义一个类型A，并给他关联一个方法，然后就可以通过类型A的变量来调用这个方法，这种调用方式其实是\"语法糖\"，实际上和下边那个调用方式一样。 Go语言中，函数类型只和参数与返回值相关，所以下边输出为True，可以说明==方法本质上就是普通函数，接收者就是隐含的第一个参数==。 1.2.3.2 方法调用 其实和函数调用一样。 举例说明过程： Go语言中传参值拷贝，此处为值接收者，所以参数首先为：data=addr1 4； 执行Name()中第一行时，data指向新的string，更新为：data=addr2 8； 返回值就是值拷贝的参数，因此main中的局部变量并未受到影响。 再举个例子对比： Go语言中传参值拷贝，此处为指针接收者，所以参数首先为：pa=\u0026a； 执行Name()中第一行时，修改pa地址处的变量，也就是a，a指向新的string，更新为：data=addr2 8； 返回值就是值拷贝的参数，即a指向的变量。此处main中的局部变量a也会被修改。 上述例子中，通过值调用值接收者的方法，通过指针调用指针接收者的方法，那么如果用值调用指针接收者的方法或用指针调用值接收者的方法，是否可行呢？ 答：可行，这些也是\"语法糖\"，在编译阶段，编译器会进行转换。 1.2.3.3 方法表达式和方法变量 来看看将一个方法赋给一个变量是怎么一回事？ Go语言中，函数作为变量、参数和返回值时都是以Function Value形式存在的，闭包也只是有捕获列表的Function Value而已。 先来看看什么是方法表达式和方法变量： 从本质上讲，方法表达式和方法变量都是Function Value。 看这段代码： ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:3","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.4 接口 1.2.4.1 概述 计算机科学中，接口是计算机系统中多个组件共享的边界，不同的组件能够在边界上交换信息。如下图所示，接口的本质是引入一个新的中间层，调用方可以通过接口与具体实现分离，解除上下游的耦合，上层的模块不再需要依赖下层的具体模块，只需要依赖一个约定好的接口。 Go 语言中的接口是一种内置的类型，它定义了一组方法的签名。Go 语言中接口的实现都是隐式的，类型实现接口时只需要实现接口中的全部方法。 在 Java 中：实现接口需要显式地声明接口并实现所有方法； 在 Go 中：实现接口的所有方法就隐式地实现了接口； 1.2.4.2 数据结构 Go 语言根据接口类型是否包含一组方法将接口类型分成了两类： 使用 runtime.iface 结构体表示包含方法的接口，又称非空接口类型； 使用 runtime.eface 结构体表示不包含任何方法的 interface{} 类型，又称空接口类型，可以接收任意类型的数据； runtime.eface 结构体： type eface struct { // 16 字节 _type *_type // 动态类型：表示类型元数据 data unsafe.Pointer // 动态值：记录在哪 } 举例说明：赋值前_type和data字段都为nil，赋值后： runtime.iface 结构体： type iface struct { // 16 字节 tab *itab // 记录动态类型和方法列表 data unsafe.Pointer // 动态值 } type itab struct { // 32 字节 inter *interfacetype // 接口的类型元数据，包含接口的方法列表：需要实现的方法 _type *_type // 接口的动态类型元数据 hash uint32 // 类型哈希值：用于快速判断类型是否相等，类型断言时会用到 _ [4]byte fun [1]uintptr // 方法地址数组：用于快速调用方法，无需再去接口的类型元数据寻找方法地址 } hash 是对 _type.hash 的拷贝，当我们想将 interface 类型转换成具体类型时，可以使用该字段快速判断目标类型和具体类型 runtime._type 是否一致； fun 是一个动态大小的数组，它是一个用于动态派发的虚函数表，存储了一组函数指针。虽然该变量被声明成大小固定的数组，但是在使用时会通过原始指针获取其中的数据，所以 fun 数组中保存的元素数量是不确定的。 举例说明：赋值前tab和data字段都为nil，赋值后： ==Point：== itab结构体内容一旦确定(接口类型和动态类型)，实际上是不会改变的，因此是可复用的。Go语言会将itab缓存起来，并且以接口类型和动态类型的组合为key(接口类型的hash ^ 动态类型的hash)，以\u0026itab为value构造一个哈希表。需要一个itab时，会先在这里边寻找，如果已经有对应的itab，就直接拿来用，如果没有，就新创建并添加。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:4","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.5 类型断言 类型断言作用在抽象类型上，包括：空接口和非空接口。而断言的目标类型可以是具体类型或非空接口类型。这样就组合出来了四种类型断言： 空接口.(具体类型) 非空接口.(具体类型) 空接口.(非空接口) 非空接口.(非空接口) 1.2.5.1 空接口.(具体类型) 1.2.5.2 非空接口.(具体类型) 1.2.5.3 空接口.(非空接口) 1.2.5.4 非空接口.(非空接口) 1.2.5.5 小结 类型断言的关键是：明确接口的**==动态类型==及对应的动态类型实现了哪些方法**，而明确这些的关键又在于动态类型的类型元数据，以及空接口与非空接口的**“数据结构”**。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:5","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.6 反射 反射的作用就是把类型元数据暴露给用户使用。 反射包中有两对非常重要的函数和类型，两个函数分别是： reflect.TypeOf 能获取类型信息； reflect.ValueOf 能获取数据的运行时表示。 两个类型是 reflect.Type 和 reflect.Value，它们与函数是一一对应的关系： 1.2.6.1 三大法则 Go 语言反射的三大法则： 从 interface{} 变量可以反射出反射对象； 从反射对象可以获取 interface{} 变量； 要修改反射对象，其值必须可设置； 法则1 为什么是从 interface{} 变量到反射对象？我们也可以执行reflect.ValueOf(1)呀，1是int类型呀，并不是interface{}？ 由于 reflect.TypeOf、reflect.ValueOf 两个方法的入参都是 interface{} 类型，所以在方法执行的过程中发生了类型转换。因为 Go 语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型 int 会转换成 interface{} 类型，这也就是为什么第一条法则是从接口到反射对象。 通过TypeOf获得变量类型； 通过ValueOf获得变量值； 然后就可以通过Method获得类型实现的方法； 通过Field获得类型包含的全部字段。 法则2 从反射对象可以获取 interface{} 变量。reflect 中的 reflect.Value.Interface 就能完成这项工作。 不过调用 reflect.Value.Interface 方法只能获得 interface{} 类型的变量，还需要进行类型断言才能变成原类型。 从反射对象到接口值的过程是从接口值到反射对象的镜面过程，两个过程都需要经历两次转换： 从接口值到反射对象： 从基本类型到接口类型的类型转换； 从接口类型到反射对象的转换； 从反射对象到接口值： 反射对象转换成接口类型； 通过显式类型转换变成原始类型(如果原来就是接口类型，那么不必这一步)。 法则3 假如想要更新原变量的值，如果这样写，是不行的： func main() { i := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) } 需要这样写： func main() { i := 1 v := reflect.ValueOf(\u0026i) v.Elem().SetInt(10) fmt.Println(i) } 调用 reflect.ValueOf 获取变量指针； 调用 reflect.Value.Elem 获取指针指向的变量； 调用 reflect.Value.SetInt 更新变量的值： 1.2.6.2 类型和值 TypeOf 如何传递参数 可以思考一下此处栈上参数列表应该是怎样的？ 由于TypeOf的参数是空接口类型，空接口是动态类型，实际大小不知道，因此需要传递地址，但是如果传递a的地址进去，就会违背Go语言值拷贝的特性，可能会修改原a的值，那么应该怎么做呢？ 实际上在编译阶段，会对a进行copy，实际传的是copy of a的地址，所有参数为空接口类型的情况，都是这样。 返回值是什么？ 通过TypeOf返回的，其实是一个非空接口变量： ValueOf 参数传递 同TypeOf，同时，ValueOf会将这个临时变量地址显式的逃逸到堆上。 例： a的地址被显式的逃逸到堆，注意此处的返回值ptr=\u0026a： 接下来调用v.Elem()，会拿到v.ptr指向的变量a，并把它包装成reflect.Value类型的返回值(ptr又变为\u0026a)，赋值给v： 然后在调用v.SetString()，此时通过参数v拿到a的地址，修改的就是原来的a： ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:6","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.7 方法集 问题：T和*T的方法集是啥关系？ T和*T是两种类型，分别有着自己的类型元数据，而根据自定义类型的类型元数据，可以找到该类型关联的方法列表，既然T和*T各有各的方法集，那为什么还要限制T和*T不能定义同名方法？又怎么会有\"*T的方法集包含T的方法集\"这种说法？ **答：**首先，可以确定的是，T的方法集里，全部都是有明确定义的接收者为T类型的方法；而*T的方法集里，除了有明确定义的接收者为*T的方法以外，**还会有编译器生成的一些\"包装方法\"：**这些包装方法是对接收者为T类型的同名方法的\"包装\"，为什么编译器要为接收者为T的方法包装一个接收者为*T的同名方法呢？ 你可能会想到 Go 支持通过指针变量访问方法。但这里首先要明确一点：通过*T类型的变量直接调用T类型接收者的方法只是一种语法糖，经验证，这种调用方式，编译器会再调用端进行指针解引用，并不会用到这里的包装方法。 ==实际上，编译器生成包装方法主要是为了支持接口。== 非空接口的数据结构只包含两个指针，一个和类型元数据相关，一个和接口装载的数据相关，虽然有数据指针，但却不能像上述语法糖那样，通过指针解引用来调用值接收者的方法。**原因：**方法的接收者是方法调用时隐含的第一个参数，Go 中的函数参数是通过栈来传递的，如果参数指针类型，那就很好实现：平台确定了，指针大小就确定了。但如果要解引用为值类型，就要有明确的类型信息，编译器才能确定这个参数要在栈上占用多大的内存空间。而对于接口，编译阶段并不能确定它会装载哪一类的数据，所以编译器并不能生成对应的指令来解引用。 总而言之，==接口不能直接使用接收者为值类型的方法==。 针对这个问题，编译器选择为值类型接收者的方法，生成指针接收者\"同名\"包装方法这一解决方案。 因此，回到最初的问题：“为什么还要限制T和*T不能定义同名方法？”，如果给T和*T定义了同名方法，就有可能和编译器生成的包装方法发生冲突，所以 Go 干脆不允许为T和*T定义同名方法。 至于，\"*T的方法集包含T的方法集的所有方法\"，这种说法可以这样理解。虽然编译器会为所有接收者为T的方法生成接收者为*T的包装方法，但是链接器会把程序中确定用不到的方法都裁剪掉，所以如果去分析可执行文件的话，就会发现不止是这些包装方法，就连我们明确定义的方法，也不一定会存在于可执行文件中。不过，一定要从可执行文件中去分析，不能通过反射去验证，因为反射的实现也是基于接口。若通过反射来验证，会被链接器认为用到了这个方法，从而把它保留下来，这就\"测不准\"了。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:7","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.2.8 泛型 go 1.17 在代码中经常会用到一些本地缓存组件，它们是复用性极高的基础组件，在使用体验上和map差不多，都提供了Set和Get方法。为了支持任意类型，这些方法都使用了空接口类型的参数，内部实际存储数据的是个值类型为空接口的map。 使用Set方法时，一般不会觉得有什么不方便，因为从具体类型或接口类型，到空接口的赋值不需要额外处理。但是Get方法使用时，需要通过类型断言，把取出来的数据转换成预期的类型。比如想从本地缓存c里面取出来一个string，就需要这样写： if v, ok := c.Get(\"key\"); ok { if s, ok := v.(string); ok { // use s } } 如果是仅仅多这一步，那也无可厚非，可实际上并不这么简单。 **空接口本质上是一对指针，用来装载值类型时会发生装箱，造成变量逃逸。**例如用Cache来缓存int64类型，缓存对象c底层是个map，在map的buckets中存储着元素的哈希值、key和value，对于c而言，bucket这里存储的value是一个一个的空接口，而实际上的int64会在堆上单独分配，空接口的data指针指向堆上的int64，相较于直接把int64存储在map的bucket里，堆分配方式凭空多出来一次堆分配，而且还多占用了两倍的内存空间。 针对这个问题，改造上述缓存为泛型缓存。 将Cache改为cache，因为 Go 1.17 的泛型实现还不支持导出，泛型相关的类型和函数只能在当前包中使用； Go 1.17 的泛型支持默认是关闭的，构建可执行文件时应指定参数来显式的开启，而且，据观察build命令只有在编译main包时，才会透传这个参数，这就限制了只能在main包中使用泛型。 改造好后，同样用来存储int64类型的数值，然后，通过反射观察底层map存储的是什么样类型的元素，下边的代码会打印int64，也就是说，泛型缓存cache的底层map会直接在bucket中存储int64类型的数值，没有额外的堆分配。 可以看出，泛型能够解决这个问题。但是，这不是没有代价的。 泛型的实现： 使用泛型最直接的代价就是：编译器会为同一套模板的每个类型，都生成一套代码，可能会导致可执行文件大小有所增加；而且，即便使用泛型，要想在一个缓存对象里面存储多种不同类型的值，依然要使用空接口，否则，一个缓存对象就只能存储一种类型的值。 所以说，泛型本质上是编译阶段的代码生成，它并不会替代空接口，空接口主要用来实现语言的动态特性，它们的适用场景根本不同~ go 1.18 Go 从 1.18 正式开始支持泛型，这里的T就是类型参数，与java、c++对比，没有使用\u003c\u003e，而是使用[]： 同时，为了让编译器能够更高效的检查类型参数的合法性，还引入了类型参数的约束条件。这个约束条件在语法层面是通过接口来实现的，它明确描述了调用方传入的类型参数，需要符合什么样的要求。 这里的fmt.Stringer接口限制了调用ToString方法时，传入的参数必须实现了String()方法，如果传入的参数不符合要求，就无法通过编译。当然，此处的接口也并不是原来的接口。 若使用原来的接口，就只能通过接口的方法集来约束类型参数，但这有时是行不通的。因为，这些内置类型是没有实现任何方法的，比如int32、int64。 例如，写了一个Sum()函数，想让它支持所有整型类型，该如何实现呢？ Go 1.18 将接口扩展了一下。原来的接口只能定义方法集，扩展后的接口增加了类型集，通过类型集指明哪些类型是被支持的。 例如，Integer接口用作约束条件时，就可以支持所有的有符号整型。 但这依然不够，如果我们自定义了type MyInt int类型，同样也希望被支持，这个约束条件又该怎么写呢？总不能每次新增加自定义类型都去改一下接口的类型集吧？ 为了解决这个问题，Go 新增加了符号~，只要写~int，就可以支持**int类型以及基于int创建的所有自定义类型**， **注意：**这种扩展后的接口，目前只用于泛型的约束条件。 现在有了泛型，只需要实现一遍功能函数，就可以通过多种类型参数来调用。 **问题：**编译器会不会给每种支持的类型都生成一套代码呢？// ==TODO== 貌似不用。通过字典和gcshape实现。没听懂。先这样吧。。。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:8","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.3 常用关键字 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:3:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.3.1 defer 使用defer的最常见场景是在函数调用结束后完成一些收尾工作，通常用来： 关闭文件描述符； 关闭数据库连接； 解锁资源 通常使用defer会遇到两个常见的问题： defer 关键字的调用时机以及多次调用 defer 时执行顺序是如何确定的； defer 关键字使用传值的方式传递参数时会进行预计算，导致不符合预期的结果。 ==执行顺序== deferProc()负责把要执行的函数信息保存起来，称之为**defer注册**；defer注册完成后，会继续执行后面的逻辑，直到返回之前通过deferreturn执行注册的defer函数。即：先注册，再延迟调用。 defer会在函数返回之前，按照倒序执行。这是因为goroutine运行时会有一个对应的结构体g，其中有一个字段指向defer链表头，defer链表链起来的是一个个_defer结构体，新注册的defer会添加到链表头，执行时从头开始，因此执行顺序是注册顺序的倒序。 ==预计算参数== Go 语言中所有的函数调用都是传值的，虽然 defer 是关键字，但是也继承了这个特性。如下代码： func main() { startedAt := time.Now() defer fmt.Println(time.Since(startedAt)) time.Sleep(time.Second) } $ go run main.go 0s 为什么会输出0呢？这是因为：调用 defer 关键字会立刻拷贝函数中引用的外部参数，所以 time.Since(startedAt) 的结果不是在 main 函数退出之前计算的，而是在 defer 关键字调用时计算的，最终导致上述代码输出 0s。 想要解决这个问题的方法非常简单，我们只需要向 defer 关键字传入匿名函数： func main() { startedAt := time.Now() defer func() { fmt.Println(time.Since(startedAt)) }() time.Sleep(time.Second) } $ go run main.go 1s 1.3.1.1 数据结构 defer在Go语言中的结构： type _defer struct { siz int32 // 参数和返回值共占多少字节 started bool // 标记defer是否已经执行 openDefer bool // sp uintptr // 调用者栈指针 pc uintptr // 返回地址 fn *funcval // defer 关键字中传入的函数，即注册函数 _panic *_panic // 触发延迟调用的结构体，可能为空 link *_defer // 下一个_defer指针 } 可以看出runtime._defer 结构体其实是_defer调用链表上的一个元素，所有的结构体都会通过 link 字段串联成链表。 1.3.1.2 执行机制 堆分配、栈分配和开放编码是处理 defer 关键字的三种方法。 Go 1.12 引入：堆分配runtime._defer 结构体； Go 1.13 引入：栈分配的结构体； Go 1.14- 引入：基于开放编码的 defer。 1.3.1.3 堆分配 deferproc函数执行时，需要堆分配一段空间，存放_defer结构体及参数与返回值。实际上Go语言也会预分配不同规格的_defer池，执行时从空闲_defer池中取出一个，没有合适的或空闲的就会进行堆分配，用完之后再放入_defer池，以避免频繁的堆分配与回收。 Go 1.12 defer很慢！原因： _defer结构体堆分配：即使有预分配的deferpool，也需要去堆上获取和释放，而且，参数还要在堆栈间来回拷贝； _defer注册通过链表：链表本身的操作就慢！ 1.3.1.4 栈上分配 先来对比一下1.12版本和1.13版本中，defer指令编译后有什么不同？ 1.12 将_defer结构体分配在堆上。在1.13中，通过在编译阶段，增加局部变量，把defer信息保存到当前函数栈的局部变量区域，再通过deferprocStack把栈上这个_defer结构体注册到_defer链表中，执行依然是通过deferreturn实现。优化点：减少defer信息的堆分配。 1.13中的defer，官方提供的性能提升是30%。 1.3.1.5 开放编码 Go 1.14是通过在编译阶段插入代码，把defer函数的执行逻辑展开在所属函数内，从而免于创建_defer结构体，而且不需要注册到_defer链表。这种方式省去了构造_defer链表项，并注册到链表的过程。举例说明： A1可以简单的通过：定义局部变量，并在return前插入调用A1的指令 来实现延迟调用效果。但是对于A2呢？他在编译阶段是无法确定是否被调用的，因此需要一些处理。 Go语言通过一个**标识变量df**来解决这个问题。 df变量中的每一位对应一个defer函数是否要被执行。 这里先以A1举例： df变量首先需要通过异或运算|=将第1位置为1； return前插入的调用指令也应该进行修改，需要判断df变量第1位是否\u003e0，若\u003e0，在调用A1前，需要将df变量的第1位置为0，这是为了避免重复调用。 再以A2举例： 首先插入 判断是否需要将A2的标志位置为1 的代码； 然后在return前插入 检查df标志位 的代码。 这种方法将性能提高了一个数量级，但不是没有代价。 如果在code to do something，也就是还未执行到defer函数调用处，就发生了panic或runtime.Goexit函数，后面这些代码根本无法执行到，因此需要通过栈扫描的方式来发现。所以，defer变快了，但panic变得更慢了。 1.3.1.6 小结 需要注意的是，栈上分配和开放编码的方法均不适用于循环中的defer，因此也保留1.12中的堆分配方法。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:3:1","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"1.3.2 panic和recover panic 能够改变程序的控制流，调用 panic 后会立刻停止执行当前函数的剩余代码，并在当前 Goroutine 中递归执行调用方的 defer； recover 可以中止 panic 造成的程序崩溃。它是一个只能在 defer 中发挥作用的函数，在其他作用域中调用不会发挥作用。 1.3.2.1 现象 跨协程失效：panic 只会触发当前 Goroutine 的 defer； 失效的崩溃恢复：recover 只有在 defer 中调用才会生效； 嵌套崩溃：panic 允许在 defer 中嵌套多次调用。 跨协程失效 func main() { defer println(\"in main\") go func() { defer println(\"in goroutine\") panic(\"\") }() time.Sleep(1 * time.Second) } ❯ go run test_go.go in goroutine panic: ... 上述代码没有执行main中的defer，只执行了 goroutine 中的defer。 **总结：**当程序发生崩溃时只会调用当前 goroutine 的defer。 失效的崩溃恢复 func main() { defer println(\"in main\") if err := recover(); err != nil { fmt.Println(err) } panic(\"unknown err\") } ❯ go run test_go.go in main panic: unknown err ... 在主程序中调用 recover 试图中止程序的崩溃，但是从运行的结果中我们也能看出，程序没有正常退出。应该如下面这样写： func main() { defer println(\"in main\") defer func() { if err := recover(); err != nil { fmt.Println(\"错误发现:\", err) } }() panic(\"unknown err\") } ❯ go run test_go.go 错误发现: unknown err in main 可以发现程序正常执行。 总结：recover 只有在发生 panic 之后调用才会生效。然而在上面的控制流中，recover 是在 panic 之前调用的，并不满足生效的条件，所以需要在 defer 中使用 recover 关键字。 嵌套崩溃 func main() { defer println(\"in main\") defer func() { defer func() { panic(\"panic again and again\") }() panic(\"panic again\") }() panic(\"panic once\") } ❯ go run test_go.go in main panic: panic once panic: panic again panic: panic again and again ... 可以确定程序多次调用 panic 也不会影响 defer 函数的正常执行，所以使用 defer 进行收尾工作一般来说都是安全的。 1.3.2.2 数据结构 panic 关键字在 Go 语言的源代码是由数据结构 runtime._panic 表示的： type _panic struct { argp unsafe.Pointer // defer的参数空间 arg interface{} // panic的参数 link *_panic // link to earlier panic recovered bool // 是否被 recover 恢复 aborted bool // 是否被终止 pc uintptr sp unsafe.Pointer goexit bool } 和defer一样，panic也是一个链表，当有新的panic出现，也是在链表头插入新的_panic结构体。 panic执行defer时，是从头开始执行的。首先把_defer的started字段置为true，标记该defer已经开始执行，并且会把panic字段指向当前执行的panic，表示这个defer是由这个panic触发的。 如果函数A2能够正常执行，那么就会移除A2。 之所以这样设计，是为了应对defer函数没有正常结束的情况。假如此时A2顺利执行，那么执行A1： 因为A1也会触发panic，那么需要将panicA1链在panic头部，此时正在执行的panic就变成了panicA1，然后也会去执行defer链表，从标记字段会发现A1已经在执行了，且触发他的panic是panicA，所以会根据该指针找到panicA，把他**aborted标记为已终止**。 所以现在panicA已终止，A1也执行完毕，A1会被移除，当前defer链表为空。 接下来就该打印panic信息了，注意：**panic打印异常信息时，会从链表尾开始，即panic的发生顺序逐个输出。**所以此处会先panicA，再panic A1。 1.3.2.3 recover 上述过程没有添加recover，接下来看看添加recover之后的情况。 recover只做一件事，就是把当前panic的recovered字段变为true。 **以下为例。**当执行完A2时，会将当前panicA的recovered=true。每个defer执行完毕，panic都会检查当前recovered是否为true。此时会发现panicA已经被恢复了，就会把他从panic链表中移除，并且移除A2。不过A2被移除之前，要保存_defer.sp和_defer.pc，接下来就要利用这两个值跳出panicA的处理流程。 sp和pc是注册defer函数时保存的。这里sp就是函数A的栈指针，而pc就是调用deferproc函数的返回地址。 通过sp可以返回到函数A的栈帧，通过pc可以返回到调用deferproc处(即判定r\u003e0)处。若此时r=0，那么code to do something就会被重复执行，所以会将寄存器中的r=1，这样就可以跳转到deferreturn处，继续执行defer链表。**注意：deferreturn只负责执行当前函数A注册的defer函数，**他是通过栈指针来判断的。 所以，A2执行完毕，还会继续执行A1，执行完毕就结束了。 **这里要注意：**只有当defer函数执行完毕，panic才会去检查是否被恢复。但是如果defer先recover，然后又panic了呢？ 此时，由于发生了panic，所以会将panicA2注册到panic链表头，并成为当前的panic，他会去执行defer链表，当执行A2时，从标记字段发现A2已经开始执行，并且触发者是panicA，那么会将panicA终止(aborted=true)，并把A2从defer链表移除。继续执行下一个defer，A1就是由panicA2触发的了。 A1执行完毕后，会被移除，此时defer链表为空。 接下来就要输出panic信息了。 注意：在输出已经被recover的panic时，打印时会带上recovered标记。panic每一项被输出后，程序退出。 小结 用defer进行收尾工作通常是安全的，这是因为panic可以终止其他代码的执行，但不会影响到defer的执行。 在判断panic的执行过程时，只需要把握住两个链表defer和panic的执行顺序即可。 二、运行时 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:3:2","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1 并发编程 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1.1 GMP 2.1.1.1 概述 Go语言在并发编程方面有强大的能力，这离不开语言层面对并发编程的支持。谈到Go语言调度器，绕不开的是操作系统、进程与线程这些概念。 **多个线程可以属于同一个进程并共享内存空间。**因为多线程不需要创建新的虚拟内存空间，所以它们也不需要内存管理单元处理上下文的切换，线程之间的通信也正是基于共享的内存进行的，与重量级的进程相比，线程显得比较轻量。这不是挺好的嘛，为啥还要引入goroutine？ **引入goroutine的原因：**虽然线程比较轻量，但是在调度时也有比较大的额外开销。每个线程都会占用 1M 以上的内存空间，在切换线程时不止会消耗较多的内存，恢复寄存器中的内容还需要向操作系统申请或者销毁资源，每一次线程上下文的切换都需要消耗 ~1us 左右的时间，但是 Go 调度器对 Goroutine 的上下文切换约为 ~0.2us，减少了 80% 的额外开销。 ==Point：== Go语言中： 协程对应的数据结构是runtime.g； 工作线程对应的数据结构是runtime.m； 后来引入了runtine.p，**引入原因：**一开始所有的g都在一个全局队列中，多个m从全局队列中获取g时需要频繁的加解锁及等待；引入p后，m就可以直接从关联的p处获取待执行的g，不用每次都和众多m从一个全局队列中争抢任务，提高了并发性能。 其中，allgs、allm、allp分别记录所有的g、m和p。 首先看一个简单的场景 只有一个mian.main。 在main goroutine创建前，G、P、M的情况如上图。 main goroutine创建后，被加入当前P的本地队列中； 然后通过mstart开启调度循环。这个mstart是所有工作线程的入口，主要就是调用schedule函数，也就是执行调度循环。 当前队列中只有main goroutine等待执行，所以m0切换到main goroutine； 执行入口自然是runtime.main，它会做很多事情：创建监控线程、进行包初始化等，包括调用main.main，然后就可以执行main.main了！ 一个改进的场景 在main.main中又创建新的goroutine。 我们通过go关键字创建goroutine，会被编译器转换为newproc函数调用。(main goroutine也是由newproc创建的) 创建goroutine时，我们只负责指定入口、参数，而newproc会给goroutine构造一个栈帧，目的是让协程任务结束后，返回到go exit函数中，进行协程资源回收处理等工作。 新创建的goroutine，此处叫做hello goroutine，会被添加到当前P的本地runq中； 然后main.main就会返回了，然后exit()函数被调用，进程就结束了。所以此处hello goroutine并未能执行。 **问题：**问题在于，当main.main返回后，直接会调用exit()函数，会把进程都结束掉，没给hello goroutine调度执行的时间。所以应该在main.main返回前，拖延点时间给hello goroutine执行。 2.1.1.2 goroutine创建、让出与恢复 还通过一个例子来看一下。 通过函数栈帧看一下newproc的调用过程： main函数栈帧自然分配在main goroutine的协程栈中； newproc主要做的就是切换到g0栈去调用newproc1函数；为什么要切换到g0栈呢？简单来说，g0栈空间大。因为runtime中很多函数都有no-split标记，意味着这个函数不支持栈增长，而协程栈空间本来就小，容易栈溢出，而g0的栈直接分配在线程栈上，栈空间足够大。 newproc1(协程入口, 参数地址, 参数大小, 父协程, 返回地址)； newproc1首先通过acquirem()禁止当前m被抢占。**为什么不能被抢占？**因为接下来要执行的程序中，可能会把当前p保存到局部变量中，若此时m被抢占，p关联到别的m，等再次恢复时，继续使用这个局部变量里保存的p，就会造成问题。所以为了保持数据的一致性，会暂时禁止m被抢占。 接下来，会尝试获取一个空闲的g，如果当前p和调度器中都没有空闲的g，就创建一个并添加到全局变量allgs中。此处我们依然将此添加的g记为hello goroutine，此时它的状态是_Gdead，而且已然拥有自己的协程栈。 接下来，如果协程入口函数有参数，就把参数移动(拷贝)到协程栈上。 接下来，会把goexit()的地址+1，压入协程栈，即返回地址； 再把协程(hello goroutine)对应的g的startpc置为协程入口函数的起始地址，gopc置为父协程调用newproc后的返回地址，g.sched结构体用于保存现场：g.sched.sp置为协程栈指针，g.sched.pc置为协程入口函数的起始地址。 等到这个协程得到调度执行的时候，通过g.sched恢复现场，就会从协程入口函数处开始执行，而函数结束后便会返回到goexit()中，执行协程资源回收等收尾工作。到此，协程如何出场与收场就都有了着落。 接下来，newproc1还会给新建的goroutine赋予一个唯一id。给g.goid赋值前，会把协程的状态置为_Grunnable，这个状态意味着这个g可以进到run queue中了。 所以接下来会调用runqput把这个g放到当前p的本地队列中。 接下来判断，如果当前有空闲p，而且没有处于spinning状态的m，即所有m都忙，而且主协程已经开始执行了，那么就调用wakep()：启动一个m并把它置为spinning状态。 最后与一开始的acquirem()呼应，会调用releasem()允许当前m被抢占；而spinning状态的m启动后，会一直执行调度循环寻找任务，从本地runq到全局runq再到其他p的runq，只为找到个待执行的g。但此时，若main.main已经返回，那也不会执行剩余的g。 此处我们通过等待一个channel来实现调度执行g。 当前main goroutine会阻塞在\u003c-ch这里等待数据； 然后chanrecv()通过gopark()函数挂起当前goroutine，让出cpu； gopark()首先会调用acquirem()禁止当前m被抢占，然后把main goroutine的状态从_Grunning修改为_Gwaiting，main goroutine就不再是执行中状态了； 接下来调用releasem()解除m的抢占禁令； 最后调用mcall(park_m)：负责保存当前协程的执行现场； 然后切换到g0栈，调用由mcall的参数传入的这个函数，对应到这里就是park_m()函数； park_m()函数会根据g0找到当前m，把m.curg置为nil。此时当前m正在执行的g便不再是main goroutine了； 最后会调用schedule()寻找下一个待执行的g。 然后，hello goroutine要么被当前m0调度执行，要么被其他m调度执行，总归是能执行了。 等到hello goroutine执行完毕，关闭main gorutine等待的channel时，不止会修改channel的closed状态，还会处理等待队列中的g，最终调用goready()函数来结束这个g的等待状态； 而goready()函数会切换到g0栈，并执行runtime.ready()函数，目前待ready的协程自然是main goroutine，此时它的状态是_Gwaiting，接下来会被修改为_Grunnable，表示它又可以被调度执行了。 然后，它会被放入当前p的本地runq中，同协程创建时一样，接下来也会检查是否有空闲的p，并且没有spinning状态的m，是的话，也会调用weakp()函数启动新的m； 接下来hello goroutine结束，main goroutine得到调度执行，最终结束进程。 总结：底层通过newproc创建goroutine，通过gopark实现协程让出，使用goready把协程恢复到runnable状态放回到runq中 接下来，就需要了解调度循环schedule()是做啥的了，以及如何把一个可运行的协程真正的运行起来？ 2.1.1.3 goroutine让出、抢占、监控和调度 协程让出CPU分为两种：主动让出和被动让出(抢占)。其中，主动让出指协程自身要等待某种条件而主动让出，被动让出指调度器通过某种规则强制使协程让出。 主动让出 主动让出主要包括三种形式：time.Sleep()，\u003c-chan和I/O操作。 time.Sleep() 整体过程：协程执行time.Sleep()时，状态会从_Grunning变为_Gwaiting，并进入到对应的timer中等待，而timer中持有一个回调函数，在指定时间到达后调用这个回调函数，把等在这里的协程恢复到_Grunnable状态并放回到runq中。 **这里有一个问题？**谁负责触发timer注册的回调函数呢？ 答：其实每个p都有一个最小堆，存储在p.timers中，用于管理自己的timer，堆顶的timer就是接下来要触发的那一个。而每次调度时，都会调用checkTimers()函数，检查并执行那些已经到时间的timer。不过这不够稳妥，万一所有的m都在忙，那么就不能及时触发调度了，可能会导致timer执行时间发生较大偏差。所以还会通过监控线程来增加一层保障。 (接上)。监控线程是由main goroutine创建的，与GPM中的工作","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:1","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1.2 Mutex Mutex的由来，应该是mutual exclusion的前缀组合，称为\"互斥锁\"。 2.1.2.1 两种模式 Go语言sync包中Mutex的数据结构是这样的： type Mutex struct { state int32 // 存储互斥锁的状态 sema uint32 // 信号量, 用作等待队列 } state存储互斥锁的状态，加锁和解锁都是通过atomic包提供的函数原子性的操作该字段： sema用作一个信号量，主要用作等待队列。 Mutex有两种模式： **正常模式：在正常模式下，一个尝试加锁的goroutine会先自旋几次，尝试通过原子操作获得锁。若几次自旋(自旋阶段)**后仍不能获得锁，则通过信号量排队等待，所有等待者会按照先入先出(FIFO)的顺序排队。 但是当锁被释放，第一个等待者被唤醒后并不会直接拥有锁，而是需要和后来者竞争，也就是那些处于自旋阶段，尚未排队等待的goroutine，这种情况下后来者更有优势：一方面，它们正在CPU运行，自然比刚唤醒的goroutine更有优势，另一方面处于自旋状态的goroutine可以有很多，而被唤醒的goroutine每次只有一个，所以被唤醒的goroutine有很大概率拿不到锁。 这种情况下它会被重新插入到队列的头部，而不是尾部。而当一个goroutine本次加锁等待的时间超过1ms后，它会把当前Mutex从正常模式切换至饥饿模式。 **饥饿模式：**在饥饿模式下，Mutex的所有权从执行Unlock的goroutine，直接传递给等待队列头部的goroutine。后来者不会自旋，也不会尝试获得锁，即使Mutex处于Unlocked状态。它们会直接从队列的尾部排队等待。 当一个等待者获得锁后，它会在以下两种情况时将Mutex由饥饿模式切换回正常模式： 此轮获得锁的等待者的等待时间小于1ms，也就是它刚来不久； 它是最后一个等待者，等待队列已经空了，后面自然就没有饥饿的goroutine了。 综上所述：在正常模式下自旋和排队时同时存在的，执行Lock的goroutine会先一边自旋，尝试过几次后如果还没拿到锁，就需要去排队等待了。这种在排队之前先让大家来抢的模式，能够有更高的吞吐量，因为频繁的挂起、唤醒goroutine会带来较多的开销。但是又不能无限制的自旋，要把自旋的开销控制在较小的范围内。所以，在正常模式下，Mutex会有更好的性能，但是可能会出现队列尾端的goroutine迟迟抢不到锁的情况(尾端延迟)。 而饥饿模式下不再尝试自旋，所有goroutine都要排队，严格的先来后到，对于防止出现尾端延迟非常重要。 2.1.2.2 Lock和Unlock 首先看一下关于Mutex.state的几个常量定义：state的类型是int32。 第一位用作锁状态标识，置为1就表示已加锁，对应掩码常量为mutexLocked。 第二位用于记录是否已有goroutine被唤醒了，置为1表示已唤醒，对应掩码常量为mutexWoken。 第三位标识Mutex的工作模式，0代表正常模式，1代表饥饿模式，对应掩码常量为mutexStarving。 而常量mutexWaiterShift等于3，表示除了最低3位以外，state的其他位用来记录有多少个等待者在排队。 接下来看一下Lock和Unlock的代码，精简掉注释和部分race检测相关的代码。 两个方法中主要通过atomic函数实现了Fast path，相应的Slow path被单独放在了lockSlow和unlockSlow方法中，这样是为了便于编译器对Fast path进行内联优化。 Lock方法中的Fast path期望Mutex处于Unlocked状态，没有goroutine在排队，更不会饥饿。理想状况下，一个CAS操作就可以获得锁。但是如果CAS操作没能获得锁，就需要进入Slow path，也就是lockSlow方法。 Unlock方法同理，首先通过原子操作从state中减去mutexLocked，也就是释放锁。然后根据state的新值来判断是否需要执行Slow path。如果新值为0，也就意味着没有其他goroutine在排队，所以不需要执行额外操作；如果新值不为0，那就需要进入Slow path，看看是不是需要唤醒某个goroutine。 2.1.2.3 Slow path **问题：**当一个goroutine尝试给mutex加锁时，如果其他goroutine已经加了锁还没有释放，而且当前mutex工作在正常模式下，是不是就要开始自旋了呢？ 答：不一定。因为如果当前是单核场景，或者 GOMAXPROCS=1，或者当前没有其他P正在运行。这些情况下自旋是没有意义的： 自旋的goroutine在等待持有锁的goroutine释放锁，而持有锁的goroutine在等待自旋的goroutine让出CPU。 除此之外，如果当前P的本地runq不为空，相较于自旋来说，切换到本地goroutine更有效率，所以为保障吞吐量也不会自旋。 问：Goroutine 自旋的条件？ 最终，==只有在多核场景下，且GOMAXPROCS \u003e 1，且至少有一个其他的P正在running，且当前P的本地runq为空的情况下，才可以自旋。== 进入自旋的goroutine会先去争抢mutex的唤醒标识位，设置mutexWoken标识位的目的是在正常模式下，告知持有锁的goroutine在Unlock的时候不用再唤醒其他goroutine了，已经有goroutine在这里等待，以免唤醒太多的等待goroutine。 Mutex中的自旋，底层是通过procyield循环执行30次PAUSE，自旋次数上限为4，而且每自旋一次都要重新判断是否可以继续自旋。如果锁被释放了，或者锁进入了饥饿模式，亦或者已经自旋了4次，都会结束自旋。 结束自旋或者根本不用自旋的goroutine就该尝试原子操作修改mutex的状态了。把此时mutex.state保存到old中，把要修改为的新state记为new： 如果old处于饥饿模式或加锁状态，goroutine就得去排队，所以这些情况下排队规模要加1。 如果是正常模式，就要尝试设置lock位，所以new中这一位要置为1； 如果当前goroutine等待的时间已经超过1ms，而且锁还没被释放，就要将mutex的状态切换为饥饿模式。 把排队规模和几个标识位都设置好后，在执行原子操作修改state前，若是当前goroutine持有唤醒标识的话，还需要将唤醒标识位重置，因为，接下来无论是去抢锁还是单纯去排队： 如果原子操作成功了，要么成功抢到了锁，要么是成功进到了等待队列，当前goroutine都不再是被唤醒的goroutine了，所以要释放唤醒标识。 而如果原子操作失败，也就意味着其他goroutine在我们保存mutex.state到old后又修改了state的值，当前goroutine就要回过头去继续从自旋检查这里开始再次尝试，所以也需要释放自己之前抢到的唤醒标识位，从头再来。 Lock操作的Slow path 继续展开原子操作成功的分支： 如果是抢锁操作成功了，那么加锁的Slow path就可以宣告结束了； 如果是排队规模设置成功了，还要决定是排在等待队列头部还是尾部。如果当前goroutine已经排过队了，是在Unlock时从等待队列中唤醒的，那就要排到等待队列头部；如果是第一次排队，就得排到等待队列尾部，并且从第一次排队开始记录当前goroutine的等待时间。接下来就会让出，进到等待队列里，队列里的goroutine被唤醒时，要从上次让出的地方开始继续执行。接下来会判断，如果mutex处在正常模式，那就接着从自旋开始抢锁，如果唤醒后mutex处在饥饿模式，那就没有其他goroutine会和自己抢了，锁已经轮到自己这里，只需要把mutex.state中lock标识位设置为加锁，把等待队列规模减去1，再看看是不是要切换到正常模式，也就是自己的等待时间是不是小于1ms，或者等待队列已经空了，最后设置好mutex.state就一切ok了。 Unlock操作的Slow path 进到Unlock的Slow path说明除去lock标识位以外，剩下的位不全为0。 如果处在正常模式，若等待队列为空，或者已经有goroutine被唤醒或获得了锁，或者锁进入了饥饿模式，那就不需要唤醒某个goroutine，直接返回即可。否则就要尝试抢占mutexWoken标识位，获取唤醒一个goroutine的权利。抢占成功后，就会通过runtime_Semrelease函数唤醒一个goroutine；如果抢占不成功就进行循环尝试，直到等待队列为空，或者已经有一个goroutine被唤醒或获得了锁，或者锁进入了饥饿模式，则退出循环。 而在饥饿模式下，后来的goroutine不会争抢锁，而是直接排队，锁的所有权是直接从执行Unlock的goroutine传递给等待队列中首个等待者的，所以不用抢占mutexWoken标识位。第一个等待者唤醒后，会继承当前goroutine的时间片立刻开始运行，也就是继续lockSlow这里goroutine被唤醒以后的逻辑。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:2","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1.3 信号量 上节主要讲解 sync.Mutex 的第一个字段 state，本节主要讲解 sync.Mutex 的第二个字段 sema。 **问题：**协程等待一个锁时，要如何休眠、等待和唤醒呢？ **答：**这要靠runtime.semaphore来实现，这是可供协程使用的信号量。runtime内部会通过一个大小为251的sematable来管理所有semaphore，怎么通过这个大小固定的table来管理执行阶段数量不定的semaphore呢？大致思路如下： 这个sematable存储的是251课平衡树的根，平衡树中每个节点都是一个sudog类型的对象，要使用一个信号量时，需要提供一个记录信号量数值的变量，根据它的地址进行计算，映射到sematable中的一颗平衡树上，找到对应的节点就找到了该信号量的等待队列。 例如，我们常用的sync.Mutex中，有一个sema字段，用于记录信号量的数值，如果有协程想要等待这个Mutex，就会根据sema字段的地址计算映射到sematable中的某棵平衡树上，找到对应的节点，也就找到了这个Mutex的等待队列了。所以，syne.Mutex是通过信号量来实现排队的。 而channel需要有读(发送)等待队列以及写(接收)等待队列，还要支持缓冲区功能，所以并没有直接使用信号量来实现排队，而是自己实现了一套排队逻辑。 不过，无论是信号量还是channel，底层实现都离不开runtime.mutex，因为它们都需要保障在面临多线程并发时，不会出现同步问题。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:3","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1.4 抢占式调度 2.1.4.1 Go 1.13 Go 1.13 的抢占方式是依赖于栈增长检测代码的，并不算严格意义上的抢占式调度。 首先看一段代码： 按理来说，这段代码运行后应该会不断输出递增的数字，但是在 Go 1.14 之前，运行这段代码会发生阻塞。 运行环境是双核CPU，排查之后发现是在执行STW时发生的阻塞。 GC 开始前需要STW来进行开启写屏障等准备工作，所以STW就是要抢占所有的P，让GC得以正常工作。而示例程序中的main goroutine没能被抢占，它一直在执行，而STW一直在等待它让出，这样就陷入了僵局。 **问题：**为什么会陷入这样的局面？ 答：首先，梳理下STW的主要逻辑。GC需要抢占所有的P，但这不是说抢占就ok的，所以它会记录下自己要等待多少个P让出，当这个值减为0，目的就达到了。对于当前P、以及陷入系统调用的P(_Psyscall)、还有空闲状态的P，直接将其设置为_Pgcstop即可。对于还有G在运行的P，则会将对应的g.stackguard0设置为一个特殊标识(runtime.stackPreempt)，告诉它GC正在等待它让出。此外，还会设置一个gcwaiting标识(sched.gcwaiting=1)，接下来就通过这两个标识符的配合，来实现运行中的P的抢占。 这是怎么实现的呢？ goroutine创建之初，栈的大小时固定的，为了防止出现栈溢出的情况，编译器会在有明显栈消耗的函数头部插入一些检测代码。通过g.stackguard0来判断是否需要进行栈增长，但如果g.stackguard0被设置为特殊标识runtime.stackPreempt，便不会执行栈增长，而是去执行一次调度(schedule())，在schedule()调度执行时，会检测gcwaiting标识，若发现GC在等待执行，便会让出当前P，将其置为_Pgcstop状态。 这样看来，示例main goroutine之所以没能让出，是因为空的for循环并没有调用函数，也就没有机会执行栈增长检测代码，所以它并不知道GC在等待它让出。 2.1.4.2 Go 1.14 之后 依赖栈增长检测代码的抢占方式，遇到没有函数调用的情况就会出现问题。 在 Go 1.14 及之后，这一问题得到了解决。在Linux系统上，这种真正的抢占式调度是基于信号来实现的，所以也称为异步抢占。 函数preemptone用来抢占一个P，定位到该函数，对比 1.13 和 1.14 的实现有何不同。 信号发送 1.13 中，preemptone函数主要负责设置g.preempt=true，并将g.stackguard0设置为特殊标识(stackPreempt)。 而在 1.14 中，增加了最后这个if语句块： 第一个判断用于确认当前硬件环境是否支持这种异步抢占，这个常量值(preemptMSupported)是在编译期间就确定的； 第二个判断(debug.asyncpreemptoff)用于检测用户是否允许开启异步抢占，默认情况下是允许的，但是用户可以通过GODEBUG环境变量来禁用异步抢占。 如果这两条验证都通过了，就将p.preempt字段置为true，实际的抢占操作会交由preemptM函数来完成。 定位到preemptM函数，它的主要逻辑是通过runtime.signalM函数，向指定M发送sigPreempt信号，怎么发送的呢？ signalM函数会通过调用操作系统中信号相关的系统调用，将指定信号发送给目标线程。信号发出去了，异步抢占的前一半工作就算是完成了。 信号处理 后一半工作就要由接收到信号的工作线程来完成了。 线程接收到信号后，会调用对应的信号handler来处理，Go 语言中的信号交由runtime.sighandler来处理，sighandler在确定信号为sigPreempt以后，会调用doSigPreempt函数。它会首先判断runtime是否要对指定的G进行异步抢占，通过什么来判断呢？ 首先，指定的G与其对应P的preempt字段都要为true，而且指定的G还要处在_Grunning状态，还要确认在当前位置打断G并执行抢占是安全的，那么怎么确保安全性呢？ 指定的G可以挂起并安全的扫描它的栈和寄存器，并且当前被打断的位置并没有打断写屏障； 指定的G还有足够的栈空间来注入一个异步抢占函数调用(asyncPreempt)； 这里可以安全的和runtime进行交互，主要就是确定当前并没有持有runtime相关的锁，继而不会在后续尝试获得锁时发生死锁。 确认了要抢占这个G，并且此时抢占是安全的以后，就可以放心的通过pushCall向G的执行上下文中注入异步抢占函数调用了，被注入的异步抢占函数(asyncPreempt)是一个汇编函数，它会先把各个寄存器的值保存在栈上，也就是先保存现场到栈上，然后调用runtime.asyncPreempt2函数，这个函数最终会去执行schedule()，到这里，异步抢占就完成了。 再去执行上边的示例程序，发现可以正常运行。也就是说，即使空的for循环没有被插入栈增长检测代码，在 1.14 中，通过注入异步回调函数的方式，同样能实现抢占式调度。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:4","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1.5 Channel 2.1.5.1 数据结构 type hchan struct { qcount uint dataqsiz uint buf unsafe.Pointer elemsize uint16 closed uint32 elemtype *_type sendx uint recvx uint recvq waitq sendq waitq lock mutex } 问：channel底层数据结构是怎么设计的？ 通过make创建一个缓冲区大小为5，元素类型为int的channel，ch是存在于函数栈帧上的一个指针，指向堆上的hchan数据结构。 因为channel支持协程间并发访问，所以要有一把锁lock来保护整个数据结构。 对于有缓冲来讲，需要知道缓冲区在哪，已经存储了多少个元素，最多存储多少个元素，每个元素占多大空间，所以实际上，缓冲区就是个数组buf、elemsize。 因为 Go 运行中，内存复制、垃圾回收等机制依赖数据的类型信息，所以hchan还要有一个指针，指向元素类型的类型元数据elemtype。 此外，channel支持交替的读(接收)写(发送)，需要分别记录读、写下标的位置recvx、sendx。 当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读(接收)和写(发送)recvq、sendq。 此外，channel能够close，所以还要记录它的关闭状态closed。 综上所述，channel底层就长这个样子： 初始状态下，ch的缓冲区为空，读、写下标都指向下标0的位置，等待队列也都为空。然后，一个协程g1向ch发送数据[1,5]，此时缓冲区已满，若还要继续发送数字6，g1就会进到ch的发送等待队列中。这是一个sudog类型的链表，里面会记录哪个协程在等待，等待哪个channel，等待发送的数据在哪儿等信息。 接下来协程g2从ch接收一个元素，recvx指向下一个位置，第0个位置就空出来了，所以会唤醒sendq中的g1，将这里的数据发送给ch，然后缓冲区再次满了，sendq队列为空。 这个过程中，sendx和recvx都会从0到4再到0，循环移动，所以channel的缓冲区也被称为环形缓冲区。 2.1.5.2 发送数据 阻塞式发送 如果使用以下方式给channel发送数据： ch \u003c- 10 不阻塞的情况： 缓冲区还有空闲位置； 有协程在等着接收数据； 阻塞的情况： ch为nil； ch没有缓冲区，而且也没有协程等着接收数据； ch有缓冲区，但缓冲区已用尽。 非阻塞式发送 select { case ch \u003c- 10: ... default: ... } 若采用这种写法，如果检测到ch可以发送数据，就会执行case分支；如果会发生阻塞就执行default分支。 2.1.5.3 接收数据 阻塞式接收 以下是接收数据的三种写法，都允许发生阻塞： \u003c-ch // 1. 丢弃结果 v := \u003c-ch // 2. 将结果赋值给v v, ok := \u003c-ch // 3. comma ok风格的写法，ok为false表示ch已关闭，此时v是channel元素类型的零值 不阻塞的情况： 在缓冲区中有数据； 有协程等着发送数据； 阻塞的情况： ch为nil； ch无缓冲而且没有协程等着发送数据； ch有缓冲但缓冲区无数据； 非阻塞式接收 select { case \u003c-ch: ... default: ... } 若采用非阻塞式接收方式，如果检测到ch的recv操作不会阻塞时，就会执行case分支；如果会阻塞就会执行default分支。 2.1.5.4 多路select 上面的select只是针对单个channel的操作。多路select是指存在两个或更多的case分支，每个分支可以是一个channel的send或recv操作。 例如一个协程通过多路select等待ch1和ch2，这里default分支是可选的，暂且把这个协程记为g1。 多路select会被编译器转换为对runtime.selectgo函数调用，首先看参数： 第一个参数cas0指向一个数组，数组里装的是select中所有的case分支，顺序是send在前recv在后； 第二个参数order0指向一个uint16类型的数组，数组大小等于case分支的2倍，实际上被用作两个数组：第一个数组用来对所有channel的轮询进行乱序，第二个数组用来对所有的channel的加锁操作进行排序。轮询需要乱序才能保障公平性，而按照固定算法确定加锁顺序才能避免死锁； 第三个参数pc0和race检测相关； nsends和nrecvs分别表示所有case中，执行send和recv操作的分支分别有多少个。 block表示多路select是否要阻塞等待。对应到代码中，就是有default分支的不会被阻塞，没有的会阻塞。 再看返回值： 第一个返回值int类型，代表最终哪个case分支被执行了，对应到cas0指向的数组下标。但是如果进入到default分支，就会对应-1。 第二个返回值bool类型，用于在执行recv操作的case分支时，表明是实际接收到了一个值，还是因channel关闭而得到了零值。 多路select需要进行轮询来确定哪个case分支可操作了，但是轮询前需要先加锁，所以selectgo函数执行时，会先按照有序的加锁顺序，对所有的channel加锁； 然后按照乱序的轮询顺序检查所有channel的等待队列和缓冲区； 假如检查到ch1时，发现有数据可读，那就直接拷贝数据，进入对应分支； 假如所有的channel都不可操作，就把当前协程添加到所有channel的sendq或recvq中，对应这个例子，g1会被添加到ch1的recvq及ch2的sendq中，之后g1会被挂起，并解锁所有的channel； 假如接下来ch1有数据可读了，g1就会被唤醒，完成对应的分支操作后，会再次按照加锁顺序对所有channel加锁，然后从所有的sendq或recvq中将自己移除； 最后全部解锁后返回。 虽然，channel的读写操作写法众多，但事实上，channel阻塞式的send操作会被编译器转换为对runtime.chansend1()的调用，而它内部只是调用了runtime.chansend()；非阻塞式的send操作会被编译器转换为对runtime.selectnbsend()的调用，它也仅仅是调用了runtime.chansend()。所以，send操作主要是通过runtime.chansend()函数实现的。 同样的，channel阻塞式的recv操作会被编译器转换为对runtime.chanrecv1()的调用，而它内部只是调用了runtime.chanrecv()；comma ok风格的写法会被编译器转换为对runtime.chanrecv2()的调用，它的内部也是调用runtime.chanrecv()，只不过比chanrecv1()多了一个返回值；非阻塞式的recv操作会根据是否为comma ok风格，被编译器转换为对runtime.selectnbrecv()或selectnbrecv2()的调用，而它们两个也仅仅是调用了runtime.chanrecv()，所以，recv操作主要是通过runtime.chanrecv()函数实现的。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:5","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.1.6 协程 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:6","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.2 内存管理 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.2.1 内存分配器 程序中的数据和变量都会被分配到程序所在的虚拟内存中，内存空间包含两个重要区域：栈区（Stack）和堆区（Heap）。函数调用的参数、返回值以及局部变量大都会被分配到栈上，这部分内存会由编译器进行管理；不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，堆中的对象由内存分配器分配并由垃圾收集器回收。 从进程虚拟空间地址来看： 程序要执行的指令在代码段； 全局变量、静态数据等都会分配在数据段； 函数的局部变量、参数和返回值都会分配在函数栈帧； 2.2.1.1 设计原理 内存管理一般包含三个不同的组件，分别是用户程序（Mutator）、分配器（Allocator）和收集器（Collector），当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:1","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.2.2 GC 从进程虚拟空间地址来看： 程序要执行的指令在代码段； 已初始化的全局变量、静态常量等都会分配在**==数据段==**； 未初始化的全局变量、静态常量等都会分配在**==BSS段==**； 函数的局部变量、参数和返回值都会分配在**==函数栈帧==**； ==Point：== 由于函数调用栈会在函数返回后销毁，因此，如果不能在编译阶段确定数据对象的大小，或者对象生命周期会超过当前所在函数，那么就不适合分配在栈上，而应该分配到堆上。 问题：为什么需要垃圾回收？ 主要是为了释放==堆内存==。随着程序运行，有些数据不会再被用到了，直接分配在栈上的数据，会随着函数调用栈的销毁释放自身占用的内存；但是分配在堆上的数据，它们占用的内存需要程序主动释放才可以重新使用，否则就会成为垃圾，而越积越多的垃圾会不断的消耗系统内存。 垃圾回收有几种常见方式： 手动垃圾回收：C、C++、Rust。一旦释放早了，后续对该数据的访问便会出错，这就是所谓“悬挂指针”问题；而如果忘了释放，它又会一直占用内存，出现“内存泄露”； 自动垃圾回收：Python、Ruby、Java、Go。由运行时识别不再有用的数据并释放他们所占的内存，内存何时被释放，被释放的内存如何处理，都不需要我们关心。 跟踪式垃圾回收 引用计数式垃圾回收 2.2.2.1 设计原理 问题：自动垃圾回收怎么区分哪些数据是垃圾呢？ 可以确定，程序中用得到的数据，一定是从==栈、数据段==这些根节点追踪得到的数据。也就是说，从这些根节点追踪不到的数据一定是没用的数据，一定是垃圾。因此，目前主流的自动垃圾回收算法都是使用**“可达性”近似等价“存活性”**的。 标记-清扫算法 标记清除（Mark-Sweep）算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成**标记（Mark）和清除（Sweep）**两个阶段： 标记阶段 — 从根对象出发查找并标记堆中所有存活的对象； 清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表。 三色抽象 三色抽象可以清晰的展现追踪式回收中对象状态的变化过程。 垃圾回收开始时，所有数据均为白色； 然后把直接追踪到的root节点都标记为灰色：灰色代表基于当前节点展开的追踪还未完成； 当基于某个节点的追踪任务完成后，便会把该节点标记为黑色：表示它是存活数据，而且无需基于它再次进行追踪了。 基于黑色节点找到的所有节点都被标记为灰色，表示还要基于它们进一步开始追踪。 当没有灰色节点时，就意味着标记工作可以结束了。此时，有用数据都为黑色，垃圾都为白色。接下来回收这些白色数据即可。 标记-清扫算法的缺点： 标记-清扫算法容易造成很多小内存，这一问题可以： 基于**BiBOP(Big Bag of Pages)**的思想，把内存块划分为多种大小规格，对相同规格的内存块进行统一管理。 还可以通过紧凑的方法减少碎片化内存，但是会带来多次移动的开销。 复制回收算法 还有一种复制式回收算法，他会把堆划分为两个相等的空间From和To，程序执行时使用From空间，垃圾回收时会扫描From空间，把能追踪到的数据复制到To空间，当所有能追踪到的数据都复制到To空间后，把From和To空间角色对换，原来的To变为From，原来的From可以全部回收用作新的To。这种复制式不会产生碎片化问题，但是会浪费一半的堆内存。 为了提高堆内存利用率，通常会和其他垃圾回收算法搭配使用，只在一部分堆内存中使用复制式回收。比如分代回收。 分代回收 分代回收主要基于弱分代假说：大部分对象都会在年轻时死亡。 新生代对象：新创建的对象； 老年代对象：经受住特定次数GC而依然存活的对象； 基于弱分代假说，大部分对象会在最初经历的GC中死亡，也就是说新生代对象成为垃圾的概率高于老年代对象。因此，可以将数据划分为新生代和老年代，降低老年代执行垃圾回收的频率，不用每次都处理所有数据，将明显提高垃圾回收执行的效率。而且，新生代和老年代还可以分别采用不同的回收策略，进一步提升回收效益并减少开销。 以上均为跟踪式垃圾回收，而引用计数式垃圾回收有很大的不同。 引用计数式 **引用计数指的是一个数据对象被引用的次数。**程序执行过程中，会更新数据对象的引用计数，当对象的引用计数为0时，就表示这个对象不再被使用，可以回收它所占用的内存。因此，在引用计数法中垃圾识别的任务已经被分摊到每次对数据对象的操作中。虽然引用计数法可以及时回收无用内存，但是高频率的更新引用计数也会造成不小的开销，而且如果发生循环引用情况，那么将无法回收。 以上讨论均是在暂停用户程序，只专注于垃圾回收的前提下进行的，也即所谓**==STW==(Stop The World)**。但实际上用户程序无法接受长时间的暂停。 增量式垃圾回收 **增量式垃圾回收：**将长时间的垃圾回收，分成若干小段，和用户程序交替执行，即缩短每次暂停的时间，但增加暂停的次数。 **这会带来新的问题：**保不齐垃圾回收程序前脚刚标记一个黑色对象，用户程序后脚就修改了它(将它指向白色对象，此时原黑色对象应变为灰色，但并没有)，垃圾回收程序有可能误判将白色对象(应为灰色对象)回收。原因如下： 在三色抽象中，黑色对象处理完毕，不会被再次扫描，而灰色对象还会被回收器继续处理，所以若出现黑色对象到白色对象的引用，同时没有任何灰色对象可以抵达这个白色对象，它就会被判为垃圾，但实际上它仍是存活数据。 强三色不变式与弱三色不变式 如果能够做到不出现黑色对象到白色对象的引用，就必然不会出现这样的错误了。这被称为**“强三色不变式”**。 若把条件放宽一点，允许出现黑色对象到白色对象的引用，但是可以保证通过灰色对象可以抵达该白色对象，这样也可以避免这个错误，这被称为**“弱三色不变式”**。 读写屏障 实现**“强/弱三色不变式”通常的做法是建立“读/写屏障”**。 **写屏障：**会在写操作中插入指令，目的是把数据对象的修改通知到垃圾回收器，所以写屏障通常要有一个记录集，而记录集是采用顺序存储还是哈希表、记录精确到被修改的对象还是只记录其所在页等问题，就是写屏障具体实现要考虑的了。 “强三色不变式”提醒我们关注白色指针指向黑色对象的写入操作，无论如何都不允许出现黑色对象到白色对象的引用。可以把白色指针变为灰色，也可以把黑色对象变为灰色。这些都属于**==“插入\"写屏障==**。 “弱三色不变式”则提醒我们关注对那些到白色对象路径的破坏行为。例如要删除灰色对象到白色对象的引用时，可以把白色对象变为灰色。这种写屏障属于**==“删除\"写屏障==**。 **读屏障：**确保用户程序不会访问到已经存在副本的陈旧对象。（主要针对复制式回收） 多核 **并行垃圾回收：**多线程并行执行垃圾回收程序。 并发垃圾回收：用户程序与垃圾回收程序并发执行，这有可能导致错误(有些线程开启了写屏障，有些还没开启，所以通常采用下边那种) 主体并发式垃圾回收：在某些阶段采取STW(确保大伙儿都开启了写屏障)，在其他阶段支持并发。 主体并发增量式垃圾回收：在\"主体并发式垃圾回收\"基础上支持增量式回收， 2.2.2.2 Go Go语言的垃圾回收采用标记-清扫算法，支持**==主体并发增量式回收==，使用插入与删除两种写屏障结合的混合写屏障**。 Go语言的GC在准备阶段(Mark Setup)会为每个p创建一个mark worker协程，把对应的g指针存储到p中，这些后台mark worker创建后很快进入休眠，等到标记阶段得到调度执行。 接下来第一次STW，GC进入_GCMark阶段。全局变量gcphase记录GC阶段标识，全局变量writeBarrier记录是否开启写屏障，全局变量gcBlackenEnabled用于标识是否允许进行GC标记工作(此处置为1，标识允许)。 在STW的情况下开启写屏障。等所有准备工作做好以后，start the world，所有p都会知道写屏障已开启，然后这些后台mark worker可以得到调度执行，展开标记工作。 当没有标记任务时，第二次STW，GC进入_GCMarkTermination阶段，确认标记工作确实已经完成，然后停止标记工作，将gcBlackenEnabled置为0。 接下来，进入_GCOff阶段，关闭写屏障。**start the world，进入清扫阶段。**进入_GCOff阶段前，新分配的对象会直接标记为黑色，进入_GCOff阶段后，再新分配的对象就是白色的了。 执行清扫工作的协程由runtime.main在gcenable中创建，对应g指针存储在全局变量sweep中，到清扫阶段，这个后台的**sweeper会被加入到runq中，它得到调度执行时会执行清扫任务**，因为清扫工作也是增量进行的，所以每一轮GC开始前，还要先确保完成上一轮GC未完成的清扫工作。 这样看来似乎只需要两轮STW，标记与清扫工作并发增量执行的GC而已。 问题： **关于GC标记工作：**依照标记-清扫算法，标记工作要从扫描bss段、数据段、以及协程栈上的这些root结点开始，追踪到堆上的节点，那怎么确定这些数据对象是否是GC感兴趣的指针呢？ Go语言在编译阶段会生成bss段、数据段等对应的元数据，存储在可执行文件中，通过各模块对应的moduledata可以获得gcdatamask、gcbssmask等信息，它们会被用于判断特定root节点是否为指针。 协程栈也有对应的元数据，存储在stackmap中，扫描协程栈时，通过对应元数据，可以知道栈上的局部变量、参数、返回值等对象中那些","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:2","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.2.3 堆内存分配 Go语言的runtime将堆地址空间划分成一个一个的arena，arena区域的起始地址被定义为常量arenaBaseOffset，在amd64架构下的Linux环境下，每个arena的大小是64MB，起始地址也对齐到64MB。每个arena包含8192个page，所以每个page大小为8KB。 **问题：**因为程序运行起来所需分配的内存块有大有小，而分散的、大小不一的碎片化内存一方面可能降低内存利用率，另一方面可能会提高要找到大小合适的内存块的代价。 解决：为降低碎片化内存给程序性能造成的不良影响，Go语言的堆分配采用了与tcmalloc内存分配器类似的算法。**简单来讲就是：**按照一组预置的大小规格把内存页划分成块，然后把不同规格的内存块放入对应的空闲链表中。程序申请内存时，分配器会先根据要申请的内存大小，找到最匹配的规格，然后从对应空闲链表中分配一个内存块。 Go 1.16 runtime包给出了67种预置的大小规格，最小8B，最大32KB。 所以，在划分的整整齐齐的arena里，又会按需划分出不同的span，每个span包含一组连续的page，并且按照特定规格划分成等大的内存块。大小关系是：arena -\u003e span -\u003e page -\u003e 内存块。这些就组成了堆内存。 2.2.3.1 数据结构 在堆内存之外，有一大票用于管理堆内存的数据结构。 mheap用于管理整个堆内存； 一个arena对应一个heapArena结构； 一个span对应一个mspan结构； mheap中，有一个全局的mspan管理中心，它是一个长度为136的数组，数组元素是一个**mcentral结构**+一个padding。 问题：mcentral怎么管理span呢？ **解答：**实际上，一个mcentral对应一种mspan规格类型，记录在spanclass中，spanclass高七位标记内存块大小规格编号，runtime提供的预置规格对应编号1到67，编号0留出来用作标记大于32KB的大块内存，也即一共68种。然后每种规格会按照是否不需要GC扫描，进一步区分开，用最低位进行标识。包含指针的需要GC扫描，归为scannable这一类，不含指针的归为noscan这一类。所以共分为136种。 每种spanclass的mcentral中，会进一步将已用尽与未用尽的mspan分别管理，每一种又会放到两个并发安全的set中：一个是已清扫的，一个是未清扫的。 全局mspan管理中心mcentral方便取用各种类型的mspan，但是为了保障多个p之间并发安全，免不了频繁的加锁、解锁，为降低多个p之间的竞争性，Go语言的每个p都有一个本地小对象缓存p.mcache，从这里取用就不用再加锁了。mcache有一个长度为136的*mspan类型的数组，还有专门用于分配小于16字节的noscan类型的tiny内存，当前p需要用到特定规格类型的mspan时，先去本地缓存这里找对应的mspan，如果没有或者用完了，就去mcentral获取一个放到本地，把已用尽的归还到mcentral的full set中， 接下来看heapArena，这里存储着arena的元数据，里面有一群位图标记。 其中，bitmap位图，用一位标记这个arena中一个指针大小的内存单元到底是指针还是标量，再用一位来标记这块内存单元的后续单元是否包含指针，而且为了便于操作，bitmap中用一字节标记arena中4个指针大小的内存空间，低4位用于用于标记指针/标量，高4位用于标记扫描/终止。例如此处slice，bitmap第一字节的0-3位分别标记三个对应字段是指针还是标量，第4-6位分别标记三个对应字段是否需要继续扫描。 pageInUse是个uint8类型的数组，长度为1024，所以一共8192位。这个位图只标记**处于使用状态(mSpanInUse)**的span的第一个page。例如，arena中第一个使用状态的span包括两个page，对应pageInUse中第0位标为1，第二个span也在使用中，它包括三个page，但只有第一个page对应的第2位会被标记为1。 pageMarks的用法和pageInUse一样，只标记每个span的第一个page，在GC标记阶段会修改这个位图，标记哪些span中存在被标记的对象，在GC清扫阶段会根据这个位图，来释放不含标记对象的span， spans是个*mspan类型的数组，大小为8192，正好对应arena中的8192个page，所以用于定位一个page对应的mspan在哪儿。mspan管理着span中一组连续的page，同mcentral一样，将划分的内存块规格类型记录在spanclass中。 nelem记录着当前span共划分成多少个内存块，freeIndex记录着下个空闲内存块的索引。 与heapArena不同，mspan这里的位图标记，面向的是划分好的内存块单元。 allocBits位图用来标记哪些内存块已经被分配了。 gcmarkBits是当前span的标记位图，在GC标记阶段会对这个位图进行标记，一个二进制位对应span中的一个内存块，到GC清扫阶段会释放掉旧的allocBits，然后把标记好的gcmarkBits用作新的allocBits，这样未被GC标记的内存块就能回收利用了。当然，还会重新分配一段清零的内存给gcmarkBits位图。 2.2.3.2 分配策略 mallocgc是负责堆分配的关键函数，runtime中的new系列和make系列函数都依赖它。 它的主要逻辑可以分为四个部分： 第一部分：辅助GC。如果程序申请堆内存时，正处于GC标记阶段，当下已分配的堆内存还没标记完，你这边又要分配新的内存，万一内存申请的速度超过了GC标记的速度，就可能会出现内存不够的情况。所以，申请一字节内存需要做多少扫描工作？或者说，完成一字节扫描工作后可以分配多大的内存空间？这都是根据GC扫描的进度更新计算的。 每次执行辅助GC，最少要扫描64KB。这是因为协程每次执行辅助GC，多出来的部分会作为信用存储到当前g中，就像信用卡的额度一样，后续再执行mallocgc()时，只要信用额度用不完，就不用执行辅助GC了。 此外，还有一种方法可以逃避辅助GC：窃取信用。后台的GC mark worker执行扫描任务时，会在全局gcController这里(bgScanCredit)积累信用，如果能够窃取足够多的信用值来抵消当前协程背负的债务(说明此时空闲内存足够大)，那就不用执行辅助GC了。 **第二部分：空间分配。**这里需要根据要分配的空间大小，以及是否为noscan型空间来选择不同的分配策略。 如果是noscan类型且大小\u003cmaxTinySize，会使用tiny allocator； 大小\u003emaxSmallSize的内存分配，包括noscan和scanable类型，都会采用大块内存分配器； maxSmallSzie\u003e=大小\u003e=maxTinySize的noscan类型、以及maxSmallSize\u003e=大小的scanable类型，会使用直接匹配预置大小规格来分配。 大小\u003e32KB的大块内存额外处理，这是因为预置的内存规格最大才32KB，所以会直接根据所需页面数，分配一个新的span。 而对于\u003c16B的内存分配，也不直接匹配预置内存规格，主要是为了减少浪费：如果需要连续分配16次1B的内存，每次分配时匹配预置的内存规格为8B(这是最小的了)，那么每次就会浪费7B。而**tiny allocator能够将几个小块的内存分配请求合并**，所以例子中16次1B的内存分配请求可以合并到一个16B的内存块中。诸如此类，可以提高内存使用率。 **tiny allcoator分配内存的大致过程：**每个p的mcache有专门用于tiny allocator的内存(mcache.tiny)。这是一个16B的内存单元，mcache.tinyoffset记录这段内存已经用到哪里了，如果tiny allocator还够分配size大小的内存，就在tiny内存块中直接分配。 (接上)如果剩余的空间不够了，就从当前p的mcache中，找到对应的mspan，重新拿一个16B大小的内存块来用。如果本地缓存中相应规格的mspan也没有空间了，就会从mcentral中拿一个新的mspan过来，分配完以后，如果新拿来的内存块的剩余空间比旧内存的剩余空间还要大，那就用新的内存块把旧的tiny替换掉(旧的还在mcache，只不过不引用了)。 对于最后一种，直接通过本地mcache与全局mcentral配合工作，找到匹配规格的mspan即可。 空间分配好了还没完，还要记录下哪些内存已被分配，哪些数据需要GC扫描，才能继续内存管理工作。所以接下来需要进行一系列位图标记。 2.2.3.3 位图标记 **问题：**通过一个堆内存地址，如何找到对应的heapArena和mspan？ 已知：一个堆内存地址p，arena区域起始地址如图(arenaBaseOffset)，每个arena大小为heapArenaBytes。 求：p在第几个arena中？ 答：arena编号 = (p-arenaBaseOffset)/heapArenaBytes 已知：amd64架构的Linux环境下，一个arena大小和对齐边界都是64M(26位)，而虚拟地址空间中的线性地址有48位，那48位的线性地址可以寻址的虚拟空间就是2^48这么大。 求：这么大的空间可以划分成多少个arena？ 答：2^48/64M=4M Go开发者把h","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:3","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"2.2.4 栈内存分配 2.2.4.1 栈内存分配过程 堆内存分配中的arena中的span除了用作堆内存分配外，也用于栈内存分配，只是用途不同的span对应的mspan状态不同，用作堆内存的mspan是mSpanInUse状态，用作栈内存的是mSpanManual状态。 为提高栈内存分配效率，调度器初始化时，会初始化两个用于栈内存分配的全局对象： stackpool面向32KB以下的栈分配，栈大小必须是2的幂，最小为2KB； **大于等于32KB的栈，由stackLarge**来分配这也是个mspan链表的数组，长度为25，mspan规格从8KB开始，之后每个链表的mspan规格都是前一个的2倍，8KB和16KB这两个链表实际上一直是空的，留着他们是方便使用mspan包含页面数的(以2为底)对数作为数组下标。 初始化后，这些链表都还是空的，接下来它们会作为全局栈缓存来使用。 同堆内存分配一样，每个p也有用于栈分配的本地缓存，这相当于是stackpool的本地缓存。 要分配栈内存时： 小于32KB的栈空间，会优先使用当前p的本地缓存。如果本地缓存中对应规格的内存块链表为空，就从stackpool分配16KB的内存放到本地缓存(stackcache)中，然后继续从本地缓存分配；如果stackpool中对应的链表也为空，就从堆内存中直接分配一个32KB的span，划分成对应的内存块大小放到stackpool中；不过有些情况下，是无法使用本地缓存的，在不能使用本地缓存的情况下，就直接从stackpool分配； 本地无可用缓存，从stackpool分配： stackpool也为空： 无法使用本地缓存： 大于等于32KB的栈空间，就计算需要的page数目，并以2为底求对数(log2npage)，将得到的结果作为stackLarge数组的下标，找到对应的空闲span链表。若链表不为空，就拿一个过来用；若链表为空，就直接从堆内存分配一个拥有这么多个页面的span，并把它整个用于分配栈内存， 链表不为空： 链表为空： 2.2.4.2 栈增长 栈内存初始分配发生在goroutine创建时，由于初始栈大小都是2KB，在实际业务中可能会不够用，所以需要实现一种在运行阶段动态增长栈的机制。 goroutine的栈增长，是通过编译器和runtime合作实现的。编译器会在函数的头部安插检测代码，检查当前剩余的栈空间是否够用。若不够用，就调用runtime中的相关函数来增长栈空间(runtime.morestack_noctxt)，栈空间是成倍增长的，需要增长时，就先把当前的栈空间大小x2，并把协程状态置为_Gcopystack，接下来调用copystack函数分配新的栈空间并拷贝旧栈上的数据，释放旧栈的空间，最后恢复协程运行_Grunning。 2.2.4.3 栈收缩 栈收缩可以减少运行中的协程对栈空间的浪费。 栈收缩不会缩到比2KB还小。 唯一可以触发栈收缩的地方就是**GC**。 GC通过scanstack函数寻找标记root节点时，如果发现可以安全的收缩栈，就会执行栈收缩；不能马上执行时，就设置栈收缩标识(g.preemptShrink=true)，等到协程检测到抢占标识(stackPreempt)，在让出CPU前会检查这个栈收缩标识，为true时就会先进行栈收缩，再让出CPU。 2.2.4.4 栈释放 但是结束运行的协程的栈空间该怎么回收利用？ 常规gorontine结束时，会被放到调度器对象的空闲g队列(sched.gFree)中，这里的空闲协程分两种： 一种有协程栈(sched.gFree.stack)； 一种没有协程栈(sched.gFree.noStack)。 创建协程时，会先看看这里有没有空闲协程可以用，优先使用有栈的协程，其次使用无栈的协程。 不过，常规goroutine运行结束时，都有协程栈，应该进到哪个队列呢？ 如果协程栈没有增长过(还是2KB)，就把这个协程放到有栈的空闲g队列中。而这些空闲协程的栈，也会在GC执行markroot时被释放，到时候有栈的空闲g也会加入到无栈的空闲g队列中。 如果协程栈有增长过，就把协程栈释放掉，再把协程栈放入无栈的空闲g队列中。 **问题：**那么栈释放到哪里了呢？是放回到当前p的本地缓存？还是放回到全局栈缓存？抑或是直接还给堆内存？ **答：**其实都有可能，要视情况而定。 小于32KB的栈：在释放时会先放回本地缓存中，如果本地缓存对应链表中栈空间总和大于32KB，就把一部分放回stackpool中，本地这个链表只保留16KB；如果本地缓存不可用，也会直接放回stackpool中。而且，如果发现这个mspan中，所有内存块都被释放了就会把它归还给堆内存。 **大于等于32KB的栈：**如果当前处于GC清理阶段(gcphase == _GCoff)，就直接释放到堆内存；否则先把它放回到stackLarge。 三、面试题 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:4","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.1 Goroutine调度 题目：1 func main() { runtime.GOMAXPROCS(1) var wg sync.WaitGroup wg.Add(3) go func(n int) { println(n) wg.Done() }(1) go func(n int) { println(n) wg.Done() }(2) go func(n int) { println(n) wg.Done() }(3) wg.Wait() } 首先，第2行runtime.GOMAXPROCS(1)把GMP模型中**P的数量限制为1**，这也就限制了任一时刻只允许一个M执行Go代码。在这个前提下，再来分析这几个goroutine的执行顺序。 通过关键字go来创建新的goroutine，实际上会被编译器转化为对runtime.newproc的调用。该函数的主要逻辑就是先切换至系统栈，然后调用newproc1函数，分配并初始化一个新的g，再通过runqput把新的g添加到**当前P的本地runq**中。 听起来，最后的输出应该是1 2 3。但实际上最后的输出是3 1 2。 实际上，P不仅有本地runq，还有一个runnext字段，用来保存下次要运行的g，newproc1中调用runqput时会用到这个runnext。过程如下，我们将输出的数值作为对应goroutine的代号，： 首先，1号goroutine被记在runnext中，2号goroutine把1号goroutine挤走，1号goroutine进入到本地runq； 接下来，3号goroutine又会把2号goroutine挤走，2号goroutine会进入本地runq队列尾部； 调度goroutine执行时，通过runqget获取待执行的g。而runqget也会对runnext特殊处理，**优先调度runnext**这里记录的g，再按顺序调度本地runq中记录的g； 因此，3号goroutine优先执行，然后是本地runq队列，也就是3 1 2。 **本题只有 3 个goroutine，那如果是 4、5、6、… 个呢？**又是什么情况？请看下题！ 题目：2 func main() { runtime.GOMAXPROCS(1) var wg sync.WaitGroup N := 4 // 可以不断增大 N，临界点在 257 for i := 1; i \u003c= N; i++ { wg.Add(1) go func(n int) { println(n) wg.Done() }(i) } wg.Wait() } 其中，4个goroutine的输出是4 1 2 3，5个goroutine的输出是5 1 2 3 4，直到257个goroutine的输出是257 1 2 ... 256，可以看出N \u003c= 257时，都是这个规律。 但是N \u003e 257时又是什么情况呢？不要忘记全局runq！！！ 先解释一下N \u003c= 257是为啥？P的runnext可以记录1个g，本地runq可以记录256个g，一共就是257个。所以若N = 257，就会出现如下情况： 接下来若又到达258号g，会把257号g挤走，但本地runq已满，所以**257号g会和本地runq中的前一半g**一起进到全局runq中(之所以取前一半是为了防止饥饿，之所以随机放到全局runq是为了避免多核cpu修改同一个缓存)。 按照平时描述的调度逻辑：先从本地runq获取待执行的g，没有的话再从全局runq获取，还没有的话就去别的p那里steal一部分。所以： 这里最先执行的是runnext中的258号goroutine； 接下来是本地runq中的129号-256号； 最后全局队列中的g才会被拿回本地runq。 ==但实际上并非如此==。实际运行发现，在129号-256号之间，会发现1号和2号也穿插在这段区间内被执行了。这个问题与runq的排队逻辑无关，属于调度逻辑的范畴。 在介绍runtime.schedule时，介绍过每隔61个schedtick就会优先从全局runq中获取goroutine，这样是为了避免在每个p的本地runq都繁忙的时候，全局runq中的goroutine迟迟得不到调度的情况。 问答题集合 问：GPM模型中，P引入的原因？ 答： 一开始所有的g都在一个全局runq中，用一个全局的mutex保护全局runq，多个m从全局runq中获取g时需要频繁的加解锁及等待； g的每次执行会被随机的分到不同的m，造成在不同m的频繁切换，破坏程序的局部性；(这点有点怪，有待确定) 每个m都会关联一个内存分配缓存，造成大量的内存开销，但实际上只有执行g的m才需要，那些阻塞在调度的m根本不需要； 引入p后，m就可以直接从p处获取待执行的g，不用每次都和众多m从一个全局队列中争抢任务，提高了并发性能。 问：多个线程可以属于同一个进程并共享内存空间。 因为多线程不需要创建新的虚拟内存空间，所以它们也不需要内存管理单元处理上下文的切换，线程之间的通信也正是基于共享的内存进行的，与重量级的进程相比，线程显得比较轻量。这不是挺好的嘛，为啥还要引入goroutine？ 答： 虽然线程比较轻量，但是在调度时也有比较大的额外开销； 每个线程都需要一个用户栈和内核栈，当需要使用系统资源的时候，会通过系统调用进入内核态。(为什么要分开？为了防止用户态代码访问内核数据)。当系统的线程达到一定规模，内核栈和用户栈会占用大量内存；并且，操作系统基于时间片的策略调度所有线程，若线程规模过大，为了降低延迟，线程每次获得的时间片会被压缩，从而导致线程切换频率变大。线程的频繁切换也会占用大量CPU资源。而高并发的场景需求就是要频繁切换。 引入协程，可以节省内存空间，降低调度代价。协程的调度不需要操作系统参与，只需要用户态程序调度。 每个线程都会占用 1M 以上的内存空间，在切换线程时不止会消耗较多的内存，恢复寄存器中的内容还需要向操作系统申请或者销毁资源，每一次线程上下文的切换都需要消耗 ~1us 左右的时间，但是 Go 调度器对 Goroutine 的上下文切换约为 ~0.2us，减少了 80% 的额外开销。 **问：**谁负责触发timer注册的回调函数？ 答：timer的触发分为调度触发和监控线程触发，两者主要是通过调用函数checkTimers()来实现。 其实每个p都有一个最小堆p.timers，用于管理自己的timer，堆顶的timer就是接下来要触发的那一个(老版本这个堆是全局的，就很慢！)。而工作线程每次调度时(执行schedule()时)，都会调用checkTimers()函数，检查并执行那些已经到时间的timer。不过这不够稳妥，万一所有的m都在忙，那么就不能及时触发调度了，可能会导致timer执行时间发生较大偏差。所以还会通过监控线程来增加一层保障。 监控线程是由main goroutine创建的，与GPM中的工作线程不同，并不需要依赖p，也不由GPM调度。监控线程有多个任务，其中一项便是保障timer的正常执行。监控线程检测到接下来有timer要执行时(遍历所有的p，找出下次最先执行(时间值最小)的时间和其所在的p)，若此时无空闲m，便会创建新的工作线程以保障timer可以顺利执行。 问：如何抢占？具体说说？ 答：监控线程要本着公平调度的原则，对运行时间过长的p实行**“抢占”**操作。就是告诉那些运行时间超过特定阈值(10ms)的g，该让出了！ Go 1.14之前依赖于栈增长。**展开：**当runtime希望某个协程让出CPU时，就会把他的stackguard赋值为stackPreempt，这是一个非常大的值，真正的栈指针不会指向这个位置，因此用作特殊标识。进而会跳转到morestack处，而morestack会调用runtime.newstack()函数，负责栈增长工作。不过他在进行栈增长工作前会先判断stackguard0是否等于stackPreempt，等于的话就不进行栈增长了，而是执行一次协程调度。这种方式的缺点是过度依赖栈增长代码，如果来个空的for{}循环，因为与栈增长无关，程序就会卡死在这个地方。 其实，为了充分利用CPU，监控线程还会抢占处在系统调用中的p，因为一个协程要执行系统调用，就要切换到g0栈，在系统调用没执行完之前，这个m和g其实绑定了，不能被分开，也就用不到p，所以在陷入系统调用前，当前m会让出p，解除m.p与当前p的强关联，只在m.oldp中记录这个p。p的数目毕竟有限，如果有其他协程正在等待执行，那就会把他关联到其他m。 不过如果当前m从系统调用中恢复，会先检测之前的p是否被占用，没有的话就继续使用，否则再去申请一个，没申请到的话，就把当前g放入全局runq中，然后当前线程就睡眠了。 **问：**那抢占时，怎么知道某个g运行时间过长了呢？ 答：p里面有一个schedtick字段，每当调度执行一个新的g，并且不继承上个g的时间片时，就会把p.schedtick++，而sysmontick.schedwhen记录上一次调度的时间。监控线程如果监测到sysmontick.schedtick与p.schedtick不相等，说明这个p发生了新的调度，就会同步sysmontick.schedtick的值，并更新调度时间sysmontick.schedwhen；但若二者相等，说明没发生新的调度，或者即使发生了新的调度，也沿用了之前的时间片，所以可以通过当前时间与sysmontick.schedwhen的差值来判断当前p上的g是","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:6:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.2 组合式继承 问：如下代码输出什么？ 问：组合式继承中，编译器生成包装方法的规则？ ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:7:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.3 闭包 func main() { x()() } func x() (y func()) { y = func() { println(\"y\") } return func() { println(\"z\") y() } } 会输出什么呢？ 会不断的输出z。 先看main函数的栈帧： x函数只有返回值没有参数，而x的返回值是一个函数。函数作为参数、返回值或者被赋值给变量时，就被称为Function Value。所以这里的y是一个Function Value。Function Value本质上是一个指针，指向一个runtime.funcval结构体，这个结构体存储了对应函数的指令入口地址。x返回一个匿名函数，而这个函数中捕获了y，所以这个返回值是一个闭包对象。闭包对象就是一个有捕获列表的Function Value而已。 也就是说在这个函数入口地址后面，会有该闭包函数捕获的变量，**不过这里捕获的究竟是变量的值还是它的地址？**其实，如果被捕获的变量在其赋初值后没有在被修改过，就会捕获变量的值；反之，就捕获变量的地址。 在函数x中，先给y赋初值，return又将新的返回值写到了y，所以闭包对象这里捕获的是变量的地址。 但是当y的地址被捕获了，当x执行结束，main函数调用返回的y时，这里的栈帧就不再为调用x服务了，所以被捕获的变量需要逃逸到堆上，返回值这里就要存储y在堆上的地址，但是，这样就改变了返回值的类型，所以让y逃逸到堆上是行不通的。 那么，编译器会怎样处理返回值的地址被捕获的情况呢？ 实际上，编译器会在堆上分配一个y的副本，记为y'，同时为x生成一个局部变量，存储y'在堆上的地址，记为py'，然后在函数x和返回的闭包对象中都使用副本y'，这里捕获的是y'的地址，只在x返回前将y'的值拷贝到返回值空间，这样y和y'都指向堆上的同一个闭包对象。而在调用x的栈帧销毁后，这个闭包对象依然可以正常使用其捕获的变量。 当返回值y被调用，找到这里的闭包函数，输出第一个字母z，然后通过捕获列表找到y'，调用y'指向的函数-还是这个函数，因此会不停输出z。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:8:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.4 GC 问：自动垃圾回收怎么区分哪些数据是垃圾呢？ 可以确定，程序中用得到的数据，一定是从栈、数据段这些根节点追踪得到的数据。也就是说，从这些根节点追踪不到的数据一定是没用的数据，一定是垃圾。因此，目前主流的自动垃圾回收算法都是使用**“可达性”近似等价“存活性”**的。 ==标记-清扫算法== 标记清除（Mark-Sweep）算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成**标记（Mark）和清除（Sweep）**两个阶段： 标记阶段 — 从根对象出发查找并标记堆中所有存活的对象； 清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表。 ==三色抽象== 三色抽象可以清晰的展现追踪式回收中对象状态的变化过程。 垃圾回收开始时，所有数据均为白色； 然后把直接追踪到的root节点都标记为灰色：灰色代表基于当前节点展开的追踪还未完成； 当基于某个节点的追踪任务完成后，便会把该节点标记为黑色：表示它是存活数据，而且无需基于它再次进行追踪了。 基于黑色节点找到的所有节点都被标记为灰色，表示还要基于它们进一步开始追踪。 当没有灰色节点时，就意味着标记工作可以结束了。此时，有用数据都为黑色，垃圾都为白色。接下来回收这些白色数据即可。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:9:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.5 Mutex 问：RWMutex 是读优先还是写优先？读优先的话，如果一直有读请求，那么写请求会饥饿吗？⭐🚩 RWMutex 是一个读/写互斥锁，在某一时刻只能由任意数量的 reader 持有 或者 一个 writer 持有。也就是说，要么放行任意数量的 reader，多个 reader 可以并行读；要么放行一个 writer，多个 writer 需要串行写。 一旦涉及到多个 reader 和 writer ，就需要考虑优先级问题，是 reader 优先还是 writer 优先： 读者优先（readers-preference）：读者优先是读操作优先于写操作，即使写操作提出申请资源，但只要还有读者在读取操作，就还允许其他读者继续读取操作，直到所有读者结束读取，才开始写。读优先可以提供很高的并发处理性能，但是在频繁读取的系统中，会长时间写阻塞，导致写饥饿。 写者优先（writers-preference）：写者优先是写操作优先于读操作，如果有写者提出申请资源，在申请之前已经开始读取操作的可以继续执行读取，但是如果再有读者申请读取操作，则不能够读取，只有在所有的写者写完之后才可以读取。写者优先解决了读者优先造成写饥饿的问题。但是若在频繁写入的系统中，会长时间读阻塞，导致读饥饿。 RWMutex 的数据结构： type RWMutex struct { w Mutex // 用于控制多个写锁，获得写锁首先要获取该锁，如果有一个写锁在进行，那么再到来的写锁将会阻塞于此 writerSem uint32 // 写阻塞等待的信号量，最后一个读者释放锁时会释放信号量 readerSem uint32 // 读阻塞的协程等待的信号量，持有写锁的协程释放锁后会释放信号量 readerCount int32 // 记录读者个数 readerWait int32 // 记录写阻塞时读者个数 } RWMutex 设计采用写优先方法。 问题要点： 写操作是如何阻止写操作的？ RWMutex包含一个互斥锁(Mutex)，写锁定必须要先获取该互斥锁。 写操作是如何阻止读操作的？ RWMutex.readerCount是个整型值，用于表示读者数量，不考虑写操作的情况下，每次读锁定将该值+1，每次解除读锁定将该值-1，所以readerCount取值为[0, N]，N为读者个数，实际上最大可支持2^30^个并发读者。 当写锁定进行时，会先将readerCount减去2^30^，从而readerCount变成了负值，此时再有读锁定到来时检测到readerCount为负值，便知道有写操作在进行，只好阻塞等待，同时还会对readerCount+1，这样等待的读操作个数并不会丢失，只需要将readerCount加上2^30^即可获得。 所以，写操作将readerCount变成负值来阻止读操作。 读操作是如何阻止写操作的？ 写操作到来时，会把RWMutex.readerCount值拷贝到RWMutex.readerWait中，用于标记排在写操作前面的读者个数。前面的读操作结束后，除了会递减RWMutex.readerCount，还会递减RWMutex.readerWait值，当RWMutex.readerWait值变为0时唤醒写操作。 为什么写锁定不会被饿死？ 写操作要等待读操作结束后才可以获得锁，写操作等待期间可能还有新的读操作持续到来，如果写操作等待所有读操作结束，很可能被饿死。然而，通过RWMutex.readerWait可完美解决这个问题。 写操作到来时，会把RWMutex.readerCount值拷贝到RWMutex.readerWait中，用于标记排在写操作前面的读者个数。 前面的读操作结束后，除了会递减RWMutex.readerCount，还会递减RWMutex.readerWait值，当RWMutex.readerWait值变为0时唤醒写操作。 问：Mutex的工作模式？正常模式和饥饿模式？ Mutex 共有两种工作模式：正常模式和饥饿模式。 正常模式下，一个尝试加锁的goroutine会先自旋几次，尝试通过原子操作获得锁。若几次自旋之后不能获得锁，就会通过信号量进行排队等待。所有的等待者会按照先入先出的顺序排队，但是当锁被释放，被唤醒的等待者并不会直接获得锁，它需要和处于自旋阶段尚未排队的goroutine进行竞争。 这种情况后来者更有优势，首先是因为处于自旋状态的goroutine可能有多个，且后来者正在CPU上运行，显然比刚被唤醒的goroutine有优势。如果被唤醒的goroutine没有获得锁，它将再次进入排队队列，但是是直接在队头。 当一个goroutine本次等待加锁的时间超过1ms，它会把当前Mutex切换到饥饿模式，Mutex的所有权直接转让给队首goroutine，此时后来者也不再自旋，而是直接进入队列尾部开始排队。 当获得Mutex的goroutine是队列中最后一个时，或者它的等待时间小于1ms，它会把Mutex的状态改回正常模式。 正常模式需要大家争抢锁，从而获得更高的吞吐量；而饥饿模式对防止出现尾端延迟特别重要。 问：什么时候会发生自旋？ 加锁时，如果当前 Locked 位为1，则说明当前该锁由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续探测 Locked 位是否变为0，这个过程就是「自旋」。实际上就是执行了30次PAUSE。 多核场景。因为单核场景是没有意义的，一个占着CPU进行自旋等待锁，一个占着锁。这无意义。 gomaxprocs\u003e1。同上。 至少有一个其他的p正在running \u0026\u0026 当前p的本地runq队列为空。比起调度这个goroutine进行自旋，不如调度别的goroutine。 自旋上限为4，每执行一次自旋都会重新判断是否可以继续自旋。如果锁被释放了，或者锁进入了饥饿模式，或者已经自旋了4次，都会结束自旋。 问：为什么自旋次数有上限？ 自旋是为了避免频繁获得锁失败导致的协程切换，这样开销很大。若锁的持有时间很短，自旋几次就能获得，这样就能减少切换，但如果锁的持有时间很长，那就会无意义的自旋，反倒浪费了CPU资源，所以通常限制自旋次数，自旋次数内无法获得锁就让出CPU，以免长时间无意义的等待。 问：协程是如何进行排队的呢？ 通过sema字段。runtime内部会通过一个大小为251的sematable来管理所有semaphore，这个sematable存储的是251课平衡树的根，平衡树中每个节点都是一个sudog类型的对象，要使用一个信号量时，需要提供一个记录信号量数值的变量，根据它的地址进行计算，映射到sematable中的一颗平衡树上，找到对应的节点就找到了该信号量的等待队列，该信号量的协程就在这个队列中进行等待唤醒。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:10:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.6 方法集 问：为什么要限制 T 和 *T 不能声明同名方法？ 首先，T和*T是两种类型，分别有着自己的类型元数据，而根据自定义类型的类型元数据，可以找到该类型关联的方法列表。 可以确定的是，T的方法集里，全部都是有明确定义的接收者为T类型的方法；而*T的方法集里，除了有明确定义的接收者为*T的方法以外，**还会有编译器生成的一些\"包装方法”：**这些包装方法是对接收者为T类型的同名方法的\"包装”。 如果给T和*T定义了同名方法，就有可能和编译器生成的包装方法发生冲突，所以 Go 干脆不允许为T和*T定义同名方法。 问：为什么编译器要为 *T 生成 T 的同名方法？ 这里首先要明确一点：通过*T类型的变量直接调用T类型接收者的方法只是一种语法糖。经验证，这种调用方式，编译器会在调用端进行指针解引用，并不会用到这里的包装方法。 ==实际上，编译器生成包装方法主要是为了支持接口。== 问：为什么是为了支持接口？ 非空接口包含两个指针：一个和类型元数据相关，一个和接口装载的数据相关。虽然有数据指针，但是并不能像语法糖那样，对指针进行解引用来调用值接收者的方法。这是为啥呢？ 原因：方法的接收者是方法调用时隐含的第一个参数，Go 中的函数参数通过栈进行传递，如果参数是指针类型，平台确定了，指针大小也就确定了。但如果要解引用为值类型，就必须有明确的类型信息，编译器才能知道这个参数该在栈上分配多大的内存空间。对于接口来说，编译阶段并不能确定该接口会装载的数据类型，也就不能进行指针解引用。所以选择为*T生成一套T的包装方法。 在链接阶段，不会用到的方法会被忽略。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:11:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.7 抢占式调度 问：如何进行抢占式调度？ Go 1.14 之前，是借助于栈增长检测来实现抢占式调度的，若goroutine中没有导致栈增长的代码，就不会被抢占，所以这不算真正的抢占式调度。 以GC举例，STW阶段需要抢占所有的P，但不是说抢占就能抢占的，会先记录要等待多少个P，当这个值减为0，目的就达到了。 对于当前P、以及陷入系统调用的P(_Psyscall)、还有空闲状态的P，直接将其设置为_Pgcstop即可； 对于还有G在运行的P，则会将对应的g.stackguard0设置为一个特殊标识(runtime.stackPreempt)，告诉它GC正在等待它让出。此外，还会设置一个gcwaiting标识(设置gcwaiting=1)，接下来就通过这两个标识符的配合，来实现运行中的P的抢占。 goroutine创建之初，栈的大小是固定的，为了防止出现栈溢出的情况，编译器会在有明显栈消耗的函数头部插入一些检测代码，通过g.stackguard0来判断是否需要进行栈增长：如果g.stackguard0被设置为特殊标识runtime.stackPreempt，便不会执行栈增长，而是去执行一次调度(schedule())；在schedule()调度执行时，会检测gcwaiting标识，若发现GC在等待执行，便会让出当前P，将其置为_Pgcstop状态。 依赖栈增长检测代码的抢占方式，遇到没有函数调用的情况就会出现问题。 Go 1.14 之后，preemptone函数会判断当前硬件环境是否支持异步抢占，还会判断用户是否允许开启异步抢占，默认情况下是允许的。如果这两条验证都通过了，就将p.preempt字段置为true，实际的抢占操作会交由preemptM函数来完成。preemptM函数会调用signalM函数，通过调用操作系统中信号相关的系统调用，将指定信号发送给目标线程。 线程接收到信号后，会调用对应的信号处理函数sighandler来处理，sighandler在确定信号为sigPreempt(抢占信号)以后，它会首先判断runtime是否要对指定的G进行异步抢占，通过什么来判断呢？ 指定的G与其对应P的preempt字段都要为true，而且指定的G还要处在_Grunning状态； 还要确认在当前位置打断G并执行抢占是安全的 指定的G可以挂起并安全的扫描它的栈和寄存器，并且当前被打断的位置并没有打断写屏障； 指定的G还有足够的栈空间来注入一个异步抢占函数调用(asyncPreempt)； 这里可以安全的和runtime进行交互，主要就是确定当前并没有持有runtime相关的锁，继而不会在后续尝试获得锁时发生死锁。 确认了要抢占这个G，并且此时抢占是安全的以后，就可以放心的通过pushCall向G中注入异步抢占函数调用了，被注入的异步抢占函数(asyncPreempt)最终会去执行schedule()，到这里，异步抢占就完成了。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:12:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.8 Channel 问：channel 是否是并发安全的？ 是滴 问：怎么通过 channel 实现协程间的通信？ 问：向已关闭的 channel 写 会发生什么？从已关闭的 channel 读 会发生什么？⭐ func testClose() { intChan := make(chan int, 3) intChan \u003c- 2 // 1. 关闭一个channel close(intChan) // 2. 向关闭的channel中写入数据 //intChan \u003c- 3 // 会报错 panic: send on closed channel // 3. 从关闭的channel读取数据 num, ok := \u003c-intChan fmt.Println(num, ok) // 2 true num, ok = \u003c-intChan fmt.Println(num, ok) // 0 false } 问：如何优雅关闭一个 Channel？⭐⭐ 先说说为啥Channel关闭这么麻烦： 不能无脑关闭，如果一个channel已经关闭，重复关闭channel会导致panic 往一个关闭的channel写数据，也会导致panic **channel的关闭原则：**⭐ 不要在消费者端关闭channel 不要在有多个并行的生产者时关闭channel(应该只在唯一或者最后一个生产者协程中关闭channel) ==优雅的关闭，其实要分情况的：== 单个生产者，单个消费者 ​ 直接让生产者关闭。 单个生产者，多个消费者 这种情况很简单，直接让生产者关闭即可。 多个生产者，单个消费者 ​ 不能在消费端关闭，这违背了channel关闭原则。可以让消费者标记一个close信号，通知生产者不要继续写数据。 多个生产者，多个消费者 ​ 可以设置一个中间调解者角色。 首先设置一个通道toStop，当生产者或消费者达到条件，就向toStop发送关闭信号，中间角色收到后关闭stopCh(仅用作通知发送者不要再向数据通道dataCh写数据了)，生产者收到stopCh的关闭信号后，不再向dataCh写数据。 请注意，信号通道toStop的容量必须至少为1。如果它的容量为0，则在中间调解者还未准备好的情况下就已经有某个协程向toStop发送信号时，此信号有可能被抛弃。 参考文章： https://gfw.go101.org/article/channel-closing.html 问：channel 的发送、接收、关闭？ 发送： 发送操作会对 hchan 加锁； 当 recvq 中存在等待接收的 goroutine 时，若有 goroutine 要发送数据，就会调用 memmove 函数从发送 goroutine 的栈中，直接拷贝数据到接收 goroutine 的栈中，不经过 channel (无论 channel 是否有缓冲区)； 当 recvq 等待队列为空时，会判断 hchan.buf 是否可用。如果可用，则会将发送的数据拷贝至 hchan.buf 中； 如果 hchan.buf 已满，那么将当前发送 goroutine 置于 sendq 中排队，并在运行时中挂起； 向已经关闭的 channel 发送数据，会引发 panic； 对于无缓冲的 channel 来说，它天然就是 hchan.buf 已满的情况，因为它的 hchan.buf 的容量为 0。 接收： 接收操作会对 hchan 加锁。 当 sendq 中存在等待发送的 goroutine 时，意味着此时的 hchan.buf 已满（无缓存的天然已满），分两种情况： 如果是有缓存的 hchan，那么先将缓冲区的数据拷贝给接收 goroutine，再将 sendq 的队头 sudog 出队，将出队的 sudog 上的元素拷贝至 hchan 的缓存区。 如果是无缓存的 hchan，那么直接将出队的 sudog 上的元素拷贝给接收 goroutine。两种情况的最后都会唤醒出队的 sudog 上的发送 goroutine。 当 sendq 发送队列为空时，会判断 hchan.buf 是否可用。 如果可用，则会将 hchan.buf 的数据拷贝给接收 goroutine。 如果 hchan.buf 不可用，那么将当前接收 goroutine 置于 recvq 中排队，并在运行时中挂起。 与发送不同的是，当 channel 关闭时，goroutine 还能从 channel 中获取数据。如果 recvq 等待列表中有 goroutines，那么它们都会被唤醒接收数据。如果 hchan.buf 中还有未接收的数据，那么 goroutine 会接收缓冲区中的数据，否则 goroutine 会获取到元素的零值。 关闭： 如果关闭已关闭的 channel 会引发 painc。 关闭 channel 后，如果有阻塞的读取或发送 goroutines 将会被唤醒： 读取 goroutine 会获取到 hchan 的已接收元素，如果没有，则获取到元素零值； 发送 goroutine 的执行则会引发 painc。 问：channel 非得关闭吗？⭐🚩 不用，channel 没有被任何协程用到后最终会被 GC 回收。 但，需要分别考虑两种情况： channel 的发送次数 == 接收次数： 发送者 goroutine 和接收者 goroutine 分别都会在发送或接收结束时结束各自的 goroutine (也即是channel中没有阻塞的goroutine)，此时，channel由于没有被使用，就会被垃圾收集器自动回收。这种情况下，不关闭 channel，没有任何副作用。 channel 的发送次数 != 接收次数： channel 的发送次数不等于接收次数时，可能会导致发送者或接收者阻塞在channel。因此channel由于一直被使用，导致无法被垃圾回收。阻塞的 goroutine 和未被回收的 channel 都造成了内存泄漏的问题。 问：如何判断channel已关闭？🤔❓ 通过 v, ok := \u003c-chan，若已关闭，ok 就是 false； 似乎得分有缓冲和无缓冲： // 1. 有缓冲时，只要缓冲区有数据，ok就是true，因此不能用这种方法判断 func main() { ch := make(chan int, 2) ch \u003c- 1 close(ch) // 此处已关闭，但channel依然有数据未读完 v1, ok1 := \u003c-ch // 此时channel依然有数据未读完 fmt.Println(v1, ok1) // 1 true v2, ok2 := \u003c-ch // 此时channel没数据可读 fmt.Println(v2, ok2) // 0 false } // 2. 无缓冲时，可以酱紫判断。 func main() { ch := make(chan int) //ch \u003c- 1 close(ch) // 此处已关闭 v1, ok1 := \u003c-ch fmt.Println(v1, ok1) // 0 false v2, ok2 := \u003c-ch // 此时channel没数据可读 fmt.Println(v2, ok2) // 0 false } 通过 for range，会自动判断 channel 是否结束，如果结束则自动退出 for 循环。 同上，也得分有无缓冲。 似乎，没有什么好办法？ 问：Channel 有啥应用？ 终止信号通知。例如，main goroutine等待hello goroutine执行完毕； 任务定时。与timer结合，实现超时控制。Etcd中很常见 select { case \u003c-time.After(100 * time.Millisecond): case \u003c-s.stopc: return false } 生产者和消费者。生产者向Channel写数据，消费者从Channel读数据； 控制并发数； var limit = make(chan int, 3) func main() { // ………… for _, w := range work { go func() { limit \u003c- 1 w() \u003c-limit }() } // ………… } 问：Channel 啥时候会导致内存泄漏？ 泄漏的原因是 goroutine 操作 channel 后，处于发送或接收阻塞状态，而 channel 处于满或空的状态，一直得不到改变。 此时 goroutine 一直阻塞，得不到释放，就造成了内存泄露。其实并不是channel本身的内存泄漏？ 问：channel的底层是怎样的？ 用make创建chan时，函数栈帧上会存储chan的指针，指向堆上的hchan结构体。 因为channel支持协程间并发访问，所以要有一把**锁lock**来保护整个数据结构。 对于有缓冲来讲，需要知道缓冲区在哪，已经存储了多少个元素，最多存储多少个元素，每个元素占多大空间，所以实际上，缓冲区就是个数组buf、elemsize。 因为 Go 运行中，内存复制、垃圾回收等机制依赖数据的类型信息，所以hchan还要有一个指针，指向元素类型的类型元数据elemtype。 此外，channel支持交替的读(接收)写(发送)，需要分别记录读、写下标的位置recvx、sendx。 当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读(接收)和写(发送)rec","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:13:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.9 内存 问：内存逃逸？⭐🚩 编译器会根据变量是否被外部引用来决定是否逃逸： 如果函数外部没有引用，则优先放到栈中； 如果函数外部存在引用，则必定放到堆中； 如果栈上放不下，则必定放到堆上； 案例： **指针逃逸：**函数返回值为局部变量的指针，函数虽然退出了，但是因为指针的存在，指向的内存不能随着函数结束而回收，因此只能分配在堆上。 **栈空间不足：**当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量s占用内存过大，编译器会将其分配到堆上； **变量大小不确定：**编译期间无法确定slice的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存； **动态类型：**动态类型就是编译期间不确定参数的类型、参数的长度也不确定的情况下就会发生逃逸； **闭包引用对象：**闭包函数中局部变量i在后续函数是继续使用的，编译器将其分配到堆上； 反射：ValueOf。 问：make和new有啥区别？ **两者的作用类型不同：**new给int、string、数组分配内存，make给slice、map、channel分配内存； **两者的返回值不同：**new的返回值类型为一个指向新分配好的内存空间的一个指定类型指针。而make的返回值类型为它本身。 hash := make(map[int]bool, 10) // hash 是一个指向 runtime.hmap 结构体的指针 ch := make(chan int, 5) // ch 是一个指向 runtime.hchan 结构体的指针 new分配的内存空间会被清零，make分配空间之后会被初始化。 new分配的内存空间不一定会在堆上分配，比如说该指针就在本函数内使用。 若用ps := new([]string)初始化，new 是不负责底层数组的分配的，仅仅返回slice的起始地址，此时这个slice还没有底层数组，如果对其进行赋值，就会出错。 需要通过Append进行分配底层数组。 问：为什么要内存对齐？ 首先，CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如 32 位的 CPU ，字长为 4 字节，那么 CPU 访问内存的单位也是 4 字节。 有两个目的： 减少访存次数； 便于原子性操作。 减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如： 当内存对齐时，读取 b 只需要读取一次内存。 非内存对齐时，读取 b 需要两次访存([0, 3]，[4, 7]，然后拼接出 b)： 内存对齐对实现变量的原子性操作也是有好处的，每次内存访问是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，这个特性在并发场景下至关重要。 问：结构体是怎么进行内存对齐的？成员的顺序不同，结构体的大小会不同吗？ type demo1 struct { a int8 b int16 c int32 } type demo2 struct { a int8 c int32 b int16 } func main() { fmt.Println(unsafe.Sizeof(demo1{})) // 8 fmt.Println(unsafe.Sizeof(demo2{})) // 12 } ==结构体内存对齐规则==： 每个字段按照自身的对齐倍数来确定在内存中的偏移量，对齐倍数 = min(自身的长度，机器字长)； 排列完成后，需要对结构体整体再进行一次内存对齐。 成员的顺序不同，结构体的大小可能不同，因此结构体的内存对齐有技巧。 分析上面的代码示例(机器字长 32 位)，首先是 demo1： a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。 b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。 c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。 因此 demo1 的内存占用为 8 字节。 其次是 demo2： a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。 c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。 b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节。 demo2 的对齐倍数由 c 的对齐倍数决定，也是 4，因此，demo2 的内存占用为 12 字节。 ==额外的问题==：空 struct{} 的对齐 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 struct{} 作为结构体最后一个字段时，需要内存对齐。因为如果有指针指向该字段，返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。 因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全。我们做个试验，验证下这种情况。 type demo3 struct { c int32 a struct{} } type demo4 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(demo3{})) // 8 fmt.Println(unsafe.Sizeof(demo4{})) // 4 } 可以看到，demo4{} 的大小为 4 字节，与字段 c 占据空间一致，而 demo3{} 的大小为 8 字节，即额外填充了 4 字节的空间。 另，没有任何字段的空 struct{} 和没有任何元素的 array 占据的内存空间大小为 0，不同的大小为 0 的变量可能指向同一块地址。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:14:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.10 数据结构 问：map 是并发安全的吗？那怎么让他并发安全？那加锁的 map 和 sync.map 有啥区别？sync.map 的适用场景？⭐🚩 普通的map不是并发安全的，sync.map是并发安全的。 如何让普通的map并发安全，一般的思路有两种： 加锁，操作前先获取锁，操作完释放。缺点是：粒度太大，效率不高； 划分成几个小的 map，只操作相应小的 map。缺点是：实现复杂，容易出错。 先看看sync.map： type Map struct { mu Mutex // 保护 dirty 和 read read atomic.Value // readOnly，只读，所以是并发安全的 dirty map[interface{}]*entry // 一个非线程安全的原始 map misses int // 计数作用。每次从read中读失败，则计数+1 } map+锁 和 sync.map 的对比： 自己实现的加锁的Map，每次操作都需要先获得锁，这就造成极大的性能浪费； sync.map中有只读数据read、锁mu、普通的Mapdirty、计数器misses。其中，执行增删查改前，都会先对read进行操作，因为这是只读的，支持原子操作，也就支持并发访问。这就会省去很大一部分加锁解锁带来的开销。 性能测试结论： 插入元素：SyncMapStore \u003c MapStore \u003c RwMapStore； 查找元素：MapLookup \u003c RwMapLookup \u003c SyncMapLookup； 删除元素：RwMapDelete \u003c MapDelete \u003c SyncMapDelete 测试如下： ❯ go test -bench=. goos: windows goarch: amd64 pkg: goLearn/sync/08-sync.map cpu: 12th Gen Intel(R) Core(TM) i7-12700K BenchmarkBuiltinMapStoreParalell-20 15114511 81.30 ns/op BenchmarkBuiltinRwMapStoreParalell-20 16176103 83.39 ns/op BenchmarkSyncMapStoreParalell-20 8515656 171.0 ns/op BenchmarkBuiltinMapLookupParalell-20 21025113 61.02 ns/op BenchmarkBuiltinRwMapLookupParalell-20 26539101 45.61 ns/op BenchmarkSyncMapLookupParalell-20 285766286 4.159 ns/op BenchmarkBuiltinMapDeleteParalell-20 20315636 60.36 ns/op BenchmarkBuiltinRwMapDeleteParalell-20 18308758 69.12 ns/op BenchmarkSyncMapDeleteParalell-20 296166151 4.112 ns/op PASS ok goLearn/sync/08-sync.map 13.145s 场景分析： sync.map的读和删，性能非常好，领先 map+锁； 写，性能非常差，落后于 map+锁。 sync.map的适用场景：大量读，少量写。这是因为，sync.map本质上是利用了**==读写分离==，如果是大量写的场景，会导致missess一直增加，也就会一直触发dirty晋升为read，导致性能反而不如普通的Map+锁**。 思维发散： 可以对大Map进一步划分，分成很多个小Map，单独对每部分加锁解锁，也就是细化锁的粒度。只是实现起来太麻烦了。 问：map中，key可以为nil吗？⭐🚩 需要分情况讨论。 nil是interface{}、chan、map等类型的零值。因此，如果map的key的类型是interface{}，那么key可以为nil，就跟空接口效果一样； 如果是其他类型，nil是肯定不行的，但是对应类型的零值是ok的。 问：map中，func 可以做key吗？什么类型能做？为什么？⭐🚩 **不可以。**必须是可比较类型才能做key。那为什么要可比较的类型才能做key呢？不是直接通过 top 8 位就能拿到吗？ 因为查找 key 的过程是这样的：当出现哈希冲突，就会到同一个桶中寻找，通过 top 8 位找到对应的 key’，用 key’ 和 key 进行对比，如果一样，就可以拿到对应的 value。 因为还需要一次 对比！所以当然要可比较。。。 问：[]byte{} 和 string 怎么转换？性能？原理？各自的适用场景？⭐🚩 共两种方法： 标准转换 s1 := \"hello\" b := []byte(s1) s2 := string(b) 强制转换 func String2Bytes(s string) []byte { sh := (*reflect.StringHeader)(unsafe.Pointer(\u0026s)) bh := reflect.SliceHeader{ Data: sh.Data, Len: sh.Len, Cap: sh.Len, } return *(*[]byte)(unsafe.Pointer(\u0026bh)) } func Bytes2String(b []byte) string { return *(*string)(unsafe.Pointer(\u0026b)) } 强转换方式的性能会明显优于标准转换。 ==可以延伸如下问题==： 为啥强转换性能会比标准转换好？ 对于标准转换，无论是从[]byte转string还是string转[]byte都会涉及底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。这样，当然后者的性能会更好。 为啥当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？ 标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针指向。所以，当转换数据较大时，两者性能差距会愈加明显。 既然强转换方式性能这么好，为啥go提供给我们使用的是标准转换方式？ 首先，我们需要知道Go是一门类型安全的语言，而安全的代价就是性能的妥协。但是，性能的对比是相对的，这点性能的妥协对于现在的机器而言微乎其微。另外强转换的方式，会给我们的程序带来极大的安全隐患。如下代码会直接报错： func main() { s := \"hello\" b := String2Bytes(s) fmt.Println(b) b[0] = 'l' fmt.Println(s) } unexpected fault address 0x6c47f8 fatal error: fault [signal 0xc0000005 code=0x1 addr=0x6c47f8 pc=0x6ab5aa] s是string类型，是不可修改的。通过强转换将s的底层数组赋给b，而b是一个[]byte类型，它的值是可以修改的，所以这时对底层数组的值进行修改，将会造成严重的错误（通过defer+recover也不能捕获）。 string为啥要设计成不可修改的？ string不可修改，意味它是只读属性，这样的好处就是：在并发场景下，我们可以在不加锁的控制下，多次使用同一字符串，在保证高效共享的情况下而不用担心安全问题。 因此，对于这两种方法的适用场景，有如下参考： 在你不确定安全隐患的条件下，尽量采用标准方式进行数据转换。 当程序对运行性能有高要求，同时满足对数据仅仅只有读操作的条件，且存在频繁转换（例如消息转发场景），可以使用强转换。 问：两种方法的转换原理？ // slice 的底层数据结构 type slice struct { array unsafe.Pointer // 指向的是某个数组的首地址 len int cap int } // string 的底层数据结构 type stringStruct struct { str unsafe.Pointer // 指向的是某个数组的首地址 len int } 标准转换 const tmpStringBufSize = 32 type tmpBuf [tmpStringBufSize]byte func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte if buf != nil \u0026\u0026 len(s) \u003c= len(buf) { *buf = tmpBuf{} b = buf[:len(s)] } else { b = rawbyteslice(len(s)) } copy(b, s) return b } // rawbyteslice allocates a new byte slice. The byte slice is not zeroed. func rawbyteslice(size int) (b []byte) { cap := roundupsize(uintptr(size)) p := mallocgc(cap, nil, false) if cap != uintptr(size) { memclrNoHeapPoint","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:15:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.11 结构体和接口 基础 问：Go 如何实现 多态？原理是什么？⭐🚩 如何实现： 多态使内部结构不同的对象可以共享相同的外部接口。 Go 通过接口实现多态： 某个类型若实现了接口的所有方法，就隐式的实现了该接口； 某个类型的对象可以赋给它所实现的任意接口类型的变量； (网上没找到啥好的讲解，自己尝试写个吧…) 原理： 首先要明确，每个类型在底层都会有一个类型元数据，存放着类型信息和方法元数据列表。 然后，定义一个非空接口，并让某类型实现该接口； 在多态的场景下，比如一个函数的入参是定义的非空接口类型，调用该函数时传参为具体类型的对象，其实就会把该具体类型的对象赋值给该非空接口。这里要了解，非空接口的底层结构体里共有两个字段，一个是itab，一个是data： itab中会记录接口的类型元数据(包含接口的方法列表)、动态类型元数据、动态类型实现的(接口所需要的)方法的地址列表fun； data为动态值，指向具体类型的对象。 因此，赋值过程就是把data指向具体类型的对象，修改itab中的动态类型元数据为具体类型的类型元数据，并从该类型元数据中的方法元数据列表拷贝方法地址到fun。 给出一段示例代码： type test interface { print() } type hello struct { } func (h hello) print() { fmt.Println(\"hello\") } // 多态场景 func hi(t test) { t.print() } func main() { h := hello{} // 第一种调用方式 var t test t = h t.print() // 第二种 hi(h) } 问：Go 如何实现 组合 和 继承？ Go 语言中没有继承的概念，更提倡的是组合。接口和结构体都可以组合。 接口的组合，如下代码所示： type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } //ReadWriter是Reader和Writer的组合 type ReadWriter interface { Reader Writer } ReadWriter 接口就是 Reader 和 Writer 的组合，组合后的 ReadWriter 接口具有 Reader 和 Writer 中的所有方法，这样新接口 ReadWriter 就不用定义自己的方法了，组合 Reader 和 Writer 的就可以了。 结构体的组合，如下代码所示： type person struct { name string age uint address } 直接把结构体类型放进来，就是组合，不需要字段名。组合后，被组合的 address 称为内部类型，person 称为外部类型： 外部类型不仅可以使用内部类型的字段，也可以使用内部类型的方法，就像使用自己的方法一样； 如果外部类型定义了和内部类型同样的方法，那么外部类型的会覆盖内部类型，这就是方法的覆写。方法覆写不会影响内部类型的方法实现。 如下所示： p:=person{ age:30, name:\"飞雪无情\", address:address{ province: \"北京\", city: \"北京\", }, } //像使用自己的字段一样，直接使用 fmt.Println(p.province) 因为 person 组合了 address，所以 address 的字段就像 person 自己的一样，可以直接使用。 题目：1 type People struct{} func (p *People) ShowA() { fmt.Println(\"showA\") p.ShowB() } func (p *People) ShowB() { fmt.Println(\"showB\") } type Teacher struct { People } func (t *Teacher) ShowB() { fmt.Println(\"teacher showB\") } func main() { t := Teacher{} t.ShowA() } 这里定义了两个类型，类型Teacher中嵌入了类型People。**问题是：**通过Teacher类型的变量t调用方法showA()，输出结果是什么？ 答案： showA showB 解释： 首先要明确T和*T是两种类型，分别对应自己的类型元数据，有着各自的方法集，其中包含了自定义的方法以及编译器生成的方法。通过go tool compile -l -p main main.go可以生成main.go的obj文件，再通过go tool nm main.o就可以查看方法列表： ❯ go tool nm main.o | grep 'T' | grep People 301c T main.(*People).ShowA 308a T main.(*People).ShowB ❯ go tool nm main.o | grep 'T' | grep Teacher 36d9 T main.(*Teacher).ShowA 30e0 T main.(*Teacher).ShowB 可以发现，People和*People的方法集同代码中定义的一致，但Teacher和*Teacher相关的方法列表中多了一个ShowA()方法，这就是编译器自动生成的了，所以编译器为*Teacher生成了这样一个包装方法(红字部分)： 所以，调用过程为：t.ShowA()会在语法糖的作用下转换为对(*Teacher).ShowA()方法的调用，而它又会取出People成员的地址作为接收者去执行*People这里的ShowA()方法，所以会有如上输出。 题目：2 解释到这里，这道题已经解决了。但无法知道为什么编译器只给*Teacher生成了包装方法？为此探索一下编译器生成包装方法的规则。 type A int func (a A) Value() int { return int(a) } func (a *A) Set(n int) { *a = A(n) } type B struct { A b int } type C struct { *A c int } 分析以上B和C会分别继承哪些方法。 首先，值接收者A有Value()方法，前面已经讲过，为了支持接口，编译器会为值接收者方法生成指针接收者的包装方法，所以*A会有Value()和Set()方法；B和C拥有的方法如下： 其中，只有B只继承了Value()方法，这是因为以B为接收者调用方法时，方法操作的已经是B的副本，无法获取嵌入的A的原始地址；而*A的方法从语义上来讲需要操作原始变量，也就是说，对于B而言它继承*A的方法是没有意义的，所以编译器并没有给B生成Set()方法。 **结论就是：**无论是嵌入值还是嵌入指针，值接收者方法始终能够被继承；而只有在能够拿到嵌入对象的地址时，才能继承指针接收者方法。 ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:16:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["Go","面试"],"content":"3.12 对比 Java 问：Go 和 Java 的区别？ 性能：无论在串行还是并发的的业务下，Java的性能都比Go差； goroutine 默认占用内存远比 Java 、C 的线程少(goroutine：2KB，线程：8MB)，占用资源更少； goroutine 可以避免内核态和用户态的切换导致的成本。 部署编译： Java通过虚拟机编译，使用JVM跨平台编译； Go语言针对不同的平台，编译对应的机器码。 访问权限： Java使用public、protected、private、默认等几种修饰符来控制访问权限； Go语言通过大小写控制包外可访问还是不可访问。Go语言中根据首字母的大小写来确定可以访问的权限。无论是方法名、常量、变量名还是结构体的名称，如果首字母大写，则可以被其他的包访问；如果首字母小写，则只能在本包中使用。可以简单的理解成，首字母大写是公有的，首字母小写是私有的。 接口 Java等面向对象编程的接口是侵入式接口，需要明确声明自己实现了某个接口； Go语言的非侵入式接口不需要通过任何关键字声明类型与接口之间的实现关系，只要一个类型实现了接口的所有方法，那么这个类型就是这个接口的实现类型。 异常处理 Java中错误（Error）和异常(Exception)被分类管理，二者的区别是： Error（错误）：程序在执行过程中所遇到的硬件或操作系统的错误。错误对程序而言是致命的，将导致程序无法运行。常见的错误有内存溢出，jvm虚拟机自身的非正常运行，calss文件没有主方法。程序本生是不能处理错误的，只能依靠外界干预。Error是系统内部的错误，由jvm抛出，交给系统来处理； EXCEPTION（异常）：是程序正常运行中，可以预料的意外情况。比如数据库连接中断，空指针，数组下标越界。异常出现可以导致程序非正常终止，也可以预先检测，被捕获处理掉，使程序继续运行。 Go语言中只有error，一旦发生错误逐层返回，直到被处理。Golang中引入两个内置函数panic和recover来触发和终止异常处理流程，同时引入关键字defer来延迟执行defer后面的函数。golang弱化了异常，只有错误，在意料之外的panic发生时，在defer中通过recover捕获这个恐慌，转化为错误以code,message的形式返回给方法调用者，调用者去处理，这也是go极简的精髓。 继承 Java的继承通过extends关键字完成，不支持多继承； Go语言的继承通过匿名组合完成：基类以Struct的方式定义，子类只需要把基类作为成员放在子类的定义中，支持多继承。 多态 Java的多态，必须满足继承，重写，向上转型；任何用户定义的类型都可以实现任何接口，所以通过不同实体类型对接口值方法的调用就是多态。 在Go语言中通过接口实现多态，对接口的实现只需要某个类型T实现了接口中的方法，就相当于实现了该接口。 指针 Java中不存在显式的指针，而Golang中存在显式的指针操作，使用 * 来定义和声明指针，通过\u0026来取得对象的指针。注意，Java和Golang都是只存在值传递。 并发 在Java中，通常借助于共享内存（全局变量）作为线程间通信的媒介，通常会有线程不安全问题，使用了加锁（同步化）、使用原子类、使用volatile提升可见性等解决； 但在Go语言中使用的是通道（Channel）作为协程间通信的媒介，这也是Go语言中强调的：不要通过共享内存通信，而通过通信来共享内存。 垃圾回收和内存管理机制 Java基于JVM虚拟机的分代收集算法完成GC，Go语言内存释放是语言层面，对不再使用的内存资源进行自动回收，使用三色标记算法； ","date":"2023-04-25","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:17:0","tags":["Go"],"title":"深度探索Go语言","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":["通用"],"content":" 前言：本节描述正向代理和反向代理，及其之间的对比。 ","date":"2023-04-23","objectID":"/%E4%BB%A3%E7%90%86/:0:0","tags":["计算机基础","代理"],"title":"代理","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":["通用"],"content":"一、正向代理 1.1 概念 **正向代理（forward proxy）：**是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。 这种代理其实在生活中是比较常见的，比如访问外国网站技术，其用到的就是代理技术。 有时候，用户想要访问某国外网站，该网站无法在国内直接访问，但是我们可以访问到一个代理服务器，这个代理服务器可以访问到这个国外网站。这样呢，用户对该国外网站的访问就需要通过代理服务器来转发请求，并且该代理服务器也会将请求的响应再返回给用户。这个上网的过程就是用到了正向代理。 所以，正向代理，其实是\"代理服务器\"代理了\"客户端\"，去和\"目标服务器\"进行交互。 通过正向代理服务器访问目标服务器，目标服务器是不知道真正的客户端是谁的，甚至不知道访问自己的是一个代理 1.2 作用 突破访问限制 通过代理服务器，可以突破自身IP访问限制，访问国外网站，教育网等。 提高访问速度 通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。 隐藏客户端真实IP 上网者也可以通过这种方法隐藏自己的IP，免受攻击。 ","date":"2023-04-23","objectID":"/%E4%BB%A3%E7%90%86/:0:1","tags":["计算机基础","代理"],"title":"代理","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":["通用"],"content":"二、反向代理 2.1 概念 反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 所以，反向代理，其实是\"代理服务器\"代理了\"目标服务器\"，去和\"客户端\"进行交互。 通过反向代理服务器访问目标服务器时，客户端是不知道真正的目标服务器是谁的，甚至不知道自己访问的是一个代理。 2.2 作用 隐藏服务器真实IP 使用反向代理，可以对客户端隐藏服务器的IP地址。 负载均衡 反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上。 提高访问速度 反向代理服务器可以对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度。 提供安全保障 反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。 ","date":"2023-04-23","objectID":"/%E4%BB%A3%E7%90%86/:0:2","tags":["计算机基础","代理"],"title":"代理","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":["通用"],"content":"三、正向代理和反向代理的区别 虽然正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。 1、正向代理其实是客户端的代理，帮助客户端访问其无法访问的服务器资源。反向代理则是服务器的代理，帮助服务器做负载均衡，安全防护等。 2、正向代理一般是客户端架设的，比如在自己的机器上安装一个代理软件。而反向代理一般是服务器架设的，比如在自己的机器集群中部署一个反向代理服务器。 3、正向代理中，服务器不知道真正的客户端到底是谁，以为访问自己的就是真实的客户端。而在反向代理中，客户端不知道真正的服务器是谁，以为自己访问的就是真实的服务器。 4、正向代理和反向代理的作用和目的不同。正向代理主要是用来解决访问限制问题；而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。 ","date":"2023-04-23","objectID":"/%E4%BB%A3%E7%90%86/:0:3","tags":["计算机基础","代理"],"title":"代理","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":["面试"],"content":"[toc] 一些比较好的文档： https://tanxinyu.work/raft/ https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md https://tanxinyu.work/consistency-and-consensus/ https://tanxinyu.work/zookeeper-thesis/ Zookeeper Etcd https://mp.weixin.qq.com/s/x-AdmN0UN5KT58XWO1BCOA(未) ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:0:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"常见面试题 RAFT 算法 主节点选举过程？ 怎么保证个节点的一致性？G ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:1:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"一、分布式理论和一致性模型 ==CAP== Consistency（一致性）：所有节点访问同一份最新的数据副本； Availability（可用性）：非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）； Partition Tolerance（分区容错性）：分布式系统出现网络分区的时候，仍然能够对外提供服务。 **注：**什么是网络分区？ 分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 网络分区。 问：所谓的 “3选2” ？ 其实不是任意的 “3选2”。 当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。 ==简而言之就是：==CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。 因此，分布式系统理论上不可能选择 CA 架构，==只能选择 CP 或者 AP 架构==。 问：为啥不可能同时满足 CAP 呢？ 首先，分布式系统要保障整体的服务，就必须拥有分区容错性 P。 然后，可以举个例子。若系统发生“分区”，分为A、B： 有写请求进来，修改了 A 中某数据，正常情况下要同步给 B，但分区状态，发生同步失败； 此时，B 来了读请求，要么保证一致性，阻塞请求，等待分区状态结束再继续服务；要么保证可用性，返回给旧的数据。 ==BASE== BASE：Basically Available（基本可用）、**Soft-state（软状态）**和 Eventually Consistent（最终一致性）。 **基本可用：**指分布式系统在出现不可预知故障的时候，允许损失部分可用性。损失部分可用性，例如响应时间变长，系统提供的功能变少等； **软状态：**允许系统存在短暂的数据不一致； 最终一致性：系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。 ==一致性模型== 分布式系统按照对一致性要求的不同，主要分为强一致性，弱一致性这两大类，前者是基于 safety 的概念，后者是基于 liveness 的概念。 强一致性 顺序一致性：如果一个并发执行过程所包含的所有读写操作能够重排成一个全局线性有序的序列，并且这个序列满足以下两个条件，那么这个并发执行过程就是满足顺序一致性的： 重排后的序列中每一个读操作返回的值，必须等于前面对同一个数据对象的最近一次写操作所写入的值； 原来每个进程中各个操作的执行先后顺序，在这个重排后的序列中必须保持一致。 **线性一致性：**和顺序一致性很相似，除了满足上面两个条件外，还需要满足： 不同进程的操作，如果在时间上不重叠，那么它们的执行先后顺序，在这个重排后的序列中必须保持一致。 区别： 线性一致性考虑了时间先后顺序，而顺序一致性没有。 满足线性一致性的执行过程，肯定都满足顺序一致性；反之不一定。 线性一致性总是能读到最新的数据，顺序一致性有可能读到旧版本的数据。 弱一致性 弱一致性是指系统在数据成功写入之后，不承诺立即可以读到最新写入的值，也不会具体承诺多久读到，但是会尽可能保证在某个时间级别之后，可以让数据达到一致性状态。其中包括了最终一致性。 问：那共识和一致性有什么区别？ 一致性指的是分布式系统中多个副本对外呈现的数据状态，比如顺序一致性、线性一致性等。 共识则指的是分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程，比如Paxos、Raft等算法。 因此，一致性描述的是结果状态，共识则是达成一致性的一种手段。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:2:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"错误类型与错误容忍(Fault Tolerance) 在分布式系统当中可能出现的错误主要有两种： CF (Crash Fault)：宕机故障，系统中的某些节点可能出现宕机故障，不会响应请求，但是不会恶意响应； BF (Byzantine Fault): 拜占庭故障，系统中的某些节点可能出现拜占庭故障，可能会不响应请求，也可能错误响应请求。 出现拜占庭故障的节点我们称为拜占庭节点。 能够容忍宕机故障的系统我们称为 CFT（Crash Fault Tolerance）系统； 能够容忍拜占庭故障的系统我们称为 BFT（Byzantine Fault Tolerance）系统。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:2:1","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"二、Paxos 算法 概述 主要包括两部分： Basic Paxos 算法：描述的是多节点之间如何就某个值(提案 Value)达成共识。 Multi-Paxos 思想：描述的是执行多个 Basic Paxos 实例，就一系列值达成共识。Multi-Paxos 说白了就是执行多次 Basic Paxos ，核心还是 Basic Paxos 。 Basic Paxos 中存在 3 个重要的角色： 提议者（Proposer）：也可以叫做协调者（coordinator），提议者负责接受客户端的请求并发起提案。提案信息通常包括提案编号 (Proposal ID) 和提议的值 (Value)。 接受者（Acceptor）：也可以叫做投票员（voter），负责对提议者的提案进行投票，同时需要记住自己的投票历史； 学习者（Learner）：如果有超过半数接受者就某个提议达成了共识，那么学习者就需要接受这个提议，并就该提议作出运算，然后将运算结果返回给客户端。 Multi-Paxos 思想： 思想的核心就是通过多个 Basic Paxos 实例就一系列值达成共识。 也就是说：Basic Paxos 是 Multi-Paxos 思想的核心，Multi-Paxos 就是多执行几次 Basic Paxos。 两阶段 prepare 阶段 Proposer提案者：负责提出 proposal。在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号 N，然后将该编号关联其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者； Acceptor表决者：每个表决者在 accept 某提案编号后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer 。 accept 阶段 当Proposer收到超过半数的Accepter的响应后，就会发送提案的内容与编号； 当Accepter收到提案内容与编号后，若提案编号是自己批准过的最大编号，那就Accept该提案。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:3:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"三、RAFT 算法 动态演示 RAFT 只有三种类型的节点： **Leader：**负责发起心跳，响应客户端，创建日志，同步日志。 Candidate：Leader 选举过程中的临时角色，由Follower转化而来，发起投票参与竞选。 **Follower：**接受Leader的心跳和日志同步数据，投票给 Candidate。 任期(Term) RAFT 算法划分任意时间长度的任期(Term)，任期用连续的数字表示，看作当前 term 号。 问：Term 号的作用？ 每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号。 如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值； 如果一个**Candidate或者Leader**发现自己的 term 过期了，他会立即退回成 Follower； 如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求。 日志(Log) entry：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为\u003cterm, index, cmd\u003e，其中 cmd 是可以应用到状态机的操作。 log：由 entry 构成的数组，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。 RAFT 强化了 Leader 的地位，日志算法只能由 Leader 复制给其他成员，这意味着日志复制是单向的，Leader 从不会覆盖本地日志，即所有的日志均以 Leader 为基准。 ==Leader 选举== RAFT 使用心跳机制来触发Leader的选举。 如果一台服务器能够收到来自Leader或者Candidate的有效信息，那么它会一直保持为Follower状态，并且刷新自己的 election计时器，重新计时。 问：选主过程？ 每个Follower节点都保持一个election计时器，如果一个Follower在一个周期内没有收到心跳信息，就叫做选举超时，然后它就会认为此时没有可用的 Leader，并且开始进行一次选举以选出一个新的 Leader： Follower 会自增自己的term号并且转换状态为 Candidate(候选者)； 然后他会向所有节点发起**RequestVoteRPC(投票请求)：自身的任期 term、memberId、最新日志(即最后一个Entry)的任期 term 和 index。每个节点只有一票(保证每个Term至多只有一个Leader，避免split brain)，如果发现 候选者的任期 \u003e= 自身任期 并且 候选者的最新日志 \u003e= 自身的最新日志，则回复同意；这样可以保证新 leader 节点一定包含最新提交的日志**。 Candidate的状态会持续到以下情况发生： 赢得选举：收到了来自集群内的多数选票(N/2+1)； 其他节点赢得选举； 一轮选举结束，无人胜出。 在Candidate等待选票的时候，它可能收到其他节点声明自己是Leader的心跳，此时有两种情况： 该Leader的term号\u003e=自己的term号，说明对方已经成为 Leader，则自己回退为 Follower。 该Leader的term号\u003c自己的term号，那么会拒绝该请求并让该节点更新 term。 问：会出现选不出主的情况吗？如何解决？ 会。同一时刻出现多个 Candidate，导致没有Candidate获得大多数选票，如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。 RAFT 通过随机的election时间来缓解这一问题：每一个Candidate在发起选举后，都会随机化一个新的选举超时时间，一旦超时后还没完成选举，则自增自己的Term，然后发起新一轮的选举(Term 较大的有更大的概率压倒其他节点)。这种机制使得各个服务器能够分散开来，在大多数情况下只有一个服务器会率先超时；它会在其他服务器超时之前赢得选举。 ==日志复制== 问：日志复制的过程是什么样的？ 一旦选出Leader，它就负责所有的客户端请求。每一个客户端请求都包含一条需要被复制状态机（Replicated State Mechine）执行的命令； Leader 收到客户端请求后，会生成一个 entry，包含\u003cindex, term, cmd\u003e，再将这个entry添加到自己的日志末尾后( Append Entries)； 然后 Leader 会生成日志复制请求，包含本次待复制的日志列表(新的entry)、上一条日志(已提交的最后一个entry)等信息，并行地向所有从节点广播该请求； Follower收到日志复制请求后： 如果发现 leader 的任期 \u003e= 自身任期 并且 日志一致性检查 通过，就接受待复制的日志列表，同时返回给Leader同意； 否则，返回拒绝。 如果Leader收到了多数的成功响应，Leader 会将这个entry应用到自己的状态机中，之后可以认为这个entry是 committed 的，并且向客户端返回执行结果。 ==RAFT 保证以下两个性质：== 在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd。 在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同 第一条通过**只有Leader才能生成entry来保证；第二条通过一致性检查**来保证。 问：一致性检查的过程是怎样的？/如何保证节点一致性？⭐⭐ leader 在通过AppendEntriesRPC和follower通讯时，会携带**上一个entry **的信息； follower在收到后会对比自己的日志：如果发现这个entry的信息(index、term)和自己日志内的不匹配，则会拒绝该请求； 一旦leader发现有follower拒绝了请求，则会与该follower不断进行一致性检查，直到找到双方最大的共识点，然后用leader的entries记录覆盖follower在最大共识点之后的所有数据。 这样，主从节点就一致了。 问：一致性检查失效的情况？如何解决呢？ 在出现网络分区时，不同分区A、B就会出现不同的Leader，然后两个分区就有可能出现日志不一致(因为没办法同步了呀)，例如： 如果分区状态结束，重新合并为一个区，Term号小的节点就会找到和**Term大的节点**的日志中最后一个相同的entry，并回滚该位置之后的所有entry，然后复制Term大的节点的日志Append到后面，此时所有节点的日志就一致了。 问：参加选举的节点有没有什么限制？ **Leader 需要保证自己存储全部已经提交的日志条目。**这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。 **每个 Candidate 发送 RequestVoteRPC 时，都会带上最后一个 entry 的信息。**所有节点收到投票信息时，会对该 entry 进行比较，如果发现自己的更新，则拒绝投票给该 Candidate。 **判断日志新旧的方式：**如果两个日志的 term 不同，term 大的最新；如果 term 相同，index 大的最新。 问：节点崩溃会发生什么？ Leader节点崩溃：集群中的节点在electionTimeout时间内没有收到Leader的心跳信息就会触发新一轮的选主，在选主期间整个集群对外是不可用的； Follower、Candidate节点崩溃：那么发送给它的 RequestVoteRPC 和 AppendEntriesRPC 会失败，但由于 raft 的所有请求都是幂等的，所以失败的话会无限的重试。如果崩溃恢复后，就可以收到新的请求，然后选择追加或者拒绝 entry。 问：RAFT 中的各种时间设置？ broadcastTime \u003c\u003c electionTimeout \u003c\u003c MTBF broadcastTime：向其他节点并发发送消息的平均响应时间； electionTimeout：选举超时时间； MTBF(mean time between failures)：单台机器的平均健康时间； broadcastTime应该比electionTimeout小一个数量级，为的是使Leader能够持续发送心跳信息（heartbeat）来阻止Follower开始选举； electionTimeout也要比MTBF小几个数量级，为的是使得系统稳定运行。当Leader崩溃时，大约会在整个electionTimeout的时间内不可用。我们希望这种情况仅占全部时间的很小一部分。 由于broadcastTime和MTBF是由系统决定的属性，因此需要决定electionTimeout的时间。 一般来说，broadcastTime 一般为 0.5～20ms，electionTimeout 可以设置为 150～300ms，MTBF 一般为一两个月。 日志压缩 同其他系统一样，日志总不能无限制的增长，这样不仅会导致日志文件很大，还会导致恢复数据时执行日志的时间很长。因此，需要定时的快照(snapshot)。snapsh","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:4:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"四、PBFT 算法 参考文章： https://chenquan.me/posts/pbft-key-points/ https://learnblockchain.cn/2019/08/29/pbft https://sammyne.github.io/pbft/ ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"简介 PBFT 是 Practical Byzantine Fault Tolerance 的缩写，意为实用拜占庭容错算法。 该算法首次将拜占庭容错算法复杂度从指数级降低到了多项式级，其可以在恶意节点不高于总数 1/3 的情况下同时保证安全性（Safety）和活性（Liveness）。 约定变量 集群数量定义为 N，其数量定义为 ∣N∣=n 拜占庭或者是宕机节点集合为定义为 F，其数量定义为 ∣F∣=f quorum 法定成员集合Q，即每次访问的节点数量∣Q∣ 术语 Primary: 主节点 Replica: 副本节点 Client: 客户端，用于向共识集群发送消息，请求共识 View: 视图，Primary 和 Replica 共同达成的一个状态视图，所有节点都基于某个视图进行共识 Sequence Number：序列号，由主节点生成的序列号，用于标识共识轮次 Check Point: 检查点，如果某个序列号被确认，则成为检查点 Stable checkpoint: 稳定检查点，该检查点通常会被持久化 N \u003e 3f + 1 这里先提出一个问题：在分布式系统中需要读写多少台节点才可以满足正确性要求，即 quorum 的值为多少比较合适？ 先给出结论： 在 CFT 系统中，只需要达到2f + 1就可以了； 在 BFT 系统中，就需要达到3f + 1才行，因为是允许同时存在故障节点和拜占庭节点的。 给出分析： 节点总数是n，其中作恶节点有f，那么剩下的正确节点为n - f，意味着只要收到n - f个消息就能做出决定，但是这n - f个消息有可能有f个是由作恶节点冒充的，那么正确的消息就是n - f - f个，为了多数一致，正确消息必须占多数，也就是 n - f - f \u003e f，但是节点必须是整数个，所以 n 最少是 3f + 1 个。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:1","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"算法流程 约定符号 i：节点ID(replica id)，应该是在 [0, N−1] 范围内的值； v#：视图编号(view number)，初始为零，用 v# 表示； Primary：主节点，通常采用模运算取得: Primary = v# mod N； m：即本轮共识的具体操作，可以是数据库操作，也可以是区块写入操作； d(m)：是m的摘要信息(digest)； seq# 为 sequence number； log：操作日志，通常记录了当前收到的消息，形式为 \u003cv#, seq#, status, d\u003e status 为 pre-prepared 、prepared或者是committed； 消息结构 这里列出了三阶段协议相关的消息结构，其中只有 PRE-PREPARE 消息包含新生成的区块，其他消息则主要包含一些 id、sequence number、区块摘要和签名等信息。 核心过程 STEP 1: 客户端发送请求给主节点(或者发给所有节点)，之后主节点将会触发三阶段协议。这里可以有一个优化，节点可以先把请求缓存起来，等到攒够一堆请求之后再一起发送，这样可以降低网络开销和系统负载。 STEP 2: 主节点收到客户端发送来的消息后，构造pre-prepare消息结构体 \u003c\u003cPRE-PREPARE, v#, seq#, d, sig\u003e, m\u003e (p)，其中 (p) 表示由主节点发出，d是当前消息摘要，m为原始消息，sig 为d的数字签名 PRE-PREPARE标识当前消息所处的协议阶段； v#标识当前视图编号； seq#为主节点广播消息的一个唯一递增序号； d为m的消息摘要； sig 为d的数字签名； m为客户端发来的消息。 STEP 3: 从节点检查主节点发送的 pre-prepare 消息，检查通过会存储在本节点日志。检查通过会进入PREPARE状态，广播消息\u003cPREPARE, v#, seq#, d, i,\u003e (i)，其中 (i) 标识从i节点发出。消息的有效性检查过程如下： 检查收到的消息体中摘要d，是否和自己对m生成的摘要一致，确保消息的完整性。 检查v#是否和当前视图v#一致。 检查序号seq#是否在水线h和H之间，避免快速消耗可用序号。 检查之前是否接收过相同序号seq#和v#，但是摘要d不同的消息。 STEP 4: 所有节点收到PREPARE消息后，同样也会对消息进行有效性检查，检查的内容也是 STEP3 中的1, 2, 3, 4。 当收到2f(包括自己)个检查通过且一致的PREPARE消息后，会进入COMMIT阶段，并且广播消息\u003cCOMMIT, v#, seq#, d, i\u003e (i) 2f-1 个从其他节点收到的prepare消息(不包括自己的)。这里是因为主节点不会再发送prepare消息，因此收到2f-1个prepare，加上主节点的pre-prepare，以及自己的prepare，就是2f+1个了； STEP 5: 所有节点收到COMMIT消息后，同样也会对消息进行有效性检查，检查的内容也是 STEP3 中的1, 2, 3, 4。 当收到2f+1(包括自己)个检查通过且一致的COMMIT消息后，进入committed-local状态，按照m中的请求顺序执行操作。 执行完成之后，所有节点将发送结果给到客户端。 STEP 6: 客户端收到超过2f+1的一致消息则确认当前结果成功 整个过程不需要要求所有的消息是有序到达的，因为seq#会保证顺序，只需要对应的pre-prepare，prepare和commit消息都是完整的即可。 一种优化流程 以下是基于公开资料收集的 Hyperchain 优化之后的 RBFT 算法 主要优化点： 客户端可以发送请求到任意节点，如果这个节点不是主节点的话，将会进行一次广播；(类似读写分离) 主节点收到交易之后会先进行验证，并把验证结果放在pre-prepare中，并且pre-prepare是以区块为单位处理的，这样的 pre-prepare 消息中既包含了排好序的交易信息也包含了区块验证结果； 从节点收到pre-prepare后，也是先验证消息的合法性，然后广播prepare。不同的是，在收到2f个prepare后会对区块内容进行验证，并与pre-prepare中的验证结果对比，若一致，则广播 commit 表明本节点同意主节点的验证结果；若不一致，直接发起 view-change 表明本节点认为主节点存在异常行为，需要切换主节点。 RBFT 具体流程： **交易转发阶段：**客户端将交易发送到区块链中的任意节点（包括共识节点与记账节点），其中记账节点在收到交易后会主动转发给与其相连的共识节点；而共识节点在收到客户端的交易后将其广播给其他共识节点，这样所有共识节点的交易池中都会维护一份完整的交易列表； 共识节点就是参与RBFT共识过程的节点，记账节点是不参与共识，只接受结果并写入区块的节点 PrePrepare 阶段：主节点按照如下策略进行打包：用户可以根据需求自定义打包的超时时间（batch timeout）与打包的最大区块大小（batch size），主节点在超时时间内收集到了足够多（超过最大区块大小个数）的交易或者超时时间到达后仍未收集到足够多的交易都会触发主节点的打包事件。主节点将交易按照接收的时间顺序打包成块，并进行验证，计算执行结果，最后将定好序的交易信息连同验证结果等写入 pre-prepare 消息中，广播给所有共识节点，开始三阶段处理流程； Prepare 阶段： 从节点在收到主节点的 pre-prepare 消息后，首先进行消息合法性检查，检查当前的视图与序列号号等信息，检查通过后向共识节点广播 prepare 消息； **Commit 阶段：**从节点在收到quorum-1 即(2f) 个prepare 消息以及相应的 pre-prepare 消息后进行验证，并将验证结果与主节点写入pre-prepare 消息中的验证结果进行比对，比对结果一致则广播 commit 表明本节点同意主节点的验证结果，否则直接发起 view-change 表明本节点认为主节点存在异常行为，需要切换主节点； **写入账本：**所有共识节点在收到 quorum 个 commit 消息后将执行结果写入本地账本。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:2","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"日志压缩 PBFT的每个阶段都写入了日志，长时间运行内存总会不够用，需要一种日志压缩机制。PBFT通过检查点实现日志压缩，其本质和RAFT算法采用快照的形式清理日志是一样的，只是实现的方式不同。 为每一次操作创建一个集群中稳定检查点，代价是非常昂贵的。因此，PBFT为常数k个操作创建一次稳定检查点，比如每100个操作创建一次检查点checkpoint，当这个checkpoint得到集群中多数节点认可以后，就变成了稳定检查点stable checkpoint。 总之，稳定检查点是一个确定性的系统状态快照，可以用来恢复系统状态，类比于**RDB快照**；而水位线[h, H]间的消息就相当于**AOF文件**。 稳定检查点 生成过程： 当 replica i 生成了一个 checkpoint，将广播消息 \u003cCHECKPOINT, seq#, d(state), i\u003e，其中，seq#是最后一次执行的消息序号，d是seq执行后的状态机状态的摘要； 当所有节点收到了2f+1个拥有相同的 seq# 和 d(state) 的检查点消息(包括自己)后，将会生成stable checkpoint。 作用： 当stable checkpoint生成之后，将会删除stable checkpoint之前(seq#之前)的 pre-prepare、prepare、commit消息，日志就被压缩了，并且稳定检查点是一个确定性的系统状态快照，可以用来恢复系统状态。 同时checkpoint还有一个**提高水线(water mark)**的作用，当一个stable checkpoint被创建的时候，水线h被修改为stable checkpoint的seq#，水线H为h + k而k就是之前用到创建checkpoint的那个常数。 水位线 水位线机制用于限制消息序号的有效范围，包括： 低水位线(low-water mark) h； 高水位线(high water mark) H = h + k。 设置规则： 通常来讲，低水位线是最近的一个稳定检查点的seq#，而高水位线需要在低水位线上加上一个常量k。 k要足够大，避免需要频繁创建稳定检查点； 但**k又不能太大**，避免出现故障或错误，进行状态恢复时需要重放大量的请求数量。 作用： 在共识进行的过程中，由于节点之间的性能差距，可能会出现节点间运行速率差异过大的情况。部分节点执行的序号可能会领先于其他节点，导致于领先节点的共识数据长时间得不到清理，造成内存占用过大的问题，而高低水位的作用就是对集群整体的运行速率进行限制，从而限制了节点的共识数据大小。在执行到最高水位 H 时，如果低水位 h 没有被更新，节点会暂停执行序号更大的请求，等待其他节点的执行，待低水位 h 更新后重新开始执行更大序号的请求。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:3","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"视图切换 视图切换(view-change)是为了保证系统的高可用性，主要发生在： 主节点超时； 从节点认为主节点是拜占庭节点。 view-change通过定时器来进行切换，避免从节点长时间等待请求。 原文中是这样做的：在通常情况下，主节点将会发送 pre-prepare 来正常进行共识，从节点也可以通过该消息确认主节点是否存活，因此如果超过一段时间没有收到 pre-prepare 的话就会认为该主节点有问题； 工程上：在实际运行当中，长时间没有pre-prepare是常见的，因此一般会通过心跳+定时器来进行探测保活。 View-Change 过程 当从节点收到请求时，如果有定时器在运行就重置(reset)定时器，否则开启一个定时器。但是主节点宕机的时候，从节点i就会在当前视图v#中超时，这个时候该从节点i就会触发view-change： 从节点i会将视图切换为v#+1，停止接收除了checkpoint，view-change和new view-change以外的请求，同时广播消息\u003cVIEW-CHANGE, v#+1, seq#(stable_checkpoint), C-set, P-set, i\u003e (i)到集群： seq#是节点i知道的最后一个stable checkpoint的消息序号； C-set是节点i保存的 2f+1 个能够证明seq#(stable_checkpoint)是正确检查点的的消息集合； P-set是一个保存了seq#之后所有已经达到prepared状态消息的集合，通过P-set可以把原来的在稳定检查点之后确定的交易进行重新共识。 当视图(v#+1)中的**新主节点p1**接收到2f个有效的视图切换消息以后，p1就会广播消息\u003cNEW-VIEW, v#+1, V-set, Q-set\u003e (p)： V-set是p1收到的，包括自己发送的view-change的消息集合； Q-set是PRE-PREPARE状态的消息集合，是从P-set转换过来的： 主节点根据最新stable_checkpoint的seq# s 和P-set的最大seq# t，将[s, t]间的所有seq#创建pre-prepare消息成为Q-set； 从节点接收到NEW-VIEW消息后，校验签名，V和Q中的消息是否合法，如验证通过，将执行Q-set中的请求，然后主节点和从节点都进入视图v#+1。 C、P、Q 当p1接收到2f个VIEW-CHANGE消息以后，可以确定**stable checkpoint之前的消息在视图切换的过程中不会丢**。 但是**[当前检查点，下一个检查点]间已经通过PREPARE阶段的消息**可能会被丢弃，所以在视图切换到v+1后，PBFT会把旧视图中已经PREPARE的消息变为PRE-PREPARE，组成Q然后广播。 如果集合P为空，创建\u003cPRE-PREPARE, v#+1, seq#, null\u003e，接收节点就什么也不做； 如果集合P不为空，创建\u003cPRE-PREPARE, v#+1, seq#, d\u003e。 总结一下，在view-change中最重要的就是C，P，Q三个消息的集合： C确保了视图变更的时候，stable checkpoint之前的状态安全； P确保了视图变更前，已经PREPARE的消息的安全； Q确保了视图变更后，P-set中的消息安全。 回想一下pre-prepare和prepare阶段最重要的任务是保证同一个主节点发出的请求在同一个视图(view)中的顺序是一致的，而在视图切换过程中的C，P，Q三个集合就是解决这个问题的。 Leader 选举 在介绍 view-change 时，并没有说明在新的视图中，新主节点是如何选出来的，其实不同的系统做法不同： FISCO BCOS系统中，leader索引的计算公式如下： leader_idx = (view + block_number) % node_num ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:4","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"主动恢复 区块链网络在运行过程中由于网络抖动、突然断电、磁盘故障等原因，可能会导致部分节点的执行速度落后于大多数节点。在这种场景下，节点需要能够做到自动恢复才能继续参与后续的共识流程。 传统的PBFT并没有实现主动恢复的功能，但**RBFT提供了一种动态数据自动恢复的机制(recovery)，recovery 通过主动索取现有共识网络中所有节点的视图、最新区块高度等信息，更新自身的存储状态，最终同步至整个系统的最新状态**。 在节点启动、节点重启或者节点落后的时候，节点将会自动进入 recovery，同步至整个系统的最新状态。 比如，一个节点落后太多，这个时候它收到主节点发来的消息时，对消息进行水位检查会失败，当计时器超时，就会发送view-change的消息，但是由于只有自己发起view-change达不到2f+1个节点的数量，本来正常运行的节点就退化为一个拜占庭节点。 视图协商 新增/落后节点Replica 4发起NegotiateView消息给其他节点； 其余节点收到消息以后，返回NegotiateViewResponse消息，包含自己的视图信息，节点ID，节点总数N； Replica 4收到2f+1个NegotiateViewResponse消息后，则更新本节点的视图信息； Replica 4同步完视图后，广播RecoveryInit消息到其余节点，通知其他节点本节点需要进行自动恢复，请求其余节点的检查点信息和最新区块信息； 其余节点收到RecoveryInit后将自身最新的检查点信息和区块信息返回给Replica 4; Replica 4收到quorum个RecoveryResponse消息后，更新自己的检查点到最新； 更新完成后，还要向正常节点索要P-set、Q-set和C-set的信息，同步至全网最新状态。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:5","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"增删节点(随便看看而已) 传统的PBFT算法不支持节点的动态增删，RBFT 为了能够更加方便地控制联盟成员的准入和准出，添加了保持集群非停机的情况下动态增删节点的功能。 增加节点 Replica 5新节点加入的流程： 新增节点Replica 5主动向现有的所有节点发起连接，确认所有节点连接成功后更新自身的路由表，并发起recovery； 现有节点接收到Replica 5的连接请求后向全网广播AddNode消息，表明自己同意该新节点加入整个共识网络； 当现有节点收到N条（N为现有区块链共识网络中节点总数）AddNode消息后，更新自身的路由表，随后开始回应新增节点的共识消息请求（在此之前，新增节点的所有共识消息是不予处理的）； Replica 5完成recovery之后，向全网现有节点广播ReadyForN请求； 现有节点在收到ReadyForN请求后，重新计算新增节点加入之后的N，view等信息，随后将其与PQC消息封装到AgreeUpdateN消息中，进行全网广播； Replica 5加入后的共识网络会产生一个新的主节点，该主节点在收到N-f个AgreeUpdateN消息后，以新的主节点的身份发送UpdateN消息； 全网所有节点在收到UpdateN消息之后确认消息的正确性，进行VCReset； 每个节点完成VCReset后，全网广播FinishUpdate消息； 节点在收到N-f个FinishUpdate消息后，处理后续请求，完成新增节点流程。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:6","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"五、分布式ID⭐ 参考文章 问：什么是分布式ID？ 例如，多机 MySQL 中，也就是分库了，数据库的自增主键已经没办法满足生成的主键是唯一的了。如何在不同节点生成全局唯一的主键？ 这个时候就需要 分布式ID 。 问：分布式ID 需要满足啥条件？ 其实最主要的就是 全局唯一。 ==全局唯一==：ID 的全局唯一性肯定是首先要满足的！ 高性能：分布式 ID 的生成速度要快，对本地资源消耗要小。 高可用：生成分布式 ID 的服务要保证可用性无限接近于 100%。 除了这些之外，一个比较好的分布式 ID 还应保证： 安全：ID 中不暴露系统和业务的信息。 有序递增：如果要把 ID 存放在数据库的话，ID 的有序性可以提升数据库写入速度。并且，很多时候，我们还很有可能会直接通过 ID 来进行排序。 有具体的业务含义：生成的 ID 如果能有具体的业务含义，可以让定位问题以及开发更透明化（通过 ID 就能确定是哪个业务）。 独立部署：也就是分布式系统单独有一个发号器服务，专门用来生成分布式 ID。这样就生成 ID 的服务可以和业务相关的服务解耦。不过，这样同样带来了网络调用消耗增加的问题。总的来说，如果需要用到分布式 ID 的场景比较多的话，独立部署的发号器服务还是很有必要的。 ⭐问：分布式ID 常见的解决方案？ **==数据库主键自增==**⭐ 数据库自增 ID 是最常见的一种生成 ID 方式。优势是使用简单，满足基本业务需求，天然有序；缺点是强依赖 DB，会由于数据库部署的一些特性而存在单点故障、数据一致性等问题。 以 MySQL 举例，我们通过下面的方式即可。 创建一个数据库表。 CREATE TABLE `sequence_id` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `stub` char(10) NOT NULL DEFAULT '', PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; stub 字段无意义，只是为了占位，便于我们插入或者修改数据。并且给 stub 字段创建了唯一索引，保证其唯一性。 通过 replace into 来插入数据。 BEGIN; REPLACE INTO sequence_id (stub) VALUES ('stub'); SELECT LAST_INSERT_ID(); COMMIT; 插入数据这里，我们没有使用 insert into 而是使用 replace into 来插入数据，具体步骤是这样的： 第一步：尝试把数据插入到表中。 第二步：如果主键或唯一索引字段出现重复数据错误而插入失败时，先从表中删除含有重复关键字值的冲突行，然后再次尝试把数据插入到表中。 **优点：**实现起来比较简单、ID 有序递增、存储消耗空间小 **缺点：**支持的并发量不大、每次获取 ID 都要访问一次数据库 **==数据库号段模式==**⭐⭐ 数据库主键自增模式的话，某个节点每次获取 ID 都要访问一次数据库，这肯定不太好。因此，数据库号段模式就批量获取一批 ID，存在该节点的内存中，这样就可以每次用的时候就从内存中慢慢获取了，不够用了就再申请一批，美滋滋~~ 以 MySQL 举例，我们通过下面的方式即可。 创建一个数据库表。 CREATE TABLE `sequence_id_generator` ( `id` int(10) NOT NULL, `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id', `step` int(10) NOT NULL COMMENT '号段的长度', `version` int(20) NOT NULL COMMENT '版本号', `biz_type` int(20) NOT NULL COMMENT '业务类型', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; current_max_id 字段和step字段主要用于获取批量 ID，获取的批量 ID 为： current_max_id ~ current_max_id+step。 ==Redis 自增== 优势是不依赖于数据库，使用灵活，性能也优于数据库；而缺点则是可能要引入新的组件 Redis，如果 Redis 出现单点故障问题，则会影响序号服务的可用性。 通过 Redis 的 incr 命令即可实现对 id 原子顺序递增。 127.0.0.1:6379\u003e set sequence_id_biz_type 1 OK 127.0.0.1:6379\u003e incr sequence_id_biz_type (integer) 2 127.0.0.1:6379\u003e get sequence_id_biz_type \"2\" **==UUID==**⭐ UUID 由32位的16进制数组成，可以保证唯一性，有如下生成规则： 基于时间的 UUID：主要依赖当前的时间戳和机器 mac 地址。优势是能基本保证全球唯一性，缺点是由于使用了 mac 地址，会暴露 mac 地址和生成时间； 基于随机数的 UUID：基于随机数或伪随机数生成。优势是实现简单，缺点是重复几率可计算； 基于名字空间的 UUID(MD5 版)：基于指定的名字空间/名字生成 MD5 散列值得到，优势是不同名字空间/名字下的 UUID 是唯一的，缺点是 MD5 碰撞问题； 因为其生成规则包括 MAC 地址、时间戳、名字空间、随机或伪随机数、时序等元素，计算机基于这些规则生成的 UUID 是肯定不会重复的。 很少使用 UUID。 **优点：**生成速度快，简单易用； **缺点：**存储消耗空间太大(128位)、无序(非常影响MySQL的性能)、没有具体业务含义、有可能出现重复 ID、不安全(基于 MAC 地址生成的话，有可能会泄露 MAC地址) **==雪花算法(Snowflake)==**⭐⭐⭐ Snowflake 由 64 bit 的二进制数字组成，这 64bit 的二进制被分成了几部分，每一部分存储的数据都有特定的含义： 第 0 位：符号位(标识正负)，始终为 0，没有用，不用管。 第 1~41 位：一共 41 位，用来表示时间戳，单位是毫秒，可以支撑 2 ^41 毫秒(约 69 年) 第 42~51 位：一共 10 位，机器编码，一般来说，前 5 位表示机房 ID，后 5 位表示机器 ID(实际项目中可以根据实际情况调整)。这样就可以区分不同集群/机房的节点。 第 52~63 位：一共 12 位，用来表示序列号。序列号为自增值，代表单台机器每毫秒能够产生的最大 ID 数(2^12 = 4096)，也就是说单台机器每毫秒最多可以生成 4096 个 唯一 ID。 **优点：**单机生成的 ID 有序递增、生成速度比较快、比较灵活(可根据业务需求调整bit位)； 缺点：重复 ID 问题(强依赖时间，当机器时间回拨的情况下，可能导致会产生重复 ID)、ID 可能不是全局递增，虽然 ID 在单机上是递增的，但是由于涉及到分布式环境下的每个机器节点上的时钟，可能会出现不是全局递增的场景。 ==利用Zookeeper== zookeeper 是通过 树形结构 来存储数据节点的，那也就是说，对于每个节点的 全路径，它必定是唯一的，我们可以使用节点的全路径作为命名方式了。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:6:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"六、分布式锁⭐ 概述 分布式锁示意图： 一个最基本的分布式锁需要满足： 多进程可见⭐：你总得让人知道有锁的存在吧？ 互斥⭐：任意一个时刻，锁只能被一个线程持有； 高可用：锁服务是高可用的。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。 可重入：一个节点获取了锁之后，还可以再次获取锁。 分布式锁的实现，目前常用的方案有以下三类： 数据库乐观锁； 基于分布式缓存实现的锁服务，典型代表有 Redis 和基于 Redis 的 RedLock； 基于分布式一致性服务实现的锁服务，典型代表有 ZooKeeper 和 ETCD。 通常情况下，采用ZooKeeper或者Redis获得分布式锁，Redis用的多一些。 基于 Mysql 实现分布式锁 利用MySQL本身的互斥锁机制，主要是基于主键和唯一索引。比如说两个线程去同一个数据库表进行操作，利用主键冲突来保证。 基于 Redis 实现分布式锁 加解锁流程 加锁 SET lock_name my_random_value NX PX 30000 # SETNX 获得锁 lock_name：锁名(key)，在分布式环境中，对于某一确定的公共资源，所有争用方（客户端）都应该知道对应锁的名字，全局可知； my_random_value：随机字符串(value)，作为持有者的唯一标识，避免误删； NX：只有当lock_name不存在的时候才能 SET 成功，从而保证只有一个客户端能获得锁，而其它客户端在锁被释放之前都无法获得锁，保证互斥； PX 30000：表示这个锁节点有一个 30 秒的自动过期时间，避免死锁。 释放锁 首先，向 Redis 节点发送命令，获取锁对应的 Value GET lock_name 如果查询回来的 value 和客户端自身的 my_random_value 一致，则可确认自己是锁的持有者，可以发起解锁操作，即主动删除对应的 Key，发送命令： DEL lock_name 安全性分析 死锁避免 典型的死锁场景：获得锁的客户端，在释放锁之前崩溃了，导致锁一直无法被释放，进而导致死锁。 为了解决该问题，对锁设置了过期时间，当锁到期后，Redis 会自动删除该锁对应的 key-value，也就释放了锁。 但存在隐患，比如这个场景： 客户端 A 获取锁成功； 客户端 A 在某个操作上阻塞了很长时间； 过期时间到，锁自动释放； 客户端 B 获取到了对应同一个资源的锁； 客户端 A 从阻塞中恢复过来，认为自己依旧持有锁，继续操作同一个资源，导致互斥性失效。 为了解决该问题，有如下方案： 有隐患的方案，但网上很多都是这样做的。第 5 步中，客户端 A 恢复后，可以比较下目前已经持有锁的时间，如果发现已经过期，则放弃对共享资源的操作，即可避免互斥性失效的问题。但分布式中，各节点的时钟不一定是强一致的，导致了一定的隐患。其实，任何依赖两个节点时间比较结果的互斥性算法，都存在隐患； 可取的方案。可以比较 my_random_value，即客户端 A 恢复后，在操作共享资源前应比较目前自身所持有锁的 my_random_value 与 Redis 中存储的 my_random_value 是否一致，如果不相同，说明已经不再持有锁，则放弃对共享资源的操作以避免互斥性失效的问题。 解锁操作的原子性 为了保证解锁的正确性，引入了my_random_value。具体的解锁过程就分成了两步： 先查询(GET)锁对应的 Value，与自己加锁时设置的 my_random_value 进行对比； 如果相同，则可确认这把锁是自己加的，然后再发起解锁(DEL)。 但是，GET 和 DEL 是两个操作如果是非原子性的，那么解锁本身也会存在破坏互斥性的可能。 比如在查询完，释放前，又阻塞了很长时间。下面是典型场景： 客户端 A 获取锁成功； 客户端 A 访问共享资源； 客户端 A 为了释放锁，先执行 GET 操作获取锁对应的随机字符串的值； 客户端 A 判断随机字符串的值，与预期的值相等； 客户端 A 由于某个原因阻塞了很长时间； 过期时间到了，锁自动释放了； 客户端 B 获取到了对应同一个资源的锁； 客户端 A 从阻塞中恢复过来，执行 DEL 操纵，释放掉了客户端 B 持有的锁。 为了解决该问题，有如下方案： Redis 支持 Lua 脚本并保证其原子性，使用 Lua 脚本实现锁校验与释放，并使用 Redis 的 eval 函数执行 Lua 脚本。 // Lua脚本，用于校验并释放锁 String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; // 执行Lua脚本，校验并释放锁 jedis.eval(script, Collections.singletonList(\"lock_name\"), Collections.singletonList(\"my_random_value\")); 主备切换的一致性 当主从切换时，由于 Redis 的主从复制是异步的，就可能导致切换过程中丧失锁的安全性。 典型场景： 客户端 A 从 Master 获取了锁； Master 宕机了，存储锁的 Key 还没有来得及同步到 Slave 上； Slave 升级为 Master； 客户端 B 从新的 Master 获取到了对应同一个资源的锁； 客户端 A 和客户端 B 同时持有了同一个资源的锁，锁的安全性被打破。 可以通过 RedLock 来解决。 运行 Redlock 算法的客户端依次执行以下步骤，来进行加锁的操作： 获取当前系统时间（毫秒数）； 按顺序依次向 N 个 Redis 节点执行获取锁的操作。这个获取操作跟前面基于单 Redis 节点获取锁的过程相同，包含随机字符串 my_random_value，也包含过期时间（比如 PX 30000，即锁的有效时间）。为了保证在某个 Redis 节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间（Time Out），它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个 Redis 节点获取锁失败以后，应该立即尝试下一个 Redis 节点。这里的失败，应该包含任何类型的失败，比如该 Redis 节点不可用； 计算获取锁的整个过程总共消耗了多长时间，计算方法是用当前时间减去第 1 步记录的时间。如果客户端从大多数 Redis 节点（\u003e=N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间（Lock Validity Time），那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败； 如果最终获取锁成功了，就要重新计算这个锁的有效时间，等于最初的锁的有效时间减去第 3 步计算出来的获取锁消耗的时间； 如果最终获取锁失败了（可能由于获取到锁的 Redis 节点个数少于 N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有 Redis 节点发起释放锁的操作。 释放锁的过程比较简单：即客户端向所有 Redis 节点发起释放锁的操作，不管这些节点在获取锁的时候成功与否。 但 RedLock也有缺陷(如下场景)，一般不建议用这种方式，真要用的话，真不如用Zookeeper来做。 如下场景，假设一共有 5 个 Redis 节点：A、B、C、D、E。 客户端 1 成功锁住了 A、B、C，获取锁成功（但 D 和 E 没有锁住）。 节点 C 时间异常，导致 C 上的锁数据提前到期，而被释放。 客户端 2 此时尝试获取同一把锁：锁住了C、D、E，获取锁成功。 可重入 问：如何实现可重入锁？⭐ 可重入锁指的是在一个线程中可以多次获取同一把锁，比如一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法即可重入，而无需重新获得锁。 可重入分布式锁的实现核心思路是线程在获取锁的时候判断是否为自己的锁，如果是的话，就不用再重新获取了。 实现思路：可以为每个锁关联一个可重入计数器和一个占有它的线程。若可重入计数器大于 0，则表示锁被占有，需要判断占有该锁的线程和请求获取锁的线程是否为同一个。每次获取锁时，计数器+1，每次释放锁时，计数器-1。 问：如果对资源的操作还未结束，锁就到期了咋办？⭐ 这就涉及到如何给锁优雅的续期了。有非常成熟的解决方案：Java-Redisson、Go-Redsync等。。。 **原理简单来说就是：**提供了一个专门用来监控和续期锁的 Watch Dog（ 看门狗），如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。 基于 Zookeeper 实现分布式锁 主要是利用临时顺序节点。 问：怎么利用 Zookeeper 实现分布式锁呢？能实现共享锁和独占锁嘛？ 主要是利用创建节点的有序性。 可以让多个客户端在指定节点(通常是持久节点)下创建临时顺序节点，判断自己创建的是否是有序节点中序号最小的那个，若是就获得锁；若不是，就通过Watcher进行监听，若自己前边的序号都失效了，就说明锁释放了，就可以通过回调函数尝试得到该锁。 同时实现共享锁和独占锁： 读请求：如果 没有比自己更小的节点，或比自己小的节点都是读请求，则可以获取读锁； 写请求：如果 没有比自己更小的节点，则可以获得写锁。 为避免羊群效应，可以让","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:7:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"七、分布式事务 分布式事务指事务的参与者、支持事务的服务器、资源服务器、事务管理器分别位于不同的分布式系统的不同节点上，分布式事务要保证这些操作要么全部成功要么全部失败。**本质上：**就是为了保证不同数据库的一致性。 ","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:8:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"八、Zookeeper Zookeeper 基础理论 问：Zookeeper 是什么？ Zookeeper 是一个分布式一致性解决方案集，保证了 CP，可用来实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 ZooKeeper 将数据保存在内存中。 问：Zookeeper 具有哪些特性？⭐ 顺序一致性⭐：从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。实现原理：原子广播。 **原子性⭐：**所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。实现原理：事务。 单一视图⭐：无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 **高可用⭐：**基于副本机制实现，此外 ZooKeeper 支持故障恢复。实现原理：选举 Leader。 **高性能：**ZooKeeper 将数据全量存储在内存中，所以其性能很高。 问：Zookeeper 有哪些数据类型？⭐ zookeeper 数据模型采用树形结构，使用了 znode 作为数据节点。 znode 是 zookeeper 中的最小数据单元，每个 znode 上都可以保存数据，同时还可以挂载子节点，形成一个树形化命名空间。 持久节点：一旦创建就一直存在(即使 ZooKeeper 集群宕机)，直到主动将其删除； **临时节点：**临 客户端会话（session）结束则节点消失 。并且，临时节点只能做叶子节点，不能创建子节点； 持久顺序节点：除了具有持久节点的特性外，节点ID还具有顺序性，如/node1/app0000000001、/node1/app0000000002 **临时顺序节点：**除了具有临时节点特性外，节点ID还具有顺序性。 每个 znode 由 2 部分组成: stat：状态信息； data：节点存放的数据的具体内容。 问：Zookeeper 集群中有哪些角色？⭐ 共有 Leader、Follower 和 Observer 三种角色： Leader： 负责发起并维护与各 Follower 及 Observer 间的心跳； 所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器； 一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader。 Follower： 响应 Leader 的心跳； Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票； 一个 Zookeeper 集群可能同时存在多个 Follower。 Observer：角色与 Follower 类似，但是无投票权。 Zookeeper 工作原理 读操作 Leader/Follower/Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。 由于处理读请求不需要服务器之间的交互，Follower/Observer 越多，整体系统的读请求吞吐量越大，也即读性能越好。 写操作 所有的写请求实际上都要交给 Leader 处理。Leader 将写请求以事务形式发给所有 Follower 并等待 ACK，一旦收到半数以上 Follower 的 ACK，即认为写操作成功。Follower/Observer 均可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理。 问：Watcher(事件监听器) 有啥用？⭐ 客户端注册监听它关心的 znode，当 znode 状态发生变化(数据变化、子节点增减变化)时，ZooKeeper 服务会推送给客户端。 Watcher 可以实现分布式锁、发布订阅等功能。 问：会话机制？(Zookeeper 是咋推送给客户端的呢？) 客户端通过TCP 长连接与 ZooKeeper 服务集群建立会话(Session)，之后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也可以接收到 Watch 事件的通知。 每个会话都会有一个超时时间，客户端通过心跳方式(ping)来保持会话不过期，若服务器在超时时间内没有收到任何请求或心跳，则相应会话被视为过期。 ZAB 协议 ZAB 协议主要定义了两个可以无限循环的流程： 崩溃恢复：用于故障恢复。当主节点出现故障时，选举 Leader，从而保证高可用。 原子广播：用于主从同步，从而保证数据一致性。 在 ZAB 中很重要的字段： **zxid：**是一个 64 位长度的 Long 类型。其中高 32 位表示 epoch，低 32 表示 xid； $$ zxid = (epoch, xid) $$ epoch：每个 Leader 都会具有一个不同的 epoch，用于区分不同的时期（可以理解为朝代的年号）； xid：事务 id，是一个流水号。每次朝代更替，即 leader 更换时，会重新从 0 开始递增； 每当选举产生一个新的 Leader ，就会从这个 Leader 服务器上取出本地事务日志中最大编号 Proposal 的 zxid，并从 zxid 中解析得到对应的 epoch 编号，然后再对其加 1，之后该编号就作为新的 epoch 值，并将低 32 位数字归零，由 0 开始重新生成 zxid。 **myid：**节点id。 问：Zookeeper 如何实现高可用？崩溃恢复/选举过程是啥样的？⭐⭐ Zookeeper 通过副本机制，副本机制通过原子广播实现，当 Leader 出现故障时，会进行崩溃恢复来保证高可用。 关键点：保证选举出的新 Leader 拥有集群中所有节点中最大编号(zxid)的事务！！ 崩溃恢复的过程大致是这样的： **自增选举轮次：**每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作； 初始投票：每个服务器最开始都通过广播把票投给自己，投票内容为所投票服务器的 myid 和 zxid； 接收外部投票：每个服务器都会接收其它服务器的投票，并记入自己的投票箱内； **判断选举轮次：**收到外部投票后，首先会根据投票信息中的 logicClock 进行判断： 若外部投票的 logicClock 大于自己的，说明自己落后，会立即清空并更新自己的投票箱； 若外部投票的 logicClock 小于自己的，直接忽略该选票； 若等于，就将该选票存入投票箱，之后进行投票 PK； **投票 PK：**每个节点都只有一票，这步就是确定最终投给谁。**优先选择 zxid 大的，然后选择 myid 大的。**然后将最终投票广播出去； **统计选票：**若某个 Server 的投票数大于半数以上，则该 Server 就成为了 Leader； **同步状态：**利用 leader 前一阶段获得的最新提议，同步集群中所有的副本。同步完成之后，就可以对外提供服务了。 问：Zookeeper 如何实现分布式数据一致性？⭐⭐ Zookeeper 主要依赖 ZAB 协议来实现分布式数据一致性，ZAB协议是顺序一致性的。主要是通过原子广播来保证。 详细过程： ZooKeeper 中所有的写请求都由 Leader 节点来处理： 客户端的写请求进来之后，Leader 会将写请求包装成 Proposal 事务，并添加一个递增事务 ID，也就是 Zxid。Zxid 是单调递增的，以保证每个消息的先后顺序； 广播这个 Proposal 事务。Leader 会为每一个 Follower 服务器分配一个单独的 FIFO 队列，然后把 Proposal 放到队列中； Follower 节点收到对应的 Proposal 之后会把它持久到磁盘上，当完全写入之后，发一个 ACK 给 Leader； 当 Leader 收到超过半数 Follower 的 ACK 之后，会提交本地机器上的事务，同时开始广播 commit； Follower 收到 commit 之后，完成各自的事务提交。 问：Zookeeper 如何保证事务(Proposal)发送的顺序性？⭐⭐ 如果Follower收到事务的顺序不同，那么会造成数据不一致的。 主要是靠**Zxid和队列**： Leader会为每个事务分配一个全局递增的事务ID(Zxid)，生成事务后，按照该 ID 进行排序，以保证顺序； Leader会为每一个Follower分配一个单独的队列，然后将事务 Proposal 依次放入队列中，并根据 FIFO(先进先出) 的策略进行消息发送。 问：为啥集群中的机器最好是奇数台？ Zookeeper集群中，存活主机数目 \u003e 宕机数目 时，才能继续提供服务。 也就是说，2n 和 2n-1 的容忍度是一样的，都是 n-1。既然多出一台也一样，那何必呢？ 问：Zookeeper 集群如何防止脑裂现象？⭐ ==采用过半机制。==在收到大于一半的选票才能成为 Leader。 ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。 Zookeeper 应用 参考链接 因为Zookeeper的强一致性，可以保证在高并发情况下创建全局唯一的节点。 分布式ID 在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，ZooKeeper 可以通过顺序节点的特性来生成全局唯一 ID，从而可以对分布式系统提供命名服","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:9:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"九、Etcd 主要参考： 深入解读RAFT算法与ETCD工程实现 ETCD原理与实现 Etcd 是一个基于 Raft 共识算法实现的分布式键值存储服务，是 K8s 的核心存储。在项目结构上采用了模块化设计，其中最主要的三个部分是实现分布式共识的 Raft 模块、实现数据持久化的 WAL 模块和实现状态机存储的 MVCC 模块。 更详细的架构图如下： api 接口支持 http 协议和 grpc 协议； node 主要负责 raft 算法的实现； storage 主要负责 raft 日志以及 snap 快照文件的存储； transport 主要负责集群节点间的通信； kvstore 分为 v2 和 v3 两个版本数据库，主要负责业务数据的存储，其中 v3 版本数据库的实现采用 lboltdb 和 keyIndex，支持 mvcc 机制。 RAFT 模块 ==日志复制== 在分布式环境中，如果我们要让一个服务具有容错能力，最常用的方法就是让一个服务的多个副本同时运行在多个节点上。为了保证多个副本在运行时的状态都是同步的，即客户端无论将请求发送到哪一个节点中，最后都能得到相同的结果，通常采用状态机复制（State Machine Replication）方法。 Etcd使用日志复制实现。Etcd 将日志实例化为 Entry 日志，每个节点会存储一系列 Entry 日志，每个节点的 Entry 日志都相同并且顺序也一致，状态机按顺序执行 Entry 中的命令，因此每个状态机处理相同的命令序列，这样就能得到相同的数据状态和输出序列。 RAFT 就是用来保证复制日志的一致性。服务器节点上的Consensus模块接收来自客户端的写请求，将它们添加到 WAL (Write Ahead Log，预写日志）中。随后该服务器与其他服务器上的Consensus模块通信，以确保每个服务器上具有相同的日志序列。每个服务器上的状态机按顺序执行命令，并将执行结果返回给客户端，这样就形成了高可用的复制状态机。 数据通道 为了网络层能够高效地处理不同数据量的消息，etcd 采取分类处理的方式，它抽象出 2 种类型的消息传输通道： **Stream 通道：**用于处理数据量较少、发送比较频繁的消息，例如心跳消息、追加日志消息等，节点与节点之间只维护 1 个 HTTP 长连接，交替向连接中写入数据； **Pipeline 通道：**用于处理数据量大的消息，比如传输快照消息。这种类型的消息需要与心跳消息等分开处理，否则会阻塞心跳包的传输，进而影响集群的稳定性。Pipeline 通道只通过短连接传输数据，用完即关闭。 这两种消息传输通道都使用 gRPC 传输数据。 ==Leader 选举== Raft 通过『leader 选举机制』选举出一个 Leader，由它全权管理日志复制来实现一致性。 Raft 算法论文规定了三种节点身份：Leader、Follower 和 Candidate，Etcd 的实现中又添加了 PreCandidate 和 Learner 这两种身份。 集群启动时所有节点初始状态均为 Follower，随后会有一个节点选举成功成为 Leader，在绝大多数时间里集群内的节点会处于这两种身份之一； 当一个 Follower 节点的选举计时器超时后，会切换为 PreCandidate 身份，进行**preVote**，不自增任期号仅发起预投票，也就是询问集群中其他节点是否愿意参与选举： 如果集群中的其它节点能够正常收到 Leader 的心跳消息，那么会拒绝参与选举； 如果有超过法定人数的节点响应并表示参与新一轮选举，该节点会从 PreCandidate 身份切换到 Candidate，自增任期号并投票给自己，并向其他节点广播竞选投票信息； 当节点收到其他节点的竞选消息后，首先判断竞选节点的任期号大于本节点，则可以投票给竞选节点，否则拒绝投票。 当一个节点成为 Leader 后会立即提交一条空日志，将自身携带的所有日志都设置为提交状态，包括由其它 Leader 创建但还没有提交的日志条目，然后向集群内的其它节点同步。这样就可以保证集群数据的一致性，防止 Leader 节点切换过程中发生数据丢失。 当一个新节点刚进入集群，此时就是 Learner 身份，主要是因为需要花费很长时间来同步日志，这可能导致集群无法处理新的请求，为了避免这种间隔，所以 Learner 不具有投票权，接收 Leader 发来的快照以快速赶上日志，当和Leader日志一致后会转变身份为 Follower。 Entry Raft 模块维护的**所有数据（键值对）**都被实例化为 Entry 日志表示。 Raft 算法中所有写请求都是由 Leader 节点处理的，如果收到提案的节点是 Follower，它会转发给 Leader。 Leader 收到提案后，需要对客户端发送的数据封装为 Entry 日志： Data字段是客户端发送的键值对； Term字段是当前集群的任期； Index字段是该 Entry 日志的索引，相当于全局唯一标识 ID。 封装完数据后会将这些 Entry 日志追加到 Raft Log 中。 写请求流程 client 通过负载均衡算法选择一个 Etcd 节点，发起 gRPC 调用，发送 K-V 请求； 经过检验之后，传递提案给上层，RAFT 模块收到提案后，若当前节点是 Follower，就会转发给 Leader，只有 Leader 才能处理写请求； Leader 收到提案后，通过 RAFT 模块生成 Entry，并保存到 unstable中； Leader 获得 Entry 后，会将其写入 WAL 文件，同时将其广播给集群中的其他节点； 然后 Leader 的 RAFT 模块会把该 Entry 移到 MemoryStorage； 待该 Entry 日志被复制到集群半数以上的节点时，该 Entry 日志会被 Leader 节点确认为己提交，Leader 会回复客户端写请求操作成功； 然后 Leader 将该 Entry 应用到状态机。 线性一致读 ETCD 中，所有的写请求都只由Leader处理，再通过日志复制的方法同步给其他Follower。 但所有的节点(Leader+Follower)都可以处理读请求。由于以下原因，从不同的节点读数据可能会出现不一致: Etcd 应用日志的过程是异步的，Follower的状态总的落后于Leader，且Follower之间的状态也可能存在差异； 若出现网络分区，进而出现脑裂，新旧Leader的状态也会不一致。 也就是说，各个节点并非是 实时 一致，所以读取数据很有可能读取到不一致的旧数据。 问：怎么解决线性一致读问题？⭐ Etcd 采用 ReadIndex 机制实现线性一致读，基本原理： Leader首先通过某种机制确认自己依然是Leader； Leader需要给客户端返回最近已应用的数据：即最新被应用到状态机的数据。 流程如下： 当 Follower 节点收到一个线性读请求时，它首先会向 Leader 请求获取集群最新的、已提交的日志索引，记为ReadIndex； Leader 收到 ReadIndex 请求时，会向 Follower 发送心跳消息，如果超过法定人数的节点响应了心跳消息，就说明自己是合法的 Leader，然后才能将读时已提交的索引返回给请求节点； Follower 拿到后，等待状态机『至少』应用到ReadIndex，即 AppliedIndex \u003e= ReadIndex，然后执行读请求，将结果返回给 Client。 日志存储 RAFT 共有两类数据需要持久化存储： **RAFT 日志：**已提交的日志是不能丢失的； 节点的状态：包括当前的任期 term、当前的投票目标 vote、已提交的最后一条日志索引。前两个字段是 leader 选举流程中的承诺，第三个字段是节点在重启恢复时用来控制日志回放到哪一条日志。 WAL 问：什么是 WAL ？ ETCD 使用 WAL(Write Ahead Log，预写日志) 保存上面两种数据。 所有数据在提交之前都要先写入 WAL 中； 然后定期对数据进行快照备份，快照文件存储了某一时刻 ETCD 的所有数据，数据已经存储在快照中的 WAL 文件就可以删除。 问：WAL 如何工作？ WAL 的工作过程非常像区块链： 首个 WAL 文件的文件开头 crc32 初始值为 0，之后每个记录(raft 日志或者节点状态)的 crc32值 = calc(pre_crc32, 本记录的二进制值)； 对于第二个及以后的 WAL 文件，文件开头的初始 crc32 值 = 上一个 wal 文件最后一条记录的 crc32 值。 这样的话，所有 WAL 文件，其所有记录的 crc32 值可以形成一个可进行强校验的链表。这样在重启恢复的时候，ETCD 就可以对 WAL 文件的内容进行精细化的校验。 日志压缩 WAL 是一种 Append Only 的日志文件，只会在文件结尾不断地添加新日志。当数据量越来越大，WAL 文件就会越来越大，会占用大量空间，并且，通过这么大的 WAL 文件进行数据恢复时，也会耗费很长时间。因此，同 Redis 一样，会定期创建快照，将整个节点的状态进行序列化，然后写入稳定的快照文件中，在该快照文件之前的日志记录就可以全部丢弃掉。 在 RATF 日志中，首先定义几个概念： **log_index：**最新的日志位置索引。 **commit_index：**已达成多数派一致，可提交的最大日志位置索引。 appl","date":"2023-04-23","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:10:0","tags":["计算机基础"],"title":"分布式","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":["面试"],"content":"[toc] 参考文章： 开源消息引擎系统 Kafka 3 新特性 https://juejin.cn/post/7176576097205616700 https://mp.weixin.qq.com/s/vzvmOXGcsX7rwY4J_--onw 20道经典的Kafka面试题详解 《深入理解Kafka：核心设计与实践原理》 ","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:0:0","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"一、消息队列 这里的消息队列指的是各个服务以及系统内部各个组件/模块之前的通信，属于一种中间件。使用消息队列可以降低系统耦合性、实现任务异步、有效地进行流量削峰，是分布式和微服务系统中重要的组件之一。 问：为啥要使用消息队列？消息队列有啥用？ 六个字总结：解耦、异步、削峰 解耦 传统模式下系统间的耦合性太强。举个例子：系统 A 通过接口调用发送数据到 B、C、D 三个系统，如果将来 E 系统接入或者 B 系统不需要接入了，那么系统 A 还需要修改代码，非常麻烦。 如果系统 A 产生了一条比较关键的数据，那么它就要时时刻刻考虑 B、C、D、E 四个系统如果挂了该咋办？这条数据它们是否都收到了？显然，系统 A 跟其它系统严重耦合。 **而如果我们将数据（消息）写入消息队列，需要消息的系统直接自己从消息队列中消费。**这样下来，系统 A 就不需要去考虑要给谁发送数据，不需要去维护这个代码，也不需要考虑其他系统是否调用成功、失败超时等情况，反正我只负责生产，别的我不管。 异步 将用户的请求数据存储到消息队列之后就立即返回结果，消息发送者不需要等待消息接收者的响应，可以继续执行其他任务。随后，系统再对消息进行消费。 因为用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此，使用消息队列进行异步处理之后，需要适当修改业务流程进行配合，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。这就类似我们平时手机订火车票和电影票。 削峰 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务(mysql)再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。 问：引入消息队列会带来哪些问题？ 系统可用性降低：在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况； 系统复杂性提高：加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！ 一致性问题：消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了! 问：队列模型是啥？存在啥问题？ 使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。 存在的问题： 假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容。队列模型就不好解决了。 问：发布-订阅模型是啥？ 发布-订阅模型主要是为了解决队列模型存在的问题。 发布-订阅模型(Pub-Sub)使用主题(Topic)作为消息通信载体，类似于广播模式：发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。 在发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布-订阅模型在功能层面上是可以兼容队列模型的。 ","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:1:0","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"二、Kafka Kafka 是一个分布式流处理平台。 ","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:0","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"2.1 Kafka 应用生态 ==Kafka 应用架构：== 这张图中居于核心地位的是 Kafka Core 的集群，也就是常用的消息引擎的这部分功能，是本篇的重点； 核心的左右两端分两层，下层分别是 Producer 和 Consumer 的基础 API，提供基础事件流消息的推送和消费；上层提供了更加高级的 Connect API，能够实现 Kafka 和其他数据系统的连接，比如消息数据自动推送到 MySQL 数据库或者将 RPC 请求转换为事件流消息进行推送； 最上面的是，Kafka 基于消息引擎打造了一个流式计算平台 Streams，提供流式的计算和存储一体化的服务。 ==具有三个关键功能：== 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。 存储事件流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。 处理事件流：在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。 ==Kafka 主要有两大应用场景：== 数据收集：可以将不同来源的数据流通过Kafka进行集中收集和处理； 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。 流式处理：构建实时的流数据处理程序来转换或处理数据流。 ","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:1","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"2.2 Kafka Core 架构 2.2.1 消息模型 问：Kafka 使用啥消息模型？ Kafka 使用发布-订阅模型。 消费端：消费者通过消费者组进行划分，一条消息只能由消费者组中的一个消费者消费，消费从队列的头部开始，在 HW 前结束； 消息队列：消息存储是队列的数据结构，只允许消息追加写入，此外，Kafka 的队列还设计了高水位机制，避免未被从副本完成同步的消息被消费者感知并消费； 生产端：生产端的 Producer 持续发送消息到队列中，消息追加到队列尾部，通过指定分区算法可以决定消息发往 Topic 下的哪个分区。 Kafka 将生产者发布的消息发送到 **Topic **中，需要这些消息的消费者可以订阅这些 **Topic **，如下图所示： 问：Kafka消息模型中有哪些角色和实体？ 消息模型的图中也为我们引出了，Kafka 比较重要的几个概念： Producer(生产者)：将消息发送到指定 Topic 的 Partition 中，写入到 LEO 的位置； Consumer(消费者)：从指定的 Topic 和 Partition 中拉取或推送消息，并且可以指定消费组(Consumer Group)和消费位移(Consumer Offset)等参数； Consumer Group(消费者组)：消费者组由一个或者多个消费者组成，同一个组中的消费者对于同一条消息只消费一次。每个分区只能由同一个消费者组内的一个消费者(consumer)来消费(避免竞争)，可以由不同的消费者组来消费； Controller(管理者)：整个 Kafka 集群的管理者角色，任何集群范围内的状态变更都需要通过 Controller 进行，在整个集群中是个单点的服务，可以通过选举协议进行故障转移； Topic的新建和删除； Partition的新建、重新分配； Broker 的加入、退出； 触发分区 Leader 选举。 Broker(代理)：Broker是Kafka中负责存储和转发消息的服务器节点，它可以组成一个集群，并且通过Zookeeper进行协调和管理。 Topic(主题)：一个Topic代表一类消息，是消息的逻辑分类。每个Topic可以被分为多个分区(Partition)，每个分区可以存储一定数量的消息，并且有一个唯一的ID。Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题)来消费消息； Partition(分区)：一个Partition是Topic的物理划分，是消息的存储单位。每个Partition中的消息是有序的，并且按照先进先出（FIFO）的顺序消费； Replica(副本)：每个Partition可以有多个副本，其中一个副本是Leader，负责处理读写请求，其他副本是Follower，负责同步Leader的数据。 ​ 主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份。 问：Kafka 是通过 Push 还是 Pull？ Kafka中，消费端是通过主动 pull 消息的方式来消费的。直觉上会觉得本来就应该这样，但其实不是。Kafka 的文档里有讨论这点，主要围绕：消息消费的流控策略应该放在 Broker 端还是 Consumer 端。 2.2.2 集群架构 一个具有代表性的 Kafka 集群通常具备： 1 个独立的 ZK 集群； 3 个部署在不同节点的 Broker 实例。 就以一个这样的典型集群的为例来介绍 Kafka 的整体架构： 2.2.3 Zookeeper 的作用 参考文章： 深入解读基于 Kafka 和 ZooKeeper 的分布式消息队列原理 ","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:2","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"2.3 核心机制 2.3.1 水位机制 问：水位机制的作用？ 水位机制共有两个作用： 辅助从副本完成异步同步； 定义消息可见性，即标识哪些消息可消费。 问：Partition 中的水位机制？⭐ 每个 Partition 是一个独立的消息队列： LSO(Log Stable Offset) 是起点，此偏移会随着消息过期时间等的影响，逐渐向右移动； HW 是已提交消息的可见性的边界，仅在此偏移之下的消息对外是可见的(注意，不含 HW 本身): Leader HW = min(LEO)； Follower HW = min(Follower本地 LEO, Leader HW)。 LEO(Log End Offset) 是消息队列的终点，下一条消息将在这个地方写入。 其中，[LSO, HW) 就是消息的可见范围(已提交)。 问：水位更新？⭐ (这个感觉有点问题。) 主要是高水位是如何更新的，这里用一个 3 副本的场景描述高水位是如何更新到 5 的： 阶段1：此时 ISR 中最小 LEO 为 4。副本 1 发出同步请求，获取 Offset = 4 的数据； 阶段2：同时，HW 更新为 4； 阶段3：当副本 1 收到 Offset = 4 的数据，更新本地 LEO 为 5。此时 ISR 中最小 LEO 更新为 5，于是 HW 更新到 5。 参考文章： https://juejin.cn/post/7070319066325450765 2.3.2 Partition 和 Replica Kafka 中通过分区的多副本策略解决消息备份问题，有如下概念： AR: **所有副本(replicas)**统称为assigned replicas，即 AR； ISR: leader 副本 以及与 leader 副本保持一定同步的 follower 副本，叫 In Sync Replica； OSR: 与 leader 副本同步数据有一些延迟的 follower 节点。 问：Kafka 的多分区(Partition)以及多副本(Replica)机制有什么好处呢？⭐ 多分区(Partition)的好处： 解决伸缩性问题，实现负载均衡，提高并发性能：每个Topic可以被划分为多个Partition，各个Partition可以分布在不同的Broker上，每个Partition可以被不同的Producer和Consumer并行读写，从而实现负载均衡。 多副本(Replica)的好处： 提高容错能力：每个Partition可以有多个Replica，其中一个Replica是Leader，负责处理读写请求，其他Replica是Follower，负责同步Leader的数据。当Leader出现故障时，Zookeeper会自动选举一个Follower作为新的Leader，从而保证服务可用。 问：Kafka 分区的分配策略有哪些？⭐ 消费者与主题之间的分区分配策略：用来解决到底由哪个consumer来消费哪个partition的数据。Kafka 提供了默认的分区策略，同时支持自定义分区策略。 Range(平均)：将每个主题的分区平均分配给消费者。这种策略适合每个主题的分区数相同，且消费者数量稳定的场景。 Round Robin(轮询)⭐：轮流将每个分区分配给消费者。这种策略适合每个主题的分区数不同，且需要实现负载均衡的场景。 Sticky(粘性)：在保持之前分配结果不变的前提下，尽量减少再平衡时重新分配的分区数量。这种策略适合需要避免频繁再平衡导致性能下降的场景。 问：Leader Replica 和 Follower Replica 的同步机制？⭐ ==// TODO== 问：Partition 的并发性？ 一句话总结：同一个 Topic 不同 Partition 之间是支持并发写入消息的，同一个 Partition 不支持并发写入消息。 这很好理解，单个 Partition 是临界资源，需要用锁来进行冲突检测保证同一时间只有一批消息在写入避免出现消息乱序或者写入被覆盖的情况。 问：Kafka 如何保证消息的消费顺序？⭐ Kafka 是不能保证全局消息顺序的，只能保证单个 Partition 下的顺序 Kafka 中 Partition(分区) 是真正保存消息的地方，每次添加消息到 Partition(分区) 的时候都会采用尾加法，即 Kafka 只能为我们保证 单个Partition(分区) 中的消息有序。因此，有如下两种做法： 一个 Topic 只拥有一个 Partition； 在需要保证顺序的场景可以使用 Key-Ordering 策略将同一个用户的消息发送到同一分区，即可保证顺序。例如订单ID或用户ID等，这样同一业务字段的消息会发送到同一分区，并且消费者也按照业务字段进行消费。 2.3.3 持久化 Kafka 通过： 使用**日志(Log)**来保存数据，一个日志就是磁盘上一个只能追加写(Append-only)消息的物理文件； 日志越来越大，必然要定期地删除日志以回收磁盘，这是通过日志段(Log Segment)机制。 Kafka 的日志架构： 一般情况下，一个 Topic 有很多 Partition，每个 Partition 就对应一个 Log 对象，在物理磁盘上则对应于一个子目录。比如创建了一个双 Partition 的 Topic:test-topic，那么，Kafka 在磁盘上会创建两个子目录：test-topic-0 和 test-topic-1。而在服务器端，这就是两个 Log 对象，每个子目录下存在多组日志段，也就是多组.log、.index、.timeindex文件组合，只不过文件名不同，因为每个日志段的起始位移不同。 2.3.4 消息丢失与重复消费 消息丢失 一句话概括，Kafka 只对“已提交”的消息(committed message)做有限度的持久化保证。 第一个核心要素是已提交的消息。 什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。 那为什么是若干个 Broker 呢？这取决于你对“已提交”的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，Kafka 只对已提交的消息做持久化保证这件事情是不变的。 ==总结：==当达到设定数量的Broker成功接收消息并写入保存之后，该消息就认为是已提交的。 第二个核心要素就是有限度的持久化保证。 也就是说 Kafka 不可能保证在任何情况下都做到不丢失消息。 有限度其实就是说 Kafka 不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。 问：Kafka 如何避免消息丢失？ 在使用 MQ 的时候最大的问题就是消息丢失，常见的丢失情况如下： 1）Producer 端丢失 2）Broker 端丢失 3）Consumer 端丢失 一条消息从生产到消费一共要经过以下 3 个流程： 1）Producer 发送到 Broker 2）Broker 保存消息(持久化) 3）Consumer 消费消息 3 个步骤分别对应了上述的 3 种消息丢失场景： ==实际情况分析：== Producer 端丢失 **原因：**由于网络或者Broker异常造成的。 解决方案：消息重传。 具体实现：Producer 不使用fire and forget的发送方式，永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。通过回调，如果Producer发送消息后没有收到Broker的确认回复，就会认为发送失败，进而重传。如果重试，可能会导致消息重复；如果放弃，可能会导致消息丢失。 Broker 端丢失 原因：Kafka 为了减少磁盘 I/O，采用异步批量的刷盘策略，也就是按照一定的消息量和间隔时间进行刷盘。Kafka 收到消息后会先存储在也缓存中(Page Cache)中，之后由操作系统根据自己的策略进行刷盘或者通过 fsync 命令强制刷盘。如果系统挂掉，在 PageCache 中的数据就会丢失。 解决方案：考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。 具体实现：Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份。Follower 中有一个特殊的集合叫做 ISR，当 Leader 故障时，会从 ISR 中新选举出来 Leader。Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。 由于消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个选项叫做 acks，当这个选项被设置为 all 时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 IS","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:3","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"三、常见面试题 什么是 Kafka，它有哪些特点和优势？ Kafka 的架构是怎样的，它包含哪些组件和角色？ Kafka 是如何实现高吞吐量和高可用性的？ Kafka 是如何保证消息的顺序性和一致性的？ Kafka 是如何实现分区和副本的，它们有什么作用？ Kafka 是如何实现生产者和消费者之间的通信的，它们有哪些参数和策略可以配置？ Kafka 是如何维护消费者的消费状态和偏移量的，它们存储在哪里？ Kafka使用消费者组来维护消费者的消费状态和偏移量。消费者组中的每个消费者都会读取一个或多个分区中的数据，并将其偏移量存储在内存中。Kafka使用一个名为__consumer_offsets的内部主题来存储消费者组的偏移量信息。每个消费者组都有一个对应的__consumer_offsets主题，其中包含每个分区的偏移量信息。消费者组中的每个消费者都会定期将其偏移量提交到__consumer_offsets主题中，以便其他消费者可以知道哪些数据已经被消费，哪些数据还没有被消费。 Kafka 有哪些常见的使用场景，它与其他消息系统有什么区别和联系？ Zookeeper 对于 Kafka 的作用是什么，如果 Zookeeper 宕机了会怎样？ 如何监控和度量 Kafka 的运行状态和性能指标？ 如何优化 Kafka 的生产者和消费者的性能，提高吞吐量和降低延迟？ 如何保证 Kafka 的数据安全性，避免数据丢失或重复消费？ 如何处理 Kafka 的异常情况，比如分区不平衡、主从切换、消息堆积等？ 问：Kafka是什么？ Kafka 是一款分布式流处理框架，用于实时构建流处理应用。它有一个核心的功能广为人知，即作为企业级的消息引擎被广泛使用。 问：什么是消费者组？⭐ 标准答案：关于它的定义，官网上的介绍言简意赅，**即消费者组是 Kafka 提供的可扩展且具有容错性的消费者机制。**切记，一定要加上前面那句，以显示你对官网很熟悉。 另外，最好再介绍下消费者组的原理：在 Kafka 中，消费者组是一个由多个消费者实例构成的组。多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。 此时，又有一个小技巧给到你：消费者组的题目，能够帮你在某种程度上掌控下面的面试方向。 如果你擅长位移值原理，就不妨再提一下消费者组的位移提交机制； 如果你擅长Kafka Broker，可以提一下消费者组与Broker之间的交互； 如果你擅长与消费者组完全不相关的Producer，那么就可以这么说：“消费者组要消费的数据完全来自于Producer端生产的消息，我对Producer还是比较熟悉的。” 使用这个策略的话，面试官可能会被你的话术所影响，偏离他之前想问的知识路径。当然了，如果你什么都不擅长，那就继续往下看题目吧。 问：在 Kafka 中，ZooKeeper 的作用是什么？🚩⭐ 这是一道能够帮助你脱颖而出的题目。碰到这个题目，请在心中暗笑三声。 标准答案：目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。KIP-500 提案之后，Kafka 就不再依赖于 ZooKeeper。 存放元数据：是指主题分区的所有数据都保存在ZooKeeper中，且以它保存的数据为权威，其他“人”都要与它保持对齐； 成员管理：是指Broker节点的注册、注销以及属性变更； Controller选举：是指选举集群Controller，而其他管理类任务包括但不限于主题删除、参数配置等。 KIP-500：是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举。 问：解释下 Kafka 中位移(offset)的作用？ 在 Kafka 中，每个 Partition 下的每条消息都被赋予了一个唯一的 ID 数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。 主要是用来： 记录当前消费到哪里了？ 记录当前日志提交到哪里了？引出水位机制。 问：阐述下 Kafka 中的主副本(Leader Replica)和从副本(Follower Replica)的区别？ 可以这么回答：Kafka 副本分为 Leader 副本和 Replica 副本。只有 Leader 副本才能对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉(PULL)的方式，被动地同步Leader副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时准备选举成 Leader 副本，实现高可用性。 通常来说，回答到这个程度，其实才只说了60%，因此，我建议你再回答两个额外的加分项。 强调 Follower 副本也能对外提供读服务。自 Kafka 2.4 版本开始，社区通过引入新的 Broker 端参数，允许 Follower 副本有限度地提供读服务； 强调 Leader 和 Follower 的消息序列在实际场景中不一致。很多原因都可能造成Leader和Follower保存的消息序列不一致，比如程序Bug、网络问题等。这是很严重的错误，必须要完全规避。你可以补充下，之前确保一致性的主要手段是高水位机制，但高水位值无法保证Leader连续变更场景下的数据一致性，因此，社区引入了Leader Epoch机制，来修复高水位值的弊端。关于“Leader Epoch机制”，国内的资料不是很多，它的普及度远不如高水位，不妨大胆地把这个概念秀出来，力求惊艳一把。上一季专栏的[第27节课]讲的就是Leader Epoch机制的原理，推荐你赶紧去学习下。 问：LEO、LSO、AR、ISR、HW 都表示什么含义？ LEO：Log End Offset。日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。举个例子，如果日志有10条消息，位移值从0开始，那么，第10条消息的位移值就是9。此时，LEO = 10； LSO：Log Stable Offset。这是Kafka事务的概念。如果你没有使用到事务，那么这个值不存在（其实也不是不存在，只是设置成一个无意义的值）。该值控制了事务型消费者能够看到的消息范围。它经常与Log Start Offset，即日志起始位移值相混淆，因为有些人将后者缩写成LSO，这是不对的。在Kafka中，LSO就是指代Log Stable Offset； HW：高水位值（High watermark）。这是控制消费者可读取消息范围的重要字段。一个普通消费者只能“看到”Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。水位以上的消息是对消费者不可见的； AR：Assigned Replicas。AR是主题被创建后，所有副本统称为assigned replicas，即 AR； ISR：In-Sync Replicas。指代的是AR中那些与Leader保持同步的副本集合。在AR中的副本可能不在ISR中，但Leader副本天然就包含在ISR中。关于ISR，还有一个常见的面试题目是如何判断副本是否应该属于ISR。目前的判断依据是：Follower LEO落后Leader LEO的时间，是否超过了Broker端参数replica.lag.time.max.ms值。如果超过了，副本就会被从ISR中移除。 问：Leader Partition 的选举策略有几种？/在哪些场景下需要执行 Leader 选举？ Partition 的 Leader 选举由 Controller 负责。当前，Kafka有 4 种 Leader Partition 选举策略： OfflinePartition Leader选举：每当有分区上线时，就需要执行 Leader 选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区 Leader 选举场景。 ReassignPartition Leader选举：当你手动运行kafka-reassign-partitions命令，或者是调用Admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举。假设原来的AR是[1，2，3]，Leader是1，当执行副本重分配后，副本集合AR被设置成[4，5，6]，显然，Leader必须要变更，此时会发生Reassign Partition Leader选举。 PreferredReplicaPartition Leader选举：当你手动运行kafka-preferred-replica-election命令，或自动触发了Preferred Leader选举时，该类策略被激活。所谓的Preferred Leader，指的是AR中的第一个副本。比如AR是[3，2，1]，那么，Preferred Leader就是3。 ControlledShutdownPartition Leader选举：当Broker正常关闭时，该Broker上的所有Leader副本都会下线，因此，需要为受影响的分区执行相应的Leader选举。 这 4 类选举策略的大致思想是类似的，即从 AR 中挑选首个在 ISR 中的副本，作为新 Leader。 问：Kafka 的哪些场景中使用了零拷贝(Zero Copy)？⭐ Zero Copy是特别容易被问到的高阶题目。Kafka的数据是持久","date":"2023-04-22","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:3:0","tags":["计算机基础"],"title":"消息队列","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":["面试"],"content":"[toc] ","date":"2023-04-21","objectID":"/07-redis/:0:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"常见面试题 记录一下常见的面试题，用于自测~~ 🚩：代表被问过 Redis 数据类型和结构（必问⭐⭐） Redis常见的数据类型，使用场景？G 各数据类型的底层数据结构是什么？G 各数据结构的底层实现，做了哪些优化？🚩G Zset底层用的跳表，为啥跳表这么快？G 为什么用跳表，而不用平衡树？G Redis 架构（必问⭐⭐⭐） Redis 为啥这么快？🚩🚩G Redis 是单线程还是多线程？哪部分是单线程？哪部分是多线程？G Redis 的线程模型？G Redis 为啥选择单线程呢？G Redis 集群（必问⭐⭐⭐） Redis 是怎么实现高可用的？G 多个节点间的一致性是咋实现的？主从复制是怎么实现的？🚩G 主节点如何判断一个从节点是不是第一次来同步数据？G 全量同步和增量同步的区别？什么时候执行全量同步？什么时候执行增量同步？G 哨兵模式是怎么实现的？🚩G 分片集群是怎么实现的？G Redis 持久化（⭐⭐） Redis 如何实现数据持久化存储？🚩G 持久化机制、持久化方式是什么，各有什么优缺点？G 混合持久化是什么？G AOF 日志重写机制？G 后台重写？G 写时复制是什么？有啥用？G RDB 创建快照时会阻塞主进程吗？若不会阻塞，那数据能被修改吗？G BigKey 有啥影响？G Redis 缓存（⭐⭐） 缓存穿透及解决方案？G 布隆过滤器原理？G 缓存击穿及解决方案？G 缓存雪崩及解决方案？G 如何保证缓存与数据库的一致性？🚩G Redis 内存淘汰策略有哪些？G Redis 怎么判断一个键值对是否过期？G 对于过期 Key 的策略？G LRU 和 LFU 有啥区别？Redis 是咋实现的？G ","date":"2023-04-21","objectID":"/07-redis/:1:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"一、Redis 概念 问：什么是 Redis？有啥用？/为什么要用缓存？ Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。 **高性能：**若从数据库读取数据，就是从磁盘读取，速度很慢；而从缓存中读取数据是从内存读取的。若把需要频繁读取的数据放入缓存，那么效率就会大大提高； **高并发：**直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以会提高系统整体的并发。 问：Redis 为啥快？ Redis 基于内存，内存的访问速度是磁盘的上千倍； Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用； Redis 内置了多种优化过后的数据结构实现，性能非常高。 问：Redis 和 Memcached 的区别？ 共同点： 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。 区别： Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。 Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。 **Redis 有灾难恢复机制。**因为可以把缓存中的数据持久化到磁盘上。 Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。 Redis 使用单线程的多路 IO 复用模型；Memcached 是多线程，非阻塞 IO 复用的网络模型。 Redis 支持发布-订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。 Redis 同时使用了惰性删除与定期删除；Memcached 过期数据的删除策略只用了惰性删除。 ","date":"2023-04-21","objectID":"/07-redis/:2:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"二、Redis 数据结构 数据类型 问：Redis 常用的数据类型有哪些？使用场景？ 5 种基础数据类型：String(字符串)、List(列表，类似双向链表)、Set(集合)、Hash(散列)、Zset(有序集合)。 3 种特殊数据类型：HyperLogLogs(基数统计)、Bitmap(位存储)、Geospatial(地理位置)。 String 类型的应用场景：缓存session、token、常规计数、分布式锁、共享 session 信息等。 List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。 Hash 类型：缓存对象、购物车等。 Set 类型：聚合计算场景，比如点赞、共同关注(交集)、抽奖活动(去重)等。 Zset 类型：排序场景，比如排行榜、电话和姓名排序等。 问：String 还是 Hash 存储对象数据更好？ 依据使用场景： String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。比如购物车。 String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。 问：常见的数据类型是怎么实现的？ Redis 基本数据类型的底层数据结构实现如下： String List Hash Set Zset SDS LinkedList/ZipList/QuickList Hash Table、ZipList ZipList、Intset ZipList、SkipList 数据结构 SDS⭐ 问：SDS 的底层实现？⭐ Redis没有直接用C中的char*实现字符串，主要是因为char*有如下缺陷： 获取字符串长度的时间复杂度为 O(N)； 字符串的结尾是以 \\0 字符标识，字符串里面不能包含有 \\0 字符，因此不能保存二进制数据； 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止； 而Redis中，String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）(类似Go的)： SDS 获取字符串长度的时间复杂度是 O(1)，因为 SDS 使用 len 属性的值 而不是\\0字符来判断字符串是否结束； SDS 不仅可以保存文本数据，还可以保存二进制数据； 当判断出缓冲区大小不够用时，SDS 支持动态扩容，避免缓冲区溢出。扩容规则： 如果新的 sds 长度(newlen) 小于 1 MB，那么最后的扩容是按照翻倍扩容来执行的，即 2 * newlen + 1；(+1 是因为结束标识符\\0) 如果新的 sds 长度(newlen) 超过 1 MB，那么最后的扩容长度应该是 newlen + 1MB + 1。 分配多余的空间，可以有效的减少内存分配次数。 这是SDS的数据结构，是不是贼像Go的： len，记录了字符串长度。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O(1)。 alloc，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。 flags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，代表了SDS的最大长度，比如2^8^-1、2^16^-1。 buf[]，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。 String 类型的应用场景：缓存session、token、常规计数、分布式锁、共享 session 信息等。 intset 问：整数集合(intset) 的底层实现？ 整数集合本质上是一块连续内存空间： typedef struct intset { //编码方式：int16_t、int32_t、int64_t uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[]; } intset; 其中，contents[] 的真正类型取决于 encoding 属性的值。 插入元素会按序排列，且占用空间相同，方便用下标寻址。 ==升级机制：== 主要针对：插入新元素时，若新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级。也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里。 例，向set[1, 2, 3]插入65535： 好处就是节省内存。 只有升级操作，没有降级操作。 哈希表⭐ 问：哈希表(dict) 的底层实现？ 哈希表的实现方式之一就是 dict (元素数量 \u003e 500时)。可以以 O(1) 的复杂度快速查询数据。 typedef struct dictht { //哈希表数组，桶数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 unsigned long sizemask; //该哈希表已有的节点数量 unsigned long used; } dictht; 哈希表比较熟悉(因为跟Go的好像hhh)，这里只记几个关键词： 与运算； 拉链法； 渐进式扩容； 负载因子： 当负载因子 \u003e= 1 ，并且Redis没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作； 当负载因子 \u003e 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。 当负载因子 \u003c 0.1 时，会做哈希表收缩。 将首个 2^n^ \u003e 新的所需容量，作为扩容/收缩后的容量。 list 问：list 的底层实现？ list的底层实现方式之一就是用List。 其实就是个双向链表。 // 链表 typedef struct list { //链表头节点 listNode *head; //链表尾节点 listNode *tail; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值比较函数 int (*match)(void *ptr, void *key); //链表节点数量 unsigned long len; } list; // 链表节点 typedef struct listNode { //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value; } listNode; 一个3节点链表的示意图： 优点： 获取链表的表头节点和表尾节点的时间复杂度只需O(1)； 获取链表中的节点数量的时间复杂度只需O(1)； 获取某个节点的前置节点或后置节点的时间复杂度只需O(1)。 缺点： 保存一个链表节点的值都需要一个链表节点结构头的分配，内存开销较大。 ziplist⭐ 问：压缩列表(ziplist) 的底层实现？ Redis 对象(List 对象、Hash 对象、Zset 对象)包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。 压缩列表是由连续内存组成的顺序型数据结构，类似数组。 压缩列表表头： zlbytes，记录整个压缩列表占用字节数； zltail，记录压缩列表「尾部」节点距离起始地址有多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。 ==节点 entry==： ==prevlen==，记录了「前一个节点」的长度，目的是为了实现从后向前遍历。(当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，导致连续更新)； encoding，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。 data，记录了当前节点的实际数据，类型和长度都由 encoding 决定； 优点： 压缩列表插入数据时，会根据数据大小和类型进行不同的空间大小分配，节省内存； 缺点： 不能保存过多的元素，否则查询效率就会降低； 新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发**==连锁更新==**的问题。 因此，压缩列表只会用于保存的节点数量不多的场景。 ==连锁更新：== 问题根源是，新插入元素时，后一元素的prevlen占用空间可能会变大，导致自身占用空间变大，然后可能导致后续元素的 prevlen 占用空间都发生变化，发生连锁更新。 quicklist 问：quicklist 的底层实现？ List 的底层对象就是 quicklist。 其实 quick","date":"2023-04-21","objectID":"/07-redis/:3:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"三、Redis 线程模型 问：Redis 到底是单线程还是多线程？ 核心业务部分由单个线程(主线程)来完成：「接收客户端请求-\u003e解析请求 -\u003e进行数据读写等操作-\u003e发送数据给客户端」 但整个 Redis 是多线程的是会启动后台线程(BIO)的： 关闭文件； AOF 刷盘； 释放内存。 一共三个后台线程，用于处理这些比较耗时的任务。 后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。 问：Redis 的单线程模型是什么样的？⭐ 首先创建一个epoll对象，然后创建一个server socket并开始监听它的 FD，初始化完后，主线程就进入到一个监听事件循环函数，主要会做以下事情： 首先，先调用处理发送队列函数，检查发送队列里是否有任务，如果有发送任务，就会注册写事件(到这里就形成闭环了：连接-\u003e读-\u003e写-\u003e返回)，等待 epoll_wait 处理。 接着，才会调用 epoll_wait 函数等待事件就绪： 如果是连接事件到来，则会调用连接事件处理函数，该函数会做这些事情：调用 accpet 获取已连接的 socket -\u003e 调用 epoll_ctl 将已连接的 socket 加入到 epoll -\u003e 注册**「读事件」**处理函数； 如果是读事件就绪，则会调用读事件处理函数，该函数会做这些事情：调用 read 获取客户端发送的数据并写到客户端对象的接收缓冲区 -\u003e 解析命令 -\u003e 处理命令 -\u003e 将执行结果写到客户端对象的发送缓存区等待发送 -\u003e 将客户端对象添加到发送队列； 如果是写事件就绪，则会调用写事件处理函数，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理。 多线程的部分主要是在 网络I/O 部分： 读事件到来，要读取请求数据，可以在这里开启多线程； 写事件，要把数据写到网络，在这里可以开启多线程。 其余执行操作时，均为单线程。 可以看到 socket对象的发送缓冲区和接收缓冲区： 当 socket 状态处于 Established时： Recv-Q 表示 socket 缓冲区中还没有被应用程序读取的字节数； Send-Q 表示 socket 缓冲区中还没有被远端主机确认的字节数； 而当 socket 状态处于 Listen 时： Recv-Q 表示全连接队列的长度； Send-Q 表示全连接队列的最大长度； 黑马Redis的视频：P171 原理篇-27 问：为啥 Redis 的单线程还这么快？ 大部分操作在内存中完成，并且采用高效的数据结构； 单线程可以避免多线程切换的开销； 采用了I/O多路复用处理客户端请求。 注：I/O 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。 问：Redis 6.0 之前为啥单线程，6.0 之后为啥多线程？⭐ ==为啥要选择单线程？== Redis 是在内存操作(最主要原因⭐)，执行速度非常快，它的性能瓶颈是 网络I/O，而不是执行速度，因此多线程并不会带来巨大的性能提升； 引入多线程的话，会面临线程安全问题，增加了系统复杂性，同时可能引发线程切换、加锁解锁等带来的性能损耗。 ==为啥又选择多线程？== 6.0 之后采用多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。所以为了提高网络 I/O 的并行度，Redis 6.0 **==仅对于网络 I/O 采用多线程==**来处理。但是对于命令的执行，Redis 仍然使用单线程来处理。 ","date":"2023-04-21","objectID":"/07-redis/:4:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"四、Redis 持久化 问：Redis 如何实现数据不丢失？ 为了保证内存中的数据不丢失，Redis 实现了数据持久化的机制，会把数据存储到磁盘。 共有三种数据持久化的方式： AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点。 问：什么是 AOF 日志？ Redis 在执行完一条写操作命令后，会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。 问：AOF 中，为什么先执行写操作命令，再写入日志？ **避免额外的检查开销：**先执行可以检查命令是否正确，要是先写入日志又发现命令有错误，就不好办了。 不会阻塞当前写操作。 也会带来风险： **数据丢失：**刚执行完，还没来得及写入日志，Redis 就寄了。 **可能阻塞后一个指令：**AOF 操作也是由主线程完成，所以有可能会阻塞下一个操作无法执行。 问：AOF 写回策略有哪几种？ 由主进程执行写入，写入 AOF 日志的过程： 3 种写回策略的优缺点： 问：AOF 日志过大，会触发什么机制？ AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。 所以，Redis 为了避免 AOF 文件越写越大，提供了 ==AOF 重写机制==。当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。 问：AOF 重写机制的过程？ 当 AOF 变得太大时，Redis 能够在后台自动重写 AOF 产生一个新的 AOF 文件(相当于压缩版 AOF)，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。 在 AOF 重写期间，Redis 服务器会维护一个 AOF 重写缓冲区，并创建一个子进程执行重写操作； 子进程会将生成的新 AOF 文件保存在一个临时文件中，同时主进程会继续将新的写命令追加到旧的 AOF 文件和一个重写缓冲区中(此处为什么还要追加到旧的 AOF？是因为怕宕机导致丢失数据，如果不追加到旧的 AOF，可能会发生宕机导致重写缓冲区没了，然后这部分写操作也没加到旧的 AOF，就造成丢失了。)； 当子进程完成重写操作后，它会向主进程发送一个信号，主进程会将重写缓冲区的内容追加到新 AOF 文件中，然后用新 AOF 文件替换旧 AOF 文件。 也就是说，主进程主要完成三个工作： 执行客户端发来的命令； 将执行后的写命令追加到「AOF 缓冲区」； 将执行后的写命令追加到「AOF 重写缓冲区」。 注意： 重写操作：扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志。 **为啥能减少命令数目呢？**就比如： 问：AOF 后台重写？ 普通的写入 AOF 日志的操作是在主进程完成的，因为它写入的内容不多，所以一般不太影响命令的操作。但 AOF 重写时，一般 AOF 文件都很大，所以不应该放到主进程里完成。 Redis 的重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的，优点：子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程。 思考：为什么是子进程而不是子线程？ 因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生**「写时复制」**，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。 问：写时复制是什么？有啥用？ 在子进程执行 AOF 重写 或 执行 RDB 的过程中，如果主进程又修改了数据，会导致数据不一致，这怎么办？ 实际上，当主进程修改了数据，就会发生写时复制，子进程就会拥有原始未更改的数据副本了。 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存。也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。这样可以共享物理内存资源，节省内存。同时，页表对应的页表项的属性会标记该物理内存的权限为只读。 当父进程或者子进程在修改共享内存中的某条数据时，CPU 就会触发写保护中断，执行写时复制。也就是说，在发生写操作时，操作系统才去复制物理内存。这个过程还会阻塞主进程。之后，主进程就可以对数据副本进行操作，子进程就可以对原数据进行 AOF 重写。 综上，共有两处阻塞主进程的地方： 创建子进程时，需要复制页表等，会阻塞主进程； 发生写时复制时，需要复制数据副本，会阻塞主进程。 问：什么是 RDB 快照？ RDB 是 Redis 默认采用的持久化方式，它会将某一时刻的内存数据以文件的形式保存到磁盘中，记录的是实际的数据。 作用： 可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能）; 还可以将快照留在原地以便重启服务器的时候使用。 Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。显然，这是一个比较重的操作。 问：RDB 创建快照时会阻塞主进程吗？若不会阻塞，那数据能被修改吗？ 提供两种方式： save : 主进程执行，会阻塞主进程； bgsave : 子进程执行，不会阻塞主进程，默认选项 若通过bgsave的方式，执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的。 主要是通过 写时复制 来实现的。详细见 AOF 。 问：如何选择 RDB 还是 AOF？ RDB 更好的地方： RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。 AOF 更好的地方： AOF 可以近实时的持久化数据，保证数据不丢失； AOF 记录了所有的命令操作，可以用于审计和故障排查，安全性更好。 综合来说： 如果需要高性能和快速恢复，并且可以容忍一定程度的数据丢失，可以选择 RDB； 如果需要高可靠性和完整性，并且可以容忍一定程度的性能损耗和恢复延迟，可以选择 AOF； 如果需要同时满足两者的需求，并且有足够的磁盘空间和内存资源，可以选择混合持久化（RDB + AOF）。 问：AOF 会丢失数据吗？ 如果命令执行成功，写入日志的时候宕机了，命令没有写入到日志中，这时候就有丢失数据的风险了。 如果 AOF 文件损坏了，可能会导致数据恢复失败或者部分丢失。 问：为啥要混合持久化？ RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。 AOF 优点是丢失数据少，但是数据恢复不快。 Redis 4.0 提出了混合使用 AOF 日志和 RDB 内存快照，也叫混合持久化。既保证了 Redis 重启速度，又降低数据丢失风险。 ==什么是混合持久化：== 混合持久化工作在 AOF 日志重写过程，重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程用新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的 AOF 文件。 混合持久化的原理是，在 AOF 重写的过程中，把 RDB 格式的全量数据写到 AOF 文件的开头，然后再追加 AOF 格式的增量数据。这样，当 Redis 启动时，只需要加载一个文件就可以恢复所有数据，而不需要先加载 RDB 文件再加载 AOF 文件。也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。 ==混合持久化优点：== 开头为 RDB 的格式，使得 Redis 可以更快的启动； 同时结合 AOF 的优点，有减低数据丢失的风险。 ==混合持久化缺点：== AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差； 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。 ","date":"2023-04-21","objectID":"/07-redis/:5:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"五、Redis 事务 问：如何使用事务？ Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务(transaction)功能。 MULTI 命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 EXEC 命令后，再执行所有的命令。 通过 DISCARD 命令取消一个事务，它会清空事务队列中保存的所有命令。 通过 WATCH 命令监听指定的 Key，当调用 EXEC 命令执行事务时，如果一个被 WATCH 命令监视的 Key 被 其他客户端/Session 修改的话，整个事务都不会被执行。 问：Redis 支持原子性吗？ Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）。 **原因：**Redis 开发者们觉得没必要支持回滚，命令执行错误应该在开发过程中就被发现而不是生产过程中。 可以将 Redis 中的事务就理解为：Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。 实际中，不建议使用 Redis 的事务。 ","date":"2023-04-21","objectID":"/07-redis/:6:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"六、Redis 性能优化 ","date":"2023-04-21","objectID":"/07-redis/:7:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"6.1 键值设计 Key 的最佳实践： 固定格式：[业务名]:[数据名]:[id] 足够简短，不超过44字节； 不包含特殊字符。 Value的最佳实践： 合理拆分数据，拒绝bigkey； 选择合适的数据结构； Hash 结构的 entry 数量不超过 1000； 设置合理的超时时间。 ","date":"2023-04-21","objectID":"/07-redis/:7:1","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"6.2 bigkey 6.2.1 bigkey 发现与删除 问：什么是 bigkey？ 简单来说，如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。 一般有以下两种情况： String 类型的值大于 10 KB； Hash、List、Set、ZSet 类型的元素的个数超过 5000 个； 问：bigkey 会造成什么影响？ 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时(慢查询)，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应； 引发网络阻塞。每次获取大 key 产生的网络流量较大； 持久化时，若对 bigkey 进行修改，会触发写时复制，由于是 bigkey，可能会阻塞主进程较长的时间； 内存分布不均。有大 key 的 Redis 节点占用内存多，出现数据和查询倾斜情况。 问：如何发现 bigkey？ redis-cli --bigkeys 使用 Redis 自带的 --bigkeys 参数来查找，可以遍历分析所有的 key，并返回 key 的整体统计信息与每个数据的 Top1 的 bigkey。 分析 RDB 文件 网上有现成的代码/工具RDB-Tools，可以进行离线的分析 RDB 文件。 网络监控 自定义工具，监控进出 Redis 的网络数据，超出预警值时主动告警。 问：如何删除 bigkey？ bigkey 内存占用较多，导致即使是删除 bigkey，也贼慢。。 unlink -keyname。redis 4.0 后提供的异步删除方式。 若是集合类型，可以遍历bigkey的元素，先逐个删除子元素，再删除该 bigkey。 6.2.2 bigkey 避免 问：假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？ 方案一 方案二 每个 key 存储的时候，还会存储它的元信息，应尽量减少 key 的数量。 方案三⭐ ","date":"2023-04-21","objectID":"/07-redis/:7:2","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"6.3 批处理优化 6.3.1 什么是批处理 普通执行 N 条命令：将 N 条命令依次发送和执行。 $$ N 次命令的响应时间 = N 次往返的网络传输耗时 + N 次Redis执行命令耗时 $$ 其中，命令耗时 是非常短的也就是大部分时间都浪费在了 网络传输。 批量执行：将 N 条命令批量发送和执行。 $$ N 次命令的响应时间 = 1 次往返的网络传输耗时 + N 次Redis执行命令耗时 $$ 那么如何实现上述的批量操作呢？ 6.3.2 批处理方案 6.3.2.1 Mset Redis 提供了很多 Mxxx 这样的命令，可以实现批量插入数据，例如： mset hmset 但 mset 只能操作 string 类型，因此具有局限性。 6.3.2.2 Pipeline⭐ mset 虽然能批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用 Pipeline。 注意事项： 批处理时要避免一次性发送过多命令，导致管道内的命令太多，进而发生网络阻塞； Pipeline 的多个命令之间不具备原子性，而 mset 具备原子性。即 Pipeline 多个命令间可能有别的命令插队。 6.3.2.3 并行slot 集群中，批处理操作通常不会成功，因为不同的 key-val 分布在不同的 slot 中。这时，可以采用并行 slot 操作(spring 已经实现了)。 实现思路：在客户端计算每个 key 的 slot，将 slot 一致的分成一组，每组都利用 Pipeline 批处理，并行执行各组命令。 $$ N 次命令的响应时间 = 1 次往返的网络传输耗时 + N 次Redis执行命令耗时 $$ ","date":"2023-04-21","objectID":"/07-redis/:7:3","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"6.4 服务端优化 6.4.1 慢查询 慢查询：在 Redis 执行时耗时超过某个阈值的命令，称为慢查询。 通常，bigkey 会导致慢查询，可以通过慢查询日志发现哪些命令触发了慢查询，进而优化。 通常，慢查询的原因主要有： 使用复杂度过高的命令 bigkey问题 集中过期 6.4.2 内存配置 当 Redis 内存不足时，可能导致 Key 频繁被删除、响应时间变长、QPS 不稳定等问题。当内存使用率达到 90% 以上时就需要警惕，并快速定位到内存占用的原因。 ","date":"2023-04-21","objectID":"/07-redis/:7:4","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"6.5 集群优化 6.5.1 可用性 在 Redis 的默认配置中，如果发现任意一个 slot 不可用，则整个集群都会停止对外服务。 为了保证高可用性，可以将 cluster-require-full-coverage = false。这样，只有 down 的 slot 不可用。 6.5.2 集群带宽问题 集群节点间会不断的互相 ping 来确定集群中其他节点状态。每次 ping 携带的信息至少包括： slot 信息； 集群状态信息。 集群中节点越多，集群状态信息量也越大，此时每次集群互通所需带宽就会非常高。 解决途径： 避免大集群，集群节点数不要太多，最好 \u003c 1000，如果业务庞大，则建立多个集群； 避免在单个物理机上运行太多 Redis 实例； 配置合适的 cluster-node-timeout 值。 ","date":"2023-04-21","objectID":"/07-redis/:7:5","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"七、Redis 缓存设计 7.1 缓存穿透 Cache Penetration 问：什么是缓存穿透？ 简单来说就是，大量请求的 key 是不合理的，根本不存在于缓存中，也不存在于数据库中。导致这些请求直接砸到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 问：有哪些解决方法？ 缓存无效 key。就是把缓存找不到的、数据库也查不到的 key，写入到缓存中，并设置过期时间。但无法根本上解决，缓存一堆没用的数据照样能给你干宕机。 布隆过滤器。可以帮助快速判断一个给定数据是否存在于海量数据中。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走之后的流程(缓存、数据库)。 问：布隆过滤器原理？缺陷及解决？ 元素加入布隆过滤器的过程： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在多个位数组中把对应下标的值置为 1。 判断一个元素是否存在于布隆过滤器的过程： 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中对应下标元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 布隆过滤器的缺点： 还是有几率缓存穿透，布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。解决方法：可以增多哈希函数，计算出多个哈希值，只有所有哈希值对应的数组中的值都为 1 时，才会认为这个元素在集合中。 不支持删除元素，这也和哈希冲突有关。解决方法：让数组中不再只有 0 和 1 两个值，而是存储一个计数。比如如果 A 和 B 同时命中了一个数组的索引，那么这个位置的值就是 2，如果 A 被删除了就把这个值从 2 改为 1。但这会增加空间的消耗。所以，要依据业务场景来选择使用布隆过滤器。 7.2 缓存击穿 Hotspot Invalid 问：什么是缓存击穿？ 缓存击穿中，请求的 key 对应的是热点数据，该数据存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 **比如：**秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。 问：有啥解决方法？ 设置热点数据永不过期或者过期时间比较长。 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 分布式锁。控制在某一个热点缓存项失效之后启动一个后台线程获得锁，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都阻塞或直接返回； 逻辑过期，当发现数据过期，并且尝试获取互斥锁失败时，会返回旧数据，因为此时已经有其他线程去更新数据了。这主要保证数据可用性。 问：缓存穿透和缓存击穿的区别？ 缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。 缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。 7.3 缓存雪崩 问：什么是缓存雪崩？ 缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。 **比如：**数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。 问：有啥解决方法？ ==针对 Redis 宕机的情况：== 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 服务降级限流 因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动服务降级限流机制，暂停业务应用对缓存服务的访问，返回默认值或友好提示，不用再继续访问数据库，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。 服务降级限流机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作。 请求限流 为了减少对业务的影响，我们可以启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。 ==大量数据同时过期的情况：== **均匀(随机)**设置过期时间； 互斥锁。如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存。 问：缓存雪崩和缓存击穿有啥区别？ 缓存雪崩是缓存中的大量或所有数据失效； 缓存击穿是某个热点数据不存在与缓存中（通常是因为缓存中的那份数据已经过期）。 7.4 缓存一致性⭐ 缓存一致性的核心问题是：在更新数据库数据时，如何保证缓存数据也同步更新或失效，避免读取到过期或错误的数据。 常见的缓存更新策略有以下几种： Cache Aside⭐：旁路缓存策略； Read/Write Through：读穿/写穿策略； Write Back：写回策略。 以上策略都不能完全保证强一致性（即任何时刻都能读取到最新的数据），只能保证最终一致性（即经过一段时间后能够达到一致状态）。要实现强一致性，则需要牺牲系统的可用性或分区容忍性（根据CAP理论）。 这里主要介绍了旁路缓存策略，有空再看其他两种策略。 问：如何保证缓存与数据库的一致性？⭐⭐ 实际开发中，Redis 和 MySQL 的更新策略用的是旁路缓存策略(Cache Aside)。策略可以细分为「读策略」和「写策略」。 写策略： 采用先更新数据库再删除缓存⭐，主要是为了解决线程安全问题； 确保数据库与缓存操作的原子性。单体系统天生就能原子性，分布式系统的话就用分布式事务。 读策略： 缓存命中则直接返回； 缓存未命中则查询数据库，并写入缓存，设定超时时间(相当于兜底方案，避免写方案更新缓存失效)。 问：写策略中，能否先删除缓存，后更新数据库呢？⭐ 不能滴~~ 先删除缓存再更新数据库：这种方式可以保证不会读取到过期的缓存数据，但是存在并发问题。如果在删除缓存后、更新数据库前，有其他线程读取了该数据，并将旧数据写入了缓存，那么就会导致缓存和数据库不一致。 先更新数据库再删除缓存⭐：这种方式其实理论上也有问题： 存在延迟问题(会读到旧数据)。如果在更新数据库后、删除缓存前，有其他线程读取了该数据，就会读取到过期的旧数据； 理论上也可能出现缓存和数据库的不一致，不过出现的机率远小于第一种。原因是缓存的写入通常远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据，所以不会出现这种不一致的情况。 简单总结，足以适应绝大部分的互联网开发场景的决策： 针对大部分读多写少场景，建议选择更新数据库后删除缓存的策略。 针对读写相当或者写多读少的场景，建议选择更新数据库后更新缓存的策略。 问：Cache Aside 有啥问题吗？ Cache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案： 一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响； 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受。 参考文章： 万字图文讲透数据库缓存一致性问题 7.5 过期、淘汰 问：Redis 怎么判断一个键值对是否过期？ 可以通过expire设置过期时间ttl。利用两个 Dict 分别记录key-value和key-ttl。 typedef struct redisDb { dict *dict; /* 数据库键空间，存放着所有的键值对 */ dict *expires; /* 键的过期时间 */ .... } redisDb; 问：Redis 对于过期 Key 的策略？ 对于过期 key，Redis 采用的是 定期删除+惰性删除 策略。 惰性删除：在访问一个key时，先检查它是否过期，如果过期就删除它。 优点：在访问时才会检查，只会使用很少的系统资源，对 CPU 友好； 缺点：若 key 过期，之后一直没被访问到，就会一直占用内存。 定期删除：周期性的取出部分 key 进行检查，然后删除其中过期的。 优点：通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能规避惰性删除的问题； 缺点：执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。 问：大量 key 集中过期的情况怎么办？ 常采用以下两种解决方法： 给 key 设置随机过期时间； 开启惰性删除，让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 问：Redis 都有啥内存淘汰策略？ Redis 内存淘汰策略共有 8 种，这 8","date":"2023-04-21","objectID":"/07-redis/:8:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"八、Redis 集群 ","date":"2023-04-21","objectID":"/07-redis/:9:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"8.1 主从复制 问：Redis 如何实现服务高可用？ **数据持久化：**这是基础，保证系统在发生宕机或者重启之后数据不会丢失。 ==三种模式：== **主从复制：**将数据存储至多台服务器，当主节点挂了，保证能够很快的切换； 哨兵：监控主节点的状态，若主节点挂了，自动选举新的主节点，并完成故障转移； 集群：提供了多主多从的 Redis 分布式集群环境，实现分布式存储，每个节点存储不同的内容，节省了内存也提高了可用性。 问：如何保证多个 Redis 节点间的数据一致性呢？ 通过主从复制和读写分离。 问：主从复制是如何实现的？⭐🚩 主从复制是 Redis 高可用服务的最基础的保证。实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是**「读写分离」**的方式。 ==读写分离：== 读写分离指主服务器可以进行读和写操作，当发生写操作时自动将写操作同步给从服务器；而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。 该方式，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。 ==主从复制：== 全量同步(从节点是新加入集群的)： 从节点向主节点发送 slaveof 命令，包括(replid=?, offset=-1)，建立复制关系，并发送请求同步命令。 主节点收到命令后，判断要进行哪种同步，若是全量同步，会创建一个后台子线程，负责将自己的数据**快照（RDB文件）**发送给从节点。 从节点收到数据快照后，会先保存在本地，然后清空自己的数据，并载入收到的数据快照。 主节点在等待从节点同步数据的同时，还会将自己新执行的所有写命令缓存在 replication buffer 中。 当从节点完成数据快照的载入后，会向主节点发送一个消息，请求接收写命令。 主节点收到消息后，会将 replication buffer 中的写命令依次发送给从节点，从而使得从节点与主节点保持一致。 此后，主节点和从节点保持一个长连接。每执行一个写命令，就会将该命令同步给所有的从节点。 增量同步(从节点重启后同步)： 若网络不好，长连接断了。恢复后，主从服务器会采用增量同步的方式继续同步。 从节点向主节点发送同步命令(replid, offset)； 主节点判断 replid 是否一致，若一致且从节点的 offset 跟主节点的 offset 差距没有过大(未同步的数据没被覆盖)，就会增量备份，主节点会从repl_baklog获取从节点offset之后的增量数据，将增量数据写入到 replication buffer 缓冲区，然后发送给从节点。 问：主节点如何判断从节点是不是第一次来同步数据？⭐ 两个很重要的概念： **Replication Id：**简称replid，是数据集的标记，id一致说明是同一数据集。每一个主节点都有唯一的replid，从节点会继承主节点的replid。 Offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。从节点完成同步时也会记录当前同步的offset。如果从节点的offset小于主节点的offset，说明从节点数据落后于主节点，需要更新。 从节点同步数据时，必须向主节点声明自己的replid和offset，然后由主节点判断需要同步哪些数据： 若replid为 “?” 或 不一样，就是第一次，将进行全量同步； 若replid一样，就通过offset进行增量同步。 ==注意：==难道从节点断联特别久，再连接上也是增量同步吗？ 当然不是！这就跟repl_baklog有关了~ repl_baklog相当于一个环形缓冲区，写满之后就会覆盖最早的数据。如果从节点断开过久，导致尚未备份的数据已经被覆盖了，就无法基于repl_baklog做增量同步了，只能触发全量同步！ 问：全量同步和增量同步的区别？什么时候执行全量同步？什么时候执行增量同步？ 区别： **全量同步：**主节点将内存数据生成RDB，发送RDB文件给从节点。后续命令记录在baklog中，逐个发送给从节点； **增量同步：**从节点提交自己的offset到主节点，主节点获取baklog中的offset之后的命令给从节点。 什么时候全量同步： 从节点第一次连接到主节点时； 从节点离开太久，未同步的baklog已经被覆盖； 什么时候增量同步： 从节点断开又恢复，并且在baklog中能找到offset时。 问：如何优化主从数据同步？ 优化全量同步： 在网络条件很好的时候，在 master 启用无磁盘复制，也就是不把 RDB 文件写入到磁盘，而是直接写入网络IO，减少磁盘的复制； 减少全量同步次数： 适当提高repl_backlog； 发现从节点宕机时，尽快实现故障恢复，尽可能避免全量同步； 限制一个主节点上的从节点数量，如果实在太多从节点，则可以采用 主-从-从 的结构，减少主节点压力。 问：Redis主从节点时长连接还是短连接？ 长连接。 问：怎么判断 Redis 某个节点是否正常工作？ Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong 心跳检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。 Redis 主从节点发送的心跳间隔是不一样的，而且作用也有一点区别： Redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。 Redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了： 实时监测主从节点网络状态； 上报自身复制偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点的复制缓冲区中拉取丢失数据。 问：主从复制架构中，过期key如何处理？ 主节点处理了一个key或者通过淘汰算法淘汰了一个key时，主节点需要模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。 问：Redis 是同步复制还是异步复制？ Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。 问：主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？ replication buffer 、repl backlog buffer 区别如下： 出现的阶段不一样： repl backlog buffer 是在增量复制阶段出现，一个主节点只分配一个 repl backlog buffer； replication buffer 是在全量复制阶段和增量复制阶段都会出现，主节点会给每个新连接的从节点，分配一个 replication buffer； 这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样： 当 repl backlog buffer 满了，因为是环形结构，会直接覆盖起始位置数据; 当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，重新开始全量复制。 问：如何应对主从数据不一致？ 之所以会出现主从数据不一致的现象，是因为主从节点间的命令复制是异步进行的，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。 有两种方法： 第一种方法，尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。 第二种方法，可以开发一个外部程序来监控主从节点间的复制进度。具体做法： Redis 的 INFO replication 命令可以查看主节点接收写命令的进度信息（master_repl_offset）和从节点复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从节点的进度，然后，我们用 master_repl_offset 减去 slave_repl_offset，这样就能得到从节点和主节点间的复制进度差值了。 如果某个从节点的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从节点连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从节点都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。 问：主从切换如何减少数据丢失？ 主从切换过程中，产生数据丢失的情况有两种： 异步复制同步丢失 集群产生脑裂数据丢失 不可能保证数据完全不丢失，只能做到使得尽量少的数据丢失。 异步复制同步丢失： 对于 Redis 主节点与从节点之间的数据复制，是异步复制的，当客户端发送写请求给主节点的时候，会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。 减少异步复制的数据丢失的方案： Redis 配置里有一个参数 min-slaves-max-lag，表示一旦所有的从节点数据复制和同步的延迟都超过了 min-slaves-max-lag 定义的值，那么主节点就会拒绝接收任何请求。 假设将 min-slaves-max-lag 配置为 10s 后，根据目前 master-\u003eslave 的复制速度，如果数据同步完成所需要时间超过10s，就会认为 ","date":"2023-04-21","objectID":"/07-redis/:9:1","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"8.2 哨兵机制 哨兵模式是在主从复制的基础上增加了一组哨兵（sentinel）节点来监控主从节点的状态，实现主从节点自动故障转移。哨兵的结构和作用如下： 监控：Sentinel 会不断检查 Master 和 Slave 的状态； 自动故障恢复：如果 Master 故障，Sentinel 会自动将一个 Slave 提升为 Master。当故障节点恢复后也会以新的 Master 为主节点； 通知：Sentinel 充当 Redis 客户端的服务发现源，当集群发生故障转移时，会将最新信息自动推送到 Redis 客户端。 问：哨兵机制是如何实现的？⭐ 如果发现主节点失效，哨兵会自动选举出一个领导者(leader)，然后由领导者从剩余的从节点中选出一个新的主节点，并通知其他哨兵和客户端。 ==具体工作过程：== 哨兵会定期(每隔1s)向所有的主节点和从节点发送心跳包，检测它们的运行情况； 如果一个哨兵发现某个主节点没有响应心跳包，就会将其标记为主观下线，然后请求其他哨兵节点进行投票； 如果有超过指定值的哨兵(配置文件中指定的 quorum 值)都将某个主节点标记为主观下线(也就是赞成)，那么该主节点就被认为是客观下线，并开始进行故障转移； 故障转移过程前，哨兵会从该主节点的所有候选者中选出一个合适的候选者，将其升级为哨兵中的 Leader，负责进行故障转移； ​ 候选者：哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点以及投赞成票的哨兵节点就都是候选者； Leader 会从所有的从节点中选择一个合适的从节点作为新的主节点； 故障转移完成后，原来的主节点如果恢复了正常，就会变成新主节点的从节点。 问：哨兵 如何成为 哨兵Leader？ 候选者：哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点以及投赞成票的哨兵节点就都是候选者。 候选者会向其他哨兵发送投票请求； 每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己； 要成为哨兵 Leader，需满足以下条件： 第一，拿到半数以上的赞成票； 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。 问：哨兵Leader如何选择新的主节点？⭐ 哨兵 Leader 通过如下规则选择新的主节点： 选择 Slave 中优先级最高的。优先级是在 Slave 配置中设置的； ⭐哨兵 Leader 会优先选择 offset 最大的 Slave，因为它表示数据最完整。 如果有多个从节点复制偏移量相同，ID 号小的从节点胜出。 问：哨兵Leader节点进行 主从故障转移操作 的过程？⭐ 挑选出 Master； **广播通知所有 Slave **与新的 Master 进行同步； 将新的 Master 通过「发布者/订阅者机制」通知给客户端； 继续监视旧的 Master ，当它重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新的 Master 的 Slave。 问：哨兵集群是怎么组成的？ 哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。 在主从集群中，主节点上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到__sentinel__:hello 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。 问：集群脑裂？ 什么是脑裂？ 由于网络问题，哨兵和从节点都与主节点失联了，但主节点依然正常运行，此时由于哨兵以为主节点挂了，所以就会从从节点选出新的主节点，此时就有两个主节点 - ==脑裂现象==。 由于此时旧主节点依然和客户端能正常通信，客户端向旧主节点写入数据，然后网络又好了！此时旧主节点发现已经有新的主节点，就会变为从节点，清楚自身所有数据，然后进行全量同步，显然这样会导致丢失部分数据。 **总结一句话就是：**由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。 咋解决呢？ 当主节点发现 $从节点总数量 - 从节点下线或者通信超时的数量 \u003c 阈值$ 时，那么禁止主节点进行写数据操作，直接把错误返回给客户端。 等到新主节点上线时，就只有新主节点能接收和处理客户端请求，此时，新写的数据会被直接写到新主节点中。而原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有新数据丢失。 ","date":"2023-04-21","objectID":"/07-redis/:9:2","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"8.3 分片集群 问：分片集群是如何实现的？ 集群模式是将多个 Redis 节点组成一个分布式系统，每个节点负责一部分数据，并通过**槽（slot）**来映射数据分片。集群模式支持多个主节点和多个从节点，每个主节点可以有多个从节点作为备份。集群模式可以实现数据的分布式存储、读写分离、负载均衡、故障转移等功能，提高了服务可扩展性和稳定性，但是也增加了系统复杂度和维护成本。 ==散列插槽== Redis 共有 16384 个哈希槽(hash slot)，将每个 key 通过哈希函数 crc16() 将 key 转化成一个长整型数字，再对 16384 取余，最终决定这个 key 存储的哈希槽。也就是会把每个 key 映射到0-16383个插槽上，每个主节点负责一部分插槽(即一部分键值对)。 ==实现方式== 客户端分片 客户端自己计算key需要映射到哪一个主节点。 优点：降低了集群的复杂度 缺点：当新增Redis实例时需要支持动态分片 服务端分片⭐ 客户端访问某个key时，服务器计算key应该映射到哪个节点，若不是当前节点，就会重定向到指定节点。 代理分片 客户端将请求发送到代理，代理计算得到需要映射的节点信息，然后将客户端的请求转发到对应节点上，然后返回响应给客户端。 ==分片机制的缺点== 分片是由多台Redis实例共同运转，所以如果其中一个Redis实例宕机，则整个分片都将无法使用，所以分片机制无法实现高可用。 如果有不同的key映射到不同的Redis实例，这时候不能对这两个key做交集或者使用事务。 使用分片机制因为涉及多实例，数据处理比较复杂。 分片中对于实例的添加或删除会很复杂，不过可以使用预分片技术进行改善。 问：自动故障转移和手动故障转移？ 自动故障转移： 首先是 Master 与其他节点失去连接； 其他节点标记 Master 为疑似宕机； Master 确定宕机，自动提升一个 Slave 为 Master。 手动故障转移：利用 cluster failover 命令可以手动让集群中某个 Master 宕机，切换到执行 cluster failover 命令的这个 Slave 节点，实现无感知的数据迁移。 ","date":"2023-04-21","objectID":"/07-redis/:9:3","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"九、多级缓存(未) 多级缓存就是利用请求处理的每个环节，分别添加缓存，减轻 TomCat 的压力。 ","date":"2023-04-21","objectID":"/07-redis/:10:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"十、Redis 实战(未) ","date":"2023-04-21","objectID":"/07-redis/:11:0","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"10.1 如何为秒杀系统设计缓存体系 ","date":"2023-04-21","objectID":"/07-redis/:11:1","tags":["计算机基础"],"title":"Redis","uri":"/07-redis/"},{"categories":["面试"],"content":"常见面试题 用于自测，点击 G 即可跳转到相应答案~~ ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"MySQL 索引(⭐⭐必问) 索引的类型有哪些？G 索引的数据结构有哪些？G B+树和B-树的区别？G B+树和Hash的区别？G 索引创建原则？G 什么情况下索引失效？G 聚集索引是什么？选取规则是什么？G 前缀索引？G uuid 和 自增id，做索引有啥区别？G 什么是回表查询？什么时候会触发回表查询？G⭐🚩 联合索引应用场景？为什么要建联合索引？G⭐🚩 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"MySQL 事务(⭐⭐必问) 事务隔离级别？G 可重复读下，如何避免幻读？G MVCC 的实现原理？G 各事务隔离级别是如何实现的？可重复读：G；读已提交：G 事务实现原理？ACID 是怎么保证的？未 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"MySQL 锁(⭐⭐必问) 行级锁，表级锁；排它锁，共享锁；记录锁、间隙锁，临键锁；两阶段锁； 死锁的原因？G 如何避免死锁？G ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"MySQL 日志(⭐⭐常问) undo log 是啥？有啥用？G redo log 是啥？有啥用？G undo log 和 redo log 有啥区别？G 为什么有 bin log 了还要 redo log，两者有什么区别以及两者生成的时机？G 执行 update 的过程？⭐G 事务提交过程：什么是两阶段提交？G 为啥要两阶段提交？G ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:4","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"MySQL 架构(⭐常问) 主从复制是咋实现的？G 从库是越多越好吗？G 主从复制有哪些模型？/如何保持主从间的数据一致性？G 分库、分表的方式有哪些？G 水平分片有哪些规则？G ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:5","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"MySQL 数据类型 MySQL有哪些数据类型？ varchar 与 char 的区别？int 和 int (11) 区别？tinyint 与 int 区别？ MySQL 的 NULL 值是怎么存放的？会占用空间吗？ MySQL 怎么知道 varchar(n) 实际占用数据的大小？ varchar(n) 中 n 最大取值为多少？ 行溢出后，MySQL 是怎么处理的？ ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:6","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"面试问的 执行MySQL语句特别慢，可能的原因？G drop 和 delete 有啥区别？G count(1)、count(*)、count(字段)，哪个效率最高？G⭐🚩 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:1:7","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"一、事务 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:2:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"1.1 概念及原理 问：什么是事务？ 事务是一组操作的集合，是一个不可分割的单位，事务中包含若干操作，这些操作要么都成功，要么都失败。 # 开启一个事务 START TRANSACTION; # 多条 SQL 语句 SQL1,SQL2... # 提交事务 COMMIT; 问：事务的四大特性？ACID 是什么？ 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性⭐（Consistency）：执行事务前后，数据保持一致。例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后，它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 注：只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！ 问：MySQL中，各有什么机制保证以上四个属性？ 原子性、一致性、持久性：redo log、undo log； 隔离性：锁、MVCC。 问：持久性是怎么保证的？ redo log。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:2:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"1.2 并发事务 A、B同时对数据库进行事务操作时，会发生的问题。 问：并发事务会带来哪些问题？ 脏读 不可重复读 幻读 丢失修改 … 脏读：一个事务读到了另一个事务还未commit的数据； 不可重复读：一个事务中先后读取同一条数据，期间另一个事务修改了该数据，造成第一个事务先后读取到的数据不一致。即，一个事务中前后两次读到的数据不一致； 幻读：一个事务查询某条数据时，发现没有对应行，但之后另一个事务插入了该条数据，当第一个事务准备插入该条数据时，又发现这行数据已存在。即，前后读取的记录数量不一致，就像出现了幻觉一样； 丢失修改：第一个事务修改了某条数据，第二个事务随后又修改了某条数据，造成第一个事务的修改结果丢失。 问：不可重复读和幻读的区别？ 不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把区分幻读的原因主要是解决幻读和不可重复读的方案不一样。 **举个例子：**执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。 问：并发事务的控制方式有哪些？ MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。锁可以看作是悲观控制的模式，多版本并发控制（MVCC，Multiversion concurrency control）可以看作是乐观控制的模式。 锁 控制方式下会通过锁来显示控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。 共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。 读写锁可以做到读读并行，但是无法做到写读、写写并行。另外，根据根据锁粒度的不同，又被分为 表级锁（table-level locking） 和 行级锁（row-level locking） 。InnoDB 不光支持表级锁，还支持行级锁，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说，InnoDB 的性能更高。不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。 MVCC 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。 MVCC 在 MySQL 中实现所依赖的手段主要是：隐藏字段、read view、undo log。 undo log：undo log 用于记录某行数据的多个版本的数据。 read view 和 隐藏字段：用来判断当前版本数据的可见性。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:2:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"1.3 事务隔离级别 问：都有哪些事务隔离级别？ SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)：最低的隔离级别，允许读取尚未提交的数据变更。可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)：允许读取并发事务已经提交的数据。可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。可以阻止脏读和不可重复读，但幻读仍有可能发生。MySQL InnoDB 引擎的==默认隔离级别==； SERIALIZABLE(可串行化)：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰。也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × 问：可重复读下，如何避免幻读？ 首先要明确，使用「串行化」隔离级别才能彻底解决幻读现象，**==可重复读==只能在==很大程度上==**避免幻读(并不是完全解决了，详见这篇文章)。 可重复读的解决方案分为两方面： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读。因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 以下说明：为啥可重复读没完全解决幻读？ 示例场景1： 事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。注意，此时并未提交事务！ # 事务 A mysql\u003e begin; Query OK, 0 rows affected (0.00 sec) mysql\u003e select * from t_stu where id = 5; Empty set (0.01 sec) 然后事务 B 插入一条 id = 5 的记录，并且提交了事务。 # 事务 B mysql\u003e begin; Query OK, 0 rows affected (0.00 sec) mysql\u003e insert into t_stu values(5, '小美', 18); Query OK, 1 row affected (0.00 sec) mysql\u003e commit; Query OK, 0 rows affected (0.00 sec) 此时，事务 A 更新 id = 5 这条记录； # 事务 A mysql\u003e update t_stu set name = '小林coding' where id = 5; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u003e select * from t_stu where id = 5; +----+--------------+------+ | id | name | age | +----+--------------+------+ | 5 | 小林coding | 18 | +----+--------------+------+ 1 row in set (0.00 sec) 然后再次查询 id = 5 的记录，事务 A 就能看到事务 B 插入的记录了，且被自己更新过。这就产生了幻读。 整个过程的时序图： 事务 A 开始时，会创建一个 Read View； 然后，事务 B 新插入了一条记录； 接着，事务 A 通过 update 操作对该记录进行更新，此时这条新记录的**trx_id就变成了事务 A 的事务 id**； 之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。 示例场景2： T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id \u003e 100 得到了 3 条记录。 T2 时刻：事务 B 往插入一个 id= 200 的记录并提交； T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id \u003e 100 for update 就会得到 4 条记录，此时也发生了幻读现象。 场景2可以通过在开启事务之后，马上执行 select … for update 这类当前读的语句来避免，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。 问：可重复读的实现原理？⭐ 可重复读隔离级别是==启动事务时==生成一个 Read View，然后整个事务期间都在用这个 Read View。 例，假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，那这两个事务创建的 Read View 如下： 接着，在可重复读隔离级别下，事务 A 和事务 B 按顺序执行了以下操作： 事务 B 读取小林的账户余额记录，读到余额是 100 万； 事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务； 事务 B 读取小林的账户余额记录，读到余额还是 100 万； 事务 A 提交事务； 事务 B 读取小林的账户余额记录，读到余额依然还是 100 万； 具体分析下这个过程： 事务 B 第一次读取时，发现该记录的trx_id \u003c 事务 B 的 Read View 中的min_trx_id，所以该记录的该版本可见； 接着，事务 A 修改该记录(但还没提交事务)，此时 MySQL 会记录 undo log，以链表方式串联起来，形成版本链； 然后，事务 B 第二次读取，发现该记录的trx_id 在min_trx_id和max_trx_id之间，且在m_ids中存在该记录的trx_id，说明该记录是被还未提交的事务修改的，因此该版本不可见，就会顺着 undo log 链向旧版本寻找，直到某个版本的trx_id \u003c min_trx_id 或 trx_id \u003e min_trx_id 且不存在m_ids中。此处表现为读到了旧数据； 接着，事务 A 提交该事务； 但由于**「可重复读」，事务 B 第三次读取该记录时，还是基于启动事务时创建的Read View来判断当前版本**的记录是否可见，因此依然判定该记录为未提交，因此读到的依然是旧数据。 问：读已提交的实现原理？ 读提交隔离级别是在**==每次读取数据时==，都会生成一个新的 Read View**。 还是之前那个例子，假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，接着按顺序执行了以下操作： 事务 B 读取数据（创建 Read View），小林的账户余额为 100 万； 事务 A 修改数据（还没提交事务），将小林的账户余额从 100 万修改成了 200 万； 事务 B 读取数据（创建 Read View），小林的账户余额为 100 万； 事务 A 提交事务； 事务 B 读取数据（创建 Read View），小林的账户余额为 200 万； 区别就在于事务 B 第三次读取数据时，会新建 Read View： 注意，此时m_ids中只有52了，事务 B 查询该记录时，trx_id=51，小于min_trx_id，所以该记录的该版本对事务 B 可见。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:2:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"二、存储引擎 5.5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎，且所有的存储引擎中只有 InnoDB 是事务性存储引擎，也就是说只有 InnoDB 支持事务。 -- 查询当前数据库支持的数据库引擎 show engines; 问：MySQL存储引擎架构？ MySQL 存储引擎采用的是 插件式架构 ，支持多种存储引擎，我们甚至可以为不同的数据库表设置不同的存储引擎以适应不同场景的需要。存储引擎是基于表的，而不是数据库。 还可以根据 MySQL 定义的存储引擎实现标准接口来编写一个属于自己的存储引擎。(像目前最常用的 InnoDB 其实刚开始就是一个第三方存储引擎，后面由于过于优秀，其被 Oracle 直接收购了。) 问：MyISAM 和 InnoDB 有何区别？ 是否支持行级锁 MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。也就是说，MyISAM 一锁就是锁住了整张表，并发时性能远不如 InnoDB。 是否支持事务 MyISAM 不提供事务支持。 InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重复读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。 是否支持外键 MyISAM 不支持，而 InnoDB 支持。 外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗。因此，通常情况下，我们是不建议在实际生产项目中使用外键的，在业务代码中进行约束即可！ 是否支持数据库异常崩溃后的安全恢复 MyISAM 不支持，而 InnoDB 支持。 使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。 是否支持 MVCC MyISAM 不支持，而 InnoDB 支持。 MyISAM 连行级锁都不支持，而 MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。 索引的实现不同 二者均采用B+Tree作为索引结构，但是两者的实现方式不太一样。 InnoDB 引擎中，其数据文件本身就是索引文件，支持聚簇索引。 而 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录，在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引（非聚集索引）”。 详细需要看索引。 性能差别 InnoDB 的性能比 MyISAM 更强大，不管是在读写混合模式下还是只读模式下，随着 CPU 核数的增加，InnoDB 的读写能力呈线性增长。MyISAM 因为读写不能并发，它的处理能力跟核数没关系。 问：如何选择 MyISAM 和 InnoDB、MEMORY？ InnoDB⭐：如果应用对事务的完整性有较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询外，还包含很多更新、删除的操作，那么选择 InnoDB。 MyISAM：如果应用以插入和查询操作为主，很少更新和删除，并且对事务的完整性、并发性要求不高，也不需要崩溃后安全恢复的话，那么也凑合能用。(现在被 MongoDB 替代了) MEMORY：通常用于临时表及缓存，将所有数据保存在内存，访问速度快。缺点就是对表的大小有限制，且安全性无法保障。(现在被 Redis 替代了) 绝大部分情况下选择 InnoDB 都是没有问题的。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:3:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"三、索引⭐ ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:4:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"3.1 索引结构 索引是帮助 MySQL 高效获取数据(快速查询和检索数据)的数据结构(有序)。 常见的索引结构有: B 树(也称 B- 树)，B+ 树 和 Hash、红黑树。在 MySQL 中，无论是 Innodb 还是 MyIsam，都使用了 B+ 树 作为索引结构。大部分都支持 B+ 树 索引。 InnoDB 的数据是按==「数据页」(16KB)==为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。 问：B-树 和 B+树 有何异同？ B-树 的所有节点既存放键(key)也存放数据(data)，而 B+树 只有叶子节点存放 key 和 data，其他节点只存放 key； B-树 的叶子节点都是独立的；B+树 的叶子节点之间构成一个有序链表； B+树 的非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小），这样虽然有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点。 B-树 的检索可能还没有到达叶子节点，检索就结束了，查询波动比较大；而 B+树 的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程。 问：B+ Tree 相比于 B- Tree 的优点？ **范围查询效率更高。**因为 B+ 树所有叶子节点间有一个链表进行连接，只需要查到头节点，然后往后遍历即可。但 B- 树就只能通过一个一个查找完成。 **插入和删除效率更高。**因为 B+ 树有冗余节点，插入和删除时，树的结构不用怎么变化。 查询效率也更高一点。因为I/O操作会少一点嘛。 问：Hash 索引相比于 B+ 树的优缺点？ Hash索引自身只需要存储对应的哈希值，所以索引内存结构非常紧凑，查询效率很高； 但由于是通过哈希映射进行索引，因此无法排序或进行范围查询。 问：B+ Tree 的特点？ 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。 非叶子节点分为不同层次，通过分层来降低每一层的搜索量； 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询； 问：B+ Tree 索引一个元素的过程？ B+ 树如何实现快速查找主键为 6 的记录： 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项； 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录； 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。 问：为什么 InnoDB 存储引擎选用 B+Tree 索引结构？ 相比于红黑树等二叉树结构，B+Tree 层级更少，因此搜索效率更高(因为磁盘I/O操作更少)； 相比于 B-Tree ，因为 B-Tree 无论叶子节点还是非叶子节点，都会保存数据，这样会导致一页中存储的键值减少，指针也跟着减少，要保存同样的数据，只能增加树的高度，导致性能下降；其实我觉得，主要是**==减少了调页的I/O操作次数==**。 相比于 Hash索引 ，B+Tree 支持范围匹配及排序操作，比如SELECT * FROM tb1 WHERE id \u003c 500;，如果用 Hash索引，难道要把1-499都挨个hash定位吗？ 注： 其实一开始我很不理解为啥 ==“1. 层级减少，搜索效率会变高”==，因为你就算层级变少了，但是节点内的键值对变多了啊，搜索的时候还是用二分，效率并没有减少啊！ 后来，我知道了每次访问一个节点，其实就是需要一次调页操作的，也就是一次磁盘I/O，而单个节点内的键值对变多，显然会减少调页次数，也就提高了效率。 问：B+ 树不同高度的数据存储？ 假设 B+ 树的高度为 2 的话，即有一个根结点和若干个叶子结点。这棵 B+ 树的存放总记录数为 = 根结点指针数 * 单个叶子节点记录行数。 如果一行记录的数据大小为 1k，那么单个叶子节点可以存的记录数 = 16k/1k = 16. 非叶子节点内存放多少指针呢？我们假设主键ID为 bigint 类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6 = 14 字节，16KB/14B = 16*1024B/14B = 1170 因此，一棵高度为2的B+树，能存放1170 * 16=18720条这样的数据记录。同理一棵高度为 3 的 B+ 树，能存放 1170 *1170 * 16 = 21902400，大概可以存放两千万左右的记录。B+ 树高度一般为 1-3 层，如果 B+ 到了 4 层，查询的时候会多查磁盘的次数，SQL 就会变慢。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:4:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"3.2 索引类型 分类 含义 特点 关键字 主键索引 针对表中主键创建的索引 默认自动创建，只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的是文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 在 InnoDB 存储引擎中，根据索引的存储形式，又可以分为以下两种： 分类 含义 特点 聚集索引(Clustered Index) 将索引与数据存储放到一起，索引结构的叶子节点中保存了行数据 有且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点中保存了对应的主键 可以有多个 比如：select * from user where name='Tom'，会先去查找二级索引name，找到对应的主键id值，然后回表查询通过聚集索引拿到对应的行数据。 思考：以下 SQL语句，哪个执行效率高？为什么？ select * from user where id = 10; select * from user where name = 'Arm'; -- 备注：id为主键，name字段创建的有索引。 1显然效率更高。 问：索引类型？ 索引从数据结构进行划分的分为：B+树索引、B-树索引、Hash索引、二叉树索引。 索引从物理存储的角度划分为：聚族索引和非聚族索引。 从逻辑的角度分为：主键索引、普通索引、唯一索引、联合索引。 问：InnoDB 主键索引的 B+Tree 高度有多高？ 黑马视频。 问：聚集索引选取规则？ 聚集索引有且仅有一个，它将索引与数据存储放到一起，索引结构的叶子节点中保存了行数据。 如果存在主键，主键索引就是聚集索引； 如果不存在主键，第一个唯一索引就是聚集索引； 如果二者都无，则 InnoDB 会自动生成一个 隐式自增的id 作为隐藏的聚集索引。 问：SQL性能分析方法？ SQL 执行频次 慢查询日志 profiles详情 explain性能分析，可以查看执行计划 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:4:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"3.3 索引使用 索引法则 **单列索引：**一个索引值包含单个列 **联合索引：**一个索引包含了多个列 问：索引失效的情况？即，使用索引时需要的注意事项？⭐⭐🚩 最左前缀法则 如果索引了多列(联合索引)，要遵守最左前缀法则。最左前缀法则指的是查询条件从索引的最左列开始，并且不跳过索引中的列。如果跳过某一列，索引将部分失效(后面的字段索引失效)。 如果创建了一个 (a, b, c) 联合索引： # 不会失效 where a=1； where a=1 and b=2 and c=3； where b=2 and a=1 and c=3; # 查询优化器会自动进行排序 where a=1 and b=2； # 部分生效 where a=1 and c=3 # 会失效 where b=2； where c=3； where b=2 and c=3； 其实联合索引(a, b, c)，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的。 有一个比较特殊的查询条件：where a = 1 and c = 3 ，符合最左匹配吗？ 严格意义上来说是属于索引截断，不同版本处理方式也不一样： MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值； 从 MySQL 5.6 之后，有一个索引下推功能，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。 索引下推的基本原理：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 (a, b, c) 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。 因此，where a = 1 and c = 3 会部分用到索引，并且在 MySQL 5.6 后，还会用到索引下推。 详细 范围查询 联合索引中，出现范围查询(\u003e, \u003c)，范围查询右侧的列索引失效。注意：若使用 (\u003e=, \u003c=)，则不会失效，因此建议使用 (\u003e=, \u003c=)。 **字符串不加引号：**字符串类型字段使用时，若索引值不加引号，索引将失效。 explain select * from user where phone = '17799990015'; -- 不失效 explain select * from user where phone = 17799990015; -- 失效 模糊查询：如果仅仅是尾部模糊匹配，索引不会失效；如果是头部模糊匹配，索引失效。因为排序时是按字典序。 explain select * from user where prefession like '软件%' -- 不失效 explain select * from user where prefession like '%工程' -- 失效 **or连接的条件：**用or分割开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。即，只有or两边的条件均有索引，整体才会生效，否则，均不生效。 **数据分布影响：**如果 MySQL 评估使用索引比全表查询更慢，则不使用索引。 -- 数据范围：00-20 explain select * from user where phone = '17799990005'; -- 全表查询 explain select * from user where phone = '17799990015'; -- 索引查询 对索引进行表达式计算：因为索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值，所以无法走索引，只能通过把索引字段的取值都取出来，然后依次进行表达式的计算来进行条件判断，因此采用的就是全表扫描的方式。 explain select * from t_user where id + 1 = 10; # 索引失效 where id = 10 - 1; # 索引不失效 建议参考：索引失效有哪些？ 问：如何查看 MySQL 是否用到了索引？🚩 在查询语句前加上 explain 关键字。 问：优化数据库查询操作的做法？即 优化索引的方法？ 前缀索引优化； 覆盖索引优化； 主键索引最好是自增的； 防止索引失效 使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值数目； 尽量使用覆盖索引，避免使用select *，会大量造成回表查询，原因见下。 主键索引最好是自增的，这样的话，每次插入一条新记录，都是追加操作，不需要重新移动数据； 索引时，要避免索引失效。 覆盖索引、回表查询⭐🚩 如果一个索引覆盖所有需要查询的字段的值，就称之为**覆盖索引**。我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次，这样就会比较慢。 **覆盖索引，即需要查询的字段正好是索引中的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询。**因此，尽量避免使用select *，除非你联合索引的条件很多很多。 问：什么是回表查询？什么时候会触发回表查询？ 回表查询是指在查询过程中，如果需要获取的数据不在查询语句的索引列中，那么就需要通过回表操作来获取额外的数据。回表操作会根据查询语句中的主键或唯一索引定位行数据，然后再根据行数据中的其他列获取需要的数据。 例：《黑马》P84 讲的很好！ 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。 问：联合索引应用场景？为什么要建联合索引？⭐🚩 多条件联合查询：当查询语句中需要同时使用多个列进行查询时，可以使用联合索引来提高查询效率。 减少开销：建一个联合索引(a, b, c)，实际相当于建了(a)，(a, b)，(a, b, c)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引：当查询语句只需要查询索引列和联合索引中的列时，可以使用联合索引来避免回表操作，从而提高查询效率。 排序操作：当查询语句需要对多个列进行频繁排序时，可以使用联合索引来提高排序效率。例如，一个学生表包含了学生ID、姓名、年龄、成绩等列，如果需要按照成绩和年龄进行排序，可以使用联合索引（成绩，年龄）来提高排序效率。 问：一张表，有四个字段(id, username, password, status)，由于数据量大，需要对以下 SQL 语句进行优化，该如何进行才是最优方案？ select id, username, password from user where username='itcast'; **需要建立索引：**针对 username 和 password 建立联合索引，这样的话，查到username=‘itcast’时，val值为id，username和password也知道，直接返回即可，无需回表查询。 前缀索引 问：前缀索引是什么？ 字段类型为字符串时，索引很长的字符串，会让索引变得很大，导致一个索引页中的索引数量变少，层级就会变高，导致查询时，浪费大量的磁盘IO，影响查询效率。 前缀索引就是只对字符串的一部分前缀，建立索引，可以减小索引字段大小，增加一个索引页中存储的索引数量，有效提高索引的查询速度。 create index idx_xxx on table_name(column(n)) # column(n)表示列column只取前n个字符构建索引 不过，前缀索引有一定的局限性，例如： order by、group by 无法使用前缀索引； 由于只存储了部分前缀，所以也无法把前缀索引用作覆盖索引(覆盖索引需要全部的数据)。 索引下推 问：什么是索引下推？ 索引下推（Index Condition Pushdown） 是 MySQL 5.6 版本中提供的一项索引优化功能，可以在非聚簇索引遍历过程中，对索引中包含的字段在引擎层先做判断，过滤掉不符合条件的记录，减少回表次数。 索引下推并不适用于所有查询，只有在查询条件中包含索引字段和非索引字段的情况下才能发挥作用。 核心思想就是引擎层利用索引字段先过滤一次，然后判断非索引字段是否匹配，然后再返回给server层进行回表查询拿到整行数据。 索引设计原则 问：索引设计原则有哪些？ 针对数据量大、查询频繁的表建立索引； 针对常作为查询条件(where)、排序(order by)、分组(group by)操作的字段建立索引； 尽量建立唯一索引； 针对字段较长的字符串类型的字段，建立前缀索引； 尽量使用联合索引，节省存储空间(一个联合索引比多个单列索引要省空间。因为如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。)，查询时可以使用覆盖索引，提高查询效率(避免回表)； 索引字段尽量避免为null，可改用0、1、true、false代替； 限制每张表的索引数量。索引太多不仅会降低插入和更新的效率，还有可能降低查询性能！这是因","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:4:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"四、SQL优化 其实2-7都是跟索引相关。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.1 插入数据 insert优化： 批量插入，若特别大量(百万级)，建议使用load指令而非insert； 手动提交事务； 主键顺序插入，因为乱序插入可能会发生页分裂和页合并。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.2 主键优化 尽量降低主键的长度； 插入数据时，尽量选择顺序插入，选择使用auto_increment自增主键； 尽量不要使用UUID做主键或是其他自然主键，如身份证号，因为这些主键不是顺序的，插入时相当于乱序，且这些主键较长； 尽量避免对主键的修改。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.3 order by 优化 using index：直接通过索引返回数据，性能高； using filesort：需要将返回的结果在排序缓冲区重新排序。 对order by字段建立索引，默认是升序排列，查询时需要按照建立索引时指定的排列顺序，否则还是会额外的排序(filesort)； 也要遵循最左前缀法则，尽量使用覆盖索引； 不可避免出现filesort时，大数据排序时，可以适当增大排序缓冲区大小。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.4 group by 优化 对group by字段建立索引，避免using temporary； 也要遵循最左前缀法则。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:4","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.5 limit 优化 覆盖索引+子查询 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:5","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.6 count 优化 MyISAM 是把count结果记录在磁盘上，需要的时候直接读取。 InnoDB 需要一条一条读取数据，再累计计数，没有什么好的优化方法。 用法： count(主键)：遍历整张表，把每一行的主键id(不可能为null)的值都取出，然后进行累加； count(字段)： 没有not null约束：遍历整张表，取出每行的值，服务层判断是否为null，不为null的累加； 有not null约束：遍历整张表，取出每行的值，直接累加。 **count(1)：**InnoDB 遍历整张表，不取值，对每一行放一个1，直接按行累加。 **count(*)：**等价于 count(0)，InnoDB 并不把所有字段取出，专门做了优化，不取值，直接按行累加。(使用 count(*) 时，MySQL 会将 * 参数转化为参数 0 来处理)。 问：count() 是什么？ count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。 假设 count() 函数的参数是字段名，如下： select count(name) from t_order; 这条语句是统计「t_order 表中，name 字段不为 NULL 的记录」有多少个。也就是说，如果某一条记录中的 name 字段的值为 NULL，则就不会被统计进去。 再来假设 count() 函数的参数是数字 1 这个表达式，如下： select count(1) from t_order; 这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。 1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句，其实是在统计 t_order 表中有多少个记录。 问：count(1)、count(*)、count(字段)，哪个效率最高？⭐🚩 **==效率排序：==**count(字段) \u003c counts(索引字段) \u003c count(1) ≈ count(*)，所以尽量选择count(*)。 其实，尽量不要使用count来统计，可以使用： show table status 估算； 单独建个表，用来计数 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:6","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"4.7 update 优化 update 更新时，更新条件要按照索引，这样加的才是行锁，否则是表锁，会降低数据库的并行性能。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:5:7","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"五、视图 \u0026 存储过程 \u0026 触发器（未） ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:6:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"5.1 视图 视图是一种虚拟存在的表。视图只保存了查询的 SQL 逻辑，不保存查询结果。所以在创建视图的时候，主要工作就落在创建这条 SQL 查询语句上。 # 创建视图 create or replace view stu_v_1 as select id, name from student where id \u003c= 10; # 查询视图，此时就会输出id, name 两列的数据，即简化了SQL查询语句 select * from stu_v_1; # 带检查选项的创建，此时向视图插入 id\u003e10的就会报错 create or replace view stu_v_1 as select id, name from student where id \u003c= 10 with local check option; 视图的作用 **简化操作。**无需每次都指定全部条件。 **安全。**通过视图，用户只能查询和修改他们所见到的数据。 **数据独立。**屏蔽基表变化对业务的影响。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:6:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"5.2 存储过程 语法 # 创建 无返回值 create procedure 过程名 begin sql语句; end; # 调用 call 过程名; # 查看 select * from information_schema.ROUTINES where ROUTINE_SCHEMA = 'itcast'; show create procedure 过程名; # 删除 drop procedure if exists 过程名; ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:6:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"5.3 存储函数 就是有返回值的存储过程。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:6:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"六、锁 锁是协调多个进程或线程并发访问某一资源的机制。 **全局锁：**锁定数据库中的所有表；（粒度最大的锁） **表级锁：**每次操作锁住整张表；针对非索引字段； **行级锁：**每次操作锁住对应的行数据；针对索引字段；（粒度最小的锁） ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:7:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"6.1 全局锁 问：全局锁的应用场景？ 全局锁是对整个数据库实例加锁，加锁后数据库变成只读状态(DQL可执行)，DML、DDL语句都会被阻塞。典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获得一致性视图，保证数据的完整性。 flush tables with read lock; unlock tables; 但是加全局锁是个非常重的操作： 若在主库上备份，那么业务就得停摆； 若在从库上备份，那么备份期间从库不能执行主库同步，会导致主从延迟。 在 InnoDB 上备份时，加上参数–single-transaction参数可以完成不加锁的一致性数据备份。这种方式实际上是通过快照实现的。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:7:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"6.2 表级锁 **表共享锁(read lock)：**大家(包括自己)都可以读，但都不可以写 **表排他锁(write lock)：**自己可以读写，别人不可以读写 # 加锁 lock tables 表名... read/write # 释放锁 unlock tables /客户端断开连接 元数据锁(meta data lock，MDL)：MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的数据一致性，在表上有活动事务时，不可以对元数据进行写入操作。 对表进行增删改查时，加MDL读锁(共享锁)；对表结构进行变更操作时，加MDL写锁(排他锁)。 意向锁⭐：为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使表锁不用检查每行数据是否已被加锁，==使用意向锁来减少表锁对行锁的检查==。 **意向共享锁(IS)：**与表共享锁(read)兼容，与表排他锁(write)互斥； **意向排他锁(IX)：**与表共享锁(read)及表排他锁(write)都互斥。 意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InnoDB 会先获取该数据行所在在数据表的对应意向锁。 ==意向锁之间不会互斥。== IS 锁 IX 锁 IS 锁 兼容 兼容 IX 锁 兼容 兼容 意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。 IS 锁 IX 锁 S 锁 兼容 互斥 X 锁 互斥 互斥 问：意向锁有什么作用？ 使用表锁之前，如果已经有行锁存在，就会冲突，因此需要先检查是否有行锁，但是一行一行扫描的效率太低，此时就会用到意向锁。 在加行锁之后，会对表加一个意向锁，之后再加表锁时，只需检查是否有意向锁即可。当检查意向锁和要加的表锁是兼容的，那直接加，如果冲突，就会阻塞，直到意向锁释放。 例：事务A对表中某行进行修改，此时会自动加上行锁，同时还会对表加上意向排他锁，此时若事务B向表加锁(共享锁/排他锁)，都不能成功，因为有意向排他锁。 问：共享锁和排他锁？ 共享锁（S 锁）：事务在读取时获得；允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：事务在修改的时获得；不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。只允许获得该锁的事务读写，不允许其他事务操作。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:7:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"6.3 行级锁 分类： **记录锁：**锁定单行记录的锁，防止其他事务对该行进行update和delete。在RC、RR隔离级别下都支持。 **间隙锁：**锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下支持。 **临键锁⭐：**行锁和间隙锁的组合，锁住该行数据，及该行前的间隙。在RR隔离级别下支持。 插入意向锁⭐：如果某个间隙被间隙锁锁定，其他事务进行插入时就会阻塞，直到间隙锁释放，在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。插入意向锁是特殊的间隙锁，不互斥。 间隙锁的唯一目的是：防止其他事务插入该间隙，解决幻读。间隙锁是共享锁，即允许多个事务在同一间隙上采用间隙锁。 问：临键锁的范围？ 唯一索引的等值查询，数据存在时，会加行锁； 唯一索引的等值查询，数据不存在，会对查询条件主键所在的间隙加间隙锁； 普通索引的等值查询，数据存在时，会对该数据前后第一个不满足条件的两端之间的所有间隙加间隙锁，相同数据的行都加行锁，这是因为普通索引可能会插入相同的数据，所以这些间隙都得加锁；如果是范围查询，那么该范围内存在的数据的行都加行锁，其余区间都加间隙锁。 问：为什么会产生死锁？ 关键点： Innodb 引擎为了解决**「可重复读」隔离级别下的幻读问题，引出了next-key 锁**，它是记录锁和间隙锁的组合。 行锁的释放时机是在事务提交（commit）后，锁才会被释放，并不是一条语句执行完就释放行锁。 例，表中数据范围[1001-1006]，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，要先查询该订单是否存在，不存在才插入记录： 为了防止幻读嘛，查询时(注意这不是普通的快照读！)，select ... for update 语句会加临键锁，此时退化成间隙锁，间隙锁与间隙锁之间是兼容的，因此此时A、B都获得了间隙锁； 插入时，insert语句会在插入间隙上获取插入意向锁，而==插入意向锁与间隙锁是冲突的==，获得插入意向锁后，需要等待间隙锁释放，此时A、B都获得了插入意向锁，但都等待彼此的间隙锁释放，造成死锁。 满足了死锁的四个条件：互斥、保持与请求、不可被抢占、循环等待，因此发生了死锁。 **注：**为什么间隙锁与间隙锁是兼容的？ 间隙锁的意义只在于阻止区间被插入，因此是可以共存的。共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同，即两个事务可以同时持有包含共同间隙的间隙锁。 ==另外，==虽然相同范围的间隙锁是多个事务相互兼容的，但对于==记录锁==，还是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的！！！ 问：如何避免死锁？ 死锁的四个必要条件：互斥、保持与请求、不可被抢占、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 在数据库层面，有两种策略通过**「打破循环等待条件」**来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超时，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:7:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"七、MVCC ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:8:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"7.1 概念 问：当前读和快照读有什么区别？ **快照读：**一致性非锁定读，就是普通的select语句； **当前读：**一致性锁定读，会给行加X锁或S锁。 # 对读的记录加一个X锁 SELECT...FOR UPDATE # 对读的记录加一个S锁 SELECT...LOCK IN SHARE MODE # 对修改的记录加一个X锁 INSERT... UPDATE... DELETE... 快照读时，若读取的记录正在进行update/delete操作，快照读不会等待其X锁的释放，而是会去读取快照。只有在事务隔离级别 RC(读取已提交) 和 RR（可重读）下，InnoDB 才会使用快照读： 在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。 在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。 当前读时，读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前事务，所以会加锁。 问：什么是MVCC？ **多版本并发控制。**指维护一个数据的多个版本，使得读写操作没有冲突，快照读为实现MVCC提供了一个非阻塞读功能。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:8:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"7.2 MVCC实现 MVCC的实现依赖于数据库中：三个隐藏字段、undo log日志、readView。 7.2.1 隐藏字段 DB_TRX_ID：最后一次插入或更新改行的事务ID。 DR_ROLL_PTR：回滚指针，指向上个版本，即undo log。 DB_ROW_ID：隐藏主键。如果没有设置主键且没有唯一非空索引时，会使用该ID生成聚集索引。 7.2.2 undo log 回滚日志。在 insert、update、delete的时候产生的便于数据回滚的日志。 insert undo log：insert时产生的undo log。只在回滚时需要，事务提交后，可立即被删除。 update undo log：update/delete时产生的undo log。不仅在回滚时需要，在快照读时也需要，因此不会被立即删除。 7.2.3 readview ReadView(读视图)是快照读 SQL 执行时 MVCC 提取数据的依据，记录并维护系统当前活跃的事务(未提交的)ID。 包含以下字段： **m_low_limit_id：**目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见 **m_up_limit_id：**活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的数据版本均可见 m_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View 时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中） **m_creator_trx_id：**创建该 Read View 的事务 ID 问：MVCC的实现原理？⭐⭐ MVCC 的实现主要依赖： Read View； 聚簇索引中的跟事务相关的两个隐藏列[trx_id, undo_log]。 ==Read View 的结构：== creator_trx_id：指的是创建该 Read View 的事务的事务 id； m_ids：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表。注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务； **min_trx_id：**指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值； max_trx_id：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1。 ==聚簇索引的两个隐藏列：== trx_id：当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后roll_pointer 指向旧版本记录，通过它找到修改前的记录。 可以看到，聚簇索引中每行记录都会有个trx_id，可以将**所有记录的trx_id**划分为三种情况： 一个事务去访问记录时，自己的更新总是可见的，除此之外： 若当前记录的trx_id \u003c Read View 中的min_trx_id，说明是创建Read View之前已经提交的事务生成的，所以该记录对当前事务可见； 若当前记录的trx_id \u003e= Read View 中的max_trx_id，说明是创建Read View之后才启动的事务生成的，所以该记录对当前事务不可见； 若当前记录的trx_id 在min_trx_id和max_trx_id之间，需要判断trx_id是否存在m_ids列表中： 若存在，表示该事务依然活跃(也就是还没提交呢)，所以该记录对当前事务不可见，就会顺着 undo log 链寻找旧版本数据； 若不存在，表示该事务在当前事务创建Read View之前已经提交了，所以该记录对当前事务可见。 这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。 问：RC和RR隔离级别下MVCC的差异？ 在 RC 隔离级别下的 每次select 查询前都生成一个Read View (m_ids 列表) 在 RR 隔离级别下只在事务开始后 第一次select 数据前生成一个Read View（m_ids 列表） 问：MVCC+临键锁 防止幻读？ 1、执行普通 select，此时会以 MVCC 快照读的方式读取数据 在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读” 2、执行 select…for update/lock in share mode、insert、update、delete 等当前读 在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lockopen in new window 来防止这种情况。**当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。**只要我不让你插入，就不会发生幻读。 其实就是： 快照读时，通过只在第一次查询时生成Read View，来防止幻读； 当前读时，通过加临键锁，拒绝数据插入，来防止幻读。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:8:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"八、数据类型 这点之前没记，现在补充一下~ ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:9:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"8.1 表空间的文件结构 行 数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 页 InnoDB 的数据是按**「页」为单位来读写**，一次I/O操作读取一页，默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。 区 数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用**顺序 I/O **了。 段 表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:9:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"8.2 行格式 现在用的都是 Compact 行格式，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:9:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"九、日志 更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、bin log（归档日志）这三种日志。 undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC； redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； bin log（归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:10:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"undo log 和 redo log 问：undo log 是啥？有啥用？ undo log 是一种用于回退撤销的日志。在事务没提交之前，MySQL 会先把更新前的数据记录到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。 每当 InnoDB 引擎对一条记录进行更新(修改、删除、新增)时，要把回滚时需要的信息都记录到 undo log 里。 另外，undo log 还可以串成链表，称为版本链，用来实现 MVCC。 因此，undo log 共两大作用： 实现事务回滚，保障事务的原子性。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）的关键因素之一。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。 问：WAL 技术？ 说明 redo log 有啥用之前，需要先介绍 Buffer pool 和 WAL 技术。 Buffer pool 相当于数据库中的缓存，以页为单位，读取数据时也先从这里读，更新数据时，也先尝试更新 Buffer pool 中的数据页。若 Buffer pool 中的页相比原数据库中的页做了修改，就称为脏页。 内存中的数据若不刷盘，断电了就消失了，所以为了防止断电导致数据丢失，在修改 Buffer pool 中的页之后，会将本次对这个页的修改以 redo log 的形式记录下来，然后定时由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这称为 WAL(Write-Ahead Logging)技术。 WAL 技术指的是，MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。 问：redo log是啥？有啥用？ redo log 是重做日志，记录事务提交时数据页的物理修改。记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。 在事务提交时，只要先将 redo log 持久化到磁盘即可，不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。 问：undo log 和 redo log 有啥区别？⭐⭐ redo log 记录了此次事务「提交后」的数据状态，记录的是更新之后的值； undo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值； 事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务； 事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。 所以，undo log 保证了原子性，redo log 保证了持久性。 问：redo log 会满吗？ 会。redo log 类似 Redis 的 repl_backlog，也是个环形缓冲区，当写满了之后，就会触发 buffer pool 的刷盘操作，然后擦除旧的 redo log，就可以继续写入了~ ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:10:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"bin log 问：什么是 bin log？ bin log 是由 MySQL 的 Server 层生成的。 bin log 文件记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，以二进制形式保存在磁盘上。 问：为什么有了 bin log 还要有 redo log？这俩有啥区别？ 这跟 MySQL 的时间线有关系。 最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，bin log 日志只能用于归档。 而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 bin log 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。 区别： 适用对象不同 bin log 是 MySQL 的 Server 层实现的，所有的存储引擎都可以使用； redo log 是 Innodb 存储引擎实现的，也就是独有的。 文件格式不同 bin log 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED。区别如下： STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致； ROW：记录每行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已； MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式； redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新； 写入方式不同 bin log 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。 redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。 用途不同 bin log 用于备份恢复、主从复制； redo log 用于掉电等故障恢复。 问：如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？ 不可以使用 redo log 文件恢复，只能使用 bin log 文件恢复。 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。 bin log 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 bin log 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 bin log 文件恢复数据。 问：执行 update 的过程？ 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录： 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新； 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样： 如果一样的话就不进行后续更新流程； 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作； 开启事务，InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来。 InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术。 至此，一条记录更新完了。 在一条更新语句执行完成后，然后开始记录该语句对应的 bin log，此时记录的 bin log 会被保存到 bin log cache，并没有刷新到硬盘上的 bin log 文件，在事务提交时才会统一将该事务运行过程中的所有 bin log 刷新到硬盘。 事务进行两阶段提交。 问：什么是两阶段提交？ 两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是**「准备（Prepare）阶段」和「提交（Commit）阶段」**。 MySQL 使用了内部 XA 事务，由 bin log 作为协调者，存储引擎是参与者。 prepare 阶段：将 XID(内部 XA 事务的 ID) 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘； commit 阶段：把 XID 写入到 bin log，然后将 bin log 持久化到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit。 这个过程中，出现异常无非就俩时刻，时刻 A 和 时刻 B，不管是哪个，redo log 都处于 prepare 状态。 在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 bin log 查看是否存在此 XID： 若 bin log 中没有此 XID，说明异常发生时 redo log 完成了刷盘，但 bin log 还没，因此回滚事务。对应了 时刻 A； 若 bin log 中有此 XID，说明异常发生时都完成了刷盘，则提交该事务。对应时刻 B。 可以看出：两阶段提交是以 bin log 写成功为事务提交成功的标识的。 问：为啥要两阶段提交？ 事务提交后，redo log 和 bin log 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致： 如果在将 redo log 刷入到磁盘之后，MySQL 突然宕机了，而 bin log 还没有来得及写入。重启后，主库按照 redo log 恢复，从库按照 bin log 恢复，主从库就不一致了； 如果在将 bin log 刷入到磁盘之后，MySQL 突然宕机了，而 redo log 还没有来得及写入。重启后，主库按照 redo log 恢复，从库按照 bin log 恢复，主从库就不一致了。 为避免两份日志出现不一致，因此采用两阶段提交。 问：两阶段提交有啥缺点？ I/O 操作次数多。这是因为每次事务提交都至少需要两次刷盘。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:10:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"十、内存 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:11:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"基础 问：为啥要有 Buffer Pool？ MySQL 的数据存储在磁盘中，若每次操作都直接操作磁盘，效率就会很低。 因此，加一层缓存，将读出的数据页缓存到内存中，下次用到的话直接访问内存即可。Innodb 通过**缓冲池(Buffer Pool)**机制实现： 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取； 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。 问：Buffer Pool 缓存了什么？ Innodb 按页存储数据，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。 InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页，Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 Buffer Pool 除了缓存**「索引页」和「数据页」**，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。 问：查询一条数据，只需要缓存一条数据吗？ No！查询记录时，通过索引找到磁盘上的页，然后会把整页加载，并存入 Buffer Pool。 一方面是因为，索引只能定位到页；另一方面，若每次IO读入了整页，却只保留一条数据，也挺浪费的。。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:11:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"管理 问：如何管理空闲页？ 因为有的页面被使用，有的页面没被使用，总不能每次要找到个空闲页就遍历一遍吧？ 解决方案类似Go的内存管理。 通过一个带头双向链表 Free，将空闲缓存页的控制块存起来： Free 链表的头节点：包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息； Free 链表的节点：一个个控制块。 问：如何管理脏页？ 类似 Free 链表，设计了 Flush 链表存储脏页，后台线程可以遍历 Flush 链表，将脏页写入到磁盘。 问：缓存更新策略？ 类似 LRU。 问：脏页什么时候会被刷盘？⭐⭐ InnoDB 的更新操作采用的是 WAL(Write Ahead Log) 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。 下面几种情况会触发脏页的刷新： 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘； Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘； MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘； MySQL 正常关闭之前，会把所有的脏页刷入到磁盘。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:11:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"十一、集群架构 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:12:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"主从复制 问：为什么要集群？ 数据备份； 故障转移； 读写分离，减轻主库读写压力。 问：主从复制是如何实现的？ MySQL 的主从复制依赖于 bin log，复制过程： 写入 bin log：主库在事务提交时，会把**数据变更(增删改)**记录在 bin log 中； 同步 bin log：从库创建 I/O 线程，请求获取主库 bin log； 发送 bin log：主库创建一个 log dump 线程，将 bin log 发送给从库； 重放 bin log：从库将获取的 bin log 写入从库的中继日志(relay log)，同时创建线程，读取并重放 relay log，更新从库中的数据。 问：从库是越多越好吗？ 当然不是。 因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽。 所以在实际使用中，1 个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。 问：主从复制有哪些模型？/如何保持主从间的数据一致性？ 同步复制：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。实际没法用； **异步复制(默认)：**主库不用等 bin log 同步到从库就返回结果。缺点就是，主库宕机可能会丢失部分数据； **半同步复制：**主库等 bin log 复制到一部分从库再返回结果。兼顾上述方案，就算主库宕机了，也不会丢失数据。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:12:1","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"分库分表 问：为什么要分库？为什么要分表？ 为什么要分库？ 如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。从这两方面来看： 磁盘存储 业务量剧增，MySQL单机磁盘容量会撑爆，因此可以拆成多个数据库； 并发连接支撑 数据库连接数是有限的。在高并发的场景下，大量请求访问数据库，MySQL单机是扛不住的！高并发场景下，会出现too many connections报错。 为什么要分表？ 假如你的单表数据量非常大，存储和查询的性能就会遇到瓶颈了(由于B+树)，如果你做了很多优化之后还是无法提升效率的时候，就需要考虑做分表了。一般千万级别数据量，就需要分表。 问：什么时候就要进行分库分表了？ 对于MySQL，InnoDB存储引擎的话，单表最多可以存储10亿级数据。 但是的话，如果真的存储这么多，性能就会非常差。一般数据量千万级别，B+树索引高度就会到3层以上了，查询的时候会多查磁盘的次数，SQL就会变慢。 阿里巴巴的《Java开发手册》提出： 单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表。 那我们是不是等到数据量到达五百万，才开始分库分表呢？ 不是这样的，我们应该提前规划分库分表，如果估算3年后，你的表都不会到达这个五百万，则不需要分库分表。 MySQL服务器如果配置更好，是不是可以超过这个500万这个量级，才考虑分库分表？ 虽然配置更好，可能数据量大之后，性能还是不错，但是如果持续发展的话，还是要考虑分库分表 一般什么类型业务表需要才分库分表？ 通用是一些流水表、用户表等才考虑分库分表，如果是一些配置类的表，则完全不用考虑，因为不太可能到达这个量级。 问：有哪些分库、分表方式？ 垂直分库：以表为依据，根据业务，将不同的表拆分到不同的库中。 每个库的表结构都不一样； 每个库的数据也不一样； 所有库的并集是全量数据。 垂直分表：以字段为依据，根据字段属性，将不同字段拆分到不同表中。 每个表的结构都不一样； 每个表的数据也不一样，一般通过一列(主键/外键)关联； 所有表的并集是全量数据。 水平分库⭐：以字段为依据，按照一定策略，将一个库的数据拆分到多个库中。 每个库的表结构都一样； 每个库的数据都不一样； 所有库的并集是全量数据。 水平分表⭐：以字段为依据，按照一定策略，将一个表的数据拆分到多个表中。 每个表的表结构都一样； 每个表的数据都不一样； 所有表的并集是全量数据。 总结： 垂直拆分的关注点在于 业务相关性； 水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在 数据的特点。 问：水平分片的规则有哪些？ 范围分片：划分多个范围区间，落在相应区间的数据存入相应的库或表； 取模分片：指定的字段值 % 节点数量，落到哪个节点就存到哪个； 一致性hash：增加节点或删除节点时，取模分片会导致大量数据迁移；一致性hash中，只会影响一小部分数据的迁移。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:12:2","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"读写分离 就是，只有主节点负责写请求，其他节点负责读请求，可以降低单台服务器的压力。 一主一从：一主负责写，一从负责读； 双主双从：一主负责写，一主两从负责读。并且，每组主从间互为主备，一组挂了，另一组就会顶上，实现高可用。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:12:3","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"分布式 ID 当分库分表之后，同一个逻辑表的数据被分布到多个库中，这时如果使用数据库自增字段作为主键，那么只能保证在这个库中是唯一的，无法保证全局的唯一性。那么假如设计用户系统的时候，使用自增 ID 作为用户 ID，就可能出现两个用户有两个相同的 ID，这是不可接受的，那么就需要生成全局唯一的 ID。 UUID 不建议使用 UUID 作为数据库主键，因为： ID 有序更利于索引数据的插入，而 UUID 是无序的，造成了多余的数据移动的开销； UUID 不具备业务含义； UUID 是由 32 个 16 进制数字组成的字符串(128位)，如果作为数据库主键使用比较耗费空间。 ==雪花算法(Snowflake)== Snowflake 的核心思想是将 64 位的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。可以自定义各字段代表的含义和位数。 原理知道了，那工程上是怎么实现呢？ 一种是嵌入到业务代码里，也就是分布在业务服务器中。 一种是作为独立的服务部署，这也就是我们常说的发号器服务。 Snowflake 算法设计的非常简单且巧妙，性能上也足够高效，同时也能够生成具有全局唯一性、单调递增性和有业务含义的 ID，但是它也有一些缺点： 其中最大的缺点就是它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止； 另外，如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。 这一点，也是我在实际项目中踩过的坑，而解决办法主要有两个： 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均； 生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量的均衡了。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:12:4","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"十二、面试题 问：执行一条MySQL语句，非常慢，可能的原因？ 分两种情况： 大多数情况正常，偶尔很慢 数据库在刷盘，例如将 redo log、buffer 刷新到磁盘。因为采用了 WAL 技术：也就是更新数据时先写入 redo log，等空闲时再将 redo log 写入磁盘。刷脏页有以下场景： redo log 写满了，需要刷盘； buffer 不够了，需要淘汰一些页，而如果要淘汰的页刚好是脏页，就会刷盘； 空闲时； 遇到锁，拿不到锁，得阻塞等待。可以用 show processlist 这个命令来查看当前的状态。 一直执行得很慢 没用上索引，导致全表查询，还得回表，就很慢； 表中数据太多了，索引层数过高，建议分表； 分析慢查询日志； 数据库走错索引了，此时可以强制数据库走某个索引。 问：通过 select from limit 查询数据时，查询 0-10 和 990-1000 的效率一样吗？ limit 查询方式对应 limit offset, size，即从 offset 处开始查找 size 条数据。例如，当执行以下两条语句时： select * from page order by id limit 0, 10; select * from page order by id limit 6000000, 10; 第一条会获取到第0到10条完整行数据； 第二条则要先获得第0到(6000000 + 10)条完整行数据，返回给server层之后根据offset的值挨个抛弃，最后只留下最后面的size条，也就是10条数据。 由于获取到很多无用的数据，效率是不一样的。 如何优化呢？ 优化查询语句 优化查询语句：当select后面是*号时，需要拷贝完整的行信息，拷贝完整数据跟只拷贝行数据里的其中一两个列字段耗时是不同的，所以可以优化查询语句为： select * from page where id \u003e=(select id from page order by id limit 6000000, 1) order by id limit 10; 但这种方法也只是缓解，当 Offset 增长到百万千万级别，就也不太行了，这就涉及到了深度分页问题。 深度分页 这需要从背后的需求出发，不同的需求有不同的解决方案。 取出全表数据 select * from page; 因为数据量较大，mysql根本没办法一次性获取到全部数据，肯定超时报错。 解决方法：可以将所有的数据根据id主键进行排序，然后分批次取，将当前批次的最大 id 作为下次筛选的条件进行查询。如下伪代码： 这个操作，可以通过主键索引，每次定位到id在哪，然后往后遍历100个数据，这样不管是多少万的数据，查询性能都很稳定。 做分页展示 啥样的分页展示能到百万千万展示量啊？想想谷歌才提供多少页？去跟产品经理battle吧还是。。 问：执行一条MySQL语句，过程？ 连接器：建立连接，管理连接、校验用户身份； 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块； 解析 SQL：通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型； 执行 SQL：执行 SQL 共有三个阶段： 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。 优化阶段：基于查询成本的考虑，选择查询成本最小的执行计划(选择索引等)； 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端。 ","date":"2023-04-20","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:13:0","tags":["计算机基础"],"title":"数据库","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":["面试"],"content":"一、进程、线程、协程 问：什么是系统调用？ 进程的运行分为两个级别： 用户态(user mode)：用户态运行的进程可以直接读取用户程序的数据。 系统态(kernel mode)：系统态运行的进程几乎可以访问计算机的任何资源，不受限制。 用户写的程序基本上都运行在用户态，若想调用与系统级资源有关的操作，则必须通过系统调用向操作系统请求。 这些系统调用按功能大致可分为如下几类： 设备管理：完成设备的请求或释放，以及设备启动等功能。 文件管理：完成文件的读、写、创建及删除等功能。 进程控制：完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信：完成进程之间的消息传递或信号传递等功能。 内存管理：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 问：进程、线程、协程的区别？⭐⭐⭐ 进程 线程 协程 定义 拥有资源的基本单位 独立调度的基本单位 用户态的轻量级线程，线程内部调度的基本单位 切换情况 进程CPU环境（栈、寄存器、页表和文件句柄等）的保存以及新调度的进程CPU环境的设置 保存和设置程序计数器、少量寄存器和栈的内容 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复 切换者 操作系统 操作系统 用户 切换过程 用户态-\u003e内核态-\u003e用户态 用户态-\u003e内核态-\u003e用户态 用户态（没有陷入内核） 调用栈 内核栈和用户栈 内核栈和用户栈 用户栈 拥有资源 CPU资源、内存资源、文件资源和句柄等 程序计数器、寄存器、栈和状态字 拥有自己的寄存器上下文和栈 并发性 不同进程之间切换实现并发，各自占有CPU实现并行 一个进程内部的多个线程并发执行 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 系统开销 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 切换时只需保存和设置少量寄存器内容，因此开销很小 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 通信方面 进程间通信需要借助操作系统 线程间可以直接读写进程数据段（如全局变量）来进行通信 共享内存、消息队列 进程的执行体-\u003e线程，线程的执行体-\u003e协程。 每个进程拥有独立的虚拟地址空间，也就是有独立的页表，因此创建大量进程时会造成内存开销显著；操作系统进行进程调度时，需要切换虚拟地址空间，也就会切换页表。CPU 通过 MMU 将逻辑地址转到物理地址，为了减少访存次数设置了 TLB，而只有一个 TLB，因此进程切换会造成 TLB 失效，进而地址转换效率降低。而线程切换不需要切换虚拟地址空间，因此出现线程。 多线程下，进程拥有的资源是被所有线程共享的，但每个线程拥有自己的内核数据结构、内核栈和用户栈。为什么要分别拥有两个栈呢？对于内核来讲，所有用户代码都被视为不安全的，操作系统不允许用户态代码访问内核数据，线程进入内核态后执行的是内核提供的代码，若跟用户态共用一个栈就会留下安全漏洞(栈上数据可能会被用户程序非法读取)，因此要给内核态单独分配栈。 线程切换时，无需切换虚拟地址空间，也就无需切换页表，TLB 缓存也就不会失效，只需要切换自己拥有的寄存器和栈，因此性能显著提升。 ==为什么要有协程呢？== 线程的切换，是抢占式的，依然需要操作系统参与，假如并发量不断增大，线程数量达到百万级别时需要大量线程，但是每个线程只需执行很短的时间片，这样的切换就显得很笨重。 也就是说，一方面，线程的内核数据结构、内核栈和用户栈会占用大量内存；另一方面，线程是操作系统基于时间片策略进行调度的，在如此庞大的线程数量下，为了尽量降低延迟，线程每次得以运行的时间片会被压缩，造成线程切换频率的大幅提高。线程切换过于频繁时，调度会占用大量CPU资源，造成性能下降。 问题明了： 要节省内存空间，让主流服务器能轻松装载百万级的轻量线程； 要降低调度代价，切换起来更加轻快。 协程是通过主动让出的，调度无需通过操作系统，而是由用户程序管理，这就降低了调度代价。并且协程只有一个用户栈，一个线程的内存在MB级别，而协程只需要KB级别，这就节省了内存空间。 任务抽象 上下文 进程 PCB 线程 TCB 协程 use-defined ==函数和协程的区别？== 函数可以看成一个特殊的协程。函数的调用其实就是： 调用者主动让出CPU，创建函数栈帧，转而执行调用函数； return时再销毁被调函数栈帧，被调函数主动让出CPU； 返回继续执行调用者函数。 这个过程中，只有函数调用时，被调函数才拥有CPU；只有函数结束时，被调函数才会主动让出。但是，协程可以多次拥有CPU、多次主动让出CPU。这就是最大的区别。 问：线程之间共享的资源有哪些？ 可以先分析一下，哪些资源是线程私有的： 栈 程序计数器 函数运行使用的寄存器 栈指针 以上可以统称为线程上下文。 那除此之外，其余的就应该是共享的了： 代码区 线程之间共享代码区，这就意味着程序中的任何一个函数都可以放到线程中去执行，不存在某个函数只能被特定线程执行的情况。 数据区 用来存储全局变量。数据区中的全局变量有且仅有一个实例，所有的线程都可以访问到该全局变量。 堆区 只要知道变量的地址，也就是指针，任何一个线程都可以访问指针指向的数据，因此堆区也是线程共享的属于进程的资源。 栈区 上边说了，栈区是私有的。但是！！！尽管是私有的，但如果一个线程拿到了另一个线程内部变量的地址，那么照样是可以修改它的！！！理应是私有的，但没有什么保护措施，导致还算是共有的。 动态链接库 问：为什么线程切换比进程切换快呢？ 每个进程都拥有一个自己的虚拟地址空间，并且独立于其他进程的地址空间。而进程切换会涉及到虚拟地址空间的切换 虚拟地址转换为物理地址需要两个东西：CPU 上的 MMU 和 内存中的页表，为了减少访问内存的次数，设计了快表(页表缓存)。 由于进程切换会涉及到虚拟地址空间的切换，这就导致内存中的页表也需要进行切换，一个进程对应一个页表是不假，但是 CPU 中的 TLB 只有一个啊！页表切换后这个 TLB 就失效了。这样，TLB 在一段时间内肯定是无法被命中的，操作系统就必须去访问内存，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢。 而线程切换不需要切换虚拟地址空间，也就不存在这个问题了。 问：进程有哪些状态？ 创建状态(new)：进程正在被创建，尚未到就绪状态。 就绪状态(ready)：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 运行状态(running)：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 阻塞状态(waiting)：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。 以上为基础状态，但是大量进程阻塞时，也会占用内存，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。 所以需要新的状态-挂起态，来描述进程没有占用实际的物理内存空间的情况。 挂起状态可以分为两种： 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 问：进程间的通信方式？ 管道：管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程按序将数据写入缓冲区，另一端的进程则按序读出数据。管道只能承载无格式字节流以及缓冲区大小受限； 消息队列：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，并且存在用户态与内核态之间的数据拷贝开销因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程； 共享内存：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。 信号量：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 \u003c 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 \u003e= 0，则表明还有资源可使用，进程可正常继续执行。 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 \u003c= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 \u003e 0，则表明当前没有阻塞中的进程。 信号：信号是Linux系统中用于进程间互相通信或者操作的一种异步通信机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。(和信号量完全没关系！！)。比如： Ctrl+C产生Sigint信号，表示终止进程； kill pid终止进程。 套接字：主要用于在客户端和服务器之间通过网络进行通信。 问：进程调度算法有哪些？ 先到先服务(FCFS)调度算法：从就绪队列中，按照进入队列的顺序对线程分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 短作业优先(SJF)的调度算法：从就绪队列中，选出一个估计运行时间最短的进程","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:1:0","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"二、同步、锁 问：线程间的同步方式？ 互斥锁(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。 信号量(Semaphore)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件(Event)：Wait/Notify：通过通知的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 问：都有哪些锁？ **互斥锁：**一次只能一个线程拥有互斥锁，其他线程只有等待，加锁失败就让出CPU； 自旋锁：如果进/线程无法取得锁，进/线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁(忙等待)，直到获取为止； **读写锁：**多个读者可同时获得，但写者互斥，若有写者，则读者必须等待； **如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**因为线程上下文切换的代价相比自旋锁来说也很大。 问：乐观锁与悲观锁是啥？ 悲观锁：互斥锁、自旋锁、读写锁都属于悲观锁。悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。 **乐观锁：**乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。 乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**比如在线文档、Git等。 问：什么是死锁？ 死锁：两个或多个线程由于相互等待对方占有的资源而永远被阻塞的情况。 问：产生死锁的四个必要条件？ **互斥条件：**一个资源每次只能被一个进程使用。 **请求与保持条件：**一个进程因请求资源而阻塞时，对已获得的资源保持不放。 **不剥夺条件：**进程已获得的资源，在末使用完之前，不能被强行剥夺。 **循环等待条件：**若干进程之间形成一种头尾相接的循环等待资源关系。 问：解决死锁的方法？ **预防：**采用某种策略，限制并发进程对资源的请求； 破坏请求与保持：进程必须在执行前就申请到它所需要的全部资源，并且直到它所要的资源都得到满足之后才开始执行； 破坏循环等待：所有的资源被分成了多个层次，一个进程得到某一层次的资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源； 避免：系统在分配资源时，根据资源的使用情况提前做出预测，从而避免死锁的发生：银行家算法。 **检测：**当死锁发生时，能够检测死锁的发生，并精确地确定与死锁有关的进程和资源； **解除：**检测到死锁的进程，释放其持有的资源。 ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:2:0","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"三、内存管理 操作系统的内存管理主要负责内存的分配与回收。 问：内存管理机制有哪些？ 简单分为连续分配管理方式和非连续分配管理方式这两种。 连续分配管理是指为一个用户程序分配一个连续的内存空间，常见的如分区管理方式(块式管理)。 非连续分配管理允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理 和 段式管理。 块式管理：固定分区和动态分区。前者容易有内部碎片，后者有外部碎片。过程：前者将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块。后者按照进程大小划分块，按照首次适应算法分配。 页式管理：把内存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理：页式管理是从计算机角度出发设计的，对用户完全透明，而段式管理则是从用户角度出发设计的。将进程的逻辑空间划分为代码段、数据段、栈段、堆段等，段内的内存空间是连续的，段外的内存空间是不连续的。通过段表对应逻辑地址和物理地址。 段页式管理：段页式管理机制结合了段式管理和页式管理的优点。简单来说**段页式管理机制就是把主存先分成若干段，每个段又分成若干页。**每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号。 问：页式管理中，虚拟地址和物理地址怎么转换？ 页号和页内偏移。 页号作为页表的索引，页表包含物理页每页所在物理内存的基地址。基地址与页内偏移的组合就形成了物理内存地址。 问：多级页表有啥用？ 把存储大量页表项的页表，再次分页。 引入多级页表的主要目的是为了避免把全部页表项一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。 比如，32位系统，虚拟地址空间共有 4GB，假设一个页的大小是 4KB(2^12)，那么就有大约 1024 * 1024 (2^20) 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。可以划分成二级页表，第一级是1024个页表项，每个页表项对应一个页面，这个页面中又有1024个页表项，这样的好处就是：当查找时，首先通过一级页表找到二级页面，然后将指向的页面调入内存，然后找到页表项。也就是说内存中只需要存储用到的页面即可。这将大大减少需要调入内存的页表项总数。 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？ 对于 64位系统，通常采用四级页表。 问：快表(TLB) 是啥？ 快表(TLB)：将最常访问的页表项存储到访问速度更快的Cache中。 因为若把页表全部放入内存，存取一条数据至少要访问两次内存，第一次先访问页表找到数据对应的物理地址，第二次再从该地址存取数据。对于多级页表，需要访问内存的次数会更多。 而若命中快表，则只需要一次访存。 问：段页式内存管理的实现？ 先将程序划分为多个有逻辑意义的段：栈段、堆段、BSS段、数据段、代码段，也就是分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页； 地址结构就由段号、段内页号和页内位移三部分组成： 段页式地址变换中要得到物理地址须经过三次内存访问： 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。 问：虚拟地址空间是啥？有啥用？ 虚拟地址空间是程序中使用的内存地址，实际访问时通过 内存管理单元(MMU) 和 内存中的页表 转化为物理地址。==实际上并不存在。== 每个进程都拥有一个自己的虚拟地址空间，并且独立于其他进程的地址空间。虚拟地址空间将不同进程的虚拟地址和不同内存的物理地址映射起来。 虚拟地址空间主要是为了： 避免直接操作物理地址。可能会对操作系统造成影响； 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存； 易移植性。可以屏蔽操作系统物理地址的差别。 可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 问：虚拟内存是啥？虚拟内存管理有啥用？ 虚拟内存是一种逻辑上扩充物理内存的技术，就是将硬盘的一部分作为内存来使用。==是实际存在的。== 虚拟内存技术基于一个非常重要的原理，局部性原理： 1）时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环） 2）空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的） 基于这个局部性原理： 在一个程序装入内存的时候，可以只将这个程序中很快会用到的部分装入内存，暂时用不到的部分仍然留在外存（磁盘），并且程序可以正常执行； 而在程序执行过程中，当 CPU 所需要的信息不在内存中的时候，由操作系统负责将所需信息从外存（磁盘）调入内存，然后继续执行程序； 如果调入内存的时候内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。 虚拟内存管理主要是为了： 逻辑上扩大实际的物理内存。(就这一个) 问：虚拟内存的技术实现？页面置换算法有哪些？ 请求分页管理（页式虚存系统） 请求分段管理（段式虚存系统） 请求段页式管理（段页式虚存系统） 以请求分页管理为例：请求掉页、缺页中断、页面置换。 在程序执行过程中，当所访问的页不在内存时，会产生一个缺页中断，操作系统将内存中缺失的页面从磁盘调入内存； 若此时有空闲的块，就调入空闲的块； 若无空闲的块，就需要先淘汰掉某页。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到磁盘（操作系统要提供页面置换的功能， 将暂时用不到的页面换出磁盘）。 FIFO 算法，先入先淘汰； LRU 算法，效率很高，但实现复杂； Clock 算法，效率近似 LRU，但实现简单点 改进型的 CLOCK 算法步骤如下： **两个标志位：**访问位和修改位 从指针的当前位置开始，扫描循环队列。在这次扫描过程中，对访问位不做任何修改。选择遇到的第一个是第 0 类 “未被访问，未被修改 (Referenced bit = 0，Modified bit = 0)” 的页面用于替换 如果第 1 步失败，则重新扫描，查找第一个是 “未被访问，被修改 (Referenced bit = 0，Modified bit = 1)” 的页面用于替换。在这次扫描过程中，对每个跳过的页面，和简单的 CLOCK 算法一样，把它的访问位设置成 0 如果第 2 步失败，指针将回到它的最初位置，并且集合中所有页面的访问位都已经被设置为 0 了。重复第 1 步，并且如果有必要，重复第 2 步。这样一定可以找到供替换的页面。 ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:3:0","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"四、文件系统（未） ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:4:0","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"五、网络系统 ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:5:0","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"网络请求处理 黑马视频 redis 最后。 阻塞IO (Bloking IO) 先讲讲阻塞 IO 的数据接收流程： 服务端进程 A 通过 socket() 函数陷入内核态进行 socket 系统调用，该内核函数会创建 socket 内核对象，包含两个重要数据结构：等待队列和接收队列。 等待队列：存放服务端进程A的进程描述符和回调函数； 接收队列：存放网卡接收到的该 socket 要处理的数据。 进程 A 调用 recv() 函数接收数据，会进入到 recvfrom() 系统调用函数，发现 socket 的接收队列没有它要接收的数据到达时，进程 A 会让出 CPU，进入阻塞状态，进程 A 的进程描述符和它被唤醒用到的回调函数 callback func 会组成一个结构体，称为等待队列项，放入 socket 的等待队列； 客户端的发送数据到达服务端的网卡； 网卡首先会将网络传输过来的数据通过 DMA 控制程序复制到内存环形缓冲区 RingBuffer 中； 网卡向 CPU 发出硬中断； CPU 收到了硬中断后，为了避免过度占用 CPU 处理网络设备请求导致其他设备如鼠标和键盘的消息无法被处理，会调用网络驱动注册的中断处理函数，进行简单快速处理后向内核中断进程 ksoftirqd 发出软中断，就释放 CPU，由软中断进程处理复杂耗时的网络设备请求逻辑； 内核中断进程 ksoftirqd 收到软中断信号后，会将网卡复制到内存的数据，根据数据报文的 IP 和端口号，将其拷贝到对应 socket 的接收队列； 并通过进程等待队列中的回调函数，唤醒要处理该数据的进程 A，进程 A 会进入 CPU 的运行队列，等待获取 CPU 执行数据处理逻辑； 进程 A 获取 CPU 后，会回到之前调用 recvfrom() 函数时阻塞的位置继续执行，这时发现 socket 内核空间的等待队列上有数据，会在内核态将内核空间的 socket 等待队列的数据拷贝到用户空间，然后才会回到用户态执行进程的用户程序，从而真的解除阻塞。 **==阻塞 IO 模型==**如下： 会出现的问题： 进程在 recv 的时候大概率会被阻塞掉，导致第一次进程切换； 当数据到达服务端的网卡、并从网卡复制到内核空间 socket 的数据接收队列时，进程会被唤醒，第二次进程切换。此时还需要将数据从内核态复制到用户态，也就是数据复制会出现两次； 一个进程同时只能等待一条连接，如果有很多并发，则需要很多进程。 总结：一次数据到达会进行两次进程切换，一次数据读取有两次阻塞(出现在两次等待数据拷贝时)，单进程只能对单连接。 非阻塞IO (Nonbloking IO) 非阻塞的 Recv() 的效果是：如果没有数据从网卡到达内核 socket 的等待队列时，系统调用会直接返回，而不是阻塞的等待。 也就是说，非阻塞 IO，只是将等待数据从网卡到达 socket 内核空间这一部分变成了非阻塞的： 用户进程调用 recvfrom() 会重复发送请求检查数据是否到达内核空间(CPU忙等待)，如果没有到，则立即返回，重复这个过程，不会阻塞。 当数据已经到达内核空间的 socket 的等待队列后，用户进程依然要等待 recvfrom() 函数将数据从内核空间拷贝到用户空间，才会从 recvfrom() 系统调用函数中返回。 **总结：**非阻塞 IO 模型将“两处阻塞”变成了“一处阻塞”，但依然存在“两次进程切换，一处阻塞，单进程对单连接”的问题。 ==花里胡哨的，没什么用，数据没来还不停的问，有什么用？== maybe 类似自旋锁的作用？ IO多路复用 (IO Multiplexing) IO 多路复用可以解决“两次进程切换，单进程对单连接”的问题。 通过一个进程处理多个 TCP 连接，只处理有数据到达的连接。当然，如果要监听的所有连接都没有数据到达，进程还是会进入阻塞状态，直到某个连接有数据到达时被回调函数唤醒。 ==问题就在于如何发现哪个连接的数据到达了？== ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:5:1","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"详解select、poll、epoll 先说明几个重要的概念： 文件描述符 fd：是一个从 0 开始的非负整数，进程使用文件描述符来标识一个打开的文件。Linux 中一切皆文件。系统为每个进程维护了一个文件描述符表，表示该进程打开文件的记录表，文件描述符实际就是这张表中的索引。 **文件描述符集 fd_set：**select 函数参数中的 fd_set 类型表示文件描述符的集合，fd_set 的每一位来表示一个文件描述符。比如，当 select 返回 fd_set = 00010011 时，表示文件描述符 1、2、5 已经就绪。 Socket：用于不同进程间的通信。操作系统将 Socket 映射到进程的一个文件描述符上，进程就可以通过读写这个文件描述符来进行通信。通过 Socket 通信，实际上就是通过文件描述符 fd 读写文件。 IO 多路复用：利用单个进程来同时监听多个 fd，并在某个 fd 可读、可写时得到通知，从而避免无效的等待。 select select 实现多路复用的方式：将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写，接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 看个例子： 服务器进程 A 启动的时候，要监听的连接的 socket 文件描述符是 3、4、5； 如果这三个连接均没有数据到达网卡，则进程 A 会让出 CPU，进入阻塞状态；同时会将进程 A 的进程描述符和被唤醒时用到的回调函数组成等待队列项加入到 socket 对象 3、4、5 的进程等待队列中。注意，select 调用时，fdsr 文件描述符集会从用户空间拷贝到内核空间； 当网卡接收到数据，然后网卡通过中断信号通知 CPU 有数据到达，执行中断程序，中断程序主要做了两件事： 将网络数据写入到对应 socket 的数据接收队列里面； 唤醒队列中的等待进程 A，重新将进程 A 放入 CPU 的运行队列中； 假设连接 3、5 有数据到达网卡，注意，这时 select 调用结束时，fdsr 文件描述符集会从内核空间拷贝到用户空间： 进程 A 需要遍历 fd_set，获取就绪的文件描述符。 select 的缺点： 性能开销大 调用 select 时会陷入内核，这时需要将参数中的 fd_set 从用户空间拷贝到内核空间；select 执行完后，还需要将 fd_set 从内核空间拷贝回用户空间，高并发场景下这样的拷贝会消耗极大资源；（epoll 优化为不拷贝） 进程被唤醒后，不知道哪些连接已就绪，需要遍历拷贝过来的 fd_set 的每一位；（epoll 优化为异步事件通知） 同时能监听的文件描述符太少 受限于 sizeof(fd_set) 的大小，在编译内核时就确定了且无法更改。一般是 32 位操作系统是 1024，64 位是 2048。（poll、epoll 优化为适应链表方式） poll 和 select 类似，只是描述 fd 集合的方式不同：poll 使用 pollfd 结构而非 select 的 fd_set 结构。 基于链表存储，无最大数量限制，因此解决了 select 的第二个缺点。 epoll epoll 是对 select 和 poll 的巨大改进： 解决了 select 中 fd_set 不断重复拷贝到内核的问题：使用红黑树在内核中存储一份文件描述符集合，每个文件描述符只需在添加时传入内核一次，无需每次都重新传入； 通过事件的发生触发回调函数，存储就绪的文件描述符列表，而不是通过轮询的方式； 使用队列存储就绪的文件描述符，且会按需返回就绪的文件描述符，无须再次遍历。 主要涉及3个函数： // 创建一个 eventpoll 内核对象 int epoll_create(int size); // 将连接的socket对象添加到 eventpoll 对象中，epoll_event是要监听的事件 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 等待连接 socket 的数据是否到达 int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); epoll_create epoll_create 函数会创建一个内核对象 eventpoll，把它关联到当前进程的已打开文件列表中。主要包含3个成员： struct eventpoll { struct rb_root rbr; // 红黑树，管理用户进程下添加进来的所有 socket 连接 struct list_head rdllist; // 数据就绪的文件描述符都会放到这里 wait_queue_head_t wq; // 等待队列链表，存放阻塞的进程 ...... } rbr：一棵红黑树，管理所有要监听的 socket 连接，增删改的时间复杂度是 O(logn)； rdllist：就绪的描述符的链表。当某个 socket 注册事件触发时，通过注册的回调函数将就绪的 socket 放到 rdllist 链表里； wq：等待队列，如当前进程要等待数据，就会把当前进程描述符和回调函数构造成一个等待队列项，放入当前 wq 等待队列。 epoll_ctl epoll_ctl 函数有三个功能：增、删、改。主要负责把 socket 连接注册到 eventpoll 对象里，会做三件事： 创建一个 epitem 对象，主要包含两个字段：socket 的文件描述符、所属的 eventpoll 对象的指针； 将一个数据到达时用到的回调函数添加到 socket 的进程等待队列中； 将第 1 步创建的 epitem 对象插入红黑树。 epoll_wait 当 eventpoll 监控的 socket 对象有数据到达时，会通过 socket 进程等待队列中的回调函数唤醒红黑树中的节点 epitem，并将其添加到就绪队列 rdllist 中； 检查 eventpoll 对象的进程等待队列上是否有等待项，通过回调函数唤醒这个进程，进行数据的处理； 进程唤醒后，把 rdllist 中就绪的事件列表拷贝到用户空间。 问：I/O 多路复用是啥？有啥用？实现原理？⭐ IO多路复用是一种同步的IO模型。这里的I/O通常指网络I/O，也指Socket通信。 可以实现多个请求复用一个进程。利用IO多路复用模型，可以实现一个线程监视多个文件句柄；一旦某个文件句柄就绪，就能够通知到对应应用程序进行相应的读写操作；没有文件句柄就绪时就会阻塞应用程序，从而释放出CPU资源。 有三种实现方式： select：首先将所有的socket都放到一组文件描述符中，然后调入内核，内核通过轮询检查是否有网络事件发生。 若检查到事件发生，就将整组文件描述符调入用户态，然后用户程序再次轮询，对有事件发生的进行处理。 这种方式，一共轮询两次，并且需要两次拷贝文件描述符。并且有数量限制，1024个； poll：和select没啥区别，只不过没有数量限制，因为改成了用链表存储。 ==epoll：== epoll 在内核里使用**「红黑树」来关注进程所有待检测的事件**。红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。epoll 因为在内核维护了红黑树，可以保存所有待检测的事件，不需要像 select/poll 在每次操作时都传入整个事件集合，只需要传入一个待检测的事件，减少了内核和用户空间大量的数据拷贝和内存分配。 epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符，m不需要像 select/poll 那样轮询扫描整个事件集合，大大提高了检测的效率。 epoll 最大的优点是： 避免了轮询所有的文件描述符，采用回调函数定向通知程序要处理的事件，大大提高了CPU执行效率。 在内核中维护红黑树，避免文件描述符集的拷贝过程。 事件通知机制 问：epoll 支持哪几种事件通知机制？ epoll 支持两种事件触发模式，分别是边缘触发(ET)和水平触发(LT)。 LT：当被监控的 FD 有数据可读时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，直至数据处理完成。Epoll 的默认模式。 ET：当被监控的 FD 有数据可读时，服务器端只会从 epoll_wait 中苏醒一次，不管数据是否处理完成，因此要保证一次性将内核缓冲区的数据读取完； ET 的效率要比 LT 高，但是实现起来比较复杂，因为要保证一次读完所有的数据，要注意采用非阻塞的读取，也就是读不到数据了也返回，不然会一直阻塞在这里等待数据。 LT 可能会有惊群现象。 基于 epoll 的服务端模型 Redis 就跟这个类似。 ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:5:2","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"六、Linux 查看进程 ps aux | grep 进程名 ps -ef | grep 进程名 ps aux 和 ps -ef 命令都可以用于显示当前系统中运行的进程列表，但它们的输出格式略有不同。 ps aux 命令的输出格式是以用户为主导的，它显示了所有进程的详细信息，包括进程的用户、进程 ID、CPU 占用率、内存占用率等。其中，a 选项表示显示所有进程，u 选项表示显示详细信息，x 选项表示同时显示没有控制终端的进程。 ps -ef 命令的输出格式是以进程为主导的，它显示了所有进程的简要信息，包括进程的用户、进程 ID、父进程 ID、启动时间、命令等。其中，e 选项表示显示所有进程，f 选项表示显示进程的详细信息，包括父进程 ID、进程状态等。 因此，ps aux 输出的信息比 ps -ef 更详细，但也更复杂，而 ps -ef 输出的信息则更为简洁。在实际使用中，可以根据自己的需要选择使用哪个命令。 查看 socket $ netstat $ ss # 推荐 输出的内容都差不多，都包含了 socket 的状态（State）、接收队列（Recv-Q）、发送队列（Send-Q）、本地地址（Local Address）、远端地址（Foreign Address）、进程 PID 和进程名称（PID/Program name）等。 **接收队列（Recv-Q）和发送队列（Send-Q）**比较特殊，在不同的 socket 状态。它们表示的含义是不同的。 当 socket 状态处于 Established时： Recv-Q 表示 socket 接收缓冲区中还没有被应用程序读取的字节数； Send-Q 表示 socket 发送缓冲区中还没有被远端主机确认的字节数； 而当 socket 状态处于 Listen 时： Recv-Q 表示全连接队列的长度； Send-Q 表示全连接队列的最大长度； 日志分析 用一个大概几万条记录的 nginx 日志文件 access.log 作为案例，看看如何分析出「用户信息」。 准备工作 查看日志文件的大小： $ ls -lh 日志名 如果日志文件大小非常大，最好不要在线上环境做，下面的 access.log就只有 6.5 MB： 如果日志量太大，cat命令会非常影响性能，导致性能抖动；最好先用scp命令将日志文件传输到闲置的服务器再分析。 慎用cat cat读取文件时，文件中有多少数据，它就读多少，不适用于大文件。应使用less命令读取大文件的内容，因为 less 并不会加载整个文件，而是按需加载：先是输出一小页的内容，当要往下看的时候，才会继续加载。 若要看日志最新的内容，应使用tail命令： $ tail -n 5 access.log # 查看 access.log 最新的 5 条数据 $ tail -f # 实时查看日志 PV 分析 PV(Page View)：指页面的访问量(点击次数)。比如大多数博客平台，点击一次页面，阅读量就加 1，所以说 PV 的数量并不代表真实的用户数量，只是点击量。 分析 PV 比较容易，因为有多少行日志记录就有多少 PV，可以使用： $ wc -l access.log # 输出 access.log 有多少行 49903 access.log PV 分组 根据访问时间进行分组，比如按天分组，得到每天的访问量。根据日志记录的格式，时间在第 4 列，可以利用awk构造过滤语句： $ awk '{print $4}' access.log 但包含了时分秒，进一步过滤出年月日，使用awk的substr，从第 2 个字符开始，截取 11 个字符： $ awk '{print substr($4, 2, 11)}' access.log 但没排序，进一步排序，使用sort，然后使用uniq -c进行统计： $ awk '{print substr($4, 2, 11)}' access.log | sort | uniq -c 注意，使用 uniq -c 命令前，先要进行 sort 排序，因为 uniq 去重的原理是比较相邻的行，然后除去第二行和该行的后续副本。 UV 分析 UV(Uniq Visitor)：指访问人数。比如公众号的阅读量就是以 UV 统计的，不管单个用户点击了多少次，最终只算 1 次阅读量。 access.log中没有用户信息，可以用 IP地址 近似统计： $ awk '{print $1}' access.log | sort | uniq | wc -l 该命令的输出结果是 2589，也就说明 UV 的量为 2589。 awk '{print $1}' access.log，取日志的第 1 列内容，客户端的 IP 地址正是第 1 列； sort，对信息排序； uniq，去除重复的记录； wc -l，查看记录条数； UV 分组 按天分组分析每天的 UV 数量。命令较多，分开来看： 过滤出 「日期 + IP地址」 $ awk '{print substr($4, 2, 11) \" \" $1}' access.log | sort | uniq awk 将第 4 列的日期和第 1 列的客户端 IP 地址过滤出来，并用空格拼接起来； sort 对 awk 输出的内容进行排序； 接着用 uniq 去除重复的记录，也就说 日期 IP 相同的行就只保留一个； 统计次数，在上述命令后拼接：awk '{uv[$1]++;next}END{for (day in uv) print day, uv[day]}' $ awk '{print substr($4, 2, 11) \" \" $1}' access.log | sort | uniq | awk '{uv[$1]++;next}END{for (day in uv) print day, uv[day]}' awk 本身是「逐行」进行处理的，当执行完一行后，我们可以用 next 关键字来告诉 awk 跳转到下一行，把下一行作为输入； 对每一行输入，awk 会根据第 1 列的字符串(也就是日期)进行累加，这样相同日期的 ip 地址，就会累加起来，作为当天的 uv 数量； 之后的 END 关键字代表一个触发器，就是当前面的输入全部完成后，才会执行 END {} 中的语句，通过 for 遍历 uv 中所有的 key，打印出按天分组的 uv 数量。 终端类型分析 access.log 日志最末尾关于 User Agent 的信息，主要是客户端访问服务器使用的工具：手机、浏览器等。 可利用这些信息，分析不同终端类型分别有多少。 User Agent 的信息在日志里的第 12 列 $ awk '{print $12}' access.log | sort | uniq -c | sort -rn awk 过滤出第 12 列的内容； sort 排序； uniq -c 去重并统计； sort -rn(r 表示逆向排序， n 表示按数值排序)，对统计的结果排序 分析 TOP3 请求 获取到访问路径最频繁的 TOP3。 $ awk '{print $7}' access.log | sort | uniq -c | sort -rn | head -n 3 ","date":"2023-04-19","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:6:0","tags":["计算机基础"],"title":"操作系统","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["面试"],"content":"一、TCP 与 UDP 问：TCP 与 UDP 的区别⭐ 是否面向连接：UDP 在传送数据之前不需要先建立连接；而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。 是否是可靠传输：UDP 提供不可靠的传输服务，收到报文无需确认，不保证数据不丢失，不保证按序到达；TCP 提供可靠的传输服务，TCP 通过三次握手和四次挥手来建立和释放连接，数据传递时，有确认、窗口、重传、拥塞控制机制，确保传输的数据，无差错、不丢失、不重复、并且按序到达。 传输形式：TCP 是面向字节流的，UDP 是面向报文的。 是否提供广播或多播服务：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多。 首部开销：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。 传输效率：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。 问：什么时候选择 TCP，什么时候选 UDP? UDP 一般用于即时通信，比如：语音、视频、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。 TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等。 问：HTTP 基于 TCP 还是 UDP？ HTTP 3.0 之前是基于 TCP 协议的，而 HTTP3.0 将弃用 TCP，改用 基于 UDP 的 QUIC 协议 。此变化主要为了解决 HTTP/2 中存在的队头阻塞问题。由于 HTTP/2 在单个 TCP 连接上使用了多路复用，受到 TCP 拥塞控制的影响，少量的丢包就可能导致整个 TCP 连接上的所有流被阻塞。 问：基于 TCP、UDP 的协议？ ==基于 TCP 的协议== HTTP 协议：超文本传输协议(HTTP，HyperText Transfer Protocol)主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 HTTPS 协议：更安全的超文本传输协议(HTTPS，Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议 FTP 协议：文件传输协议 FTP(File Transfer Protocol)，提供文件传输服务，基于 TCP 实现可靠的传输。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。 SMTP 协议：简单邮件传输协议(SMTP，Simple Mail Transfer Protocol)的缩写，基于 TCP 协议，用来发送电子邮件。注意⚠️：接受邮件的协议不是 SMTP 而是 POP3 协议。 POP3/IMAP 协议：POP3 和 IMAP 两者都是负责邮件接收的协议。 Telnet 协议：远程登陆协议，通过一个终端登陆到其他服务器。被一种称为 SSH 的非常安全的协议所取代。 SSH 协议：SSH(Secure Shell)是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。 ==基于 UDP 的协议== DHCP 协议：动态主机配置协议，动态配置 IP 地址； DNS：域名系统(DNS，Domain Name System)将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。 我们可以将其理解为专为互联网设计的电话薄。实际上 DNS 同时支持 UDP 和 TCP 协议。 问：如何理解 TCP 是面向字节流的？ 之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的发送方的机制不同。 为什么 UDP 是面向报文的？ 当用户消息通过 UDP 协议传输时，操作系统不会对消息进行拆分，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。 为什么 TCP 是面向字节流的？ 当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。 这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。 例如，发送方准备发送 「Hi.」和「I am Xiaolin」这两个消息。 在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。至于什么时候真正被发送，取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去。 实际发送有如下可能的情况： 因此，我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。 当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。 要解决这个问题，要交给应用程序。 问：TCP 的粘包问题是啥？咋解决呢？UDP 有吗？ TCP 粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。其实就是消息边界模糊造成的。 产生原因： 由TCP连接复用造成的粘包问题。 因为TCP默认会使用 Nagle 算法，此算法会导致粘包问题：合并相连的小数据包，再一次性发送，以达到提升网络传输效率的目的。但接收方又不知道你合并了。 接收方来不及接收缓冲区的包，导致缓冲区有多个包，而一次性读取时，就发生了粘包 解决问题：tcp 协议的包头有 20 字节，ip 协议的包头也有 20 字节，如果仅仅传输 1 字节的数据，在网络上传输的就有 20 + 20 + 1 = 41 字节，其中真正有用的数据只有 1 个字节，这对效率和带宽是极大的浪费。 Nagle 算法：如果是连续的小数据包，大小没有一个 MSS（Maximum Segment Size，最大分段大小），并且还没有收到之前发送的数据包的 Ack 信息，那么这些小数据包就会在发送端暂存起来，直到小数据包累积到一个 MSS，或者收到一个 Ack 为止。 这个算法虽然减少了不必要的网络传输，但既导致了延迟，也导致了粘包。 解决方法： 以指定字符串为包结束标志，比如\\n等，比如HTTP； 添加一个自定义的包头，记录本包的数据长度，然后自己写个buffer缓冲一下，等收到指定长度了再交付处理；(你不就是用的这个吗？hhh) 比如，固定前 8 个字节，定义为数据长度，真正的数据在后面。 固定每个包的长度(太不灵活了)。 UDP 是面向报文的(具有长度字段)，具有消息边界，每个包都是独立的，因此不会。而TCP首部里是没有长度这个信息的，TCP 发送端在发的时候就不保证发的是一个完整的数据报，仅仅看成一连串无结构的字节流，这串字节流在接收端收到时哪怕知道长度也没用，因为它很可能只是某个完整消息的一部分。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:1:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"二、TCP 三次握手和四次挥手 问：TCP 三次握手和四次挥手⭐⭐⭐🚩 ==三报文握手：== 首先，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态； 客户端会随机初始化序号(client_isn)，将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态； 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号(server_isn)，将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。 注意： TCP 规定携带 SYN 的确认报文段不携带数据，但也要消耗序号； TCP 规定普通 TCP 确认报文段可以携带数据，若不携带数据，则不消耗序号。即上图传输的第一个数据报文段序号seq=x+1。即第三次握手是可以携带数据的，前两次握手是不可以携带数据的。 ==四报文挥手：== 问：用什么数据结构管理半连接队列和全连接队列？ 问：全连接队列和半连接队列满了分别会发生什么？ 全连接队列满了之后，再收到新的连接，就会丢弃； 半连接队列满了之后，再收到新的连接，也会丢弃。 但半连接队列满了，不意味着无法建立连接了。通过开启syncookies，就可以在不使用 SYN 半连接队列的情况下成功建立连接。 syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功： 问：TCP 连接建立解决的问题？ 解决了以下三个问题： 使 TCP 双方能够确认对方的存在； 使 TCP 双方能够协商一些参数(如：最大窗口值、是否使用窗口扩大选项和时间戳选项以及服务质量等)； 使 TCP 双方能够对运输实体资源(如：缓存大小、连接表中的项目等)进行分配。 问：为什么要三次握手？⭐🚩 从三个方面讲： 三次握手才可以阻止重复历史连接的初始化（主要原因）； 三次握手才可以同步双方的初始序列号； 三次握手才可以避免资源浪费。 三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。 如果是两次握手连接，就无法阻止历史连接： **避免过期连接的建立。**若为两次握手，客户端先第一次握手，然而阻塞了，然后重新发起第一次握手，此时第一次握手数据报已经到了，然后服务端第二次握手，连接就建立了，就可以发数据了，但是客户端会通通丢弃！！！造成资源浪费！！！ 三次握手第二主要的目的就是双方确认自己与对方的发送与接收是正常的，并同步双方的初始序列号。若为两次，则只有一方能确定对方的序列号： 第一次握手 ：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手 ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手 ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 问：每次建立 TCP 连接时，初始化的序列号有啥讲究？⭐🚩 每次初始化的序列号都要求不一样，主要有以下原因： 为了防止历史报文被下一个相同四元组的连接接收（主要方面）； 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收。 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接； 在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。 可以看到，如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。如果每次建立连接客户端和服务端的初始化序列号都**「不一样」**，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文。 问：初始序列号是如何随机产生的？⭐ 起始 ISN 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。 RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。 M 是一个计时器，这个计时器每隔 4 微秒加 1。 F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。 可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。 问：为什么要四次挥手？ 因为 TCP 是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 举个例子：A 和 B 打电话，通话即将结束后。 第一次挥手 ：A 说“我没啥要说的了” 第二次挥手 ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话 第三次挥手 ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了” 第四次挥手 ：A 回答“知道了”，这样通话才算结束。 问：四次挥手中，最后客户端要等待2MSL，有必要吗？为什么不直接关闭呢？ MSL：报文最大生存时间。 MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。2MSL 就相当于一来一回的最大时间。 ==回答：== 有必要。如果客户端最后一次ACK报文段丢失了，服务端就会重发 FIN，如果客户端在 2MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。 等待 2MSL 是为了保证本次连接中产生的所有报文段都从网络中消失，避免影响之后的 TCP 连接。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:2:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"三、TCP 传输可靠性 问：TCP 如何保证数据传输可靠性？⭐ TCP 基于以字节为单位的滑动窗口来实现可靠传输； TCP 拥有校验和机制。如果收到报文段的检验和有差错，TCP 将丢弃这个报文段； TCP 通过序号机制保证数据的按序交付。会将不按序到达的数据放在接收窗口，待接收完毕再按序交付给应用层； TCP 要求接收方必须有累计确认和捎带确认机制； TCP 拥有超时重传机制。会对发送的报文段启动定时器，未接收到接收端发来的确认报文会导致定时器超时，从而重新发送该报文段； 流量控制。接收端根据自身情况，当来不及处理接收到的数据时，降低发送端的发送速率，防止包丢失。 拥塞控制。网络拥塞时，缩减发送端的拥塞窗口，降低数据发送速率，防止包丢失。 问：TCP 如何实现流量控制？⭐ 接收方通过 TCP 头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题，所以流量控制是点对点控制。 过程自己想想说叭。 问：流量控制中，死锁的局面？ 问：TCP 拥塞控制如何实现？⭐🚩 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送窗口 = min(拥塞窗口, 接收窗口) TCP 的拥塞控制采用了四种算法，即慢开始、拥塞避免、快重传和快恢复。 慢开始：cwnd 初始值为 1，还未到慢开始门限时，每经过一个传播轮次，cwnd 加倍； 拥塞避免：到达慢开始门限时，cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的cwnd加 1。当重传计时器超时，很大概率发生拥塞： 慢开始门限 = 拥塞时的cwnd / 2； cwnd = 1，重新开始慢开始算法。 但是，个别报文段的丢失也会引起计时器超时，但是此时网络可能并没有拥塞，如果从慢开始再次开始，就降低了网络效率。==针对这种情况，新产生了快重传和快恢复。== 快重传：接收方不要等到自己有数据发送时才进行捎带确认，而是要立即发送确认；发送方一旦收到3个重复确认，就对相应报文段立即重传，不要等超时计时器超时。 快恢复：一旦收到3个重复确认，就知道只是丢失了个别的报文段，于是执行快恢复算法：将cwnd = 拥塞时的cwnd / 2，慢开始门限 = 拥塞时的cwnd / 2。 问：流量控制与拥塞控制的区别？ 拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。 相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，确保接收端来得及接收。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:3:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"四、HTTP 和 HTTPS ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"4.1 基础概念 HTTP 协议，全称超文本传输协议(Hypertext Transfer Protocol)，也就是传输网络上的包括文本在内的各式各样的消息。HTTP 是一个无状态(stateless)协议，也就是说服务器不维护任何有关客户端过去所发请求的消息。HTTP 是应用层协议，它以 TCP（传输层）作为底层协议。默认端口为 80。 HTTPS 协议(Hyper Text Transfer Protocol Secure)，是 HTTP 的加强安全版本。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并额外使用 SSL/TLS 协议用作加密和安全认证。默认端口号是 443。 HTTPS 协议中，SSL 通道通常使用基于密钥的加密算法，密钥长度通常是 40 比特或 128 比特。 问：HTTP 的报文格式？ HTTP 有两类报文：请求报文 和 响应报文。 HTTP 请求/响应报文由以下内容组成： 请求头 HTTP 头部字段 空行 可选的 HTTP 报文主体数据 请求报文 HTTP 的请求报文分为三个部分： 请求行 请求方法 请求地址 URL HTTP 协议版本 GET /index.html HTTP/1.1 请求头(首部行) Accept: */* Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Connection: keep-alive Content-Length: 21429 Content-Type: application/json Host: api.github.com Origin: https://github.com Referer: https://github.com/ User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36 请求头 说明 Accept 表示浏览器接受的数据类型 Accept-Encoding 表示浏览器接受的数据压缩格式 Host 表示当前请求访问的目标地址 Authorization 表示用户身份认证信息 User-Agent 表示浏览器类型 If-Modified-Since 表示当前请求资源最近一次更新时间 If-None-Match 表示当前请求资源最近一次标识的 ETag 值 Cookie 表示浏览器保存的 Cookie 信息 Referer 表示标识请求引用自哪个地址 消息体 请求体是 POST 请求方式中的请求参数，以 key = value 形式进行存储，多个请求参数之间用 \u0026 连接，如果请求当中请求体，那么在请求头当中的 Content-Length 属性记录的就是该请求体的长度。 pageNo=0\u0026pageSize=10\u0026orderNum=306735659327926273\u0026customerMobile=15626000000\u0026startTime=2019-02-01%2000:00:00\u0026endTime=2019-02-25%2014:54:20\u0026status=SUCCESS\u0026source=WECHAT_SHOPPING\u0026canteenId=104\u0026refundStatus=REFUNDED\u0026startPayTime=2019-02-01%2000:00:00\u0026endPayTime=2019-02-25%2014:54:47 响应报文 一个 http 响应报文也由三个部分组成： 状态行 http 协议版本 状态码 状态码的文本描述 标记响应状态。 HTTP/1.1 200 OK 响应头 和请求头部类似，就是两者之间有一些不同的头部字段。 HTTP/1.0 200 ok content-type: application/javascript;charset=utf-8 date: Tue, 07 Mar 2017 03:06:14 GMT sever: Domain Reliability Searver content-length: 0 x-xss-protection: 1, mode=bloack x-frame-options: SAMEORIGIN alt-svc: quic=\":443\";ma=2592000;v=\"36,35,34\" 名称 作用 Date 表示当前相应资源发送的服务器日期和时间 Last-Modified 表示当前响应资源最后被修改的服务器时间，用于协商缓存 Transfer-Encoding 表示当前响应资源传输实体的编码格式 Set-Cookie 表示设置 Cookie 信息 Location 在重定向中或者创建新资源时使用 Server 表示服务器名称 消息体 正文内容，一般在响应头中会用 Content-Length 来明确响应体的长度。 问：解释下超文本传输协议？ HTTP 的名字「超文本协议传输」，它可以拆成两个部分： 超文本 传输协议 传输协议：就是计算机之间传输数据的一种行为规范和约定； 超文本：文本是文字，但超文本涵盖了文字、图片、视频、链接等，是这些的混合体。 综上所述，HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 问：HTTP 协议的通信过程？ 通信过程主要如下： 服务器在 80 端口等待客户的请求。 浏览器发起到服务器的 TCP 连接（创建套接字 Socket）。 服务器接收来自浏览器的 TCP 连接。 浏览器（HTTP 客户端）与 Web 服务器（HTTP 服务器）交换 HTTP 消息。 关闭 TCP 连接。 问：HTTP 常见的状态码？⭐ 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。 问：打开一个网页，过程？⭐ 浏览器解析 URL：浏览器会解析 URL 确定要请求的资源所在 Web 服务器及文件名，构建 HTTP 请求报文； 域名解析：发送 HTTP 请求报文之前，会通过 DNS 将域名转换为对应的 IP 地址：首先会检查本地缓存，如果未命中则会向 本地 DNS 服务器发送查询请求，然后递归的查询； 建立 TCP 连接：浏览器根据 IP 地址和端口号，与目标服务器建立 TCP 连接(三次握手)，然后对 HTTP 请求报文进行封装，也就是加一层 TCP 报头，TCP 报文的数据部分就是 HTTP 请求报文了； 封装 IP：TCP 报文还需要通过 IP 传输到服务器，所以要在 TCP 报文前加一层 IP 头，指明目的地址和源地址，生成 IP 报文； 封装 MAC：生成 IP 报文后，还需要封装成 MAC 帧。通过 ARP 协议查询要到达目的 IP 的下一跳的 MAC 地址，MAC 头部携带发送方 MAC 地址和接收方目标 MAC 地址，用于两点间传输； 通过不断到达新的路由器，进而更新目的 MAC 地址，最终达到目的 IP 地址； 服务器处理 HTTP 请求：服务器将数据包","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:1","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"4.2 缓存 问：HTTP 缓存技术？ 对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，可以把这对「请求-响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，HTTP 有以下实现方法： 强制缓存：指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在浏览器这边。 强制缓存利用 HTTP 响应头部中的两个字段实现，用来表示资源在客户端缓存的有效期： Cache-Control，是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires，建议使用 Cache-Control(选项更多)： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 协商缓存：通过服务端告知客户端是否可以使用缓存。比如某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源。 当第一次请求静态的资源时，比如一张图片，服务端除了返回图片信息，在响应头里面还有一个 Etag 的字段； 浏览器会缓存图片信息以及这个字段的值； 当下一次再请求这个图片的时候，浏览器发起的请求头里面会有一个 If-None-Match 的字段，并且把缓存的 Etag 的值写进去发给服务端； 服务端比对图片信息是否有变化，如果没有，则返回浏览器一个 304 的状态码，浏览器会继续使用缓存的图片信息。 通过浏览器缓存的方式，可以减少网络传输的数据大小，从而提升页面展示的性能。 问：强制缓存和协商缓存是什么？ 强制缓存：指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存。决定是否使用缓存的主动性在于浏览器； 实现：主要利用两个 HTTP 响应头部字段实现，它们都用来表示资源在客户端缓存的有效期： Cache-Control，是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires 。建议使用 Cache-Control，具体的实现流程如下： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 协商缓存：服务端告知客户端是否可以使用缓存的方式被称为协商缓存。 实现：可以基于两种头部来实现。 第一种：利用请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是： 响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是： 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。 注意，协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。 当使用 ETag 字段实现的协商缓存的总过程： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的； 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期： 如果没有过期，则直接使用本地缓存； 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识； 服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较： 如果值相等，则返回 304 Not Modified，不会返回资源； 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识； 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:2","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"4.3 HTTPS 问：HTTPS 协议的通信过程？ 客户端发送https请求，把自身支持的秘钥算法套件（SSL指定版本、加密组件列表）发送给服务器； 服务器判断自身是否支持该算法套件，如果支持则返回证书信息，否则断开连接； 客户端解析证书(通过TLS协议来完成)，验证证书是否有效。如果异常，则会提示是否安装证书，常见的就是浏览器搜索栏左侧出现“X”告警按钮等。 如果证书有效、或者是授信安装证书后，开始传送用服务端公钥加密后的私钥； 服务端通过私钥解密加密信息，得到客户端发送来的会话私钥； 进行会话。 问：SSL/TLS 工作原理？ SSL/TLS 的核心要素是公钥加密和对称加密。利用公钥加密协商密钥，利用对称加密算法快速加解密数据。 其中，为防止中间人攻击，公钥由CA颁发。当客户端（浏览器）向服务器发送 HTTPS 请求时，一定要先获取目标服务器的证书，并根据证书上的信息，检验证书的合法性。一旦客户端检测到证书非法，就会发生错误。 问：CA 证书签发过程？ 服务方 S 生成公私钥，然后向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证； CA 通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等；如信息审核通过，CA 会向申请者签发认证文件-证书。证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA的信息、有效时间、证书序列号等信息的明文，同时包含一个CA的签名；签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名； 客户端 C 向服务器 S 发出请求时，S 返回证书文件； 客户端 C 对证书进行验签：读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA 的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即公钥合法； 客户端然后验证证书相关的域名信息、有效时间等信息； 客户端会内置信任 CA 的证书信息(包含公钥)，如果CA不被信任，则找不到对应 CA 的证书，证书也会被判定非法。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:3","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"五、HTTP 各版本 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"基础 问：HTTP 1.0 和 HTTP 1.1 区别？ 连接方式：HTTP 1.0 为非持续连接，每次浏览器要请求一个文件都要与服务器建立TCP链接，当收到响应后就立即关闭连接；HTTP 1.1 支持持续连接，浏览器收到响应后，仍可以保持该连接传输后续的请求和响应报文。 请求方式：HTTP 1.1 支持请求的流水线处理方式。 状态响应码：HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，100 (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址。 缓存处理：在 HTTP1.0 中主要使用 header 里的 If-Modified-Since，Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since，If-Match，If-None-Match 等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用：HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 Host头处理：HTTP/1.1在请求头中加入了Host字段。 问：HTTP 1.1 的性能问题？⭐ 队头阻塞：HTTP 1.1 可以通过流水线的方式请求，即后续请求不需要等前边的请求被响应就可以发出，这解决了请求的队头阻塞。但是，服务器必须按照接收请求的顺序发送响应，如果某个请求处理时间很长，那么后续的就只能阻塞，导致响应的队头阻塞。 不支持服务器推送：当客户端需要获取通知时，只能通过定时器不断地拉取消息，这无疑浪费大量了带宽和服务器资源； HTTP 头部巨大且重复：由于 HTTP 协议是无状态的，每一个请求都得携带 HTTP 头部，特别是对于有携带 Cookie 的头部，而 Cookie 的大小通常很大； 并发数量有限。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:1","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"HTTP 2.0 问：HTTP 1.1 和 HTTP 2.0 有啥区别？ HTTP/2 相比 HTTP/1.1 性能上的改进： 头部压缩 二进制格式 并发传输 服务器主动推送资源 头部压缩 HTTP/2 会压缩头(Header)，如果你同时发出多个请求，他们的头是一样的或是相似的，那么就会消除重复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 二进制帧 节省空间：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，这会节省很多字节，比如之前状态码200，之前是用 ‘2’‘0’‘0’ 3 个字符来表示(00110010 00110000 00110000)，共用了 3 个字节；现在就只需 1 个字节(10001000)。 节省时间：Header 和 Body 都是二进制，并且统称为帧(frame)：头信息帧(Headers Frame)和数据帧(Data Frame)。帧头一共就 9 字节。由于收到报文后，无需转换为二进制，就增加了数据传输的效率。 帧长度：帧数据的长度； 帧类型：主要分为数据帧、控制帧。数据帧主要是传递HTTP包头和包体； 帧数据：HPACK 算法压缩过的HTTP包头和包体。 并发传输⭐ HTTP/2 支持多个 Stream 复用在一条 TCP 连接。 针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。 服务器推送⭐ HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。 客户端和服务器双方都可以建立 Stream。但 Stream ID 是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。 如下图，Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:2","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"HTTP 3.0(未) 问：HTTP 3.0 做了哪些优化？（未） HTTP 3.0 将下层 TCP 协议改成了 UDP 协议。 基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:3","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"六、RPC 基础 问：什么是 RPC 协议？ RPC(Remote Procedure Call)，又叫做远程过程调用，指的是像调用本地方法一样调用远程的方法，比较有名的就是 gRPC。 举个例子，平时调用一个本地方法就像下面这样。 res = localFunc(req) 如果现在这不是个本地方法，而是个远端服务器暴露出来的一个方法 remoteFunc，如果我们还能像调用本地方法那样去调用它，这样就可以屏蔽掉一些网络细节，用起来更方便，岂不美哉？ res = remoteFunc(req) RPC 和 HTTP 的区别 问：为什么有了 HTTP 协议，还要有 RPC 协议？⭐ 从以下几点讨论。 服务发现 要向某个服务器发出请求，首先得建立连接，建立连接就得先知道服务器的IP地址和端口吧： HTTP：通过 DNS 解析域名，得到服务器的IP地址和端口； RPC：把服务器的IP地址和端口，提前注册到 ETCD 等中间件，想要访问某个服务，就去这些中间件获得 IP 和端口信息。 其实差不多，都是通过中间服务获得。 底层连接形式 HTTP：默认在建立底层 TCP 连接之后会一直保持这个连接(Keep Alive)，之后的请求和响应都会复用这条连接； RPC：建个连接池，请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用，非常环保。 但实际上，HTTP 应用的时候，也会加个连接池，所以说，也差不太多。 传输内容⭐ 基于 TCP，header没什么不同，主要是要对body中的内容进行序列化和反序列化： HTTP：主要是通过 JSON； RPC：主要是通过 Protobuf。 HTTP 示例： 二者对比： HTTP 的 Header 和 Body 都是 key-value 形式，但是key其实很多余。最明显的，像 Header 里的那些信息，其实如果我们约定好头部的第几位是 Content-Type，就不需要每次都真的把\"Content-Type\"这个字段都传过来，类似的情况其实在 body 的 JSON 结构里也特别明显。 而 RPC，可以采用体积更小的Protobuf等定制化序列化协议(详见protobuf的md)，这就是公司的微服务中使用 RPC 的==主要原因==。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:6:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"七、Cookie 和 Session 问：什么是 Cookie？为啥要有 Cookie？ HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并==保存在本地==的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。 Cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，Cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 Cookie 认出你。 问：Cookie 应用场景？ 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 问：Session 是啥？为啥要有 Session？ Session 可以存储在服务器上的文件、数据库或者内存中，也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 使用 Session 维护用户登录状态的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 问：Session 和 Cookie 的区别？⭐ Cookie Cookie是客户端保持状态的方法。 **Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。**为了保持会话，服务器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。 除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是会话Cookie，一种是持久Cookie。会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁，持久Cookie则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代理所共享的。 Session Session是服务器保持状态的方法。 首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的Session用户在客户端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。 ==两者结合，完成服务器对客户端会话状态的保持。==每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端，然后找到相应的Session来保持会话状态。 实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。 问：如果没有 Cookie ，还能用 Session 嘛？ 一般是通过 Cookie 来保存 SessionID，假如你使用了 Cookie 保存 SessionID 的方案的话， 如果客户端禁用了 Cookie，那么 Session 就无法正常工作。 但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将 SessionID 放在请求的 url 里面https://javaguide.cn/?Session_id=xxx 。这种方案的话可行，但是安全性和用户体验感降低。当然，为了你也可以对 SessionID 进行一次加密之后再传入后端。 问：多服务器节点下 Session-Cookie 方案如何做？ 举个例子：假如我们部署了两份相同的服务 A，B，用户第一次登陆的时候 ，Nginx 通过负载均衡机制将用户请求转发到 A 服务器，此时用户的 Session 信息保存在 A 服务器。结果，用户第二次访问的时候 Nginx 将请求路由到 B 服务器，由于 B 服务器没有保存 用户的 Session 信息，导致用户需要重新进行登陆。 有三种方法： 某个用户的所有请求都通过一致性哈希策略分配给同一个服务器处理。这样的话，每个服务器都保存了一部分用户的 Session 信息。服务器宕机，其保存的所有 Session 信息就完全丢失了。 单独使用一个所有服务器都能访问到的数据节点（比如缓存）来存放 Session 信息。为了保证高可用，数据节点尽量要避免是单点。 每一个服务器保存的 Session 信息都是互相同步的，也就是说每一个服务器都保存了全量的 Session 信息。每当一个服务器的 Session 信息发生变化，我们就将其同步到其他服务器。这种方案成本太大，并且，节点越多时，同步成本也越高。 问：Cookie-Session 和 Token 的区别？ Cookie-Sessioon 方案中，服务器必须保存sessionID以及该ID所代表的客户端信息。这些内容可以保存在内存，也可以保存到数据库(通常是内存数据库)；而token则可以服务器完全不用保存任何登录信息，减轻了服务器的负担。 token的流程是这样的。客户端登录通过后，服务器生成一堆客户端身份信息，包括用户名、用户组、有那些权限、过期时间等等。另外再对这些信息进行签名。之后把身份信息和签名作为一个整体传给客户端。这个整体就叫做token。之后，客户端负责保存该token，而服务器不再保存。客户端每次访问该网站都要带上这个token。服务器收到请求后，把它分割成身份信息和签名，然后验证签名，若验证成功，就直接使用身份信息(用户名、用户组、有哪些权限等等)。 token相对cookie的优势： 无状态 基于token的验证是无状态的，这也许是它相对cookie来说最大的优点。后端服务不需要记录token。每个令牌都是独立的，包括检查其有效性所需的所有数据，并通过声明传达用户信息。毕竟，查询session在进行对比可能会涉及到网络通信、数据库读取等，肯定是比做一次hash用时要多的。 服务器唯一的工作就是在成功的登陆请求上签署token，并验证传入的token是否有效。 防跨站请求伪造（CSRF），附带功能。 多站点使用 cookie绑定到单个域。foo.com域产生的cookie无法被bar.com域读取。使用token就没有这样的问题。这对于需要向多个服务获取授权的单页面应用程序尤其有用。 使用token，使得用从myapp.com获取的授权向myservice1.com和myservice2.com获取服务成为可能。 支持移动平台 好的API可以同时支持浏览器，iOS和Android等移动平台。然而，在移动平台上，cookie是不被支持的。 性能 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算的Token验证和解析要费时得多。 问：Token 的存储位置？ JWT 的保存位置，可以分为如下四种： 保存在 localStorage 保存在 sessionStorage 保存在 cookie 保存在 cookie 并设置 HttpOnly 第一种和第二种其实可以归为一类，这一类有个特点，就是该域内的 js 脚本都可以读取，这种情况下 JWT 通过 js 脚本放入 Header 里的 Authorization 字段，会存在 XSS 攻击风险。 第三种，与第四种相比，区别在于 cookie 有没有标记 HttpOnly，没有标记 HttpOnly 的 cookie ，客户端可以将 JWT 通过 js 脚本放入 Header 里的 Authorization 字段。这么看好像同时存在CSRF 攻击风险和 XSS 攻击风险，实则不然，我们虽然将 JWT 存储在 cookie 里，但是我们的服务端并没有利用 cookie 里的 JWT 直接去鉴权，而是通过 header 里的 Authorization 去鉴权，因此这种方法只有 XSS 攻击风险，而没有 CSRF 攻击风险。 而第四种，加了 HttpOnly 标记，意味着这个 cookie 无法通过js脚本进行读取和修改，杜绝了 XSS 攻击的发生。与此同时，网站自身的 js 脚本也无法利用 cookie 设置 header 的Authorization 字段，因此只能通过 cookie 里的 JWT 去鉴权，所以不可避免","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:7:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"八、ARP 问：ARP 协议是啥？有啥用？ ARP 协议，全称 地址解析协议（Address Resolution Protocol），它解决的是网络层地址和链路层地址之间的转换问题。 问：寻址原理？ 记住几个关键词：ARP 表、广播问询、单播响应。 ARP 的工作原理应分两种场景讨论： 同一局域网内的 MAC 寻址； 从一个局域网到另一个局域网中的网络设备的寻址。 很简单，看下就会了 如果ARP协议无法获取MAC地址，通常会发生以下两种情况： 目标主机不可达：如果ARP协议无法获取目标主机的MAC地址，通常说明目标主机不可达，可能是因为目标主机已经关机、网络故障、网络拥堵等原因导致数据无法到达目标主机。在这种情况下，通常需要对网络进行故障排除，找出问题所在并进行修复。 目标主机在不同的网络中：如果ARP协议无法获取目标主机的MAC地址，但是目标主机确实存在，可能是因为目标主机和发送数据的主机在不同的网络中，需要通过路由器进行通信。在这种情况下，通常需要进行路由器配置，使得数据可以从源主机到达目标主机所在的网络，并将目标主机的MAC地址映射到正确的IP地址上。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:8:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"九、网络安全 问：为什么 Cookie 无法防止 CSRF 攻击，而 Token 可以？ CSRF(Cross Site Request Forgery) 一般被翻译为 跨站请求伪造 。 当进行 Session 认证后，每次登录时，浏览器就会默认携带 Cookie，服务端通过 Cookie 中的 SessionId 标识该用户的对话。当用户浏览攻击者的页面时，若点击到构造的请求链接，就会跳转到相应页面，浏览器会把 Cookie 发送给服务端，也就相当于攻击者以用户的身份完成了一次请求。 CSRF攻击之所以能够成功，是因为服务器误把攻击者发送的请求当成了用户自己的请求。 但是，使用 Token 就不会有这个问题。 在我们登录成功获得 Token 之后，一般会选择存放在 localStorage （浏览器本地存储）中。然后我们在前端(js)通过某些方式会给每个发到后端请求的Authorization中加上这个 Token，即使有个你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 Token 的，所以这个请求将是非法的。 问：什么是 SYN 攻击？如何避免 SYN 攻击？ 攻击者伪造大量的 SYN 报文，占满服务端的半连接队列，造成拒绝服务。因为当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。 如何防御？ 设置更大的半连接队列； 减少 SYN+ACK 的重传次数，以加快处于 SYN_RECV 状态的 TCP 连接断开；这是因为处于 SYN_RECV 状态的 TCP 连接会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接； **开启 syncookies 功能。**可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接； 部署入侵检测系统IDS，识别并过滤虚假IP地址。 ","date":"2023-04-18","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:9:0","tags":["计算机基础"],"title":"计算机网络","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":["面试"],"content":"==yzb学长==： 腾讯IEG-光子工作室群-区块链研发工程师 一面面经 1、自我介绍 2、20分钟项目面，比如FISCO BCOS中的交易有哪些字段、整个交易需要签名，那么签名用的是什么加密算法， 整体流程是怎样签名的，属性加密的原理是什么，同态加密原理呢，零知识证明呢？(这里寄了，只知道用法，但是具体原理还真不太清楚) 3、FISCO用的是PBFT，那么PBFT算法的时间复杂度是多少（O(n²)) 4、PBFT整体流程是怎样的？ 5、为什么PBFT的容错率是3f+1？（现场口述推导） 6、你是怎样学习区块链知识的呢？（最开始看综述文章，后面看一些关于Bitcoin、Eth、Fabric的官方文档即白皮书黄皮书，然后是github，再就是各种各样的博文) 7、接着上述问题：你有看过哪些白黄皮书，有对哪一部分很深入的研究吗？(最开始看的是e-money的那篇文章，然后是bitcoin白皮书，然后是eth黄皮书，提到了UTXO的构造原理) 8、以太坊相比于比特币UTXO有什么区别？（以太坊有三棵树来维护状态，分别是交易树、收据树和状态树，然后每棵树的数据结构和内容分别是什么) 9、数据库知识了解吗？能说一下数据库索引的相关知识吗(为什么MySQL的InnoDB用的B+树，有什么优点) 10、对汇编原理有了解吗？(这个问的比较纳闷，答了下本科学的是微机原理，是以8086作为蓝本研究的，它的指令集相对X86、ARM、RISE-V指令集简洁很多，因为受限于CPU和寄存器等大小和性能) 11、你的编程语言怎样？（java和C++双修） 12、手撕代码：①快速排序(6min，问了下它的最优/坏时间复杂度，什么场景下最优/坏，怎么样避免最坏：先循环判断一遍是否是有序的)；②链表k个一组反转(15min,这个确实不太好写，思路比较简单但是代码细节比较多，用的滑动窗口+双指针); 13、反问：对我有什么学习上的建议吗？(可以多看看白皮书，深究一下源码，这样对区块链各个过程都会有更加深入的理解)；然后两个人就学术界和工业届区块链的发展形式发表一下看法，都觉得要想研究区块链应该是去看公链的知识，而国内的联盟链研究走偏了，很多研究都是抄的fabric。 腾讯-二面 备注：如果有项目，一定要提前准备好项目的各个方面，不仅仅局限于自己做的方向，比如：项目的核心竞争力，整个项目做了哪些东西，为什么要做这些东西，自己在项目里面负责哪一部分，这一部分为什么要这么做等等。同时上一面没有答的比较好的部分后续一定要去看一看熟悉一下，面试官会写面评，后面的面试官可能会基于面评进行拓展提问。 深挖项目(15min)：项目一定一定要非常熟悉，同时没做的部分不要写上去，除非是很熟悉过程和做了哪些东西。逻辑要连贯，为什么，怎么做。（比如之前紫金山实验室车联网那个项目，我提到项目用区块链做分布式身份认证，面试官问我为什么要用区块链做，不用区块链的话原来的技术是怎样实现身份认证的，效果如何，用了区块链有没有改善呢）。 solidity会导致哪些安全问题？（比如精度问题、未检查的外部调用、循环攻击、堆栈溢出等） 如何使用智能合约产生随机数？（这里其实有个方法叫VRF是可以解决的，一般来说正常产生随机数是根据一个随机源seed，然后根据伪随机代码产生随机数；但是由于智能合约是公开可见的，也就导致了攻击者可以看到伪随机函数具体用的是哪个，再根据随机源就可以计算出这个随机数是什么。因此需要保证随机源是随机获取的，比如说通过一个外部链接连接到一个随机数产生网站，以此来获得随机源，这样每次调用合约产生的随机数都不一样）。 了解ERC20、ERC721、ERC1155吗？（ERC721实际上就是NFT（感谢瑞伟学长的指导，前两天杰伦的NFT刚被盗，这个真的是问到脸上了），说了下ERC20和ERC721的区别（最大的区别是Token数量不同）） 【承接上个问题】杰伦的NFT被盗你知道是因为智能合约的什么漏洞问题导致的吗？（俺木晓得呀） 有木有关注以太坊比较有名的几个项目？（开放） 以太坊交易池中，交易是根据什么来进行排序的？（根据交易发起者预先估计的gasPrice来进行一定规则的排序） 那么交易费用是如何计算出来的，包含了哪两个部分？（交易费用=Gas*Gas Price，一个Gas Price就是单价，以太坊默认的Gas Price是1wei） 以太坊交易流程是咋样的？（上链前业务数据处理+业务打包上链+调用合约，这个问题很重点，需要仔细琢磨了解整个过程，在这就不展开了） 以太坊虚拟机工作流程？（如果只普通的转账交易，核实后直接去修改世界状态树中的账户状态即可；如果是合约，则进行解释器等一系列操作） 你了解其他的共识算法吗（POS,POA,DPOS等常见的） POA基本原理说一下呗（POA是以太坊可选的共识，可惜自己只知道大概的过程，就说了一下） 你平时有用到其他的加密算法吗（专利+毕设用了） 你本科毕设中客户端和服务端是如何进行安全通信的？（因为面试官问我本科毕设做的啥，本科毕设自己写了个多并发的物联网设备通信，这里直接说和TLS的过程是一样的，双方验证好身份，协商加密算法好后，客户端生成对称密钥后，用服务器的公钥加密对称密钥传给服务器，之后双方依据这个对称密钥进行通信） 客户端怎么生成公钥的（用的AES 密钥，客户端生成了一个256bit的密钥，根据一些助记词生成的） 反问：部分业务是啥（机密），你觉得我的表现如何（公司有规定，机密） 牛客网，提前批 2023/03/17 杨老师 阿里一面 ==2023/04/27 百度一面 (60 min)== 自我介绍 项目介绍 项目中遇到的难点？怎么解决的？ 项目中用到了哪些中间件？对中间件的理解？ 职业规划？以后想做哪个方向？ Go 基础 Go 有哪些引用类型？ GMP 模型底层原理，调度原理？ defer 执行顺序？return func() 和 defer 三者执行顺序？ return func() 的情况下，怎么统计该函数的执行用时？ return 返回值之后，是否还可以被修改？ 常见八股(开始吟唱…) url输入到输出的过程？ udp、tcp 差别？ http 有啥字段？ get、post 有啥区别？ session、cookie 有啥区别？禁止cookie还能用session吗？怎么实现？ MySQL 有哪些索引？ 联合索引应用场景？为什么要建联合索引？ 知道回表查询吗？什么时候会触发回表查询？ 忘了… docker和linux 了解docker吗？用过，但不了解。 了解linux吗？用过，但不了解。 算法(只能用记事本) 括号匹配； 股票买入卖出(稍微有点改动，没完全写出来)。 反问 主要做啥业务？ 实习生进去之后干点啥？ 之后还会有面试嘛？ 后续 2023/04/28 下午 约二面 ==2023/05/08 百度二面 (60 min)== 已凉。 ==2022/05/18 腾讯一面 (70 min)== 项目组介绍，反问 手撕：大数乘法。。。没写过，最后讲了思路 Go 基础 线程、协程有啥区别？ GMP 模型？ Goroutine 之间怎么通信？ 一般用 Channel，讲了 Channel 的底层原理 Channel 可以不关闭吗？不关闭会发生啥？ Goruotine 会泄露吗？比如 Goroutine 占满了？ string 和 []byte{}，怎么转换？ 讲了两种，一种会触发拷贝，一种是用 unsafe unsafe 具体得怎么操作？ 忘了。。。 为什么要进行内存对齐？ 结构体是怎么进行内存对齐的？结构体成员顺序不同，结构体的大小会不同吗？ 计算机网络 三次握手？为啥要三次握手？能两次吗？会出现啥问题？ seq 的选取有啥讲究吗？ 操作系统 epoll 了解吗？ 和 select、poll 有啥区别？那有啥改进？ ET 和 LT？(这个只大概讲了下) RAFT RAFT 是强一致性的吗？ RAFT 怎么保证的强一致性？ 讲了选主、日志复制 RAFT 选主时，每个节点有几票？ 这个记不清了，原本答的只有一票，后来想了想ZAB是一票，又改成能投多票了。。。无语！ RAFT 出现多个主节点咋办？平票咋办？ 那这个倒计时是咋生成的？咋随机的？都有哪些节点要随机生成？ 这个麻了，我忘了 Redis Redis 是咋保证集群的一致性的？ 讲了主从复制：全量复制和增量复制 Redis 会丢失数据吗？ 这个讲了持久化，真可恶，应该是讲集群间的数据丢失的。。。 Mysql MySQL 都有哪些事务隔离级别？ 默认用哪个？ 这个答的可重复读。 会出现啥问题？幻读是啥？ MySQL 索引用过吗？联合索引怎么用？ 这个答了索引失效的问题 使用联合索引时，字段能跳过吗？需要按序吗？ 怎么看MySQL语句用没用到索引？ 答了explain explain 真的会去数据库xxx查看吗？ 不知道。 Linux 都用过啥命令 ss、netstat、ps。。 怎么查询解析url的过程？ 这个不造。 开源项目 有看过开源的项目代码吗？有做过开源贡献吗？ 看过groupcache、gin、orm，麻油贡献 结束咯 ~ 凉！！！ ","date":"2023-03-25","objectID":"/%E9%9D%A2%E8%AF%95%E9%A2%98/:0:0","tags":["面试题目"],"title":"面试记录","uri":"/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":["Go"],"content":"[toc] ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:0:0","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"一、概述 在 Go 语言中，主要关注的程序运行情况包括以下几种： CPU profile：报告程序的 CPU 使用情况，按照一定频率去采集应用程序在 CPU 和寄存器上面的数据； Memory Profile(Heap Profile)：报告程序的内存使用情况； Block Profile：报告导致阻塞的同步原语的情况，可以用来分析和查找锁的性能瓶颈； Goroutine Profile：报告 goroutines 的使用情况，有哪些 goroutine，它们的调用关系是怎样的。 benchmark(基准测试) 可以度量某个函数或方法的性能，也就是说，如果我们知道性能的瓶颈点在哪里，benchmark 是一个非常好的方式。但是面对一个未知的程序，如何去分析这个程序的性能，并找到瓶颈点呢？ pprof 就是用来解决这个问题的。pprof 包含两部分： 编译到程序中的 runtime/pprof 包 性能剖析工具 go tool pprof 针对不同场景，应采用不同的分析方法： 工具类应用：执行完任务就结束退出。可以使用 runtime/pprof 库； 服务型应用：应用需要一直运行，比如 web 应用或者gRPC服务。可以使用 net/http/pprof 库，能够在应用提供 HTTP 服务时进行分析。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:1:0","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"二、性能分析类型 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:0","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"2.1 CPU 性能分析 CPU 性能分析(CPU profiling) 是最常见的性能分析类型。 主要思想：一个函数在性能分析数据中出现的次数越多，说明执行该函数的代码路径(code path)花费的时间占总运行时间的比重越大。 主要原理：启动 CPU 分析时，运行时(runtime) 将每隔 10ms 中断一次，记录此时正在运行的协程(goroutines) 的堆栈信息。程序运行结束后，可以分析记录的数据找到最热代码路径(hottest code paths)。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:1","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"2.2 内存性能分析 内存性能分析(Memory profiling) 记录堆内存分配时的堆栈信息，忽略栈内存分配信息。 内存性能分析启用时，默认每1000次采样1次，这个比例是可以调整的。因为内存性能分析是基于采样的，因此基于内存分析数据来判断程序所有的内存使用情况是很困难的。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:2","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"2.3 阻塞性能分析 阻塞性能分析(block profiling) 是 Go 特有的。 阻塞性能分析用来记录一个协程等待一个共享资源花费的时间。在判断程序的并发瓶颈时会很有用。阻塞的场景包括： 在没有缓冲区的信道上发送或接收数据。 从空的信道上接收数据，或发送数据到满的信道上。 尝试获得一个已经被其他协程锁住的排它锁。 一般情况下，当所有的 CPU 和内存瓶颈解决后，才会考虑这一类分析。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:3","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"2.4 锁性能分析 锁性能分析(mutex profiling) 与阻塞分析类似，但专注于因为锁竞争导致的等待或延时。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:4","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"三、CPU 性能分析 记录性能数据会对程序的性能产生影响，建议一次只记录一类数据。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:3:0","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"3.1 生成 profile Go 的运行时性能分析接口都位于 runtime/pprof 包中。只需要调用 runtime/pprof 库即可得到我们想要的数据。 假设我们实现了这么一个程序，随机生成了 5 组数据，并且使用冒泡排序法排序。 func generate(n int) []int { rand.Seed(time.Now().UnixNano()) nums := make([]int, n) for i := 0; i \u003c len(nums); i++ { nums[i] = rand.Int() % 1000 } return nums } func bubbleSort(nums []int) { for i := 0; i \u003c len(nums); i++ { for j := i + 1; j \u003c len(nums); j++ { if nums[i] \u003e nums[j] { nums[i], nums[j] = nums[j], nums[i] } } } } 如果我们想度量这个应用程序的 CPU 性能数据，只需要在 main 函数中添加几行代码即可： func main() { f, _ := os.OpenFile(\"cpu.pprof\", os.O_CREATE|os.O_RDWR, 0644) defer f.Close() pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() n := 10 for i := 0; i \u003c 5; i++ { nums := generate(n) bubbleSort(nums) n *= 10 } } ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:3:1","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"3.2 数据分析 go run 01-cpu.go # 用 web 的方式查看 go tool pprof -http=:9999 cpu.pprof 然后访问：localhost/:9999 即可。 # 在命令行中查看 go tool pprof cpu.pprof ❯ go tool pprof cpu.pprof Type: cpu Time: May 23, 2023 at 2:36pm (CST) Duration: 2.30s, Total samples = 1.33s (57.87%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top Showing nodes accounting for 1.33s, 100% of 1.33s total flat flat% sum% cum cum% 1.33s 100% 100% 1.33s 100% main.bubbleSort (inline) 0 0% 100% 1.33s 100% main.main 0 0% 100% 1.33s 100% runtime.main (pprof) 可以看到 main.bubbleSort 是消耗 CPU 最多的函数。 还可以按照 cum (累计消耗)排序。通过 help 查看所有的命令。 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:3:2","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"四、内存性能分析 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:4:0","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"4.1 生成 profile 假设我们实现了这么一个程序，生成长度为 N 的随机字符串，拼接在一起。 使用一个易用性更强的库 pkg/profile 来采集性能数据，pkg/profile 封装了 runtime/pprof 的接口，使用起来更简单。 package main import ( \"github.com/pkg/profile\" \"math/rand\" ) const letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" func randomString(n int) string { b := make([]byte, n) for i := range b { b[i] = letterBytes[rand.Intn(len(letterBytes))] } return string(b) } func concat(n int) string { s := \"\" for i := 0; i \u003c n; i++ { s += randomString(n) } return s } func main() { // 不太好用啊，Windows上生成的路径很烦。。。建议还是不在 Windows 上用。。。 // defer profile.Start(profile.MemProfile, profile.MemProfileRate(1)).Stop() concat(100) } 参考文章： Go程序性能分析 ","date":"2023-03-06","objectID":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:4:1","tags":["Go","性能分析"],"title":"Go浅析-性能分析","uri":"/go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"[toc] ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:0:0","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"一、概述 Go 编译器会尽可能将变量分配到到栈上。但是， 当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针(dangling pointer)； 另外，如果局部变量非常大，也会将其分配在堆上。 有如下规则可以参考： 逃逸分析是在编译器完成的，这是不同于jvm的运行时逃逸分析; 如果变量在函数外部没有引用，则优先放到栈中； 如果变量在函数外部存在引用，则必定放在堆中。 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:1:0","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"二、案例 给出一些常见的内存逃逸情况。 可通过go build -gcflags '-m -l'命令来查看逃逸分析结果，其中，-m 打印逃逸分析信息，-l 禁止内联优化： go build -gcflags '-m -l' 01-type.go go build -gcflags '-m -m -l' 01-type.go // 更详细 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:0","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"变量类型不确定 // 变量类型不确定 func main() { a := 123 fmt.Println(a) } 分析结果： ❯ go build -gcflags '-m -l' 01-type.go # command-line-arguments .\\01-type.go:11:13: ... argument does not escape .\\01-type.go:11:13: a escapes to heap ❯ go build -gcflags '-m -m -l' 01-type.go # command-line-arguments .\\01-type.go:11:13: a escapes to heap: .\\01-type.go:11:13: flow: {storage for ... argument} = \u0026{storage for a}: .\\01-type.go:11:13: from a (spill) at .\\01-type.go:11:13 .\\01-type.go:11:13: from ... argument (slice-literal-element) at .\\01-type.go:11:13 .\\01-type.go:11:13: flow: {heap} = {storage for ... argument}: .\\01-type.go:11:13: from ... argument (spill) at .\\01-type.go:11:13 .\\01-type.go:11:13: from fmt.Println(... argument...) (call parameter) at .\\01-type.go:11:13 .\\01-type.go:11:13: ... argument does not escape .\\01-type.go:11:13: a escapes to heap 分析结果告诉我们变量a逃逸到了堆上，a逃逸是因为它被传入了fmt.Println的参数中，这个方法参数自己发生了逃逸。 func Println(a ...any) (n int, err error) 因为fmt.Println的函数参数为interface类型，编译期不能确定其参数的具体类型，也就不确定开辟多大的空间给它，所以将其分配于堆上。 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:1","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"暴露给外部指针 func foo() *int { a := 123 return \u0026a } func main() { _ = foo() } 分析结果： ❯ go build -gcflags '-m -l' 02-expose.go # command-line-arguments .\\02-expose.go:4:2: moved to heap: a ❯ go build -gcflags '-m -m -l' 02-expose.go # command-line-arguments .\\02-expose.go:4:2: a escapes to heap: .\\02-expose.go:4:2: flow: ~r0 = \u0026a: .\\02-expose.go:4:2: from \u0026a (address-of) at .\\02-expose.go:5:9 .\\02-expose.go:4:2: from return \u0026a (return) at .\\02-expose.go:5:2 .\\02-expose.go:4:2: moved to heap: a 直接满足：变量在函数外部存在引用。这个很好理解，因为当函数执行完毕，对应的栈帧就被销毁，但是引用已经被返回到函数之外。如果这时外部从引用地址取值，虽然地址还在，但是这块内存已经被释放回收了，这就是非法内存，问题可就大了。所以，很明显，这种情况必须分配到堆上。 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:2","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"变量所占内存较大 // []int 太大, 导致逃逸 func foo() { s := make([]int, 8193, 8193) // \u003e 8192 就是大对象了 for i := 0; i \u003c len(s); i++ { s[i] = i } } // 外部引用, 导致逃逸 //func foo() []int { // s := make([]int, 100, 100) // for i := 0; i \u003c len(s); i++ { // s[i] = i // } // return s //} func main() { foo() } 分析结果： ❯ go build -gcflags '-m -l' 03-big.go # command-line-arguments .\\03-big.go:5:11: make([]int, 10000, 10000) escapes to heap ❯ go build -gcflags '-m -m -l' 03-big.go # command-line-arguments .\\03-big.go:5:11: make([]int, 10000, 10000) escapes to heap: .\\03-big.go:5:11: flow: {heap} = \u0026{storage for make([]int, 10000, 10000)}: .\\03-big.go:5:11: from make([]int, 10000, 10000) (too large for stack) at .\\03-big.go:5:11 .\\03-big.go:5:11: make([]int, 10000, 10000) escapes to heap 逃逸信息：too large for stack。当我们创建了一个容量为8193的int类型的底层数组对象时，由于对象过大，它也会被分配到堆上。 那为啥大对象需要分配到堆上？ goroutine 初始大小为2KB，其实说的是用户栈，它的最小和最大可以在runtime/stack.go中找到，分别是2KB和1GB，而堆内存会大很多。因此，为了不造成栈溢出和频繁的扩缩容，大对象分配在堆上更加合理(大对象的范围：\u003e 32KB)，所以s :=make([]int, n, n)中，一旦n \u003e 8192，就一定会逃逸。 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:3","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"变量大小不确定 func foo() { n := 1 s := make([]int, n) for i := 0; i \u003c len(s); i++ { s[i] = i } } func main() { foo() } 分析结果： ❯ go build -gcflags '-m -l' 04-uncertain.go # command-line-arguments .\\04-uncertain.go:5:11: make([]int, n) escapes to heap ❯ go build -gcflags '-m -m -l' 04-uncertain.go # command-line-arguments .\\04-uncertain.go:5:11: make([]int, n) escapes to heap: .\\04-uncertain.go:5:11: flow: {heap} = \u0026{storage for make([]int, n)}: .\\04-uncertain.go:5:11: from make([]int, n) (non-constant size) at .\\04-uncertain.go:5:11 .\\04-uncertain.go:5:11: make([]int, n) escapes to heap 逃逸信息：non-constant size。在make方法中，没有直接指定大小，而是填入了变量n，这时也会将其分配到堆区去。 可见，为了保证内存的绝对安全，Go的编译器可能会将一些变量不合时宜地分配到堆上，但是因为这些对象最终也会被垃圾收集器处理，所以也能接受。 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:4","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"闭包 func foo() func() int { i := 0 return func() int { i++ return i } } func main() { foo()() } 分析结果： ❯ go build -gcflags '-m -l' 05-close.go # command-line-arguments .\\05-close.go:4:2: moved to heap: i .\\05-close.go:5:9: func literal escapes to heap ❯ go build -gcflags '-m -m -l' 05-close.go # command-line-arguments .\\05-close.go:4:2: foo capturing by ref: i (addr=false assign=true width=8) .\\05-close.go:5:9: func literal escapes to heap: .\\05-close.go:5:9: flow: ~r0 = \u0026{storage for func literal}: .\\05-close.go:5:9: from func literal (spill) at .\\05-close.go:5:9 .\\05-close.go:5:9: from return func literal (return) at .\\05-close.go:5:2 .\\05-close.go:4:2: i escapes to heap: .\\05-close.go:4:2: flow: {storage for func literal} = \u0026i: .\\05-close.go:4:2: from i (captured by a closure) at .\\05-close.go:6:3 .\\05-close.go:4:2: from i (reference) at .\\05-close.go:6:3 .\\05-close.go:4:2: moved to heap: i .\\05-close.go:5:9: func literal escapes to heap 原本在函数运行栈空间上分配的内存，由于闭包的关系，变量在函数的作用域之外使用。 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:5","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"三、总结 问：进行逃逸分析有啥用？ 理解逃逸分析一定能帮助我们写出更好的程序。 知道变量分配在栈堆之上的差别，那么就要尽量写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。 所以，有些Go的项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但这是在栈上完成的操作，开销远比变量逃逸后动态地在堆上分配内存少的多。当然该做法不是绝对的，如果结构体较大，传递指针将更合适。 因此，从GC的角度来看，指针传递是个双刃剑，需要谨慎使用，否则线上调优解决GC延时可能会让你崩溃。 参考文章： 详解逃逸分析 ","date":"2023-03-05","objectID":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:3:0","tags":["Go","内存逃逸"],"title":"Go浅析-内存逃逸","uri":"/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["Go"],"content":"使用方法名字符串，调用方法 思路：通过 reflect。 type animal struct { name string } func (a *animal) Eat() { println(\"animal eat\") } func main() { a := animal{\"cat\"} reflect.ValueOf(\u0026a).MethodByName(\"Eat\").Call([]reflect.Value{}) } ","date":"2023-02-25","objectID":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/:1:0","tags":["Go","基础编程"],"title":"Go浅析-常见编程操作","uri":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"3个 goroutine 按照顺序分别打印10次\"cat\"，“fish”，“dog 思路：若限制只用 3 个 goroutine，如下 var ( catChan = make(chan int) fishChan = make(chan int) dogChan = make(chan int) allChan = make(chan struct{}) ) func cat(ch chan int) { for v := range ch { fmt.Printf(\"%v cat\\n\", v) fishChan \u003c- v if v == 10 { break } } } func fish(ch chan int) { for v := range ch { fmt.Printf(\"%v fish\\n\", v) dogChan \u003c- v if v == 10 { break } } } func dog(ch chan int) { for v := range ch { fmt.Printf(\"%v dog\\n\", v) if v == 10 { allChan \u003c- struct{}{} break } catChan \u003c- v + 1 } } func main() { go cat(catChan) go fish(fishChan) go dog(dogChan) catChan \u003c- 1 \u003c-allChan } 思路：若不限制 goroutine 数目 var ( catChan = make(chan int) fishChan = make(chan int) dogChan = make(chan int) allChan = make(chan struct{}) ) func cat() { v := \u003c-catChan fmt.Printf(\"%v cat\\n\", v) fishChan \u003c- v } func fish() { v := \u003c-fishChan fmt.Printf(\"%v fish\\n\", v) dogChan \u003c- v } func dog() { v := \u003c-dogChan fmt.Printf(\"%v dog\\n\", v) if v == 10 { allChan \u003c- struct{}{} return } catChan \u003c- v + 1 // 注意是无缓冲的 chan，若放到 if 前，就会死锁！ } func main() { for i := 0; i \u003c 10; i++ { go cat() go fish() go dog() } catChan \u003c- 1 \u003c-allChan } ","date":"2023-02-25","objectID":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/:2:0","tags":["Go","基础编程"],"title":"Go浅析-常见编程操作","uri":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"启动 2 个 goroutine 2 秒后取消，第一个 1 秒执行完，第二个 3 秒执行完 func f1(ch chan struct{}) { time.Sleep(time.Second * 1) ch \u003c- struct{}{} } func f2(ch chan struct{}) { time.Sleep(time.Second * 3) ch \u003c- struct{}{} } func main() { ctx, _ := context.WithTimeout(context.Background(), time.Second*2) ch := make(chan struct{}, 1) go func() { go f1(ch) select { case \u003c-ctx.Done(): println(\"f1 timeout\") case \u003c-ch: println(\"f1 done\") } }() go func() { go f2(ch) select { case \u003c-ctx.Done(): println(\"f2 timeout\") case \u003c-ch: println(\"f2 done\") } }() time.Sleep(time.Second * 5) } ","date":"2023-02-25","objectID":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/:3:0","tags":["Go","基础编程"],"title":"Go浅析-常见编程操作","uri":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"2 个 goroutine 交替打印 10 个字母和数字 var ( ch1 = make(chan byte) ch2 = make(chan int) ) func letter() { for i := 0; i \u003c 10; i++ { v := \u003c-ch1 fmt.Println(string(v)) ch2 \u003c- int(v - 'a' + 1) } } func number() { for i := 0; i \u003c 10; i++ { v := \u003c-ch2 fmt.Println(v) if v == 10 { return } ch1 \u003c- byte(v + 'a') } } func main() { go letter() go number() ch1 \u003c- 'a' time.Sleep(time.Second * 2) } ","date":"2023-02-25","objectID":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/:4:0","tags":["Go","基础编程"],"title":"Go浅析-常见编程操作","uri":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"当 select 监控多个 chan 同时到达就绪态时，如何先执行某个任务？ 可通过添加标签 func prioritySelect(ch1, ch2 \u003c-chan string) { for { select { case val := \u003c-ch1: fmt.Println(val) case val2 := \u003c-ch2: priority: // 标签 for { select { // 若 ch1 有值，先打印 ch1 的值，再打印 ch2 的值 case val1 := \u003c-ch1: fmt.Println(val1) default: break priority } } fmt.Println(val2) } } } ","date":"2023-02-25","objectID":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/:5:0","tags":["Go","基础编程"],"title":"Go浅析-常见编程操作","uri":"/go%E5%B8%B8%E8%A7%81%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"[toc] 参考文章： Go语言设计与实现 深入了解 Go 语言与并发编程 从 bug 中学习：六大开源项目告诉你 go 并发编程的那些坑 ","date":"2023-02-22","objectID":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/:0:0","tags":["Go","并发编程","同步","GMP"],"title":"Go浅析-GMP","uri":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"一、Go 并发机制 Go 的调度器使用 G、M、P 三个结构体来实现 Goroutine 的调度，也称之为 GMP 模型。 ","date":"2023-02-22","objectID":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/:1:0","tags":["Go","并发编程","同步","GMP"],"title":"Go浅析-GMP","uri":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"GMP 模型 G：表示 Goroutine。每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。当 Goroutine 被调离 CPU 时，调度器代码负责把 CPU 寄存器的值保存在 G 对象的成员变量之中，当 Goroutine 被调度起来运行时，调度器代码又负责把 G 对象的成员变量所保存的寄存器的值恢复到 CPU 的寄存器； M：OS 底层线程的抽象，它本身就与一个内核线程进行绑定，每个工作线程都有唯一的一个 M 结构体的实例对象与之对应，它代表着真正执行计算的资源，由操作系统的调度器调度和管理。M 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 Goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 P 结构体的实例对象之间的绑定关系； P：表示逻辑处理器。对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等。它维护一个局部 Goroutine 可运行 G 队列，工作线程优先使用自己的局部运行队列，只有必要时才会去访问全局运行队列，这可以大大减少锁冲突，提高工作线程的并发性，并且可以良好的运用程序的局部性原理。 一个 G 的执行需要 P 和 M 的支持。一个 M 在与一个 P 关联之后，就形成了一个有效的 G 运行环境（内核线程+上下文）。每个 P 都包含一个可运行的 G 的队列（runq）。该队列中的 G 会被依次传递给与本地 P 关联的 M，并获得运行时机。 M 与 KSE 之间总是一一对应的关系，一个 M 仅能代表一个内核线程。M 与 KSE 之间的关联非常稳固，一个 M 在其生命周期内，会且仅会与一个 KSE 产生关联，而 M 与 P、P 与 G 之间的关联都是可变的，M 与 P 也是一对一的关系，P 与 G 则是一对多的关系。 G 运行时，G 在调度器中的地位与线程在操作系统中差不多，但是它占用了更小的内存空间，也降低了上下文切换的开销。它是 Go 语言在用户态提供的线程，作为一种粒度更细的资源调度单元。 g 结构体部分源码(src/runtime/runtime2.go)： type g struct { stack stack // Goroutine的栈内存范围[stack.lo, stack.hi) stackguard0 uintptr // 用于调度器抢占式调度 m *m // Goroutine占用的线程 sched gobuf // Goroutine的调度相关数据 atomicstatus uint32 // Goroutine的状态 ... } type gobuf struct { sp uintptr // 栈指针 pc uintptr // 程序计数器 g guintptr // gobuf对应的Goroutine ret sys.Uintewg // 系统调用的返回值 ... } gobuf 中保存的内容会在调度器保存或恢复上下文时使用，其中栈指针和程序计数器会用来存储或恢复寄存器中的值，改变程序即将执行的代码。 atomicstatus 字段存储了当前 Goroutine 的状态，Goroutine 主要可能处于以下几种状态： 等待中：Goroutine 正在等待某些条件满足，例如：系统调用结束等，包括_Gwaiting、_Gsyscall 和_Gpreempted 几个状态 可运行：Goroutine 已经准备就绪，可以在线程运行，如果当前程序中有非常多的 Goroutine，每个 Goroutine 就可能会等待更多的时间，即_Grunnable 运行中：Goroutine 正在某个线程上运行，即_Grunning G 常见状态转换图： M Go 语言并发模型中的 M 是操作系统线程。调度器最多可以创建 10000 个线程，但是最多只会有 GOMAXPROCS(P 的数量)个活跃线程能够正常运行。在默认情况下，运行时会将 GOMAXPROCS 设置成当前机器的核数，我们也可以在程序中使用 runtime.GOMAXPROCS 来改变最大的活跃线程数。 m 结构体源码(部分)： type m struct { g0 *g // 一个特殊的goroutine，执行一些运行时任务 gsignal *g // 处理signal的G curg *g // 当前M正在运行的G的指针 p puintptr // 正在与当前M关联的P nextp puintptr // 与当前M潜在关联的P oldp puintptr // 执行系统调用之前使用线程的P spinning bool // 当前M是否正在寻找可运行的G lockedg *g // 与当前M锁定的G } P 调度器中的处理器 P 是线程和 Goroutine 的中间层，它能提供线程需要的上下文环境，也会负责调度线程上的等待队列，通过处理器 P 的调度，每一个内核线程都能够执行多个 Goroutine，它能在 Goroutine 进行一些 I/O 操作时及时让出计算资源，提高线程的利用率。 P 的数量等于 GOMAXPROCS，设置 GOMAXPROCS 的值只能限制 P 的最大数量，对 M 和 G 的数量没有任何约束。当 M 上运行的 G 进入系统调用导致 M 被阻塞时，运行时系统会把该 M 和与之关联的 P 分离开来，这时，如果该 P 的可运行 G 队列上还有未被运行的 G，那么运行时系统就会找一个空闲的 M，或者新建一个 M 与该 P 关联，满足这些 G 的运行需要。因此，M 的数量很多时候都会比 P 多。 p 结构体源码（部分）： type p struct { status uint32 // p 的状态 m muintptr // 对应关联的 M runqhead uint32 // 可运行的Goroutine队列，可无锁访问 runqtail uint32 runq [256]guintptr runnext guintptr // 缓存可立即执行的G gFree struct { // 可用的G列表，G状态等于Gdead gList n int32 } ... } P 可能处于的状态如下： 调度器 调度的主要对象就是 G、M 和 P 的实例。每个 M(即每个内核线程)在运行过程中都会执行一些调度任务，他们共同实现了 Go 调度器的调度功能。 g0 和 m0 运行时系统中的每个 M 都会拥有一个特殊的 G，一般称为 M 的 g0。M 的 g0 不是由 Go 程序中的代码间接生成的，而是由 Go 运行时系统在初始化 M 时创建并分配给该 M 的。M 的 g0 一般用于执行调度、垃圾回收、栈管理等方面的任务。M 还会拥有一个专用于处理信号的 G，称为 gsignal。 除了 g0 和 gsignal 之外，其他由 M 运行的 G 都可以视为用户级别的 G，简称用户 G，g0 和 gsignal 可称为系统 G。Go 运行时系统会进行切换，以使每个 M 都可以交替运行用户 G 和它的 g0。这就是前面所说的“每个 M 都会运行调度程序”的原因。 除了每个 M 都拥有属于它自己的 g0 外，还存在一个 runtime.g0。runtime.g0 用于执行引导程序，它运行在 Go 程序拥有的第一个内核线程之中，这个线程也称为 runtime.m0，runtime.m0 的 g0 就是 runtime.g0。 核心元素的容器 上面讲了 Go 的线程实现模型中的 3 个核心元素——G、M 和 P，下面看看承载这些元素实例的容器： 调度循环 调用 runtime.schedule 进入调度循环： 为了保证公平，当全局运行队列中有待执行的 Goroutine 时，通过 schedtick 保证有一定几率会从全局的运行队列中查找对应的 Goroutine； 从处理器本地的运行队列中查找待执行的 Goroutine； 如果前两种方法都没有找到 Goroutine，会通过 runtime.findrunnable 进行阻塞地查找 Goroutine； runtime.findrunnable 的实现非常复杂，这个 300 多行的函数通过以下的过程获取可运行的 Goroutine： 从本地运行队列、全局运行队列中查找； 从网络轮询器中查找是否有 Goroutine 等待运行； 通过 runtime.runqsteal 尝试从其他随机的处理器中窃取待运行的 Goroutine，该函数还可能窃取处理器的计时器； 因为函数的实现过于复杂，上述的执行过程是经过简化的，总而言之，当前函数一定会返回一个可执行的 Goroutine，如果当前不存在就会阻塞等待。 接下来由 runtime.execute 执行获取到的 Goroutine，做好准备工作后，它会通过 runtime.gogo 将 Goroutine 调度到当前线程上； 最终在当前线程的 g0 的栈上调用 runtime.goexit0 函数，该函数会将 Goroutine 转换会 _Gdead 状态； 在最后 runtime.goexit0 会重新调用 runtime.schedule 触发新一轮的 Goroutine 调度，Go 语言中的运行时调度循环会从 runtime.schedule 开始，最终又回到 runtime.schedule，我们可以认为调度循环","date":"2023-02-22","objectID":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/:1:1","tags":["Go","并发编程","同步","GMP"],"title":"Go浅析-GMP","uri":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"二、从 Bug 中学习 无缓冲 channel，由于 receiver 退出导致 sender 侧阻塞 举例： func finishReq(timeout time.Duration) ob { ch := make(chan ob) go func() { result := fn() ch \u003c- result // block }() select { case result = \u003c-ch: return result case \u003c-time.After(timeout): return nil } } 本意是想在调用 fn() 时，加上超时的功能，如果 fn()在超时时间没有返回，则返回 nil。但是当超时发生的时候，针对无缓冲的 ch 来说，由于已经没有 receiver 了，第 5 行将会被 block 住，导致这个 goroutine 永远不会退出。 这个 bug 的修复方式也是非常的简单，把 unbuffered channel 修改成 buffered channel。 func finishReq(timeout time.Duration) ob { ch := make(chan ob, 1) go func() { result := fn() ch \u003c- result // block }() select { case result = \u003c-ch: return result case \u003c-time.After(timeout): return nil } } 思考：在上面的例子中，虽然这样不会 block 了，但是 channel 一直没有被关闭，channel 保持不关闭是否会导致资源的泄漏呢？ 问：channel 被关闭多次引发的 bug select { case \u003c-c.closed: default: close(c.closed) } 上面这块代码可能会被多个 goroutine 同时执行，这段代码的逻辑是，case 这个分支判断 closed 这个 channel 是否被关闭了，如果被关闭的话，就什么都不做；如果 closed 没有被关闭的话，就执行 default 分支关闭这个 channel，多个 goroutine 并发执行的时候，有可能会导致这个 channel 被关闭多次。 For a channel c, the built-in function close(c) records that no more values will be sent on the channel. It is an error if c is a receive-only channel. Sending to or closing a closed channel causes a run-time panic. 这个 bug 的修复方式是： Once.Do(func() { close(c.closed) }) 把整个 select 语句块换成 Once.Do，保证 channel 只关闭一次。 WaitGroup 误用导致阻塞 var group sync.WaitGroup group.Add(len(pm.plugins)) for _, p := range pm.plugins { go func(p *plugin) { defer group.Done() }(p) group.Wait() } 当 len(pm.plugins) \u003e= 2 时，第 7 行将会被卡住，因为这个时候只启动了一个异步的 goroutine，group.Done()只会被调用一次，group.Wait()将会永久阻塞。修复如下： var group sync.WaitGroup group.Add(len(pm.plugins)) for _, p := range pm.plugins { go func(p *plugin) { defer group.Done() }(p) } group.Wait() context 误用导致资源泄漏 如下面的代码所示： hctx, hcancel := context.WithCancel(ctx) if timeout \u003e 0 { hctx, hcancel = context.WithTimeout(ctx, timeout) } 第一行 context.WithCancel(ctx) 有可能会创建一个 goroutine，来等待 ctx 是否 Done，如果 parent 的 ctx.Done()的话，cancel 掉 child 的 context。也就是说 hcancel 绑定了一定的资源，不能直接覆盖。 Canceling this context releases resources associated with it, so code should call cancel as soon as the operations running in this Context complete. 这个 bug 的修复方式是： var hctx context.Context var hcancel context.CancelFunc if timeout \u003e 0 { hctx, hcancel = context.WithTimeout(ctx, timeout) } else { hctx, hcancel = context.WithCancel(ctx) } 或者 hctx, hcancel := context.WithCancel(ctx) if timeout \u003e 0 { hcancel.Cancel() hctx, hcancel = context.WithTimeout(ctx, timeout) } 问：多个 goroutine 同时读写共享变量导致的 bug for i := 17; i \u003c= 21; i++ { // write go func() { /* Create a new goroutine */ apiVersion := fmt.Sprintf(\"v1.%d\", i) // read }() } 第二行中的匿名函数形成了一个闭包(closures)，在闭包内部可以访问定义在外面的变量，如上面的例子中，第 1 行在写 i 这个变量，在第 3 行在读 i 这个变量。这里的关键的问题是对同一个变量的读写是在两个 goroutine 里面同时进行的，因此是不安全的。 其实这里会把 i 逃逸到堆上，然后都指向堆上同一个 i。因此，如下程序会输出很多个 6： func main() { for i := 0; i \u003c= 5; i++ { // write go func() { time.Sleep(100 * time.Millisecond) // 等一下 fmt.Printf(\"%d\\n\", i) // read }() } time.Sleep(3 * time.Second) } Function literals are closures: they may refer to variables defined in a surrounding function. Those variables are then shared between the surrounding function and the function literal, and they survive as long as they are accessible. 可以修改成： for i := 17; i \u003c= 21; i++ { // write go func(i int) { /* Create a new goroutine */ apiVersion := fmt.Sprintf(\"v1.%d\", i) // read }(i) } 通过passed by value的方式规避了并发读写的问题。 问：timer 误用产生的 bug 如下面的例子： timer := time.NewTimer(0) if dur \u003e 0 { timer = time.NewTimer(dur) } select { case \u003c-timer.C: case \u003c-ctx.Done(): return nil } 原意是想 dur 大于 0 的时候，设置 timer 超时时间，但是 timer := time.NewTimer(0)导致 timer.C 立即触发。修复后： var timeout \u003c-chan time.Time if dur \u003e 0 { timeout = time.NewTimer(dur).C } select { case \u003c-timeout: case \u003c-ctx.Done(): return nil } A nil channel is never ready for communication. 上面的代码中第一个 case 分支 timeout 有可能是个 nil 的 channel，select 在 nil 的 channel 上，这个分支不会被触发，因此不会有问题。 ","date":"2023-02-22","objectID":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/:2:0","tags":["Go","并发编程","同步","GMP"],"title":"Go浅析-GMP","uri":"/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"categories":["Go"],"content":"一、结构 WaitGroup 的结构很简单，维护了三个不同的计数，分别是 counter、waiter 和 semaphore： counter 记录了要等待结束的 goroutine 个数； waiter 记录了等待在该 WaitGroup 上的 goroutine 的个数； semaphore 被用作信号量。 但是在 WaitGroup 的结构里并没有直接以这三种变量命名的成员，noCopy 用来告诉代码提示器本结构体变量不能进行值复制，这个暂且略过。在结构体内使用了一个 uint64 和一个 uint32 两个数字来表示了这三个变量，将 counter 和 waiter 两个部分当作了一个 uint64 变量进行操作，semaphore 当作一个 uint32 变量进行操作。 type WaitGroup struct { noCopy noCopy state1 uint64 state2 uint32 } 从图中看出，当 state1 是 32 位对齐和 64 位对齐的情况下，state1 中每个元素的顺序和含义也不一样: 当 state1 是 32 位对齐：state1 数组的第一位是 sema，第二位是 waiter，第三位是 counter。 当 state1 是 64 位对齐：state1 数组的第一位是 waiter，第二位是 counter，第三位是 sema。 ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:1:0","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":"为什么会有这种奇怪的设定呢？ 这里有两个前提： 在 WaitGroup 的逻辑中，counter 和 waiter 被合在了一起，当成一个 64 位的整数对外使用。当需要变化 counter 和 waiter 的值的时候，也是通过 atomic 来原子操作这个 64 位整数。 在 32 位系统下，如果使用 atomic 对 64 位变量进行原子操作，调用者需要自行保证变量的 64 位对齐，否则将会出现异常。 接下来我们看看 WaitGroup 是如何获取这两部分的地址的，通过 state()： func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { // 当 state1 的对齐边界是 8字节 或 地址已对齐到 8字节 if unsafe.Alignof(wg.state1) == 8 || uintptr(unsafe.Pointer(\u0026wg.state1))%8 == 0 { return \u0026wg.state1, \u0026wg.state2 } else { state := (*[3]uint32)(unsafe.Pointer(\u0026wg.state1)) return (*uint64)(unsafe.Pointer(\u0026state[1])), \u0026state[0] } } 当 state1 变量是 64 位对齐时，也就意味着数组前两位作为 64 位整数时，自然也可以保证 64 位对齐了。 当 state1 变量是 32 位对齐时，我们把数组第 1 位作为对齐的 padding，因为 state1 本身是 uint32 的数组，所以数组第一位也有 32 位。这样就保证了把数组后两位看做统一的 64 位整数时是64位对齐的。 第一个返回值是 counter 和 waiter 的集合体的指针，第二个返回值是 semaphore 的指针。 注: 有些文章会讲到，WaitGroup 两种不同的内存布局方式是 32 位系统和 64 位系统的区别，这其实不太严谨。准确的说法是 32 位对齐和 64 位对齐的区别。因为在 32 位系统下，state1 变量也有可能恰好符合 64 位对齐。 ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:1:1","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":"那为什么要把 counter 和 waiter 合在一起呢？ 这其实是 WaitGroup 的一个性能优化手段。因为 counter 和 waiter 在改变时需要保证并发安全。 首先，对于这种场景，我们最简单的做法是，搞一个 Mutex 或者 RWMutex 锁, 在需要读写 counter 和 waiter 的时候，加锁就完事。但是我们知道加锁必然会造成额外的性能开销。 WaitGroup 直接把 counter 和 waiter 看成了一个统一的 64 位变量。其中 counter 是这个变量的高 32 位，waiter 是这个变量的低 32 位。在需要改变 counter 时, 通过将累加值左移 32 位的方式：atomic.AddUint64(statep, uint64(delta)\u003c\u003c32)，即可实现 count += delta 同样的效果。 ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:1:2","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":"二、Add \u0026 Done 之所以将 Add 方法和 Done 方法合在一个分节里，是因为 Done 只是对 Add 的简单调用而已。本节主要来分析一下 Add 方法即可。 Add 方法的作用是修改当前等待结束的 goroutine 的数量，它接受一个参数 delta，这个参数可正可负，也就是说 Add 其实不仅可以增加也可以减少计数，只是一般不会直接使用 Add 来减少计数。 func (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 得到 counter、waiter 和 semaphore state := atomic.AddUint64(statep, uint64(delta)\u003c\u003c32) // 使用原子方法修改 v := int32(state \u003e\u003e 32) // 通过移位得到 counter w := uint32(state) // 通过类型转换得到 waiter if v \u003c 0 { panic(\"sync: negative WaitGroup counter\") } if w != 0 \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta) { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } if v \u003e 0 || w == 0 { return } if *statep != state { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } 从上面的源码中可知 Add 不仅修改了计数器 counter，同时也做了计数检查。 如果上面的 if 分支都没有匹配的话，说明 counter 已经等于 0 且 waiter 不等于 0，此时会将 counter 与 waiter 的集合体 statep 重置为 0 方便后续复用该 WaitGroup，然后根据 waiter 保存的计数，依次调用 runtime_Semrelease 触发信号 semap，唤醒所有等待中的 goroutine。 Done就是调用了Add： func (wg *WaitGroup) Done() { wg.Add(-1) } ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:2:0","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":"三、Wait Wait 的作用是将调用该方法的 goroutine 阻塞，等 WaitGroup 中的 counter 计数归零后，会将其唤醒继续执行 Wait 之后的代码。 func (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u003e\u003e 32) w := uint32(state) if v == 0 { // Counter is 0, no need to wait. return } // Increment waiters count. if atomic.CompareAndSwapUint64(statep, state, state+1) { runtime_Semacquire(semap) if *statep != 0 { panic(\"sync: WaitGroup is reused before previous Wait has returned\") } return } } } 在 for 循环中使用 CAS 原子操作，比较并修改 statep 的值，将 waiter 的计数进行累加。然后执行 runtime_Semacquire 将自己阻塞在信号 semap 上，等待唤醒。 ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:3:0","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":"四、疑问 ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:4:0","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":"4.1 为什么要将 counter 和 waiter 合并？ 为什么要煞费苦心将 counter 和 waiter 这两个计数合并成一个 uint64 类型的值？似乎可以用两个 uint32 的值来分开表示，然后在操作各自的时候都使用 uint32 的原子操作即可，这样也不用考虑内存对齐的问题。 主要是需要保证counter与waiter修改时的并发安全。因为 counter 和 waiter 这两个计数在使用时需要匹配才行，如果将这两个计数分开表示，那么就要用两次原子操作读取，在这两次原子操作之间就可能产生一些变化使 counter 和 waiter 不再匹配，从而导致一些难以预料的问题。 ","date":"2023-02-20","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/:4:1","tags":["Go","并发编程","同步"],"title":"Go浅析-WaitGroup","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-waitgroup/"},{"categories":["Go"],"content":" 前言：在 Go http包的Server中，每一个请求在都有一个对应的 goroutine 去处理。请求处理函数通常会启动额外的 goroutine 用来访问后端服务，比如数据库和RPC服务。用来处理一个请求的 goroutine 通常需要访问一些与请求特定的数据，比如终端用户的身份认证信息、验证相关的token、请求的截止时间。 当一个请求被取消或超时时，所有用来处理该请求的 goroutine 都应该迅速退出，然后系统才能释放这些 goroutine 占用的资源。 有空的时候，看看这篇讲Context实现的文章: https://wmf.im/p/%E5%88%86%E6%9E%90-go-%E6%A0%87%E5%87%86%E5%BA%93%E4%B8%AD%E7%9A%84-context-%E5%AE%9E%E7%8E%B0/ ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:0:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"一、Context 概述 Go 1.7加入了一个新的标准库context，它定义了Context类型，用来简化 处理单个用户请求的多个goroutine之间与元数据传递、截止时间、取消信号等相关操作，这些操作可能涉及多个 API 调用。当一个上下文被取消时，它派生的所有上下文也被取消。 主要内容概括为： 1 个接口：Context； 4 种类型实现：emptyCtx、cancelCtx、timerCtx、valueCtx； 6 个函数：Background、TODO、WithCancel、WithDeadline、WithTimeout、WithValue。 首先要明确的是，创建 Goroutine 和 Context 时，都会按照树的结构，生成父节点到从节点的边，最终形成一种多叉树结构： ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:1:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"二、Context 接口 context.Context是一个接口，该接口定义了四个需要实现的方法。具体接口如下： type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key any) any } Deadline方法需要返回当前Context被取消的时间，也就是完成工作的截止时间（deadline）； Done方法需要返回一个Channel，这个Channel会在当前工作完成或者上下文被取消之后关闭; Err方法会返回当前Context结束的原因，它只会在Done返回的Channel被关闭时才会返回非空的值； 如果当前Context被取消就会返回Canceled错误； 如果当前Context超时就会返回DeadlineExceeded错误； Value方法会从Context中返回键对应的值，对于同一个上下文来说，多次调用Value 并传入相同的Key会返回相同的结果，该方法仅用于传递跨API和进程间跟请求域的数据； ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:2:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"三、类型实现 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:3:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"emptyCtx 数据结构 type emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u003c-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key any) any { return } emptyCtx 是一个空的 Context，本质上类型为一个整型； Deadline 方法会返回一个公元元年时间以及 false 的 flag，标识当前 context 不存在过期时间； Done 方法返回一个 nil 值，用户无论往 nil 中写入或者读取数据，均会陷入阻塞； Err 方法返回的错误永远为 nil； Value 方法返回的 value 同样永远为 nil. Background() 和 TODO() Go内置两个函数：Background()和TODO()，这两个函数分别返回一个实现了Context接口的background和todo。我们代码中最开始都是以这两个内置的上下文对象作为最顶层的partent context，衍生出更多的子上下文对象。 var ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } Background()主要用于初始化时创建一个emptyCtx，作为Context这个树结构的最顶层的Context，也就是根Context。 TODO()：官方文档建议在本来应该使用外层传递的ctx，而外层却没有传递的地方使用。正如它的名字一样，留下一个 TODO。 background和todo本质上都是emptyCtx结构体类型，是一个不可取消，没有设置截止时间，没有携带任何值的Context。 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:3:1","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"cancelCtx 一种可取消的 Context。 数据结构 type cancelCtx struct { Context // embed 的父 Context，为空 mu sync.Mutex // 用于保护以下三个字段的锁，以保障cancelCtx是线程安全的 done atomic.Value // 用于获取该Context的取消通知 children map[canceler]struct{} // 用于存储以当前节点为根节点的所有可取消的Context err error // 用于存储取消时指定的错误信息 } type canceler interface { cancel(removeFromParent bool, err error) Done() \u003c-chan struct{} } embed 了一个 context 作为其父 context. 可见，cancelCtx 必然为某个 context 的子 context； mu：用于保护以下三个字段的锁，以保障 cancelCtx 是线程安全的； done：用于获取该 Context 的取消通知； children：用于存储以当前节点为根节点的所有可取消的 Context，以便在根 Context 取消时，把它的子节点一并取消； err：用于存储取消时指定的错误信息。 WithCancel func WithCancel(parent Context) (ctx Context, cancel CancelFunc) WithCancel函数可以将一个 Context 包装为cancelCtx，并提供一个取消函数，调用该取消函数可以 Cancel 对应的Context。 WithCancel返回带有新Done通道的父节点的副本。当调用返回的cancel函数或当关闭父上下文的Done通道时，将关闭返回上下文的Done通道。 Done func (c *cancelCtx) Done() \u003c-chan struct{} { d := c.done.Load() if d != nil { return d.(chan struct{}) } c.mu.Lock() defer c.mu.Unlock() d = c.done.Load() if d == nil { d = make(chan struct{}) c.done.Store(d) } return d.(chan struct{}) } 基于 atomic 包，读取 cancelCtx 中的 chan；倘若已存在，则直接返回； 加锁后，再次检查 chan 是否存在，若存在则返回；（double check） 初始化 chan 存储到 aotmic.Value 当中，并返回。（懒加载机制） ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:3:2","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"timerCtx 数据结构 type timerCtx struct { cancelCtx timer *time.Timer // 由 cancelCtx.mu 来保护，确保取消操作时线程安全的 deadline time.Time } 在cancelCtx基础上，又封装了一个定时器timer和一个截止时间deadline，这样及可以根据需要主动取消，也可以在到达 deadline 时通过timer触发取消动作。 注意，timer 由 cancelCtx.mu 来保护，确保取消操作时线程安全的。 WithDeadline 和 WithTimeout WithDeadline 和 WithTimeout 的函数签名如下： func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) 这两个函数都可以创建 timerCtx，区别是： 前者传入一个时间点； 后者传入一个时间段，函数内再调用WithDeadline(parent, time.Now().Add(timeout))。 通常用于数据库或者网络连接的超时控制。 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:3:3","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"valueCtx 数据结构 type valueCtx struct { Context key, val any } 一个 valueCtx 中仅有一组 kv 对。 WithValue WithValue函数签名如下： func WithValue(parent Context, key, val interface{}) Context WithValue创建一个valueCtx，其中与key关联的值为val。 valueCtx.Value() func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } return value(c.Context, key) } 假如当前 valueCtx 的 key 等于用户传入的 key，则直接返回其 value； 假如不等，则从 parent context 中向上遍历寻找. 例如，会出现子Context中的key-value覆盖父节点的： 首先会比较当前Context中的key是否等于要查找的key； 此处keyA==keyC，所以会直接返回ctxC中的val，因此出现了子节点\"覆盖\"父节点数据的情况。 为了规避子节点\"覆盖\"父节点数据的情况，最好不要直接使用string、int等基础类型作为key，而是用自定义类型包装一下： 首先比较当前Context中的key是否等于要查找的key； 此处由于类型不同，因此检查不通过，于是向父节点继续查找，进而找到正确的val。 使用规范 为了规避子节点\"覆盖\"父节点数据的情况，最好不要直接使用string、int等基础类型作为key，而是用自定义类型包装一下； 可以看出，valueCtx 不适合视为存储介质，存放大量的 kv 数据，原因有三： 一个 valueCtx 实例只能存一个 kv 对，因此 n 个 kv 对会嵌套 n 个 valueCtx，造成空间浪费； 基于 k 寻找 v 的过程是线性的，时间复杂度 O(N)； 不支持基于 k 的去重，相同 k 可能重复存在，并基于起点的不同，返回不同的 v. 由此得知，valueContext 的定位类似于请求头，只适合存放少量作用域较大的全局 meta 数据. Context本身是本着不可改变(immutable)的模式设计的，所以不要视图修改ctx中保存的值。 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:3:4","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"四、注意事项 推荐以参数的方式显示传递Context 以Context作为参数的函数方法，应该把Context作为第一个参数。 给一个函数方法传递Context的时候，不要传递nil，如果不知道传递什么，就使用context.TODO() Context的Value相关方法应该传递请求域的必要数据，不应该用于传递可选参数 Context是线程安全的，可以放心的在多个goroutine中传递 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:4:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"五、使用示例 context包中定义了四个With系列函数。 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:5:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"WithCancel WithCancel返回带有新Done通道的父节点的副本。当调用返回的cancel函数或当关闭父上下文的Done通道时，将关闭返回上下文的Done通道。 取消此上下文将释放与其关联的资源，通常使用defer来立即调用cancel()： func gen(ctx context.Context) \u003c-chan int { dst := make(chan int) cnt := 0 go func() { for { select { case \u003c-ctx.Done(): log.Println(\"gen over!\") return // return结束该goroutine，防止泄露 case dst \u003c- cnt: cnt++ } } }() return dst } func main() { ctx, cancel := context.WithCancel(context.Background()) defer cancel() // 当我们取完需要的整数后调用cancel for cnt := range gen(ctx) { fmt.Println(cnt) if cnt == 5 { break } } } 上面的示例代码中，gen函数在单独的goroutine中生成整数并将它们发送到返回的通道。gen的调用者在使用生成的整数之后需要取消上下文，以免gen启动的内部goroutine发生泄漏。 下面演示，如何通过 context 关闭多个 goroutine： func watchDog(ctx context.Context, name string) { for { select { case \u003c-ctx.Done(): fmt.Println(name, \"已收到停止指令, 马上停止\") return default: fmt.Println(name, \"正在监控...\") } time.Sleep(1 * time.Second) } } func main() { ctx, cancel := context.WithCancel(context.Background()) var wg sync.WaitGroup wg.Add(2) go func() { defer wg.Done() watchDog(ctx, \"dahuang\") }() go func() { defer wg.Done() watchDog(ctx, \"dabai\") }() time.Sleep(5 * time.Second) // 先让监控狗监控5秒 cancel() // 通知多个 goroutine 退出 wg.Wait() } ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:5:1","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"WithDeadline 取消此上下文将释放与其关联的资源，因此代码应该在此上下文中运行的操作完成后立即调用cancel。 func main() { n, d := time.Now(), time.Now().Add(50*time.Millisecond) fmt.Printf(\"当前时间为：%v\\n截止时间为：%v\\n\", n, d) ctx, cancel := context.WithDeadline(context.Background(), d) // 尽管ctx会过期，但在任何情况下调用它的cancel函数都是很好的习惯。 // 如果不这样做，可能会使上下文及其父类存活的时间超过必要的时间。 defer cancel() select { case \u003c-time.After(1 * time.Second): fmt.Println(\"overslept\") case \u003c-ctx.Done(): fmt.Println(ctx.Err()) } } 输出： $ go run test.go 当前时间为：2022-09-28 16:58:04.381338 +0800 CST m=+0.001487201 截止时间为：2022-09-28 16:58:04.431338 +0800 CST m=+0.051487201 context deadline exceeded 上面的代码中，定义了一个50毫秒之后过期的deadline，然后我们调用context.WithDeadline(context.Background(), d)得到一个上下文（ctx）和一个取消函数（cancel），然后使用一个select让主程序陷入等待：等待1秒后打印overslept退出或者等待ctx过期后退出。 在上面的示例代码中，因为ctx 50毫秒后就会过期，所以ctx.Done()会先接收到context到期通知，并且会打印ctx.Err()的内容。若d在time.After后，那么将输出overslept。 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:5:2","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"WithTimeout func dbConnect(ctx context.Context) { fmt.Printf(\"db connecting...\\n\") time.Sleep(100 * time.Millisecond) // 1. 超时 //time.Sleep(10 * time.Millisecond) // 2. 不超时 select { // 若在ctx规定时间内未连接上，则超时；否则连接成功。 case \u003c-ctx.Done(): fmt.Println(\"db connect failed, err:\", ctx.Err()) default: fmt.Println(\"db connect success!\") } wg.Done() } func main() { wg.Add(1) // 设置数据库超时期限为50ms ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond) defer cancel() go dbConnect(ctx) wg.Wait() // 等待dbConnect fmt.Println(\"main is over...\") } 输出： # 超时情况 $ go run test.go db connecting... db connect failed, err: context deadline exceeded main is over... # 不超时情况 $ go run test.go db connecting... db connect success! main is over... ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:5:3","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"WithValue func worker(ctx context.Context) { key := TraceCode(\"TRACE_CODE\") if traceCode, ok := ctx.Value(key).(string); ok { log.Println(\"trade code:\", traceCode) } else { log.Println(\"invalid key\") } wg.Done() } func main() { wg.Add(1) // 设置数据库超时期限为50ms ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond) // 在系统的入口中设置trace code传递给后续启动的goroutine实现日志数据聚合 ctx = context.WithValue(ctx, TraceCode(\"TRACE_CODE\"), \"12512312234\") defer cancel() go worker(ctx) wg.Wait() // 等待worker fmt.Println(\"main is over...\") } 输出： $ go run test.go 2022/09/28 21:06:02 trade code: 12512312234 main is over... ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:5:4","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"六、客户端超时取消实例 客户端调用服务端API时，如何实现超时控制？ server端： func indexHandler(w http.ResponseWriter, r *http.Request) { number := rand.Intn(2) if number == 0 { fmt.Fprintf(w, \"slow response\") time.Sleep(time.Second * 10) // 耗时10s的慢响应 return } fmt.Fprintf(w, \"quick response\") } func main() { http.HandleFunc(\"/\", indexHandler) err := http.ListenAndServe(\":8000\", nil) if err != nil { panic(err) } } client端： var wg sync.WaitGroup type respData struct { resp *http.Response err error } func doCall(ctx context.Context) { transport := http.Transport{ DisableKeepAlives: true, } client := http.Client{Transport: \u0026transport} req, err := http.NewRequest(\"GET\", \"http://127.0.0.1:8000/\", nil) if err != nil { fmt.Println(\"client create new request failed, err:\", err) return } // 使用带超时的ctx创建新的request req = req.WithContext(ctx) wg.Add(1) defer wg.Wait() // 调用server端api respChan := make(chan *respData, 1) go func() { resp, err := client.Do(req) // 可能发生超时错误 if err != nil { fmt.Println(\"client request api failed, err:\", err) wg.Done() return } respChan \u003c- \u0026respData{ resp: resp, err: err, } wg.Done() }() select { case \u003c-ctx.Done(): // ctx超时时 fmt.Println(\"client call server api timeout...\") case result := \u003c-respChan: // 正常调用时 fmt.Println(\"client call server api success!\") if result.err != nil { fmt.Println(\"client call server api failed, err:\", result.err) return } data, _ := ioutil.ReadAll(result.resp.Body) defer result.resp.Body.Close() fmt.Println(\"resp:\", string(data)) } } func main() { // 定义一个1s的超时ctx, 超过1s则返回ctx deadline exceed错误 ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() // 调用cancel释放子goroutine资源 doCall(ctx) } 输出： # 1. 正常调用 $ go run client.go client call server api success! resp: quick response # 2. 超时 $ go run client.go client call server api timeout... client request api failed, err: Get \"http://127.0.0.1:8000/\": context deadline exceeded ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:6:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"七、底层原理(有空看吧, 没空算了) 首先要明确的是，创建 Goroutine 和 Context 时，都会按照如上的结构，生成父节点到从节点的边，最终形成一种多叉树结构。 ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:7:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"6.1 核心数据结构 type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} // 只读的，用作结束信号 Err() error // 只在context结束时，才会产生 Value(key any) any // 数据存储，类似 map } Context 为 interface，定义了四个核心 api： Deadline：返回 context 的过期时间； Done：返回 context 中的 channel； Err：返回错误； Value：返回 context 中的对应 key 的值. 6.1.1 error var Canceled = errors.New(\"context canceled\") var DeadlineExceeded error = deadlineExceededError{} type deadlineExceededError struct{} func (deadlineExceededError) Error() string { return \"context deadline exceeded\" } func (deadlineExceededError) Timeout() bool { return true } func (deadlineExceededError) Temporary() bool { return true Canceled：context 被 cancel 时会报此错误； DeadlineExceeded：context 超时时会报此错误. ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:7:1","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"6.2 empty context 6.2.1 类的实现 type emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u003c-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key any) any { return } emptyCtx 是一个空的 context，本质上类型为一个整型； Deadline 方法会返回一个公元元年时间以及 false 的 flag，标识当前 context 不存在过期时间； Done 方法返回一个 nil 值，用户无论往 nil 中写入或者读取数据，均会陷入阻塞； Err 方法返回的错误永远为 nil； Value 方法返回的 value 同样永远为 nil. 6.2.2 context.Background() \u0026 context.TODO() var ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } 我们所常用的 context.Background() 和 context.TODO() 方法返回的均是 emptyCtx 类型的一个实例. ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:7:2","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"6.3 cancelCtx 6.3.1 数据结构 type cancelCtx struct { Context // embed 的父 Context，为空 mu sync.Mutex // protects following fields done atomic.Value // of chan struct{}, created lazily, closed by first cancel call children map[canceler]struct{} // set to nil by the first cancel call err error // set to non-nil by the first cancel call } type canceler interface { cancel(removeFromParent bool, err error) Done() \u003c-chan struct{} } embed 了一个 context 作为其父 context. 可见，cancelCtx 必然为某个 context 的子 context； 内置了一把锁，用以协调并发场景下的资源获取； done：实际类型为 chan struct{}，即用以反映 cancelCtx 生命周期的通道； children：一个 set，指向 cancelCtx 的所有子 context； err：记录了当前 cancelCtx 的错误. 必然为某个 context 的子 context； 6.3.2 Deadline 方法 cancelCtx 未实现该方法，仅是 embed 了一个带有 Deadline 方法的 Context interface，因此倘若直接调用会报错. 6.3.3 Done 方法 func (c *cancelCtx) Done() \u003c-chan struct{} { d := c.done.Load() if d != nil { return d.(chan struct{}) } c.mu.Lock() defer c.mu.Unlock() d = c.done.Load() if d == nil { d = make(chan struct{}) c.done.Store(d) } return d.(chan struct{}) } 基于 atomic 包，读取 cancelCtx 中的 chan；倘若已存在，则直接返回； 加锁后，再次检查 chan 是否存在，若存在则返回；（double check） 初始化 chan 存储到 aotmic.Value 当中，并返回.（懒加载机制） 6.3.4 Error 方法 func (c *cancelCtx) Err() error { c.mu.Lock() err := c.err c.mu.Unlock() return err } 加锁； 读取 cancelCtx.err； 解锁； 返回结果. 6.3.5 Value 方法 func (c *cancelCtx) Value(key any) any { if key == \u0026cancelCtxKey { // 系统内部调用的 return c } return value(c.Context, key) // 普通用户取数据，就像是 key-value } 倘若 key 特定值 \u0026cancelCtxKey，则返回 cancelCtx 自身的指针； 否则遵循 valueCtx 的思路取值返回，具体见 2.1.6 小节. 6.3.6 context.WithCancel 6.3.6.1 context.WithCancel() func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { if parent == nil { panic(\"cannot create context from nil parent\") } c := newCancelCtx(parent) propagateCancel(parent, \u0026c) return \u0026c, func() { c.cancel(true, Canceled) } } 校验父 context 非空； 注入父 context 构造好一个新的 cancelCtx； 在 propagateCancel 方法内启动一个守护协程，以保证父 context 终止时，该 cancelCtx 也会被终止； 将 cancelCtx 返回，连带返回一个用以终止该 cancelCtx 的闭包函数. 6.3.6.2 newCancelCtx func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } 注入父 context 后，返回一个新的 cancelCtx. 6.3.6.3 propagateCancel func propagateCancel(parent Context, child canceler) { done := parent.Done() if done == nil { return // parent is never canceled } select { case \u003c-done: // parent is already canceled child.cancel(false, parent.Err()) return default: } if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent has already been canceled child.cancel(false, p.err) } else { if p.children == nil { p.children = make(map[canceler]struct{}) // 添加到 children map 即可 } p.children[child] = struct{}{} } p.mu.Unlock() } else { atomic.AddInt32(\u0026goroutines, +1) go func() { select { case \u003c-parent.Done(): // parent is already canceled child.cancel(false, parent.Err()) case \u003c-child.Done(): } }() } } propagateCancel 方法顾名思义，用以传递父子 context 之间的 cancel 事件： 倘若 parent 是不会被 cancel 的类型（如 emptyCtx），则直接返回； 倘若 parent 已经被 cancel，则直接终止子 context，并以 parent 的 err 作为子 context 的 err； 假如 parent 是 cancelCtx 的类型，则加锁，并将子 context 添加到 parent 的 children map 当中； 假如 parent 不是 cancelCtx 类型，但又存在 cancel 的能力（比如用户自定义实现的 context），则启动一个协程，通过多路复用的方式监控 parent 状态，倘若其终止，则同时终止子 context，并透传 parent 的 err. 进一步观察 parentCancelCtx 是如何校验 parent 是否为 cancelCtx 的类型： func parentCancelCtx(parent Context) (*cancelCtx, bool) { done := parent.Done() if done == closedchan || done == nil { return nil, false } p, ok := parent.Value(\u0026cancelCtxKey).(*cancelCtx) if !ok { return nil, false } pdone, _ := p.done.Load().(chan struct{}) if pdone != done { return nil, false } return p, true } 倘若 parent 的 channel 已关闭或者是不会被 cancel 的类型，则返回 false； 倘若以特定的 cancelCtxKey 从 parent 中取值，取得的 value 是 parent 本身，则返回 true. （基于 cancelCtxKey 为 key 取值时返回 cancelCtx 自身，是 cancelCtx 特有的协议）. 6.3.6.4 cancelCtx.cancel func (c *cancelCtx) cancel(removeFromParent bool, err error) { if err == nil { panic(\"context: internal error: missing cancel error\") } c.mu.Lock() if c.err != nil { c.mu.Unlock() return // already canceled } c.err = err d, _ := c.done.Load(","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:7:3","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"6.4 timerCtx 6.4.1 数据结构 type timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } timerCtx 在 cancelCtx 基础上又做了一层封装，除了继承 cancelCtx 的能力之外，新增了一个 time.Timer 用于定时终止 context；另外新增了一个 deadline 字段用于字段 timerCtx 的过期时间. 6.4.2 timerCtx.Deadline() func (c *timerCtx) Deadline() (deadline time.Time, ok bool) { return c.deadline, true } context.Context interface 下的 Deadline api 仅在 timerCtx 中有效，展示其过期时间. 6.4.3 timerCtx.cancel func (c *timerCtx) cancel(removeFromParent bool, err error) { c.cancelCtx.cancel(false, err) if removeFromParent { removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { c.timer.Stop() c.timer = nil } c.mu.Unlock() } 复用继承的 cancelCtx 的 cancel 能力，进行 cancel 处理； 判断是否需要手动从 parent 的 children set 中移除，若是则进行处理 加锁； 停止 time.Timer 解锁返回. 6.4.4 context.WithTimeout \u0026 context.WithDeadline func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } context.WithTimeout 方法用于构造一个 timerCtx，本质上会调用 context.WithDeadline 方法： func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { if parent == nil { panic(\"cannot create context from nil parent\") } if cur, ok := parent.Deadline(); ok \u0026\u0026 cur.Before(d) { // The current deadline is already sooner than the new one. return WithCancel(parent) } c := \u0026timerCtx{ cancelCtx: newCancelCtx(parent), deadline: d, } propagateCancel(parent, c) dur := time.Until(d) if dur \u003c= 0 { c.cancel(true, DeadlineExceeded) // deadline has already passed return c, func() { c.cancel(false, Canceled) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { c.timer = time.AfterFunc(dur, func() { c.cancel(true, DeadlineExceeded) }) } return c, func() { c.cancel(true, Canceled) } } 校验 parent context 非空； 校验 parent 的过期时间是否早于自己，若是，则构造一个 cancelCtx 返回即可； 构造出一个新的 timerCtx； 启动守护方法，同步 parent 的 cancel 事件到子 context； 判断过期时间是否已到，若是，直接 cancel timerCtx，并返回 DeadlineExceeded 的错误； 加锁； 启动 time.Timer，设定一个延时时间，即达到过期时间后会终止该 timerCtx，并返回 DeadlineExceeded 的错误； 解锁； 返回 timerCtx，已经一个封装了 cancel 逻辑的闭包 cancel 函数. ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:7:4","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"6.5 valueCtx 6.5.1 数据结构 type valueCtx struct { Context key, val any } valueCtx 同样继承了一个 parent context； 一个 valueCtx 中仅有一组 kv 对. 6.5.2 valueCtx.Value() func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } return value(c.Context, key) } 假如当前 valueCtx 的 key 等于用户传入的 key，则直接返回其 value； 假如不等，则从 parent context 中向上遍历寻找. func value(c Context, key any) any { for { switch ctx := c.(type) { case *valueCtx: if key == ctx.key { return ctx.val } c = ctx.Context case *cancelCtx: if key == \u0026cancelCtxKey { return c } c = ctx.Context case *timerCtx: if key == \u0026cancelCtxKey { return \u0026ctx.cancelCtx } c = ctx.Context case *emptyCtx: return nil default: return c.Value(key) } } } 启动一个 for 循环，由下而上，由子及父，依次对 key 进行匹配； 其中 cancelCtx、timerCtx、emptyCtx 类型会有特殊的处理方式； 找到匹配的 key，则将该组 value 进行返回. 6.5.3 valueCtx 用法小结 可以看出，valueCtx 不适合视为存储介质，存放大量的 kv 数据，原因有三： 一个 valueCtx 实例只能存一个 kv 对，因此 n 个 kv 对会嵌套 n 个 valueCtx，造成空间浪费； 基于 k 寻找 v 的过程是线性的，时间复杂度 O(N)； 不支持基于 k 的去重，相同 k 可能重复存在，并基于起点的不同，返回不同的 v. 由此得知，valueContext 的定位类似于请求头，只适合存放少量作用域较大的全局 meta 数据. 6.5.4 context.WithValue() func WithValue(parent Context, key, val any) Context { if parent == nil { panic(\"cannot create context from nil parent\") } if key == nil { panic(\"nil key\") } if !reflectlite.TypeOf(key).Comparable() { panic(\"key is not comparable\") } return \u0026valueCtx{parent, key, val} } 倘若 parent context 为空，panic； 倘若 key 为空 panic； 倘若 key 的类型不可比较，panic； 包括 parent context 以及 kv对，返回一个新的 valueCtx. 参考文章： https://mp.weixin.qq.com/s?__biz=MzkxMjQzMjA0OQ==\u0026mid=2247483677\u0026idx=1\u0026sn=d1c0e52b1fd31932867ec9b1d00f4ec2\u0026chksm=c10c4fc3f67bc6d590141040342153004ea4e420d83f4e2b2afc068e8bb904778b02b5be3f97\u0026scene=126\u0026sessionid=1682837915#rd ","date":"2023-02-19","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/:7:5","tags":["Go","并发编程","同步"],"title":"Go浅析-Context","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-context/"},{"categories":["Go"],"content":"[toc] ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:0:0","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"一、Atomic 方法 如果去看文档会发现 atomic 的函数签名有很多，但是大部分都是重复的为了不同的数据类型创建了不同的签名，这就是没有泛型的坏处了，基础库会比较麻烦 1、第一类 AddXXX，当需要添加的值为负数的时候，做减法，正数做加法 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) 2、第二类 CompareAndSwapXXX，==CAS 操作==，会先比较传入的地址的值是否是 old，如果是的话就尝试赋新值，如果不是的话就直接返回 false，返回 true 时表示赋值成功。 func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) 3、第三类 LoadXXX，从某个地址中取值 func LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) func LoadUint32(addr *uint32) (val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) 4、第四类 StoreXXX ，给某个地址赋值 func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) 5、第五类 SwapXXX ，交换两个值，并且返回老的值 func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) 6、最后一类 Value 用于任意类型的值的 Store、Load，这是 1.4 版本之后引入的，签名的方法都只能作用于特定的类型，引入这个方法之后就可以用于任意类型了。 type Value func (v *Value) Load() (x interface{}) func (v *Value) Store(x interface{}) 参考文章： Golang 五种原子性操作的用法详解 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:1:0","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"二、CAS ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:2:0","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"概述 比较并交换：简称 CAS，这类操作的前缀为 CompareAndSwap，不仅支持对数值类型进行比较交换，还支持对指针进行比较交换： func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) 该操作在进行交换前：首先确保被操作数的值未被更改，即仍然保存着参数 old 所记录的值，满足此前提条件下才进行交换操作。其实这就是 CAS 汇编代码中 CMPXCHGL 的作用。 CAS的做法类似操作数据库时常见的乐观锁机制。需要注意的是，当有大量的 goroutine 对变量进行读写操作时，可能导致CAS操作无法成功，这时可以利用for循环多次尝试。 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:2:1","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"实现原理 CAS 的实现思想可用如下伪代码说明： bool Cas(int *val, int old, int new) Atomically: if(*val == old){ *val = new; return 1; } else { return 0; } 以CompareAndSwapInt32为例，它在sync/atomic/doc.go中定义的函数原型如下： func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) 对应的汇编代码位于sync/atomic/asm.s中 TEXT ·CompareAndSwapInt32(SB),NOSPLIT,$0 JMP runtime∕internal∕atomic·Cas(SB) 通过指令JMP，跳转到它的实际实现runtime∕internal∕atomic·Cas(SB)。底层由汇编代码组成，不同平台可能有所不同，此处用arm64为例： TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17 MOVQ ptr+0(FP), BX # 第一个参数addr命名为ptr，放入BX(MOVQ，完成8个字节的复制) MOVL old+8(FP), AX # 第二个参数old，放入AX（MOVL，完成4个字节的复制） MOVL new+12(FP), CX # 第三个参数new，放入CX（MOVL，完成4个字节的复制） LOCK CMPXCHGL CX, 0(BX) # 通过寄存器中的值，比较并交换 SETEQ ret+16(FP) RET 这段汇编代码的含义就是： 其实没必要完全搞懂上述汇编是啥意思，它的函数原型为func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)，其入参addr为8个字节（64位系统），old和new分别为4个字节，返回参数swapped为1个字节，所以17=8+4+4+1。 接下来解释这几条汇编指令的作用： ptr+0(FP)代表的意思就是ptr从FP偏移0byte处取内容。AX，BX，CX在这里，知道它们是存放数据的寄存器即可。MOV X Y所做的操作是将X上的内容复制到Y上去，MOV后缀L表示“长字”（32位，4个字节），Q表示“四字”（64位，8个字节）。 MOVQ ptr+0(FP), BX # 第一个参数addr命名为ptr，放入BX(MOVQ，完成8个字节的复制) MOVL old+8(FP), AX # 第二个参数old，放入AX（MOVL，完成4个字节的复制） MOVL new+12(FP), CX # 第三个参数new，放入CX（MOVL，完成4个字节的复制） 重点是LOCK指令：在多处理器环境中，指令前缀LOCK能够确保，在执行LOCK随后的指令时，处理器拥有对任何共享内存的独占使用。在汇编代码里给指令加上 LOCK 前缀，这是CPU 在硬件层面支持的原子操作。但这样的锁粒度太粗，其他无关的内存操作也会被阻塞，大幅降低系统性能，核数越多愈发显著。为了提高性能，Intel 从 Pentium 486 开始引入了粒度较细的缓存锁：MESI协议。此时，尽管有LOCK前缀，但如果对应数据已经在 cache line里，也就不用锁定总线，仅锁住缓存行即可。 LOCK CMPXCHGL CX, 0(BX) CMPXCHGL，L代表4个字节。该指令会把AX（累加器寄存器）中的内容（old）和第二个操作数（0(BX)）中的内容（ptr所指向的数据）比较。如果相等，则把第一个操作数（CX）中的内容（new）赋值给第二个操作数（0(BX)）。 SETEQ ret+16(FP) RET 这里，SETEQ 与CMPXCHGL是配合使用的，如果CMPXCHGL中比较结果是相等的，则设置ret（即函数原型中的swapped）为1，不等则设置为0。RET代表函数返回。 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:2:2","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"Mutex 其实Mutex的底层实现也是依赖原子操作中的CAS实现的，原子操作的atomic包相当于是sync包里的那些同步原语的实现依赖。 func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) m.lockSlow() } func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. new := atomic.AddInt32(\u0026m.state, -mutexLocked) if new != 0 { // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } } 参考文章： Go同步原语的基石 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:2:3","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"二、atomic.Value 在 Go 语言标准库中，sync/atomic包将底层硬件提供的原子操作封装成了 Go 的函数。但这些操作只支持几种基本数据类型，因此为了扩大原子操作的适用范围，Go 语言在 1.4 版本的时候向sync/atomic包中添加了一个新的类型Value。此类型的值相当于一个容器，可以被用来“原子地\"存储(Store)和加载(Load)任意类型的值。 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:3:0","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"原子性 一个或者多个操作在 CPU 执行的过程中不被中断的特性，称为原子性(atomicity)。这些操作对外表现成一个不可分割的整体，他们要么都执行，要么都不执行，外界不会看到他们只执行到一半的状态。而在现实世界中，CPU 不可能不中断的执行一系列操作，但如果我们在执行多个操作时，能让他们的中间状态对外不可见，那我们就可以宣称他们拥有了\"不可分割”的原子性。 由下面的问题引入 atomic.Value. 问 ：一条普通的赋值语句，是原子操作吗？ 有些朋友可能不知道，在 Go（甚至是大部分语言）中，一条普通的赋值语句其实不是一个原子操作。例如，在32位机器上写int64类型的变量就会有中间状态，因为它会被拆成两次写操作（MOV）——写低 32 位和写高 32 位，如下图所示： 如果一个线程刚写完低32位，还没来得及写高32位时，另一个线程读取了这个变量，那它得到的就是一个毫无逻辑的中间变量，这很有可能使我们的程序出现诡异的 Bug。 这还只是一个基础类型，如果我们对一个结构体进行赋值，那它出现并发问题的概率就更高了。很可能写线程刚写完一小半的字段，读线程就来读取这个变量，那么就只能读到仅修改了一部分的值。这显然破坏了变量的完整性，读出来的值也是完全错误的。 面对这种多线程下变量的读写问题，我们的主角——atomic.Value登场了，它使得我们可以不依赖于不保证兼容性的unsafe.Pointer类型，同时又能将任意数据类型的读写操作封装成原子性操作（让中间状态对外不可见）。 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:3:1","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"使用方法 atomic.Value类型对外暴露的方法就两个： v.Store(c) - 写操作，将原始的变量c存放到一个atomic.Value类型的v里。 c = v.Load() - 读操作，从线程安全的v中读取上一步存放的内容。 使用时，只需**将需要并发保护的变量读取和赋值操作用Load()和Store()**代替就行了。 举例一个简单的使用场景：应用程序定期的从外界获取最新的配置信息，然后更改自己内存中维护的配置变量。工作线程根据最新的配置来处理请求。 package main import ( \"sync/atomic\" \"time\" ) func loadConfig() map[string]string { // 从数据库或者文件系统中读取配置信息，然后以map的形式存放在内存里 return make(map[string]string) } func requests() chan int { // 将从外界中接受到的请求放入到channel里 return make(chan int) } func main() { // config变量用来存放该服务的配置信息 var config atomic.Value // 初始化时从别的地方加载配置文件，并存到config变量里 config.Store(loadConfig()) go func() { // 每10秒钟定时拉取最新的配置信息，并且更新到config变量里 for { time.Sleep(10 * time.Second) // 对应于赋值操作 config = loadConfig() config.Store(loadConfig()) } }() // 创建工作线程，每个工作线程都会根据它所读取到的最新的配置信息来处理请求 for i := 0; i \u003c 10; i++ { go func() { for r := range requests() { // 对应于取值操作 c := config // 由于Load()返回的是一个interface{}类型，所以我们要先强制转换一下 c := config.Load().(map[string]string) // 这里是根据配置信息处理请求的逻辑... _, _ = r, c } }() } } ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:3:2","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"实现原理 数据结构 atomic.Value被设计用来存储任意类型的数据，所以它内部的字段是一个any类型(也就是interface{})，非常的简单粗暴。 type Value struct { v any } 除了Value外，这个文件里还定义了一个ifaceWords类型，这其实是一个空interface (interface{}）的内部表示格式（参见runtime/runtime2.go中eface的定义）。它的作用是将interface{}类型分解，得到其中的两个字段。 // ifaceWords is interface{} internal representation. type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } unsafe.Pointer 在介绍写入之前，我们先来看一下 Go 语言内部的unsafe.Pointer类型。 出于安全考虑，Go 语言并不支持直接操作内存，但它的标准库中又提供一种*不安全（不保证向后兼容性）*的指针类型unsafe.Pointer，让程序可以灵活的操作内存。 unsafe.Pointer的特别之处在于：它可以绕过 Go 语言类型系统的检查，与任意的指针类型互相转换。也就是说，如果两种类型具有相同的内存结构（layout），我们可以将unsafe.Pointer当做桥梁，让这两种类型的指针相互转换，从而实现同一份内存拥有两种不同的解读方式。 比如说，[]byte和string其实内部的存储结构都是一样的，但 Go 语言的类型系统禁止他俩互换。他们在运行时类型分别表示为reflect.SliceHeader和reflect.StringHeader： type SliceHeader struct { Data uintptr Len int Cap int } type StringHeader struct { Data uintptr Len int } 如果借助unsafe.Pointer，我们就可以实现在零拷贝的情况下，将[]byte数组直接转换成string类型。 func main() { bytes := []byte(\"hello\") fmt.Println(bytes) // 输出 [104 101 108 108 111] p := unsafe.Pointer(\u0026bytes) // 强制转换成unsafe.Pointer，编译器不会报错 str := *(*string)(p) // 然后强制转换成string类型的指针，再将这个指针的值当做string类型取出来 fmt.Println(str) // 输出 \"hello\" } 写入(Store)操作 知道了unsafe.Pointer的作用，就可以来看代码了： func (v *Value) Store(val any) { if val == nil { panic(\"sync/atomic: store of nil value into Value\") } vp := (*ifaceWords)(unsafe.Pointer(v)) vlp := (*ifaceWords)(unsafe.Pointer(\u0026val)) for { typ := LoadPointer(\u0026vp.typ) if typ == nil { // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion. runtime_procPin() if !CompareAndSwapPointer(\u0026vp.typ, nil, unsafe.Pointer(\u0026firstStoreInProgress)) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026vp.data, vlp.data) StorePointer(\u0026vp.typ, vlp.typ) runtime_procUnpin() return } if typ == unsafe.Pointer(\u0026firstStoreInProgress) { // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue } // First store completed. Check type and overwrite data. if typ != vlp.typ { panic(\"sync/atomic: store of inconsistently typed value into Value\") } StorePointer(\u0026vp.data, vlp.data) return } } 大概的逻辑： 第 5~6 行 - 通过unsafe.Pointer将现有的和要写入的值分别转成ifaceWords类型，这样我们下一步就可以得到这两个interface{}的原始类型（typ）和真正的值（data）。 从第 7 行开始就是一个无限 for 循环。配合CompareAndSwap使用，可以达到乐观锁的功效。 第 8 行，我们可以通过LoadPointer这个原子操作拿到当前Value中存储的类型。下面根据这个类型的不同，分3种情况处理： 第一次写入（第9~24行） - 一个Value实例被初始化后，它的typ字段会被设置为指针的零值 nil，所以第 9 行先判断，如果typ是 nil，那就证明这个Value还未被写入过数据。那之后就是一段初始写入的操作： runtime_procPin()是runtime中的一段函数，具体的功能我不是特别清楚，也没有找到相关的文档。这里猜测一下，一方面它禁止了调度器对当前 goroutine 的抢占（preemption），使得它在执行当前逻辑的时候不被打断，以便可以尽快地完成工作，因为别人一直在等待它。另一方面，在禁止抢占期间，GC 线程也无法被启用，这样可以防止 GC 线程看到一个莫名其妙的指向^uintptr(0)的类型（这是赋值过程中的中间状态）。 使用CAS操作，先尝试将typ设置为^uintptr(0)这个中间状态。如果失败，则证明已经有别的线程抢先完成了赋值操作，那它就解除抢占锁，然后重新回到 for 循环第一步。 如果设置成功，那证明当前线程抢到了这个\"乐观锁\"，它可以安全的把v设为传入的新值了（19~23行）。注意，这里是先写data字段，然后再写typ字段。因为我们是以typ字段的值作为写入完成与否的判断依据的。 第一次写入还未完成（第25~30行）- 如果看到 typ字段还是^uintptr(0)这个中间类型，证明刚刚的第一次写入还没有完成，所以它会继续循环，“忙等\"到第一次写入完成。 第一次写入已完成（第31行及之后） - 首先检查上一次写入的类型与这一次要写入的类型是否一致，如果不一致则抛出异常。反之，则直接把这一次要写入的值写入到data字段。 这个逻辑的主要思想就是：为了完成多个字段的原子性写入，我们可以抓住其中的一个字段，以它的状态来标志整个原子写入的状态。 读取(Load)操作 // Load returns the value set by the most recent Store. // It returns nil if there has been no call to Store for this Value. func (v *Value) Load() (val any) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026vp.typ) if typ == nil || typ == unsafe.Pointer(\u0026firstStoreInProgress) { // First store not yet completed. return nil } data := LoadPointer(\u0026vp.data) vlp := (*ifaceWords)(unsafe.Pointer(\u0026val)) vlp.typ = typ vlp.data = data return } 读取相对就简单很多了，它有两个分支： 如果当前的typ是 nil 或者^uintptr(0)，那就证明第一次写入还没有开始，或者还没完成，那就直接返回 nil （不对外暴露中间状态）。 否则，根据当前看到的typ和data构造出一个新的interface{}返回出去。 参考文章： Go 语言标准库中 atomic.Value 的前世今生 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:3:3","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"面试题 问：原子操作和锁的区别？⭐ 原子操作由底层硬件支持，而锁则由操作系统的调度器实现； 锁应当用来保护一段逻辑，原子操作用来对一个变量的更新保护，如果要更新的是一个复合对象，则应当使用atomic.Value封装好的实现。 问：CAS 底层实现原理？⭐ 从思想方面，从汇编代码方面回答。 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/:4:0","tags":["Go","同步","锁","并发编程"],"title":"Go浅析-Atomic","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-atomic/"},{"categories":["Go"],"content":"[toc] 参考文章： Golang Channel 实现原理 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:0:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"一、核心数据结构 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:1:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"1.1 hchan type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters lock mutex } qcount：当前 channel 中存在多少个元素； dataqsize: 当前 channel 能存放的元素容量； buf：channel 中用于存放元素的环形缓冲区； elemsize：channel 元素类型的大小； closed：标识 channel 是否关闭； elemtype：channel 元素类型； sendx：发送元素进入环形缓冲区的 index； recvx：接收元素所处的环形缓冲区的 index； recvq：因接收而陷入阻塞的协程队列； sendq：因发送而陷入阻塞的协程队列； ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:1:1","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"1.2 waitq type waitq struct { first *sudog last *sudog } waitq：阻塞的协程队列 first：队列头部 last：队列尾部 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:1:2","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"1.3 sudog type sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer // data element (may point to stack) isSelect bool c *hchan } sudog：用于包装协程的节点 g：goroutine，协程； next：队列中的下一个节点； prev：队列中的前一个节点； elem: 读取/写入 channel 的数据的容器; isSelect：标识当前协程是否处在 select 多路复用的流程中； c：标识与当前 sudog 交互的 chan. ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:1:3","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"二、 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:2:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"面试题 问：要求实现一个 map： 支持高并发； 只存在插入和查询操作 O(1)； 查询时，若 key 存在，直接返回 val；若 key 不存在，阻塞直到 key-val 被放入后，获取 val 返回；等待指定时长仍未放入，就返回超时错误； 不能有死锁或者 panic 风险。 ","date":"2023-02-18","objectID":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/:3:0","tags":["Go","并发编程","同步"],"title":"Go浅析-Channel","uri":"/go%E6%A0%87%E5%87%86%E5%BA%93-channel/"},{"categories":["Go"],"content":"Go实践操作 [toc] ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:0:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"二、基础 记录遇到的问题： 当使用go get安装包之后，在pkg中也可找到，但还是无法使用，显示unresolved。这其实是因为你的项目没有external libraries，所以go get或go build的包无法在当前目录找到，只需要： ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"1. 结构体 结构体变量在内存中的布局： 结构体的所有字段在内存中是连续的。 2022/01/24 看别的视频 接口与多态 多态： 不同的类拥有同名的方法，方法有所不同。同一个语句 不同类型的对象可以调用各自类型的方法输出不同的结果 **接口： ** 避免不必要的信息泄露 只能调用接口中有的方法 不能调用原对象拥有的方法 给一个接口赋值的时候 需要采用指针 // 定义一个接口 注意类型是 interface type IAttack interface { // 接口函数可以有多个 但是只能有函数原型 不可以有实现 Attack() } // 使用接口 var player IAttack // 定义一个包含Attack的接口变量 // 对player赋值为lowLevel 接口需要使用指针类型来赋值 接口只能访问接口中的方法 player = \u0026lowlevel 常量 基础介绍： 常量使用 const 修饰 常量在定义的时候必须初始化 常量一经定义就不能修改 常量只能修饰bool、数值类型(int, float等)、string类型 通过大小写控制常量的访问范围 语法：const 常量名 常量type = value 写法： 1. 比较简洁的写法 const ( a = 1 b = 1 ) 2. 更专业 const ( a = iota // 表示给 a 赋值为 0， b 在 a 的基础上 +1，c 在 b 的基础上 +1 b c ) func main() { const ( a = iota b c ) fmt.Println(a, b, c) // 0, 1, 2 } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"2. 接口 核心中的核心。 类似于多态。 基本语法： // 定义一个接口 type 接口名 interface { method1(参数列表) 返回值列表 method2(参数列表) 返回值列表 } // 实现接口 func (t 自定义类型) method1(参数列表) 返回值列表 { // 方法实现 } func (t 自定义类型) method2(参数列表) 返回值列表 { // 方法实现 } 注：interface不能包括任何变量 // 示例： type Usb interface { Start() Stop() } // Phone 2. Phone实现Usb接口方法 type Phone struct { } func (p Phone) Start() { fmt.Println(\"Phone开始工作...\") } func (p Phone) Stop() { fmt.Println(\"Phone停止工作...\") } 注：golang中的接口不需要显式实现。只要一个变量（结构体），含有接口类型中的所有方法，那么这个变量就实现了这个接口。。因此，golang中没有Java中的implement关键字。 所有类型都实现了空接口，我们可以把任何一个变量赋给空接口。 接口vs继承 接口可看作是继承的一种补充。结构体是个体的抽象，接口是行为的抽象。 接口和继承解决的问题不同： **继承：**解决代码的复用性和可维护性 **接口：**设计，设计好各种规范（方法），让其他自定义类型去实现这些方法。 接口比继承更加灵活，继承是满足 is a 的关系，而接口只需满足 like a 的关系。 接口在一定程度实现代码解耦。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"3. 多态 Go中的多态通过接口实现。可以按照统一的接口来调用不同的实现，这时接口变量就呈现不同的形态。比如：不同结构体的排序。 3.1 接口体现多态的两种形式 多态参数 比如不同结构体的排序。 多态数组 一个接口数组，可以存放不同的结构体对象。 3.2 类型断言 **类型断言：**由于一个接口是一般类型，不知道具体类型，如果要转成具体类型，就需要使用类型断言。 type Point struct { x int y int } func main() { var a interface{} point := Point{1, 2} a = point var b Point // 这样是不可以的 //b = a // 类型断言 b = a.(Point) fmt.Println(b) } b = a.(Point) 就是类型断言，表示判断a是否指向Point类型的变量，如果是就转成Point类型并赋给b变量，否则报错。 带检测机制的类型断言： b, ok := a.(Point) if ok { fmt.Println(b) } else { fmt.Println(\"类型断言出错！\") } 类型断言实践： func typeJudge(items ...interface{}) { for index, x := range items { // 类型断言 switch x.(type) { case bool: fmt.Printf(\"第%v个参数是bool类型，值是%v\\n\", index, x) case float64: fmt.Printf(\"第%v个参数是float64类型，值是%v\\n\", index, x) case float32: fmt.Printf(\"第%v个参数是float32类型，值是%v\\n\", index, x) case int, int32, int64: fmt.Printf(\"第%v个参数是int类型，值是%v\\n\", index, x) case string: fmt.Printf(\"第%v个参数是string类型，值是%v\\n\", index, x) default: fmt.Printf(\"第%v个参数是 不确定 类型，值是%v\\n\", index, x) } } } func main() { var n1 float32 = 1.1 var n2 float64 = 2.2 var n3 int32 = 3 n4 := \"北京\" n5 := 300 var n6 string = \"nihao\" typeJudge(n1, n2, n3, n4, n5, n6) } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"4. 文件操作 4.1 基本介绍 os.File 封装所有文件相关操作，File 是一个结构体。 打开文件 os.Open() file, err := os.Open(\"./test.txt\") if err != nil { fmt.Println(err) } 关闭文件 file对象.Close() file 其实是个指针。 err = file.Close() if err != nil { fmt.Println(err) } 读文件 带缓冲 不带缓冲 ioutil.ReadFile一次性读取： file := \"./test.txt\" content, err := ioutil.ReadFile(file) if err != nil { fmt.Println(\"read file err = \", err) } fmt.Println(string(content)) // 读取内容为[]byte // 没有显式open文件，此处也不必close，因为文件的open和close被封装到了ReadFile中 // 这种方式很简洁，但文件很大的时候，将会效率很低，因为是一次读取所有内容 写文件 func OpenFile(name string, flag int, perm FileMode) (file *File, err error) 其中，name指定文件，flag代表打开模式（可以组合），perm权限控制（unix） const ( O_RDONLY int = syscall.O_RDONLY // 只读模式打开文件 O_WRONLY int = syscall.O_WRONLY // 只写模式打开文件 O_RDWR int = syscall.O_RDWR // 读写模式打开文件 O_APPEND int = syscall.O_APPEND // 写操作时将数据附加到文件尾部 O_CREATE int = syscall.O_CREAT // 如果不存在将创建一个新文件 O_EXCL int = syscall.O_EXCL // 和O_CREATE配合使用，文件必须不存在 O_SYNC int = syscall.O_SYNC // 打开文件用于同步I/O O_TRUNC int = syscall.O_TRUNC // 如果可能，打开时清空文件 ) 实例： 创建一个新文件，写入 5 句 hello, world!. func writeNew() { // 1. 打开文件 filePath := \"testOpen.txt\" file, _ := os.OpenFile(filePath, os.O_WRONLY|os.O_CREATE, 0666) // 2. 写入 str := \"hello, world!\\n\" // 带缓存的 *Writter writer := bufio.NewWriter(file) for i := 0; i \u003c 5; i++ { writer.WriteString(str) } // 因为writter是带缓存的，因此在调用WritterString时， // 其实内容是先写到缓存的 ，所以需要调用Flush方法将缓存的数据， // 真正写到磁盘 writer.Flush() } 在已存在文件后，追加 hello, JY!. func writeAppend() { // 1. 打开文件 filePath := \"testOpen.txt\" file, _ := os.OpenFile(filePath, os.O_WRONLY|os.O_APPEND, 0666) // 2. 写入 str := \"hello, JY!\\r\\n\" // 带缓存的 *Writter writer := bufio.NewWriter(file) for i := 0; i \u003c 5; i++ { writer.WriteString(str) } // 因为writter是带缓存的，因此在调用WritterString时， // 其实内容是先写到缓存的 ，所以需要调用Flush方法将缓存的数据， // 真正写到磁盘 writer.Flush() } 注意，只是打开文件的模式不同。 边读边追加 func writeAndRead() { // 1. 打开文件 filePath := \"testOpen.txt\" file, _ := os.OpenFile(filePath, os.O_RDWR|os.O_APPEND, 0666) defer file.Close() // 2. 先读取原来的内容并显示在终端 reader := bufio.NewReader(file) for { str, err := reader.ReadString('\\n') if err == io.EOF { // 若读取到文件末尾 break } fmt.Print(str) // 打印 } // 3. 追加 str := \"你好, JY!\\r\\n\" // 带缓存的 *Writter writer := bufio.NewWriter(file) for i := 0; i \u003c 5; i++ { writer.WriteString(str) } // 因为writter是带缓存的，因此在调用WritterString时， // 其实内容是先写到缓存的 ，所以需要调用Flush方法将缓存的数据， // 真正写到磁盘 writer.Flush() } 判断文件是否存在 自定义一个函数： func PathExists(path string) (bool, error) { _, err := os.Stat(path) if err != nil { // 文件目录存在 return true, nil } if os.IsNotExist(err) { return false, err } return false, err } 拷贝文件 将一个已存在的文件内容写入到另一个文件中。 // 将file1的内容复制到file2 func readAndWrite() { file1Path := \"./test.txt\" file2Path := \"./testOpen.txt\" data, err := ioutil.ReadFile(file1Path) if err != nil { fmt.Println(\"read file err = \", err) return } err = ioutil.WriteFile(file2Path, data, 0666) if err != nil { fmt.Println(\"write file err = \", err) return } } 拷贝视频等 func Copy(dst Writer, src Reader) (written int64, err error) func copyFile(srcFileName, dstFileName string) (int64, error) { srcFile, err := os.Open(srcFileName) if err != nil { fmt.Println(\"open file err = \", err) return 0, err } defer srcFile.Close() dstFile, err := os.OpenFile(dstFileName, os.O_WRONLY|os.O_CREATE, 0666) if err != nil { fmt.Println(\"open file err = \", err) return 0, err } defer dstFile.Close() // 拿到reader和writer reader := bufio.NewReader(srcFile) writer := bufio.NewWriter(dstFile) // copy return io.Copy(writer, reader) } 4.2 实例 统计文件中有多少个英文、数字、空格和其他字符 func fileCount(fileName string) (Record, error) { /* 1. 打开一个文件，创建reader 2. 逐行统计 3. 记录在结构体 */ file, err := os.Open(fileName) if err != nil { fmt.Println(\"open file err = \", err) return Record{}, err } defer file.Close() record := Record{} reader := bufio.NewReader(file) for { str, err := reader.ReadString('\\n') // 为了兼容中文，可以将string转[]rune // 遍历str，进行统计 for _, v := range str { switch { case 'a' \u003c= v \u0026\u0026 v \u003c= 'z': fallthrough // 穿透 case 'A' \u003c= v \u0026\u0026 v \u003c= 'Z': record.CharCount++ case v == ' ' || v == '\\t': record.SpaceCount++ case '0' \u003c= v \u0026\u0026 v \u003c= ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:4","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5. flag 解析命令行参数 func parseCommand() { // 1. 定义几个变量用来存放命令行参数 var ( user string pwd string host string port int ) // 2. 转换 /* \u0026user: 接收用户命令行输入的 -u 后面的参数值 \"u\": -u 指定参数 \"\": 默认参数 \"用户名，默认为空\": 说明 */ flag.StringVar(\u0026user, \"u\", \"\", \"用户名，默认为空\") flag.StringVar(\u0026pwd, \"pwd\", \"\", \"密码，默认为空\") flag.StringVar(\u0026host, \"h\", \"localhost\", \"主机名，默认为localhost\") flag.IntVar(\u0026port, \"port\", 3306, \"端口号，默认为3306\") flag.Parse() // 一定要调用 // 3. 输出结果 fmt.Printf(\"user=%v pwd=%v host=%v port=%v\", user, pwd, host, port) } $ go run 06-flag.go -u root -pwd 123456 -h 127.0.0.1 -port 3300 user=root pwd=123456 host=127.0.0.1 port=3300 $ go run 06-flag.go -u root -pwd 123456 user=root pwd=123456 host=localhost port=3306 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:5","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"6. json 6.1 基础使用 轻量级的数据交换格式，易于机器解析，可提升网络传输效率。通常在网络传输时会先将数据（数据结构、map等）序列化成json字符串，到接收方得到json字符串时，再反序列化成原来的数据格式（数据结构、map等）。 应用场景： 6.2 序列化 将数据结构序列化为json格式。 /* 1. 将结构体序列化 2. 将map序列化 3. 对Slice序列化 4. 对基本数据类型进行序列化（意义不大） */ data, err := json.Marshal() 6.3 tag的使用 **原理：**利用reflect机制。 **目的：**如果我们希望序列化后key的名字是指定的名字，**同时不受go的命名限制，**可以指定tag标签。 type Monster struct { Name string `json:\"name\" ` Age int `json:\"age\" ` Birthday string `json:\"birthday\"` Salary float64 `json:\"salary\"` Skill string `json:\"skill\"` } // 1. 将结构体序列化 type Monster struct { Name string `json:\"name\" ` Age int `json:\"age\" ` Birthday string `json:\"birthday\"` Salary float64 `json:\"salary\"` Skill string `json:\"skill\"` } func testStruct() { monster := Monster{ Name: \"牛魔王\", Age: 18, Birthday: \"2011-11-11\", Salary: 3000.0, Skill: \"牛魔拳\", } // 将monster 序列化 data, err := json.Marshal(\u0026monster) if err != nil { fmt.Println(\"序列化错误 err = \", err) } fmt.Println(\"序列化的结果：\", string(data)) } // 2. 将map序列化 func testMap() { a := make(map[string]interface{}) a[\"name\"] = \"红孩儿\" a[\"age\"] = 30 a[\"address\"] = \"洪崖洞\" data, err := json.Marshal(a) if err != nil { fmt.Println(\"序列化错误 err = \", err) } fmt.Println(\"a map 序列化后为：\", string(data)) } // 3. 对Slice序列化 func testSlice() { slice := []map[string]interface{}{} m1 := map[string]interface{}{} m1[\"name\"] = \"jack\" m1[\"age\"] = 10 m1[\"address\"] = []string{\"墨西哥\", \"夏威夷\"} m2 := map[string]interface{}{} m2[\"name\"] = \"chuyu\" m2[\"age\"] = 18 m2[\"address\"] = \"南京\" slice = append(slice, m1, m2) data, err := json.Marshal(slice) if err != nil { fmt.Println(\"序列化错误 err = \", err) } fmt.Println(\"slice 序列化后为：\", string(data)) } // 4. 对基本数据类型进行序列化(意义不大) func testFloat64() { num1 := 1234.5678 data, err := json.Marshal(num1) if err != nil { fmt.Println(\"序列化错误 err = \", err) } fmt.Println(\"num1 序列化结果为：\", string(data)) } 序列化的结果： {\"name\":\"牛魔王\",\"age\":18,\"birthday\":\"2011-11-11\",\"salary\":3000,\"skill\":\"牛魔拳\"} 6.4 反序列化 将json格式反序列化成对应的数据结构（结构体、map、Slice）。 err := json.Unmarshal([]byte(str), \u0026monster) 注意点： 反序列化一个json字符串时，需要保证反序列化后的数据类型和序列化前的数据类型一致**（结构体须保证字段完全一致）**。 json字符串如果是传输过来的（本来就是json字符串），无需进行转义处理。 /* 1. 反序列化为struct 2. 反序列化为map 3. 反序列化为slice */ // 1. 反序列化为 struct type Monster struct { Name string `json:\"name\" ` Age int `json:\"age\" ` Birthday string `json:\"birthday\"` Salary float64 `json:\"salary\"` Skill string `json:\"skill\"` } func unMarshalStruct() { // 1. 得到序列化后的字符串，比如网络传输过来的 str := \"{\\\"name\\\":\\\"牛魔王\\\",\\\"age\\\":18,\" + \"\\\"birthday\\\":\\\"2011-11-11\\\",\\\"salary\\\":3000,\\\"skill\\\":\\\"牛魔拳\\\"}\" monster := Monster{} err := json.Unmarshal([]byte(str), \u0026monster) if err != nil { fmt.Println(\"反序列化错误 err = \", err) } fmt.Printf(\"反序列化的结果：%v\\n\", monster) } // 2. 反序列化为Map func unMarshalMap() { str := \" {\\\"address\\\":\\\"洪崖洞\\\",\\\"age\\\":30,\\\"name\\\":\\\"红孩儿\\\"}\" a := map[string]interface{}{} err := json.Unmarshal([]byte(str), \u0026a) if err != nil { fmt.Println(\"反序列化失败 err = \", err) } fmt.Printf(\"序列化结果为：%v\\n\", a) } // 3. 反序列化为Slice func unMarshalSlice() { str := \"[{\\\"address\\\":[\\\"墨西哥\\\",\\\"夏威夷\\\"],\\\"age\\\":10,\" + \"\\\"name\\\":\\\"jack\\\"},{\\\"address\\\":\\\"南京\\\",\\\"age\\\":18,\\\"name\\\":\\\"chuyu\\\"}]\" slice := []map[string]interface{}{} err := json.Unmarshal([]byte(str), \u0026slice) if err != nil { fmt.Println(\"反序列化失败 err = \", err) } fmt.Printf(\"反序列化结果为：%v\\n\", slice) } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:6","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"7. 单元测试 测试一个函数是否有效，传统做法就是调用一下他，观察结果是否符合预期，但这样具有缺点： 不方便，还需要自己编写实例去测试，需要在main函数中调用代码，也就是需要去改动代码，若项目正在运行，那么有可能还需要停下项目； 不利于管理，当测试多个函数或模块时，都需要写在main函数，不利于管理。 Go带有一个轻量级的测试框架testing和自带的go test来实现单元测试和性能测试，testing框架和其它语言中的测试框架相似。 单元测试主要找到逻辑漏洞； 性能测试主要测试程序在高并发高压力环境下的运行状况。 testing 提供对 Go 包的自动化测试的支持。通过 go test 命令，能够自动执行如下形式的任何函数： func TestXxx(*testing.T) 其中 Xxx 可以是任何字母数字字符串（但第一个字母不能是 [a-z]），用于识别测试例程。 要编写一个新的测试套件，需要创建一个名称以 _test.go 结尾的文件，该文件包含 TestXxx 函数。 示例： 文件名格式：xxx_test.go package test import \"testing\" // 一个测试文件中可含有多个测试用例 // 1. 第一个测试函数 func addUpper(n int) int { res := 0 for i := 1; i \u003c= n; i++ { res += i } return res } // 第一个测试用例 func TestGetSub(t *testing.T) { res := getSub(10, 7) // 写在别的文件中 // 若错误 if res != 5 { t.Fatalf(\"getSub(10, 7) 执行错误 期望值 = %v 实际值 = %v\\n\", 5, res) } // 若正确 t.Logf(\"getSub(10, 7) 执行正确...\") } // 第二个测试用例 func TestAddUpper(t *testing.T) { // 调用 res := addUpper(10) // 若错误 if res != 55 { t.Fatalf(\"addUpper(10) 执行错误 期望值 = %v 实际值 = %v\\n\", 55, res) } // 若正确 t.Logf(\"addUpper(10) 执行正确...\") } // 不需要main函数 $ go test -v === RUN TestGetSub 09-add_test.go:19: getSub(10, 7) 执行错误 期望值 = 5 实际值 = 3 --- FAIL: TestGetSub (0.00s) === RUN TestAddUpper 09-add_test.go:33: addUpper(10) 执行正确... --- PASS: TestAddUpper (0.00s) FAIL exit status 1 FAIL goLearn/test 0.157s -v：无论正确与否，都输出日志 注意点： 测试文件名：xxx_test.go 测试用例名：func TestXxx(*testing.T) 若有多个测试文件，可以用go test -v 指定测试文件名 原文件测试指定的文件。 若一个测试文件中，有多个测试用例，可以用go test -v -test.run 测试用例函数名指定测试用例。 $ go test -v -test.run TestGetSub === RUN TestGetSub 09-add_test.go:19: getSub(10, 7) 执行错误 期望值 = 5 实际值 = 3 --- FAIL: TestGetSub (0.00s) FAIL exit status 1 FAIL goLearn/test 0.155s ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:7","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"8. 并发 8.1 引出 **进程：**程序在操作系统中的一次执行过程，是系统进行资源分配和调度的基本单位。 **线程：**是进程的一个执行实例，是程序执行的最小单元，它是比进程更小的能独立运行的基本单位。 关系： 一个进程可以创建和销毁多个线程，同一个进程中的多个线程可以并发执行。 一个程序至少有一个进程，一个进程至少有一个线程。 假设，需要统计1-900000000000000000的数字中，哪些是素数？ 若按传统遍历，需要一个循环，从头到尾 若按并发或并行，多个routine同时执行，将极大提升效率 8.2 goroutine 8.2.1 基础知识 **并发：多线程程序在单核上运行，就是并发。**一段时间内交替执行多个任务，但相同时间只能执行一个任务。（切换的很快，以至于让人感觉是\"同时\"进行） **并行：多线程程序在多核上运行。**多个任务同时进行。（多个CPU，同时执行各自的任务） C语言里面实现并发过程使用的是多线程（C++的最小资源单位），无法开启很多线程。 **Go主线程：**一个Go线程可以起多个goroutine，goroutine是轻量级的线程。 ==\u003e goroutine，每一个goroutine占用的系统资源远远小于线程，一个goroutine大约需要4k-5k的内存资源。一个程序可以启动大量的goroutine： 线程 ==\u003e 几十个 goroutine可以轻松启动成百上千上万个，==\u003e 对于实现高并发，性能非常好 只需要在目标函数前加上go关键字即可 关系： 主线程是一个物理线程，直接作用在CPU上，是重量级的，非常消耗CPU资源。 goroutine是从主线程开启的，是轻量级的线程，是逻辑态的，对资源消耗较小。 goroutine的特点（面试一定被问到）⭐⭐⭐： 有独立的栈空间，数据是独立的，不会打架； 共享程序堆空间； 调度由用户控制； 协程是轻量级的线程。 goroutined的调度模型MPG： M:操作系统的主线程（物理线程） P:协程执行需要的上下文 G:协程 8.2.2 demo /* 1. 在主线程开启一个goroutine，每一秒输出一个\"hello, world\" 2. 在主线程也每一秒输出一个\"hello, world\" 3. 要求：主线程和goroutine同时执行 */ func test() { for i := 0; i \u003c 10; i++ { fmt.Println(\"test() hello, world\" + strconv.Itoa(i)) time.Sleep(time.Second) } } func main() { // 1. 在主线程开启一个goroutine go test() // 2. 主线程的输出 for i := 0; i \u003c 10; i++ { fmt.Println(\"main() hello, world\" + strconv.Itoa(i)) time.Sleep(time.Second) } } $ go run 01-goroutinedemo.go main() hello, world0 test() hello, world0 test() hello, world1 main() hello, world1 main() hello, world2 test() hello, world2 ..... 可以看出，主线程和goroutine同时在执行，由此引发问题： 谁执行完触发程序退出？ 答：主线程执行完毕时，即使goroutine还未执行完毕，也依然会退出；goroutine执行完毕，主线程若还没执行完毕，依然会继续执行。因此，按照主线程为准。 8.3 设置运行的CPU数 在golang里，设置运行的CPU数目。 import \"runtime\" runtime.NumCPU() // 1. 返回机器的cpu个数 cpuNum := runtime.NumCPU() runtime.GOMAXPROCS(cpuNum) // 2. 设置CPU数目 runtime.GOMAXPROCS(cpuNum) go1.8后，默认程序运行于多核，不用手动设置 go1.8前，需要手动设置 8.4 channel 8.4.1 先看一个需求 **需求：**要计算1-200的各个数的阶乘，并且把各个数的阶乘放入到map中，最后显示出来。要求使用goroutine。 /* 思路： 1. 编写一个函数，计算阶乘，并放入map 2. 启动多个协程，统计结果放入map（全局共用） 3. 所有的协程都对同一个map进行操作，会造成资源竞争，因此需要对全局变量上锁 */ 8.4.2 上锁 import \"sync\" sync包提供了基本的同步基元，如互斥锁。除了Once和WaitGroup类型，大部分都是适用于低水平程序线程，高水平的同步使用channel通信更好一些。 var ( myMap = map[int]int{} // 3. 全局互斥锁 lock sync.Mutex ) func calculate(n int) { res := 1 for i := 1; i \u003c= n; i++ { res *= i } // 加锁 lock.Lock() myMap[n] = res // 解锁 lock.Unlock() } func main() { // 起了20个协程 for i := 1; i \u003c= 20; i++ { go calculate(i) } // 此处不能马上遍历，因为不一定执行完毕 time.Sleep(time.Second) for num, res := range myMap { fmt.Println(num, res) } } 低水平的，下面进一步 ==使用无缓冲Channel== package main /* 基于无缓冲的channel的main和 goroutine的同步 */ import ( \"io\" \"log\" \"net\" \"os\" ) func main() { conn, err := net.Dial(\"tcp\", \"127.0.0.1:8001\") if err != nil { log.Fatal(err) } done := make(chan string) // done := make(chan struct{}) go func() { io.Copy(os.Stdout, conn) log.Println(\"groutine: done!\") done \u003c- \"I am done\" // close(done) }() //从客户端输入,将客户端标输入的数据发给客户端套接字 io.Copy(conn, os.Stdin) conn.Close() //此时main要主动关闭conn, 否则goroutine里面的io.Copy()会一直阻塞等待conn log.Println(\"main wait goroutine...\") // 读阻塞在此处 \u003c-done log.Println(\"main: done!\") //这样我们就保证了 \"main::done!\"打印之前 一定先打印\"groutine:done!\" } 基于channels发送消息有两个重要方面。首先每个消息都有一个值，但是有时候通讯的事实和发生的时刻也同样重要。当我们更希望强调通讯发生的时刻时，我们将它称为消息事件。有些消息事件并不携带额外的信息，它仅仅是用作两个goroutine之间的同步，这时候我们可以用struct{}空结构体作为channels元素的类型，虽然也可以使用bool或int类型实现同样的功能，done \u003c- 1语句也比done \u003c- struct{}{}更短。 8.4.3 channel管道 为什么需要channel？ 主线程等待所有goroutine完成的时间很难确定，比如上例中设置了1s，仅仅是估算。 若主线程等待时间长了，则会延长程序运行时间；若等待时间短了，则有可能还有goroutine未完成，而主线程的结束将导致未完成的goroutine销毁。 通过加全局变量互斥锁来实现通讯，并不利于多个goroutine对全局变量的读写操作。 channel的特点 channel本质就是一个数据结构-队列； 数据是先进先出的； 是线程安全的，多goroutine访问时，不需要加锁，也不会发生资源竞争问题； channel是有类型的，一个string的channel只能存放string类型的数据。 基本语法 声明channel channel遍历 channel关闭 声明channel var chan名 chan 数据类型 chan名 := make(chan 数据类型, cap) // example var intChan chan int var mapChan chan map[int]string var perChan chan Person var perChan chan *Person var allChan chan interface{} 说明： channel是引用类型的； channel必须初始化才能写入数据，即必须make； channel是有类型的，即intChan只能写入int型。如果想啥类型都存，就声明成interface{}型，但是取的时候需要类型断言； 向channel写入数据时，不能超过其cap（不会自动扩充），否则会deadlock； 从channel读取数据时，不能chan","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:8","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9. reflect 9.1 引出 应用场景： 结构体的tag标签 编写函数的适配器，桥连接 …… 基本介绍： 反射可以在运行时动态获取变量的各种信息，比如变量的类型(type)，类别(kind)； 如果是结构体变量，还可以获取到结构体本身的信息（包括结构体的字段，方法）； 通过反射，可以修改变量的值，可以调用关联的方法； 使用反射，需要 import \"reflect\" 示意图 reflect包实现了运行时反射，允许程序操作任意类型的对象。 典型用法是用静态类型interface{}保存一个值， 通过调用TypeOf获取其动态类型信息，该函数返回一个Type类型值（和普通的Type不一样）； 调用ValueOf函数返回一个Value类型值（和普通的值不一样），该值代表运行时的数据，且可以利用很多方法获取信息； Zero接受一个Type类型参数并返回一个代表该类型零值的Value类型值。 9.2 快速入门 example1 演示对（基本数据类型、interface {}、reflect.Value）进行反射的基本操作。 // 1. example1 // 通过反射拿到data的type、kind、值 func reflectDemo1(data interface{}) { // 1. 获取reflect.Type refType := reflect.TypeOf(data) fmt.Println(\"refType:\", refType, \"refType's type:\", reflect.TypeOf(refType)) // 2. 获取reflect.Value refValue := reflect.ValueOf(data) fmt.Println(\"refValue:\", refValue) // 操作refValue numInt64 := int64(1) // 不能直接操作rVal类型 //num += refValue numInt64 += refValue.Int() fmt.Println(\"numInt64 =\", numInt64) // 3. 将rVal转成interface{} iv := refValue.Interface() // 将 interface{} 通过类型断言转成需要的类型 numInt := 1 numInt += iv.(int) fmt.Println(\"numInt =\", numInt) } func main() { // 1. example1 reflectDemo1(12) } example2 演示对（结构体、interface{}、reflect.Value）进行反射的基本操作。 func reflectDemo2(data interface{}) { // 1. 获取reflect.Type refType := reflect.TypeOf(data) fmt.Println(\"refType:\", refType, \" refType's type:\", reflect.TypeOf(refType)) // 2. 获取reflect.Value refValue := reflect.ValueOf(data) fmt.Println(\"refValue:\", refValue) // 3. 获取变量对应的Kind fmt.Printf(\"refType kind = %v\\n\", refType.Kind()) fmt.Printf(\"refValue kind = %v\\n\", refValue.Kind()) // 4. 转成 interface{} iv := refValue.Interface() fmt.Printf(\"iv = %v, iv type = %T\\n\", iv, iv) // 即使当前输出是Student类型，也不能取出数据 // 5. 通过类型断言转换成相应类型 stu := iv.(Student) fmt.Println(\"stu.Name =\", stu.Name, \", stu.Age =\", stu.Age) } func main() { // 2. example2 student := Student{ Name: \"Lily\", Age: 12, } reflectDemo2(student) } 9.3 通过反射修改值 传入指针，利用 rVal.Elem()得到指针指向的值，然后利用 Set 系列函数更改值。 // 通过反射，修改 num int 的值 func reflectDemo3(data interface{}) { rVal := reflect.ValueOf(data) fmt.Println(\"rVal kind =\", rVal.Kind()) // ptr // 这样是不行的，因为rVal是指针，需要先取到指针的值 //rVal.SetInt(20) rVal.Elem().SetInt(20) // .Elem() 可以获取ptr指向的值，然后再改 } func main() { num := 10 reflectDemo3(\u0026num) fmt.Println(\"num =\", num) } func main() { str := \"tom\" rVal := reflect.ValueOf(\u0026str) // 会报错 //rVal.SetString(\"lily\") rVal.Elem().SetString(\"lily\") fmt.Println(str) } 9.4 实战 9.4.1 example1 使用反射遍历结构体的字段，调用结构体的方法，并获取结构体标签的值。 rTyp := reflect.TypeOf(a) rVal := reflect.ValueOf(a) rVal.NumField() // 获取字段数 rVal.Field(i) // 获取第i个字段的值 rTyp.Field(i).Tag.Get(\"json\") // 获取第i个字段的json tag rVal.NumMethod() // 获取方法数 // Method调用方法时，按照函数字母(ASCII码)进行排序，和定义时候的顺序无关。 rVal.Method(1).Call(nil) // 调用第2个方法，并传入参数nil params := []reflect.Value{} rVal.Method(0).Call(params) // 传入的参数要是[]reflect.Value{}格式 // 1. 定义Monster结构体 type Monster struct { Name string `json:\"name,omitempty\"` Age int `json:\"age,omitempty\"` Score float64 Sex string } func (s Monster) Print() { fmt.Println(\"---start---\") fmt.Println(s) fmt.Println(\"---end---\") } func (s Monster) GetSum(n1, n2 int) int { return n1 + n2 } func (s *Monster) Set(name string, age int, score float64, sex string) { s.Name = name s.Age = age s.Score = score s.Sex = sex } // 2. 反射 func testStruct(a interface{}) { rTyp := reflect.TypeOf(a) rVal := reflect.ValueOf(a) rKd := rVal.Kind() if rKd != reflect.Struct { fmt.Println(\"expect struct...\") return } num := rVal.NumField() fmt.Printf(\"struct has %d fields.\\n\", num) for i := 0; i \u003c num; i++ { fmt.Printf(\"Field %d: 字段值 = %v.\\n\", i, rVal.Field(i)) tagVal := rTyp.Field(i).Tag.Get(\"json\") if tagVal != \"\" { fmt.Printf(\"Field %d: 字段tag = %v.\\n\", i, tagVal) } } numOfMethod := rVal.NumMethod() fmt.Printf(\"struct has %d methods.\\n\", numOfMethod) // Method调用方法时，按照函数字母(ASCII码)进行排序，和定义时候的顺序无关。 // 调用 Print 函数 rVal.Method(1).Call(nil) // 赋值 params := []reflect.Value{} params = append(params, reflect.ValueOf(10)) params = append(params, reflect.ValueOf(40)) // 调用 GetSum 函数 res := rVal.Method(0).Call(params) fmt.Println(\"res =\", res[0","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:9","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"10.init函数 init函数的主要特点： init函数先于main函数自动执行，不能被其他函数调用； init函数没有输入参数、返回值； 每个包可以有多个init函数； 包的每个源文件也可以有多个init函数，这点比较特殊； 同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序。 不同包的init函数按照包导入的依赖关系决定执行顺序。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:1:10","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"三、并发 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:2:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"1. 基础 并发：一段时间内交替执行多个任务，但相同时间只能执行一个任务。（切换的很快，以至于让人感觉是\"同时\"进行） 并行：多个任务同时进行。（多个CPU，同时执行各自的任务） C语言里面实现并发过程使用的是多线程（C++的最小资源单位），进程 Go语言里面不是线程，而是go程 == \u003e goroutine，每一个go程占用的系统资源远远小于线程，一个go程大约需要4k-5k的内存资源。一个程序可以启动大量的go程： 线程 ==\u003e 几十个 go程可以启动成百上千个，==\u003e 对于实现高并发，性能非常好 只需要在目标函数前加上go关键字即可 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:2:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"2. 提前退出 // GOEXIT ===\u003e 提前退出当前go程 // return ===\u003e 返回当前函数 // exit ===\u003e 退出当前进程 func main() { // 三个匿名函数 go func() { go func() { // 两个go程 func() { fmt.Println(\"这是子go程内部的函数! \") //return // 这是返回当前函数 其他函数依然会执行 包括外层的函数也会继续 因此fmt.Println(\"子go程结束! \")也会执行 //os.Exit(-1) // 这是退出进程 fmt.Println(\"子go程结束! \") 和 fmt.Println(\"Over! \")就不会执行了 runtime.Goexit() // 只是退出当前子go程！ 注意是当前！！ 只退出一层！ 不会执行 fmt.Println(\"子go程结束! \")和 fmt.Println(\"go程22222222222\") 但会继续执行 fmt.Println(\"go程11111111111\")和fmt.Println(\"Over! \") }() fmt.Println(\"子go程结束! \") fmt.Println(\"go程22222222222\") }() time.Sleep(2 * time.Second) fmt.Println(\"go程11111111111\") }() fmt.Println(\"这是主go程! \") time.Sleep(5 * time.Second) fmt.Println(\"Over! \") } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:2:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"3. 缓冲通道 sync.RWMutex{} 当C语言涉及多线程时，使用互斥量，通过上锁来保持资源同步，避免资源竞争问题 而go语言支持这种方式，但有更好的方式 ===\u003e 通道、管道（不需要自己进行加解锁） A往通道里写数据，B从通道里读数据。go自动帮我们做好数据同步 // 1. 无缓冲的通道 numChan := make(chan int) // 装数字的管道，使用管道时一定要make，同map一样，否则是nil // 2. 有缓冲的通道 numChan := make(chan int, 10) 有缓冲通道： 当缓冲写满后，写阻塞，当被读取后，再恢复写入 当缓冲读取完毕，读阻塞 如果管道没有使用make分配空间，那么管道默认是nil的，读取、写入都会阻塞 对于一个管道，读与写的次数要对等，否则会发生死锁。若不一致： 阻塞发生在主go程，那么程序将锁死崩溃 阻塞发生在子go程，那么会出现内存泄露，子go程会一直等待，当进程结束时，内存才能释放 numsChan1 := make(chan int, 10) // 写 go func() { for i := 0; i \u003c 50; i++ { numsChan1 \u003c- i fmt.Println(\"写入数据: \", i) } }() // 读 // 主程序的次数多 当主程序被通道阻塞时, 那么程序将锁死崩溃; 若是go程，将一直卡在go程，造成内存泄露 // 一定要读写次数一致 // 主go程 func() { for i := 0; i \u003c 60; i++ { fmt.Println(\"读数据: \", \u003c-numsChan1) } }() // 子go程 //go func() { // for i := 0; i \u003c 60; i++ { // fmt.Println(\"读数据: \", \u003c-numsChan1) // } //}() for { fmt.Println(\"子go程正在阻塞\") time.Sleep(3 * time.Second) } 为了避免不一致，在读取数据时可采用for-range读取管道。 // 遍历管道时，只返回一个值 // 问题是: for-range不知道管道是否已经写完，所以会一直等待写入 // 解决: 在写入端将管道关闭，for range遍历关闭管道时，会退出 // 遍历管道时，只返回一个值 // 问题是: for-range不知道管道是否已经写完，所以会一直等待写入 // 解决: 在写入端将管道关闭，for range遍历关闭管道时，会退出 func main() { numsChan2 := make(chan int, 10) // 写 go func() { for i := 0; i \u003c 50; i++ { numsChan2 \u003c- i fmt.Println(\"写入数据: \", i) } fmt.Println(\"数据写入完毕, 即将关闭管道! \") close(numsChan2) }() // 遍历管道时，只返回一个值 // 问题是: for-range不知道管道是否已经写完，所以会一直等待写入 // 解决: 在写入端将管道关闭，for range遍历关闭管道时，会退出 for v := range numsChan2 { fmt.Println(\"读取数据: \", v) } fmt.Println(\"Over!!!\") } 判断管道是否已经关闭： 需要知道一个管道的状态，如果已经关闭了，再进行写入或重复关闭将造成崩溃的风险。 map: ==\u003e v, ok := m1[0] channel: ==\u003e v, ok := \u003c- numChan ok-idom 模式判断 // 判断通道是否已经close //// 读 //for v := range numChan{ // fmt.Println(\"v: \", v) //} for { v, ok := \u003c-numChan // ok-idom 模式判断 if !ok { fmt.Println(\"管道已经关闭了!!! 准备退出!!! \") break } fmt.Println(\"v: \", v) // 加了读操作 } fmt.Println(\"Over!!! \") 单向通道： numChan := make(chan int, 10) ==\u003e 双向通道，既可以读，也可以写 单向通道：为了明确语义，一般用于函数参数 单向读通道：var numChanReadOnly \u003c- chan int 单向写通道：var numChanWriteOnly \u003c- chan int func main() { // 生产者消费者模型 // C: 数组+锁 thread1: 写， thread2: 读 // GO: goroutine + channel // 1. 在主函数中创建一个双向通道numChan numChan := make(chan int, 5) // 2. 将numChan 传递给producer，负责生产 go producer(numChan) // 双向通道可以赋值给同类型的单向通道，单向不能转双向 // 3. 将numChan 传递给consumer，负责消费 go consumer(numChan) time.Sleep(2 * time.Second) } // producer生产者 ==\u003e 提供一个只写通道 func producer(out chan\u003c- int) { for i := 0; i \u003c 10; i++ { out \u003c- i //data := \u003c- out // 会报错 写通道不允许有读取操作 fmt.Println(\"======\u003e 向管道中写入数据: \", i) } } // consunmer消费者 ==\u003e 提供一个只读通道 func consumer(in \u003c-chan int) { //in \u003c- 10 // 读通道不允许写数据 for v := range in { fmt.Println(\"从管道中读取数据: \", v) } } 管道总结： 管道写满 ==\u003e 写阻塞 管道读完 ==\u003e 读阻塞 如果管道没有使用make分配空间，则默认是nil 从nil的管道中读、写数据，都会阻塞（__注：__不会崩溃） 从一个已经close的管道读取数据时，会返回零值（__注：__不会崩溃；此处的零值并非普通int 0，而是逻辑假，可以终止for循环） 对一个已经close的管道进行关闭或写数据操作时，程序将崩溃 关闭管道的动作，一定要放在写端，不能放在读端（读端怎么知道什么时候写完呢？） 读和写的次数一定要对等，否则： 子go程中，资源泄露 主go程中，程序崩溃 (deadlock) ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:2:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"4. Select 当程序中有多个channel协同工作：ch1、ch2，某时刻ch1或ch2被触发，程序要做相应的处理。 使用select来监听多通道，当管道被触发时（写入数据、读取数据、关闭通道） select语法与switch case很像，但是所有的分支条件都必须是通道io func main() { // var chan1, chan2 chan int chan1 := make(chan int) chan2 := make(chan int) // 启动一个go程，负责监听两个channel go func() { for { fmt.Println(\"监听中.........\") select { case data1 := \u003c-chan1: fmt.Println(\" 从chan1读取数据成功, data1: \", data1) case data2 := \u003c-chan2: fmt.Println(\"------------\u003e 从chan2读取数据成功, data2: \", data2) default: // 没触发上边的就触发default fmt.Println(\"select default called\") time.Sleep(time.Second) } } }() // 启动go1 写chan1 go func() { for i := 0; i \u003c 10; i++ { chan1 \u003c- i time.Sleep(1 * time.Second / 2) } }() // 启动go2 写chan2 go func() { for i := 0; i \u003c 10; i++ { chan2 \u003c- i time.Sleep(1 * time.Second) } }() for { fmt.Println(\"Over!!! \") time.Sleep(5 * time.Second) } } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:2:4","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"四、网络编程（韩） ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:3:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"4.1 基础知识 端口： 在计算机（尤其是做服务器），要尽可能少开端口 一个端口只能被一个程序监听 可以使用 netstat -an 查看本机有哪些端口在监听 可以使用 netstat -anb 查看监听端口的pid，再结合任务管理器关闭不安全的端口 服务端需要起多个goroutine处理多个客户端的请求。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:3:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"4.2 实例 服务器： 可连接多个客户端； 可多次接收客户端发送消息； 接收 exit 关闭连接。 客户端： 可多次发送消息； 发送 exit 关闭连接。 server.go func serverDemo() { fmt.Println(\"服务器开始监听......\") // 1. 开启一个监听端口 listener, err := net.Listen(\"tcp\", \"0.0.0.0:8888\") if err != nil { fmt.Println(\"listen err =\", err) return } defer listener.Close() fmt.Println(\"listener is:\", listener) // 2. 等待连接 for { fmt.Println(\"等待客户端连接......\") conn, err := listener.Accept() if err != nil { fmt.Println(\"accept err =\", err) } fmt.Println(\"conn is:\", conn) fmt.Println(\"该连接的客户端ip =\", conn.RemoteAddr()) // 获得客户端的ip地址 // 接收数据 go serverProcess(conn) } } // 接收客户端数据 func serverProcess(conn net.Conn) { // 循环接收 defer conn.Close() // 一定要记得关闭 fmt.Printf(\"server 等待 客户端:%v 发送信息......\\n\", conn.RemoteAddr()) for { // 创建切片，用来接收 buf := make([]byte, 1024) // 1. 等待客户端通过conn发送信息 // 2. 如果客户端没有write[发送信息]，那么协程就阻塞在这里 n, err := conn.Read(buf) if err != nil { fmt.Println(\"server conn.Read err =\", err) return } //fmt.Println(\"读取message长度为:\", n) // 显示message message := string(buf[:n]) // 注意要[:n] fmt.Printf(\"信息: %v 来自客户端:%v\\n\", message, conn.RemoteAddr()) if message == \"exit\" { break } } fmt.Printf(\"客户端: %v 退出......\\n\", conn.RemoteAddr()) } func main() { serverDemo() } client.go func clientDemo() { conn, err := net.Dial(\"tcp\", \"192.168.0.108:8888\") if err != nil { fmt.Println(\"client dial err =\", err) return } fmt.Println(\"client conn is:\", conn) clientProcess(conn) } func clientProcess(conn net.Conn) { defer conn.Close() for { fmt.Print(\"请输入要发送的信息: \") // 功能1：客户端发送单行数据，然后退出 reader := bufio.NewReader(os.Stdin) // os.Stdin 代表标准输入（终端） // 从终端读取一行用户输入，并准备发给服务器 message, err := reader.ReadString('\\n') // 会多读一个'\\n' if err != nil { fmt.Println(\"ReadString err =\", err) } message = strings.Trim(message, \" \\r\\n\") // 删掉 \" \\r\\n\" // 再将message发送给服务器 n, err := conn.Write([]byte(message)) if err != nil { fmt.Println(\"conn.Write err =\", err) } fmt.Printf(\"message长度为%v 发送成功......\\n\", n) // 当输入 exit 退出 if message == \"exit\" { break } } fmt.Println(\"客户端退出......\") } func main() { clientDemo() } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:3:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"五、Redis ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:4:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5.1 基本介绍 Redis(REmote Dictionary Server(远程字典服务器)) 是NoSQL数据库，不是传统关系型数据库，也被称为数据结构数据库。 性能非常高，通常用作缓存、持久化。 开源，分布式，基于内存运行并支持持久化。 Redis的五大数据类型： String（字符串） Hash（哈希） List（列表） Set（集合） zset（sorted set: 有序集合） ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:4:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5.2 安装配置 下载后直接解压就有Redis的服务端程序(redis-server.exe)和客户端程序(redis-cli.exe)，双击直接运行，无需安装。 Redis操作原理图： 双击打开 redis-server.exe。 然后打开 redis-cli.exe 即可连接上。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:4:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5.3 基本使用 Redis使用手册：http://doc.redisfans.com/ 说明： Redis安装好后，默认有16个数据库，初始默认使用0号库，编号是0…15. 添加 key-value [set] 查看当前redis的所有 key [keys *] 获取 key 对应的值 切换 redis 数据库 [select index] 如何查看当前数据库的 key-val 数量 [dbsize] 清空当前数据库的 key-val 和 清空所有数据库的 key-val [flushdb] [flushall] 127.0.0.1:6379\u003e set key1 hello OK 127.0.0.1:6379\u003e keys * 1) \"key1\" 127.0.0.1:6379\u003e get key1 \"hello\" 127.0.0.1:6379\u003e select 1 OK 127.0.0.1:6379[1]\u003e keys * (empty list or set) 127.0.0.1:6379[1]\u003e select 0 OK 127.0.0.1:6379\u003e dbsize (integer) 1 127.0.0.1:6379\u003e flushdb OK 127.0.0.1:6379\u003e keys * (empty list or set) ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:4:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5.4 Redis的Crud操作 5.4.1 基本数据类型 Redis的五大数据类型： String（字符串） Hash（哈希） List（列表） Set（集合） zset（sorted set: 有序集合） 5.4.2 String 127.0.0.1:6379\u003e set address beijing OK 127.0.0.1:6379\u003e get address \"beijing\" 127.0.0.1:6379\u003e del address (integer) 1 127.0.0.1:6379\u003e get address (nil) **注意：**此处的 set，如果存在就是修改，如果不存在就是添加。 增改：set 查：get 删：del 限时的键值对：setex key seconds value 127.0.0.1:6379\u003e setex message 6 hello OK 127.0.0.1:6379\u003e get message \"hello\" # 6s 后 127.0.0.1:6379\u003e get message (nil) 同时设置多个键值对：mset key1 value1 key2 value2 同时获取多个键值对：mget key1 key2 127.0.0.1:6379\u003e mset key1 hello key2 world OK 127.0.0.1:6379\u003e keys * 1) \"key2\" 2) \"key1\" 127.0.0.1:6379\u003e get key1 \"hello\" 127.0.0.1:6379\u003e get key2 \"world\" 127.0.0.1:6379\u003e mget key1 key2 1) \"hello\" 2) \"world\" 5.4.3 Hash（类似map） Redis hash 是一个键值对(key-value)集合(key 不能重复)。是一个string类型的field和value的映射表，hash特别适合用于存储对象。例如存放一个user信息： key: user1 value: name “smith” age 30 job “coder” # 这就是三对field-value 增改：hset key field value 查：hget key field value 删：hdel key field.. 同时设置多个field-value对：hmset key field value field value.. 同时获取多个field-value对：hmget key field.. 获取该key的所有信息：hgetall key 获取某key的field数：hlen key 判断某key的某field是否存在：hexists key field 127.0.0.1:6379\u003e hset user1 name \"smith\" (integer) 1 127.0.0.1:6379\u003e hset user1 age 30 (integer) 1 127.0.0.1:6379\u003e hset user1 job coder (integer) 1 127.0.0.1:6379\u003e hget user1 name \"smith\" 127.0.0.1:6379\u003e hget user1 job \"coder\" 127.0.0.1:6379\u003e hget user1 age \"30\" 127.0.0.1:6379\u003e hgetall user1 1) \"name\" 2) \"smith\" 3) \"age\" # 前边的是field，下边是value 4) \"30\" 5) \"job\" 6) \"coder\" 127.0.0.1:6379\u003e hdel user1 name age job (integer) 3 127.0.0.1:6379\u003e hmset user1 name jerry age 24 job \"java coder\" OK 127.0.0.1:6379\u003e hmget user1 name age job 1) \"jerry\" 2) \"24\" 3) \"java coder\" 127.0.0.1:6379\u003e hlen user1 (integer) 3 127.0.0.1:6379\u003e hexists user1 name (integer) 1 127.0.0.1:6379\u003e hexists user1 work (integer) 0 由上述输出也可看出，当redis存储的时候，类型都是string。 5.4.4 List List是简单的字符串列表，按照插入顺序排序。**可以头插和尾插。**List本质是个链表，List的元素是有序的，且可以重复。 增改：lpush key value../rpush key value..。 查：lrange key start stop，返回列表key中指定区间的元素，0表示第一个，-1表示最后一个，以此类推。 ​ lpop key/rpop key，弹出左/右栈顶元素（查看并删除）。 删：del key..，删除多个List。 查看List的长度：llen key，若不存在，返回0。 127.0.0.1:6379\u003e lpush city beijing shanghai tianjin (integer) 3 127.0.0.1:6379\u003e lrange city 0 -1 1) \"tianjin\" 2) \"shanghai\" 3) \"beijing\" # 发现没？是倒着的，相当于栈(右边是底)。 127.0.0.1:6379\u003e lpush heroList aaa bbb ccc (integer) 3 127.0.0.1:6379\u003e lrange heroList 0 -1 1) \"ccc\" 2) \"bbb\" 3) \"aaa\" 127.0.0.1:6379\u003e rpush heroList ddd eee (integer) 5 127.0.0.1:6379\u003e lrange heroList 0 -1 1) \"ccc\" 2) \"bbb\" 3) \"aaa\" 4) \"ddd\" 5) \"eee\" 127.0.0.1:6379\u003e lpop heroList \"ccc\" 127.0.0.1:6379\u003e rpop heroList \"eee\" 127.0.0.1:6379\u003e lrange heroList 0 -1 1) \"bbb\" 2) \"aaa\" 3) \"ddd\" 127.0.0.1:6379\u003e del heroList (integer) 1 127.0.0.1:6379\u003e lpop heroList (nil) 127.0.0.1:6379\u003e llen heroList (integer) 0 127.0.0.1:6379\u003e lpush heroList aaa bbb ccc (integer) 3 127.0.0.1:6379\u003e llen heroList (integer) 3 5.4.5 Set（集合） Redis的Set是string类型的无序集合。底层是HashTable数据结构，Set也是存放很多字符串元素，但字符串元素是无序的，且元素不可重复。 增改：sadd key member.. 查：smembers key 删：del key 判断是否存在某个member：sismember key member 删除指定member：srem key member.. 127.0.0.1:6379\u003e sadd emails tom@sohu.com jack@qq.com (integer) 2 127.0.0.1:6379\u003e smembers emails 1) \"jack@qq.com\" 2) \"tom@sohu.com\" 127.0.0.1:6379\u003e sadd emails aaa@bbb.com ccc@ddd.com (integer) 2 127.0.0.1:6379\u003e smembers emails 1) \"ccc@ddd.com\" 2) \"jack@qq.com\" 3) \"aaa@bbb.com\" 4) \"tom@sohu.com\" 127.0.0.1:6379\u003e del emails (integer) 1 127.0.0.1:6379\u003e smembers emails (empty list or set) 127.0.0.1:6379\u003e sadd emails tom@sohu.com jack@qq.com (integer) 2 127.0.0.1:6379\u003e sismember emails tom@sohu.com (integer) 1 127.0.0.1:6379\u003e srem emails tom@sohu.com (integer) 1 127.0.0.1:6379\u003e sismember emails tom@sohu.com (integer) 0 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:4:4","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5.5 Golang操作Redis 5.5.1 安装 安装第三方开源的Redis库： go get github.com/gomodule/redigo/redis 5.5.2 基本操作 其实和直接用redis-cli一样，只不过是把命令写在 conn.Do(\"命令\", )，然后各参数本来是按空格分开的，现在改成逗号隔开。 5.5.2.1 添加和获取key-value 建立连接： conn, err := redis.Dial(\"tcp\", \"127.0.0.1:6379\") if err != nil { fmt.Println(\"redis.Dial err =\", err) return } defer conn.Close() 写数据： // 2. 通过go 向redis写入数据 string [key-value] _, err = conn.Do(\"set\", \"name\", \"tomjerry\") if err != nil { fmt.Println(\"set err =\", err) return } 读数据： // 3. 读取数据 string [key-value] r, err := redis.String(conn.Do(\"get\", \"name\")) // 转换成string if err != nil { fmt.Println(\"get err =\", err) return } fmt.Println(\"操作ok，返回数据:\", r) 5.5.2.2 操作hash func operateHash() { // 1. 连接到redis conn, err := redis.Dial(\"tcp\", \"127.0.0.1:6379\") if err != nil { fmt.Println(\"redis.Dial err =\", err) return } defer conn.Close() //fmt.Println(\"redis conn is\", conn) // 2. 通过go 向redis写入数据 hset [key-field-value] /* // 单个添加 _, err = conn.Do(\"hset\", \"user1\", \"name\", \"tomjerry\") if err != nil { fmt.Println(\"hset err =\", err) return } _, err = conn.Do(\"hset\", \"user1\", \"age\", \"20\") if err != nil { fmt.Println(\"hset err =\", err) return }*/ // 批量添加 _, err = conn.Do(\"hmset\", \"user2\", \"name\", \"john\", \"age\", \"18\") if err != nil { fmt.Println(\"hmset err =\", err) return } // 3. 读取数据 string [key-value] /* // 单个读取 r1, err := redis.String(conn.Do(\"hget\", \"user1\", \"name\")) // 转换成string if err != nil { fmt.Println(\"hget err =\", err) return } r2, err := redis.Int(conn.Do(\"hget\", \"user1\", \"age\")) // 转换成string if err != nil { fmt.Println(\"hget err =\", err) return } fmt.Printf(\"操作ok，返回数据: %v: %v\\n\", r1, r2)*/ // 批量读取 r, err := redis.Strings(conn.Do(\"hmget\", \"user2\", \"name\", \"age\")) // 转换成string if err != nil { fmt.Println(\"hmget err =\", err) return } for i, v := range r { fmt.Printf(\"%v: %v\\n\", i, v) } } 5.5.3 连接池 上面的操作，需要每次都新开一个conn连接，然后用完就关闭。其实这样很浪费资源，因此采用Redis连接池。 说明： 事先初始化一定数量的连接，放入连接池，即初始化连接池； 当Go需要操作Redis时，就从连接池取出一个conn即可； 等到完全不需要了，关闭连接池； 这样可以节省临时建立conn的时间，提高效率。 核心代码： // 定义一个全局pool var pool *redis.Pool func init() { pool = \u0026redis.Pool{ Dial: func() (redis.Conn, error) { // 初始化连接的代码，连接哪个ip，端口 return redis.Dial(\"tcp\", \"localhost:6379\") }, TestOnBorrow: nil, MaxIdle: 8, // 最大空闲连接数 MaxActive: 0, // 表示和数据库的最大连接数，0表示没有限制 IdleTimeout: 100, // 最大空闲时间 Wait: false, MaxConnLifetime: 0, } } func operatePool() { // 先从一个pool取出一个连接 conn := pool.Get() defer conn.Close() _, err := conn.Do(\"set\", \"name\", \"tom\") if err != nil { fmt.Println(\"set err =\", err) return } r, err := redis.String(conn.Do(\"get\", \"name\")) if err != nil { fmt.Println(\"get err =\", err) return } fmt.Println(\"get r =\", r) // 关闭pool pool.Close() conn = pool.Get() // 此时取不出了，因为pool已关闭 } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:4:5","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"六、MySQL Go语言中的database/sql包提供了保证SQL或类SQL数据库的泛用接口，并不提供具体的数据库驱动。使用database/sql包时必须注入（至少）一个数据库驱动。 我们常用的数据库基本上都有完整的第三方实现。例如：MySQL驱动 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:5:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"6.1 安装配置 下载MySQL https://dev.mysql.com/downloads/windows/installer/8.0.html 选择8.0版本下载。 下载驱动 go get -u github.com/go-sql-driver/mysql 导入驱动 import ( \"database/sql\" _ \"github.com/go-sql-driver/mysql\" ) ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:5:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"6.2 基础操作 6.2.1 准备database create database go_db; use go_db; create table user_tb1(id integer primary key auto_increment, username varchar(20), password varchar(20)); insert into user_tb1(username, password) values(\"tom\", \"123\"); insert into user_tb1(username, password) values(\"kite\", \"456\"); select * from user_tb1; 6.2.2 初始化连接 Open函数可能只是验证其参数格式是否正确，实际上并不创建与数据库的连接。如果要检查数据源的名称是否真实有效，应该调用Ping方法。 返回的DB对象可以安全地被多个goroutine并发使用，并且维护其自己的空闲连接池。因此，Open函数应该仅被调用一次，很少需要关闭这个DB对象。 dsn := \"user:password@tcp(127.0.0.1:3306)/dbname\" db, err := sql.Open(\"mysql\", dsn) if err != nil { panic(err) } defer db.Close() 接下来定义一个全局变量db，用来保存数据库连接对象。 var db *sql.DB func initDB() (err error) { dsn := \"root:123456@tcp(127.0.0.1:3306)/go_db?charset=utf8mb4\u0026parseTime=True\" // 不会校验账号密码是否正确 // 注意此处不用：:= db, err = sql.Open(\"mysql\", dsn) if err != nil { return err } // 尝试与数据库建立连接 err = db.Ping() if err != nil { return err } return nil } func main() { err := initDB() if err != nil { fmt.Println(\"init db failed, err:\", err) return } } 其中，sql.DB是表示连接的数据库对象（结构体实例），它保存了连接数据库相关的所有信息。它内部维护着一个具有零到多个底层连接的连接池，它可以安全地被多个goroutine同时使用。 其他初始化函数 SetMaxOpenConns func (db *DB) SetMaxOpenConns(n int) SetMaxOpenConns设置与数据库建立连接的最大数目。 如果n大于0且小于最大闲置连接数，会将最大闲置连接数减小到匹配最大开启连接数的限制。 如果n\u003c=0，不会限制最大开启连接数，默认为0（无限制）。 SetMaxIdleConns func (db *DB) SetMaxIdleConns(n int) SetMaxIdleConns设置连接池中的最大闲置连接数。 如果n大于最大开启连接数，则新的最大闲置连接数会减小到匹配最大开启连接数的限制。 如果n\u003c=0，不会保留闲置连接。 6.2.3 Crud 事先我们已经准备好了一个go_db用于测试。 6.2.3.1 查询数据 分为两种： 单行查询 多行查询 通常查询数据前，要先定义结构体来接收数据。 // 先定义一个结构体，用于接收数据 type User struct { id int username string password string } 单行查询 单行查询db.QueryRow()执行一次查询，并期望返回最多一行结果（即Row）。QueryRow总是返回非nil的值，直到返回值的Scan方法被调用时，才会返回被延迟的错误。（如：未找到结果） func (db *DB) QueryRow(query string, args ...interface{}) *Row // 1.1 查询单行数据 func queryOneRow() { s := \"select * from user_tb1 where id = ?\" user := User{} // 非常重要：确保QueryRow之后调用Scan方法，否则持有的数据库链接不会被释放 err := db.QueryRow(s, 1).Scan(\u0026user.id, \u0026user.username, \u0026user.password) if err != nil { fmt.Println(\"queryOneRow failed, err:\", err) return } fmt.Println(\"query result:\", user) } 多行查询 多行查询db.Query()执行一次查询，返回多行结果（即Rows），一般用于执行select命令。参数args表示query中的占位参数。 func (db *DB) Query(query string, args ...interface{}) (*Rows, error) // 1.2 多行查询 func queryRows() { s := \"select * from user_tb1 where id \u003e ?\" rows, err := db.Query(s, 0) // 取出 id \u003e 0 的 row if err != nil { fmt.Println(\"queryRows failed, err:\", err) return } defer rows.Close() // 循环读取 for rows.Next() { user := User{} err = rows.Scan(\u0026user.id, \u0026user.username, \u0026user.password) if err != nil { fmt.Println(\"scan failed, err:\", err) return } fmt.Println(\"query result:\", user) } } 6.2.3.2 插入数据 插入、更新和删除操作都使用Exec方法。 func (db *DB) Exec(query string, args ...interface{}) (Result, error) // 2. 插入数据 func insert() { s := \"insert into user_tb1 (username, password) values(?, ?)\" r, err := db.Exec(s, \"jerry\", \"789\") if err != nil { fmt.Println(\"insert failed, err:\", err) return } theId, _ := r.LastInsertId() // 新插入数据的id fmt.Printf(\"insert %v success...\", theId) } 6.2.3.3 更新数据 // 3. 更新数据 func updateRow() { s := \"update user_tb1 set username=?, password=? where id=?\" ret, err := db.Exec(s, \"chuu\", \"0404\", 1) if err != nil { fmt.Println(\"update failed, err:\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Println(\"get rowAffected failed, err:\", err) return } fmt.Println(\"update success, affected rows:\", n) } 6.2.3.4 删除数据 // 4. 删除数据 func deleteRow() { s := \"delete from user_tb1 where id=?\" ret, err := db.Exec(s, 2) if err != nil { fmt.Println(\"delete failed, err:\", err) return } n, err := ret.RowsAffected() if err != nil { fmt.Println(\"get rowAffected failed, err:\", err) return } fmt.Println(\"delete success, affected rows:\", n) } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:5:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"七、MongoDB mongoDB是目前比较流行的一个基于分布式文件存储的数据库。mongoDB中将一条数据存储为一个文档（document），数据结构由键值（key-value）对组成。 其中文档类似于我们平常编程中用到的JSON对象。 文档中的字段值可以包含其他文档，数组及文档数组。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:6:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"7.1 相关概念 MongoDB术语/概念 说明 对比SQL术语/概念 database 数据库 database collection 集合 table document 文档 row field 字段 column index index 索引 primary key 主键 MongoDB自动将_id字段设置为主键 primary key ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:6:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"7.2 常用命令 7.1 collection # 1. 创建新collection \u003e db.createCollection(\"student\"); { \"ok\" : 1 } # 2. 查看所有collection \u003e show collections; student # 3. 删除某条collection \u003e db.student.drop(); true \u003e show collections; \u003e 7.2 document # 1. 插入一条document \u003e db.student.insertOne({name:\"小王子\", age:18}); { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"62e251bd229c90eb53214c33\") } # 2. 插入多条document \u003e db.student.insertMany([ ... {name:\"张三\", age:20}, ... {name:\"李四\", age:25}, ... ]) { \"acknowledged\" : true, \"insertedIds\" : [ ObjectId(\"62e25228229c90eb53214c34\"), ObjectId(\"62e25228229c90eb53214c35\") ] } # 3. 查找student的所有document \u003e db.student.find() { \"_id\" : ObjectId(\"62e251bd229c90eb53214c33\"), \"name\" : \"小王子\", \"age\" : 18 } { \"_id\" : ObjectId(\"62e25228229c90eb53214c34\"), \"name\" : \"张三\", \"age\" : 20 } { \"_id\" : ObjectId(\"62e25228229c90eb53214c35\"), \"name\" : \"李四\", \"age\" : 25 } # 4. 查找age\u003e20的所有document \u003e db.student.find( ... {age:{$gt:20}} ... ) { \"_id\" : ObjectId(\"62e25228229c90eb53214c35\"), \"name\" : \"李四\", \"age\" : 25 } # 5. 更新document \u003e db.student.update( ... {name:\"小王子\"}, ... {name:\"老王子\",age:98} ... ); WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 }) \u003e db.student.find(); { \"_id\" : ObjectId(\"62e251bd229c90eb53214c33\"), \"name\" : \"老王子\", \"age\" : 98 } { \"_id\" : ObjectId(\"62e25228229c90eb53214c34\"), \"name\" : \"张三\", \"age\" : 20 } { \"_id\" : ObjectId(\"62e25228229c90eb53214c35\"), \"name\" : \"李四\", \"age\" : 25 } # 6. 删除document \u003e db.student.deleteOne({name:\"李四\"}); { \"acknowledged\" : true, \"deletedCount\" : 1 } \u003e db.student.find(); { \"_id\" : ObjectId(\"62e251bd229c90eb53214c33\"), \"name\" : \"老王子\", \"age\" : 98 } { \"_id\" : ObjectId(\"62e25228229c90eb53214c34\"), \"name\" : \"张三\", \"age\" : 20 } 更多命令见：官方文档：shell命令和官方文档：CRUD操作。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:6:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"7.3 Go操作MongoDB 安装mongoDB Go驱动包 go get github.com/mongodb/mongo-go-driver 7.3.1 初始化 启动连接： var client *mongo.Client func initDB() error { // 设置客户端连接 clientOptions := options.Client().ApplyURI(\"mongodb://root:123456@127.0.0.1:27017\") // 连接到db c, err := mongo.Connect(context.TODO(), clientOptions) if err != nil { log.Fatalln(err) return err } else { fmt.Printf(\"client: %v\\n\", c) } err = c.Ping(context.TODO(), nil) if err != nil { log.Fatalln(err) return err } else { fmt.Println(\"连接成功!\") } client = c return nil } 关闭连接： func mongoClose() { err := client.Disconnect(context.TODO()) if err != nil { log.Fatalln(err) } fmt.Println(\"Connection to MongoDB closed.\") } 连接池模式： func connectToDB(uri, name string, timeout time.Duration, num uint64) (*mongo.Database, error) { ctx, cancel := context.WithTimeout(context.Background(), timeout) defer cancel() o := options.Client().ApplyURI(uri) o.SetMaxPoolSize(num) client, err := mongo.Connect(ctx, o) if err != nil { return nil, err } return client.Database(name), nil } 7.3.2 BSON MongoDB中的JSON文档存储在名为BSON(二进制编码的JSON)的二进制表示中。与其他将JSON数据存储为简单字符串和数字的数据库不同，BSON编码扩展了JSON表示，使其包含额外的类型，如int、long、date、浮点数和decimal128。这使得应用程序更容易可靠地处理、排序和比较数据。 连接MongoDB的Go驱动程序中有两大类型表示BSON数据：D和Raw。 类型D家族被用来简洁地构建使用本地Go类型的BSON对象。这对于构造传递给MongoDB的命令特别有用。D家族包括四类: D：一个BSON文档。这种类型应该在顺序重要的情况下使用，比如MongoDB命令。 M：一张无序的map。它和D是一样的，只是它不保持顺序。 A：一个BSON数组。 E：D里面的一个元素。 要使用BSON，需要先导入下面的包： import \"go.mongodb.org/mongo-driver/bson\" 下面是一个使用D类型构建的过滤器文档的例子，它可以用来查找name字段与’张三’或’李四’匹配的文档: bson.D{{ \"name\", bson.D{{ \"$in\", bson.A{\"张三\", \"李四\"}, }}, }} Raw类型家族用于验证字节切片。你还可以使用Lookup()从原始类型检索单个元素。如果你不想要将BSON反序列化成另一种类型的开销，那么这是非常有用的。这个教程我们将只使用D类型。 7.3.3 Crud 首先，定义一个Student类型： ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:6:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"八、Template html/template包实现了数据驱动的模板，用于生成可防止代码注入的安全的HTML内容。它提供了和text/template包相同的接口，Go语言中输出HTML的场景都应使用html/template这个包。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:7:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"8.1 模板与渲染 在一些前后端不分离的Web架构中，我们通常需要在后端将一些数据渲染到HTML文档中，从而实现动态的网页（网页的布局和样式大致一样，但展示的内容并不一样）效果。 我们这里说的模板可以理解为事先定义好的HTML文档文件，模板渲染的作用机制可以简单理解为文本替换操作–使用相应的数据去替换HTML文档中事先准备好的标记。 很多编程语言的Web框架中都使用各种模板引擎，比如Python语言中Flask框架中使用的jinja2模板引擎。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:7:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"8.2 Go语言的模板引擎 Go语言内置了文本模板引擎text/template和用于HTML文档的html/template。它们的作用机制可以简单归纳如下： 模板文件通常定义为.tmpl和.tpl为后缀（也可以使用其他的后缀），必须使用UTF8编码。 模板文件中使用{{和}}包裹和标识需要传入的数据。 传给模板这样的数据就可以通过点号（.）来访问，如果数据是复杂类型的数据，可以通过{ { .FieldName }}来访问它的字段。 除{{和}}包裹的内容外，其他内容均不做修改原样输出。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:7:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"8.3 模板引擎的使用 Go语言模板引擎的使用可以分为三部分：定义模板文件、解析模板文件和模板渲染. 8.3.1 定义模板文件 其中，定义模板文件时需要我们按照相关语法规则去编写，后文会详细介绍。 8.3.2 解析模板文件 上面定义好了模板文件之后，可以使用下面的常用方法去解析模板文件，得到模板对象： func (t *Template) Parse(src string) (*Template, error) func ParseFiles(filenames ...string) (*Template, error) func ParseGlob(pattern string) (*Template, error) 当然，你也可以使用func New(name string) *Template函数创建一个名为name的模板，然后对其调用上面的方法去解析模板字符串或模板文件。 8.3.3 模板渲染 渲染模板简单来说就是使用数据去填充模板，当然实际上可能会复杂很多。 func (t *Template) Execute(wr io.Writer, data interface{}) error func (t *Template) ExecuteTemplate(wr io.Writer, name string, data interface{}) error 8.3.4 基本示例 8.3.4.1 定义模板文件 我们按照Go模板语法定义一个hello.tmpl的模板文件，内容如下： \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"\u003e \u003ctitle\u003eHello\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eHello {{.}}\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 8.3.4.2 解析和渲染模板文件 然后我们创建一个main.go文件，在其中写下HTTP server端代码如下： // main.go func sayHello(w http.ResponseWriter, r *http.Request) { // 解析指定文件生成模板对象 tmpl, err := template.ParseFiles(\"./hello.tmpl\") if err != nil { fmt.Println(\"create template failed, err:\", err) return } // 利用给定数据渲染模板，并将结果写入w tmpl.Execute(w, \"沙河小王子\") } func main() { http.HandleFunc(\"/\", sayHello) err := http.ListenAndServe(\":9090\", nil) if err != nil { fmt.Println(\"HTTP server failed,err:\", err) return } } 将上面的main.go文件编译执行，然后使用浏览器访问http://127.0.0.1:9090就能看到页面上显示了“Hello 沙河小王子”。 这就是一个最简单的模板渲染的示例，Go语言模板引擎详细用法请往下阅读。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:7:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"8.4 模板语法 8.4.1 {{.}} 模板语法都包含在{{和}}中间，其中{{.}}中的点表示当前对象。 当我们传入一个结构体对象时，我们可以根据.来访问结构体的对应字段。例如： // main.go type UserInfo struct { Name string Gender string Age int } func sayHello(w http.ResponseWriter, r *http.Request) { // 解析指定文件生成模板对象 tmpl, err := template.ParseFiles(\"./hello.tmpl\") if err != nil { fmt.Println(\"create template failed, err:\", err) return } // 利用给定数据渲染模板，并将结果写入w user := UserInfo{ Name: \"小王子\", Gender: \"男\", Age: 18, } tmpl.Execute(w, user) } 模板文件hello.tmpl内容如下： \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"\u003e \u003ctitle\u003eHello\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eHello {{.Name}}\u003c/p\u003e \u003cp\u003e性别：{{.Gender}}\u003c/p\u003e \u003cp\u003e年龄：{{.Age}}\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 同理，当我们传入的变量是map时，也可以在模板文件中通过.根据key来取值。 8.4.2 注释 {{/* a comment */}} 注释，执行时会忽略。可以多行。注释不能嵌套，并且必须紧贴分界符始止。 8.4.3 pipeline pipeline是指产生数据的操作。比如{{.}}、{{.Name}}等。Go的模板语法中支持使用管道符号|链接多个命令，用法和unix下的管道类似：|前面的命令会将运算结果(或返回值)传递给后一个命令的最后一个位置。 **注意：**并不是只有使用了|才是pipeline。Go的模板语法中，pipeline的概念是传递数据，只要能产生数据的，都是pipeline。 8.4.4 变量 我们还可以在模板中声明变量，用来保存传入模板的数据或其他语句生成的结果。具体语法如下： $obj := {{.}} 其中$obj是变量的名字，在后续的代码中就可以使用该变量了。 8.4.5 移除空格 有时候我们在使用模板语法的时候会不可避免的引入一下空格或者换行符，这样模板最终渲染出来的内容可能就和我们想的不一样，这个时候可以使用{{-语法去除模板内容左侧的所有空白符号， 使用-}}去除模板内容右侧的所有空白符号。 例如： {{- .Name -}} 注意：-要紧挨{{和}}，同时与模板值之间需要使用空格分隔。 8.4.6 条件判断 Go模板语法中的条件判断有以下几种: {{if pipeline}} T1 {{end}} {{if pipeline}} T1 {{else}} T0 {{end}} {{if pipeline}} T1 {{else if pipeline}} T0 {{end}} 8.4.7 range Go的模板语法中使用range关键字进行遍历，有以下两种写法，其中pipeline的值必须是数组、切片、字典或者通道。 {{range pipeline}} T1 {{end}} 如果pipeline的值其长度为0，不会有任何输出 {{range pipeline}} T1 {{else}} T0 {{end}} 如果pipeline的值其长度为0，则会执行T0。 8.4.8 with {{with pipeline}} T1 {{end}} 如果pipeline为empty不产生输出，否则将dot设为pipeline的值并执行T1。不修改外面的dot。 {{with pipeline}} T1 {{else}} T0 {{end}} 如果pipeline为empty，不改变dot并执行T0，否则dot设为pipeline的值并执行T1。 8.4.9 预定义函数 执行模板时，函数从两个函数字典中查找：首先是模板函数字典，然后是全局函数字典。一般不在模板内定义函数，而是使用Funcs方法添加函数到模板里。 预定义的全局函数如下： and 函数返回它的第一个empty参数或者最后一个参数； 就是说\"and x y\"等价于\"if x then y else x\"；所有参数都会执行； or 返回第一个非empty参数或者最后一个参数； 亦即\"or x y\"等价于\"if x then x else y\"；所有参数都会执行； not 返回它的单个参数的布尔值的否定 len 返回它的参数的整数类型长度 index 执行结果为第一个参数以剩下的参数为索引/键指向的值； 如\"index x 1 2 3\"返回x[1][2][3]的值；每个被索引的主体必须是数组、切片或者字典。 print 即fmt.Sprint printf 即fmt.Sprintf println 即fmt.Sprintln html 返回与其参数的文本表示形式等效的转义HTML。 这个函数在html/template中不可用。 urlquery 以适合嵌入到网址查询中的形式返回其参数的文本表示的转义值。 这个函数在html/template中不可用。 js 返回与其参数的文本表示形式等效的转义JavaScript。 call 执行结果是调用第一个参数的返回值，该参数必须是函数类型，其余参数作为调用该函数的参数； 如\"call .X.Y 1 2\"等价于go语言里的dot.X.Y(1, 2)； 其中Y是函数类型的字段或者字典的值，或者其他类似情况； call的第一个参数的执行结果必须是函数类型的值（和预定义函数如print明显不同）； 该函数类型值必须有1到2个返回值，如果有2个则后一个必须是error接口类型； 如果有2个返回值的方法返回的error非nil，模板执行会中断并返回给调用模板执行者该错误； 8.4.10 比较函数 布尔函数会将任何类型的零值视为假，其余视为真。 下面是定义为函数的二元比较运算的集合： eq 如果arg1 == arg2则返回真 ne 如果arg1 != arg2则返回真 lt 如果arg1 \u003c arg2则返回真 le 如果arg1 \u003c= arg2则返回真 gt 如果arg1 \u003e arg2则返回真 ge 如果arg1 \u003e= arg2则返回真 为了简化多参数相等检测，eq（只有eq）可以接受2个或更多个参数，它会将第一个参数和其余参数依次比较，返回下式的结果： {{eq arg1 arg2 arg3}} 比较函数只适用于基本类型（或重定义的基本类型，如”type Celsius float32”）。但是，整数和浮点数不能互相比较。 8.4.11 自定义函数 Go的模板支持自定义函数。 func sayHello(w http.ResponseWriter, r *http.Request) { htmlByte, err := ioutil.ReadFile(\"./hello.tmpl\") if err != nil { fmt.Println(\"read html failed, err:\", err) return } // 自定义一个夸人的模板函数 kua := func(arg string) (string, error) { return arg + \"真帅\", nil } // 采用链式操作在Parse之前调用Funcs添加自定义的kua函数 tmpl, err := template.New(\"hello\").Funcs(template.FuncMap{\"kua\": kua}).Parse(string(htmlByte)) if err != nil { fmt.Println(\"create template failed, err:\", err) return } user := UserInfo{ Name: \"小王子\", Gender: \"男\", Age: 18, } // 使用user渲染模板，并将结果写入w tmpl.Execute(w, user) } 我们可以在模板文件hello.tmpl中按照如下方式使用我们自定义的kua函数了。 {{kua .Name}} 8.4.12 嵌套template 我们可以在template中嵌套其他的template。这个template可以是单独的文件，也可以是通过define定义的template。 举个例子： test.tmpl文件内容如下： \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"\u003e \u003ctitle","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:7:4","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"8.5 text/template与html/tempalte的区别 html/template针对的是需要返回HTML内容的场景，在模板渲染过程中会对一些有风险的内容进行转义，以此来防范跨站脚本攻击。 例如，我定义下面的模板文件： \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"\u003e \u003ctitle\u003eHello\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e {{.}} \u003c/body\u003e \u003c/html\u003e 这个时候传入一段JS代码并使用html/template去渲染该文件，会在页面上显示出转义后的JS内容。 \u003cscript\u003ealert('嘿嘿嘿')\u003c/script\u003e 这就是html/template为我们做的事。 但是在某些场景下，我们如果相信用户输入的内容，不想转义的话，可以自行编写一个safe函数，手动返回一个template.HTML类型的内容。示例如下： func xss(w http.ResponseWriter, r *http.Request){ tmpl, err := template.New(\"xss.tmpl\").Funcs(template.FuncMap{ \"safe\": func(s string)template.HTML { return template.HTML(s) }, }).ParseFiles(\"./xss.tmpl\") if err != nil { fmt.Println(\"create template failed, err:\", err) return } jsStr := `\u003cscript\u003ealert('嘿嘿嘿')\u003c/script\u003e` err = tmpl.Execute(w, jsStr) if err != nil { fmt.Println(err) } } 这样我们只需要在模板文件不需要转义的内容后面使用我们定义好的safe函数就可以了。 {{ . | safe }} 即，信任的用safe，不信任的用. ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:7:5","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"九、Gin Gin是一个用Go语言编写的web框架。它是一个类似于martini但拥有更好性能的API框架, 由于使用了httprouter，速度提高了近40倍。 如果你是性能和高效的追求者, 你会爱上Gin。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.1 Gin框架介绍 Go世界里最流行的Web框架，Github上有32K+star。 基于httprouter开发的Web框架。 中文文档齐全，简单易用的轻量级框架。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.2 Gin框架安装与使用 9.2.1 安装 下载并安装Gin: go get -u github.com/gin-gonic/gin 9.2.2 第一个Gin示例： package main import ( \"github.com/gin-gonic/gin\" ) func main() { // 创建一个默认的路由引擎 r := gin.Default() // GET：请求方式；/hello：请求的路径 // 当客户端以GET方法请求/hello路径时，会执行后面的匿名函数 r.GET(\"/hello\", func(c *gin.Context) { // c.JSON：返回JSON格式的数据 c.JSON(200, gin.H{ \"message\": \"Hello world!\", }) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 r.Run() } 将上面的代码保存并编译执行，然后使用浏览器打开127.0.0.1:8080/hello就能看到一串JSON字符串。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.3 RESTful API REST与技术无关，代表的是一种软件架构风格，REST是Representational State Transfer的简称，中文翻译为“表征状态转移”或“表现层状态转化”。 推荐阅读阮一峰 理解RESTful架构 简单来说，REST的含义就是客户端与Web服务器之间进行交互的时候，使用HTTP协议中的4个请求方法代表不同的动作。 GET用来获取资源 POST用来新建资源 PUT用来更新资源 DELETE用来删除资源。 只要API程序遵循了REST风格，那就可以称其为RESTful API。目前在前后端分离的架构中，前后端基本都是通过RESTful API来进行交互。 例如，我们现在要编写一个管理书籍的系统，我们可以查询对一本书进行查询、创建、更新和删除等操作，我们在编写程序的时候就要设计客户端浏览器与我们Web服务端交互的方式和路径。按照经验我们通常会设计成如下模式： 请求方法 URL 含义 GET /book 查询书籍信息 POST /create_book 创建书籍记录 POST /update_book 更新书籍信息 POST /delete_book 删除书籍信息 同样的需求我们按照RESTful API设计如下： 请求方法 URL 含义 GET /book 查询书籍信息 POST /book 创建书籍记录 PUT /book 更新书籍信息 DELETE /book 删除书籍信息 Gin框架支持开发RESTful API的开发。 func main() { r := gin.Default() r.GET(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"GET\", }) }) r.POST(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"POST\", }) }) r.PUT(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"PUT\", }) }) r.DELETE(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"DELETE\", }) }) } 开发RESTful API的时候我们通常使用Postman来作为客户端的测试工具。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.4 Gin渲染 9.4.1 HTML渲染 我们首先定义一个存放模板文件的templates文件夹，然后在其内部按照业务分别定义一个posts文件夹和一个users文件夹。 posts/index.html文件的内容如下： {{define \"posts/index.html\"}} \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"\u003e \u003ctitle\u003eposts/index\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e {{.title}} \u003c/body\u003e \u003c/html\u003e {{end}} users/index.html文件的内容如下： {{define \"users/index.html\"}} \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"\u003e \u003ctitle\u003eusers/index\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e {{.title}} \u003c/body\u003e \u003c/html\u003e {{end}} Gin框架中使用LoadHTMLGlob()或者LoadHTMLFiles()方法进行HTML模板渲染。 func main() { r := gin.Default() r.LoadHTMLGlob(\"templates/**/*\") //r.LoadHTMLFiles(\"templates/posts/index.html\", \"templates/users/index.html\") r.GET(\"/posts/index\", func(c *gin.Context) { c.HTML(http.StatusOK, \"posts/index.html\", gin.H{ \"title\": \"posts/index\", }) }) r.GET(\"users/index\", func(c *gin.Context) { c.HTML(http.StatusOK, \"users/index.html\", gin.H{ \"title\": \"users/index\", }) }) r.Run(\":8080\") } 9.4.2 自定义模板函数 定义一个不转义相应内容的safe模板函数如下： func main() { router := gin.Default() router.SetFuncMap(template.FuncMap{ \"safe\": func(str string) template.HTML{ return template.HTML(str) }, }) router.LoadHTMLFiles(\"./index.tmpl\") router.GET(\"/index\", func(c *gin.Context) { c.HTML(http.StatusOK, \"index.tmpl\", \"\u003ca href='https://liwenzhou.com'\u003e李文周的博客\u003c/a\u003e\") }) router.Run(\":8080\") } 在index.tmpl中使用定义好的safe模板函数： \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003ctitle\u003e修改模板引擎的标识符\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv\u003e{{ . | safe }}\u003c/div\u003e \u003c/body\u003e \u003c/html\u003e 9.4.3 静态文件处理 当我们渲染的HTML文件中引用了静态文件时，我们只需要按照以下方式在渲染页面前调用gin.Static方法即可。 func main() { r := gin.Default() r.Static(\"/static\", \"./static\") r.LoadHTMLGlob(\"templates/**/*\") // ... r.Run(\":8080\") } 9.4.4 使用模板继承 Gin框架默认都是使用单模板，如果需要使用block template功能，可以通过\"github.com/gin-contrib/multitemplate\"库实现，具体示例如下： 首先，假设我们项目目录下的templates文件夹下有以下模板文件，其中home.tmpl和index.tmpl继承了base.tmpl： templates ├── includes │ ├── home.tmpl │ └── index.tmpl ├── layouts │ └── base.tmpl └── scripts.tmpl 然后我们定义一个loadTemplates函数如下： func loadTemplates(templatesDir string) multitemplate.Renderer { r := multitemplate.NewRenderer() layouts, err := filepath.Glob(templatesDir + \"/layouts/*.tmpl\") if err != nil { panic(err.Error()) } includes, err := filepath.Glob(templatesDir + \"/includes/*.tmpl\") if err != nil { panic(err.Error()) } // 为layouts/和includes/目录生成 templates map for _, include := range includes { layoutCopy := make([]string, len(layouts)) copy(layoutCopy, layouts) files := append(layoutCopy, include) r.AddFromFiles(filepath.Base(include), files...) } return r } 我们在main函数中 func indexFunc(c *gin.Context){ c.HTML(http.StatusOK, \"index.tmpl\", nil) } func homeFunc(c *gin.Context){ c.HTML(http.StatusOK, \"home.tmpl\", nil) } func main(){ r := gin.Default() r.HTMLRender = loadTemplates(\"./templates\") r.GET(\"/index\", indexFunc) r.GET(\"/home\", homeFunc) r.Run() } 9.4.5 补充文件路径处理 关于模板文件和静态文件的路径，我们需要根据公司/项目的要求进行设置。可以使用下面的函数获取当前执行程序的路径。 func getCurrentPath() string { if ex, err := os.Executable(); err == nil { return filepath.Dir(ex) } return \"./\" } 9.4.6 JSON渲染 func main() { r := gin.Default() // gin.H 是map[string]interface{}的缩写 r.GET(\"/someJSON\", func(c *gin.Context) { // 方式一：自己拼接JSON c.JSON(http.StatusOK, gin.H{\"message\": \"Hello world!\"}) }) r.GET(\"/moreJSON\", func(c *gin.Context) { // 方法二：使用结构体 var msg struct { Name string `json:\"user\"` Message string Age int } msg.Name = \"小王子\" msg.Message = \"Hello world!\" msg.Age = 18 c.JSON(http.StatusOK, msg) }) r.Run(\":8080\") } 9.4.7 XML渲染 注意需要使用具名的结构体类型。 func main() { r := gin.Default() // gin.H 是map[string]interface{}的缩写 r.GET(\"/someXML\", func(c *gin.Context) { // 方式一：自己拼接JSON c.XML(http.StatusOK, gin.H{\"message\": \"Hello world!\"}) }) r.GET(\"/moreXML\", func(c *gin.Context) { // 方法二：使用结构体 type MessageRecord struct { Name string Message string Age int } va","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:4","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.5 获取参数 9.5.1 获取querystring参数 querystring指的是URL中?后面携带的参数，例如：/user/search?username=小王子\u0026address=沙河。 获取请求的querystring参数的方法如下： func main() { //Default返回一个默认的路由引擎 r := gin.Default() r.GET(\"/user/search\", func(c *gin.Context) { username := c.DefaultQuery(\"username\", \"小王子\") //username := c.Query(\"username\") address := c.Query(\"address\") //输出json结果给调用方 c.JSON(http.StatusOK, gin.H{ \"message\": \"ok\", \"username\": username, \"address\": address, }) }) r.Run() } 9.5.2 获取form参数 当前端请求的数据通过form表单提交时，例如向/user/search发送一个POST请求，获取请求数据的方式如下： func main() { //Default返回一个默认的路由引擎 r := gin.Default() r.POST(\"/user/search\", func(c *gin.Context) { // DefaultPostForm取不到值时会返回指定的默认值 //username := c.DefaultPostForm(\"username\", \"小王子\") username := c.PostForm(\"username\") address := c.PostForm(\"address\") //输出json结果给调用方 c.JSON(http.StatusOK, gin.H{ \"message\": \"ok\", \"username\": username, \"address\": address, }) }) r.Run(\":8080\") } 9.5.3 获取json参数 当前端请求的数据通过JSON提交时，例如向/json发送一个POST请求，则获取请求参数的方式如下： r.POST(\"/json\", func(c *gin.Context) { // 注意：下面为了举例子方便，暂时忽略了错误处理 b, _ := c.GetRawData() // 从c.Request.Body读取请求数据 // 定义map或结构体 var m map[string]interface{} // 反序列化 _ = json.Unmarshal(b, \u0026m) c.JSON(http.StatusOK, m) }) 更便利的获取请求参数的方式，参见下面的 参数绑定 小节。 9.5.4 获取path参数 请求的参数通过URL路径传递，例如：/user/search/小王子/沙河。 获取请求URL路径中的参数的方式如下。 func main() { //Default返回一个默认的路由引擎 r := gin.Default() r.GET(\"/user/search/:username/:address\", func(c *gin.Context) { username := c.Param(\"username\") address := c.Param(\"address\") //输出json结果给调用方 c.JSON(http.StatusOK, gin.H{ \"message\": \"ok\", \"username\": username, \"address\": address, }) }) r.Run(\":8080\") } 9.5.5 参数绑定 为了能够更方便的获取请求相关参数，提高开发效率，我们可以基于请求的Content-Type识别请求数据类型并利用反射机制自动提取请求中QueryString、form表单、JSON、XML等参数到结构体中。 下面的示例代码演示了.ShouldBind()强大的功能，它能够基于请求自动提取JSON、form表单和QueryString类型的数据，并把值绑定到指定的结构体对象。 // Binding from JSON type Login struct { User string `form:\"user\" json:\"user\" binding:\"required\"` Password string `form:\"password\" json:\"password\" binding:\"required\"` } func main() { router := gin.Default() // 绑定JSON的示例 ({\"user\": \"q1mi\", \"password\": \"123456\"}) router.POST(\"/loginJSON\", func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026login); err == nil { fmt.Printf(\"login info:%#v\\n\", login) c.JSON(http.StatusOK, gin.H{ \"user\": login.User, \"password\": login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) } }) // 绑定form表单示例 (user=q1mi\u0026password=123456) router.POST(\"/loginForm\", func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(\u0026login); err == nil { c.JSON(http.StatusOK, gin.H{ \"user\": login.User, \"password\": login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) } }) // 绑定QueryString示例 (/loginQuery?user=q1mi\u0026password=123456) router.GET(\"/loginForm\", func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(\u0026login); err == nil { c.JSON(http.StatusOK, gin.H{ \"user\": login.User, \"password\": login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) } }) // Listen and serve on 0.0.0.0:8080 router.Run(\":8080\") } ShouldBind会按照下面的顺序解析请求中的数据完成绑定： 如果是 GET 请求，只使用 Form 绑定引擎（query）。 如果是 POST 请求，首先检查 content-type 是否为 JSON 或 XML，然后再使用 Form（form-data）。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:5","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.6 文件上传 9.6.1 单个文件上传 文件上传前端页面代码： {{define \"upload_files.html\"}} \u003c!DOCTYPE html\u003e \u003chtml lang=\"zn-CN\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e上传文件\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cform action=\"/uploadSingle\" method=\"post\" enctype=\"multipart/form-data\"\u003e 上传单个文件： \u003cinput type=\"file\" name=\"file\"\u003e \u003cinput type=\"submit\" value=\"上传\"\u003e \u003c/form\u003e \u003cform action=\"/uploadMulti\" method=\"post\" enctype=\"multipart/form-data\"\u003e 上传多个文件： \u003cinput type=\"file\" name=\"files[]\" multiple\u003e \u003cinput type=\"submit\" value=\"上传\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e {{end}} 后端gin框架部分代码： func uploadSingleFile(r *gin.Engine) { r.POST(\"/uploadSingle\", func(context *gin.Context) { // 单个文件 file, err := context.FormFile(\"file\") if err != nil { context.JSON(http.StatusInternalServerError, gin.H{\"message\": err.Error()}) return } log.Println(file.Filename) dst := fmt.Sprintf(\"./upload_files/%s\", file.Filename) // 上传文件到指定文件夹 err = context.SaveUploadedFile(file, dst) if err != nil { context.JSON(http.StatusInternalServerError, gin.H{\"message\": \"upload failed.\"}) } context.JSON(http.StatusOK, gin.H{\"message\": fmt.Sprintf(\"%s upload success.\", file.Filename)}) }) //r.Run() } 9.6.2 多个文件上传 func uploadMultiFiles(r *gin.Engine) { r.POST(\"/uploadMulti\", func(context *gin.Context) { form, _ := context.MultipartForm() files := form.File[\"files[]\"] for index, file := range files { log.Println(file.Filename) dst := fmt.Sprintf(\"./upload_files/%d_%s\", index, file.Filename) // 上传文件到指定目录 context.SaveUploadedFile(file, dst) } context.JSON(http.StatusOK, gin.H{\"message\": fmt.Sprintf(\"%d files upload success.\", len(files))}) }) //r.Run() } func main() { r := gin.Default() // 1. 静态页面 默认显示./upload下的index.html页面。注意，必须是index命名 //r.Static(\"/\", \"./upload_files\") // 2. 动态显示 r.LoadHTMLFiles(\"./upload_files/upload_files.html\") r.GET(\"/\", func(context *gin.Context) { context.HTML(http.StatusOK, \"upload_files.html\", gin.H{ \"title\": \"upload_files\", }) }) // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 r.MaxMultipartMemory = 8 \u003c\u003c 20 // 8 MiB uploadSingleFile(r) uploadMultiFiles(r) r.Run() } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:6","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.7 重定向 9.7.1 HTTP重定向 HTTP 重定向很容易。 内部、外部重定向均支持。 r.GET(\"/test\", func(c *gin.Context) { c.Redirect(http.StatusMovedPermanently, \"http://www.sogo.com/\") }) 9.7.2 路由重定向 路由重定向，使用HandleContext： r.GET(\"/test\", func(c *gin.Context) { // 指定重定向的URL c.Request.URL.Path = \"/test2\" r.HandleContext(c) }) r.GET(\"/test2\", func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\"hello\": \"world\"}) }) ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:7","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.8 Gin路由 9.8.1 普通路由 r.GET(\"/index\", func(c *gin.Context) {...}) r.GET(\"/login\", func(c *gin.Context) {...}) r.POST(\"/login\", func(c *gin.Context) {...}) 此外，还有一个可以匹配所有请求方法的Any方法如下： r.Any(\"/test\", func(c *gin.Context) {...}) 为没有配置处理函数的路由添加处理程序，默认情况下它返回404代码，下面的代码为没有匹配到路由的请求都返回views/404.html页面。 r.NoRoute(func(c *gin.Context) { c.HTML(http.StatusNotFound, \"views/404.html\", nil) }) 9.8.2 路由组 我们可以将拥有共同URL前缀的路由划分为一个路由组。习惯性一对{}包裹同组的路由，这只是为了看着清晰，你用不用{}包裹功能上没什么区别。 func main() { r := gin.Default() userGroup := r.Group(\"/user\") { userGroup.GET(\"/index\", func(c *gin.Context) {...}) userGroup.GET(\"/login\", func(c *gin.Context) {...}) userGroup.POST(\"/login\", func(c *gin.Context) {...}) } shopGroup := r.Group(\"/shop\") { shopGroup.GET(\"/index\", func(c *gin.Context) {...}) shopGroup.GET(\"/cart\", func(c *gin.Context) {...}) shopGroup.POST(\"/checkout\", func(c *gin.Context) {...}) } r.Run() } 路由组也是支持嵌套的，例如： shopGroup := r.Group(\"/shop\") { shopGroup.GET(\"/index\", func(c *gin.Context) {...}) shopGroup.GET(\"/cart\", func(c *gin.Context) {...}) shopGroup.POST(\"/checkout\", func(c *gin.Context) {...}) // 嵌套路由组 xx := shopGroup.Group(\"xx\") xx.GET(\"/oo\", func(c *gin.Context) {...}) } 通常我们将路由分组用在划分业务逻辑或划分API版本时。 9.8.3 路由原理 Gin框架中的路由使用的是httprouter这个库。 其基本原理就是构造一个路由地址的前缀树。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:8","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.9 Gin中间件 Gin框架允许开发者在处理请求的过程中，加入用户自己的钩子（Hook）函数。这个钩子函数就叫中间件，中间件适合处理一些公共的业务逻辑，比如登录认证、权限校验、数据分页、记录日志、耗时统计等。 9.9.1 定义中间件 Gin中的中间件必须是一个gin.HandlerFunc类型。 9.9.1.1 记录接口耗时的中间件 例如我们像下面的代码一样定义一个统计请求耗时的中间件。 // StatCost 是一个统计耗时请求耗时的中间件 func StatCost() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Set(\"name\", \"小王子\") // 可以通过c.Set在请求上下文中设置值，后续的处理函数能够取到该值 // 调用该请求的剩余处理程序 c.Next() // 不调用该请求的剩余处理程序 // c.Abort() // 计算耗时 cost := time.Since(start) log.Println(cost) } } 9.9.1.2 记录响应体的中间件 我们有时候可能会想要记录下某些情况下返回给客户端的响应数据，这个时候就可以编写一个中间件来搞定。 type bodyLogWriter struct { gin.ResponseWriter // 嵌入gin框架ResponseWriter body *bytes.Buffer // 我们记录用的response } // Write 写入响应体数据 func (w bodyLogWriter) Write(b []byte) (int, error) { w.body.Write(b) // 我们记录一份 return w.ResponseWriter.Write(b) // 真正写入响应 } // ginBodyLogMiddleware 一个记录返回给客户端响应体的中间件 // https://stackoverflow.com/questions/38501325/how-to-log-response-body-in-gin func ginBodyLogMiddleware(c *gin.Context) { blw := \u0026bodyLogWriter{body: bytes.NewBuffer([]byte{}), ResponseWriter: c.Writer} c.Writer = blw // 使用我们自定义的类型替换默认的 c.Next() // 执行业务逻辑 fmt.Println(\"Response body: \" + blw.body.String()) // 事后按需记录返回的响应 } 9.9.1.3 跨域中间件cors 推荐使用社区的https://github.com/gin-contrib/cors 库，一行代码解决前后端分离架构下的跨域问题。 注意： 该中间件需要注册在业务处理函数前面。 这个库支持各种常用的配置项，具体使用方法如下。 package main import ( \"time\" \"github.com/gin-contrib/cors\" \"github.com/gin-gonic/gin\" ) func main() { router := gin.Default() // CORS for https://foo.com and https://github.com origins, allowing: // - PUT and PATCH methods // - Origin header // - Credentials share // - Preflight requests cached for 12 hours router.Use(cors.New(cors.Config{ AllowOrigins: []string{\"https://foo.com\"}, // 允许跨域发来请求的网站 AllowMethods: []string{\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"}, // 允许的请求方法 AllowHeaders: []string{\"Origin\", \"Authorization\", \"Content-Type\"}, ExposeHeaders: []string{\"Content-Length\"}, AllowCredentials: true, AllowOriginFunc: func(origin string) bool { // 自定义过滤源站的方法 return origin == \"https://github.com\" }, MaxAge: 12 * time.Hour, })) router.Run() } 当然你可以简单的像下面的示例代码那样使用默认配置，允许所有的跨域请求。 func main() { router := gin.Default() // same as // config := cors.DefaultConfig() // config.AllowAllOrigins = true // router.Use(cors.New(config)) router.Use(cors.Default()) router.Run() } 9.9.2 注册中间件 在gin框架中，我们可以为每个路由添加任意数量的中间件。 9.9.2.1 为全局路由注册 func main() { // 新建一个没有任何默认中间件的路由 r := gin.New() // 注册一个全局中间件 r.Use(StatCost()) r.GET(\"/test\", func(c *gin.Context) { name := c.MustGet(\"name\").(string) // 从上下文取值 log.Println(name) c.JSON(http.StatusOK, gin.H{ \"message\": \"Hello world!\", }) }) r.Run() } 9.9.2.2 为某个路由单独注册 // 给/test2路由单独注册中间件（可注册多个） r.GET(\"/test2\", StatCost(), func(c *gin.Context) { name := c.MustGet(\"name\").(string) // 从上下文取值 log.Println(name) c.JSON(http.StatusOK, gin.H{ \"message\": \"Hello world!\", }) }) 9.9.2.3 为路由组注册中间件 为路由组注册中间件有以下两种写法。 写法1： shopGroup := r.Group(\"/shop\", StatCost()) { shopGroup.GET(\"/index\", func(c *gin.Context) {...}) ... } 写法2： shopGroup := r.Group(\"/shop\") shopGroup.Use(StatCost()) { shopGroup.GET(\"/index\", func(c *gin.Context) {...}) ... } 9.9.3 中间件注意事项 9.9.3.1 gin默认中间件 gin.Default()默认使用了Logger和Recovery中间件，其中： Logger中间件将日志写入gin.DefaultWriter，即使配置了GIN_MODE=release。 Recovery中间件会recover任何panic。如果有panic的话，会写入500响应码。 如果不想使用上面两个默认的中间件，可以使用gin.New()新建一个没有任何默认中间件的路由。 9.9.3.2 gin中间件中使用goroutine 当在中间件或handler中启动新的goroutine时，不能使用原始的上下文（c *gin.Context），必须使用其只读副本（c.Copy()）。 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:9","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"9.10 运行多个服务 我们可以在多个端口启动服务，例如： package main import ( \"log\" \"net/http\" \"time\" \"github.com/gin-gonic/gin\" \"golang.org/x/sync/errgroup\" ) var ( g errgroup.Group ) func router01() http.Handler { e := gin.New() e.Use(gin.Recovery()) e.GET(\"/\", func(c *gin.Context) { c.JSON( http.StatusOK, gin.H{ \"code\": http.StatusOK, \"error\": \"Welcome server 01\", }, ) }) return e } func router02() http.Handler { e := gin.New() e.Use(gin.Recovery()) e.GET(\"/\", func(c *gin.Context) { c.JSON( http.StatusOK, gin.H{ \"code\": http.StatusOK, \"error\": \"Welcome server 02\", }, ) }) return e } func main() { server01 := \u0026http.Server{ Addr: \":8080\", Handler: router01(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, } server02 := \u0026http.Server{ Addr: \":8081\", Handler: router02(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, } // 借助errgroup.Group或者自行开启两个goroutine分别启动两个服务 g.Go(func() error { return server01.ListenAndServe() }) g.Go(func() error { return server02.ListenAndServe() }) if err := g.Wait(); err != nil { log.Fatal(err) } } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:8:10","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"五、HTTP ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:9:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"1. 概述 编写web的语言： Java php，现在都在尝试用go重写 python，豆瓣 go，beego，gin两个主流的web框架 https协议：我们使用浏览器访问的时候发送的就是http请求 http是应用层协议，底层还是依赖传输层；tcp（短连接），网络层（ip） 无状态的，每一次请求都是独立的，下次请求需要重新建立连接 https： http是标准协议 https = http + ssl（非对称加密，数字证书） 现在所有网站都尽量要求使用https开发，为了安全 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:9:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"2. http请求报文格式 一个http请求可以分为4部分： 请求行 格式：方法 + URL + 协议版本号 实例：POST + /chapter17/user.html + HTTP/1.1 请求方法： GET：获取数据 POST：上传数据（表单格式，json格式） PUT：修改数据 DELETE：用于删除数据 请求头 格式：key：value 可以有很多个键值对（包含协议自带，也包含用户自定义的） 重要的头： Accept：接收数据的格式 User-Agent：描述用户浏览器的信息 Connection：Keep-Alive（长连接），Close（短连接） Accept-Encoding：gzip，xxx，描述可接受的编码 Cookie：由服务器设置的key = value数据，客户端下次请求可以携带以验证 Content-Type： application/-form（表示上传的数据是表单格式） application/json（表示body的数据是json格式） 用户可以自定义的： name：DUKE age：18 空行 告诉服务器，请求头结束了，用于分割 请求包体（可选的） 一般在POST方法时，会配套提供BODY 在GET的时候也可以提供BODY，但这样容易让人混淆，建议不要这样使用 上传两种数据格式： 表单：姓名，性别，年龄 json数据格式 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:9:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"3. http响应消息格式 http响应消息格式分为四个部分： 状态行 协议格式：协议版本号 + 状态码 + 状态描述 实例：HTTP/1.1 + 200 + OK 实例：HTTP/1.1 + 404 + Page not found 常用状态码 1xx：客户端可以即时发送请求（一般感知不到） 2xx：正常访问，200 3xx：重定向 4xx： 401：未授权 not authorized 404：Not found 5xx： 501：Internal Error（服务器内部错误） 响应头 Content-Type：application/json Server：Apache Data：Mon，12 Sep … 空行 用于分割，表示下面没有响应头了 响应体 通常是返回json格式数据 func main() { // http包 client := http.Client{} // func (c *Client) Get(url string) (resp *Response, err error) { resp, err := client.Get(\"https://www.baidu.com\") if err != nil { fmt.Println(\"client.Get err: \", err) return } // 读取Header ct := resp.Header.Get(\"Content-Type\") data := resp.Header.Get(\"Date\") ser := resp.Header.Get(\"Server\") fmt.Println(\"content-type: \", ct) fmt.Println(\"date: \", data) fmt.Println(\"server: \", ser) fmt.Println(\"----------------------\") // 读取状态行 url := resp.Request.URL code := resp.StatusCode status := resp.Status fmt.Println(\"url: \", url) fmt.Println(\"code: \", code) fmt.Println(\"status: \", status) fmt.Println(\"----------------------\") // 读取响应体 body := resp.Body // func ReadAll(r io.Reader) ([]byte, error) readBodyStr, err := ioutil.ReadAll(body) if err != nil { fmt.Println(\"read body err: \", err) return } fmt.Println(\"body string: \", string(readBodyStr)) } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:9:3","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"4. http-server func main() { // 注册路由 router // xxx/user ==\u003e func1 // xxx/name ==\u003e func2 // xxx/id ==\u003e func3 // https://127.0.0.1:8080/user func是回调函数，用于路由的响应，这个回调函数原型是固定的 http.HandleFunc(\"/user\", func(writer http.ResponseWriter, request *http.Request) { // request: ===\u003e 包含客户端发来的数据 fmt.Println(\"用户请求详情: \") fmt.Println(\"request: \", request) // 这里是具体处理业务逻辑 // writer: ===\u003e 通过writer将数据返回给客户端 _, _ = io.WriteString(writer, \"这是/user请求返回的数据!\") }) // https://127.0.0.1:8080/name http.HandleFunc(\"/name\", func(writer http.ResponseWriter, request *http.Request) { _, _ = io.WriteString(writer, \"这是/name请求返回的数据!\") }) // https://127.0.0.1:8080/id http.HandleFunc(\"/id\", func(writer http.ResponseWriter, request *http.Request) { _, _ = io.WriteString(writer, \"这是/id请求返回的数据!\") }) // func ListenAndServe(addr string, handler Handler) error // 常规写法 fmt.Println(\"Http Server Start ...\") err := http.ListenAndServe(\"127.0.0.1:8080\", nil) if err != nil { fmt.Println(\"http start failed, err: \", err) return } /*// 简便写法 if err := http.ListenAndServe(\"127.0.0.1:8080\", nil); err != nil { fmt.Println(\"http start failed, err: \", err) return }*/ } ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:9:4","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"5. json { \"name\": \"矮大紧\", \"sex\": \"man\", \"age\": 131, \"girls\": [\"金莲\", \"凤姐\", \"马融\", \"春哥\"], \"成绩\": [2, 14, 9, 78, 96], \"家电\": {\"彩电\": \"海尔\", \"洗衣机\": \"三星\"}, \"stars\": [ {\"name\": \"Faye\", \"address\": \"北京\"}, {\"name\": \"Andy\", \"address\": \"香港\"}, {\"name\": \"Eddie\", \"address\": \"台湾\"} ] } 记住：json最后一个元素后面不能加逗号 json编解码 在网络传输的时候，把结构体，编码成json字符串，再进行传输 接收字符串，需要把字符串转换成结构体，然后操作 ==\u003e 字符串 ==\u003e 结构体 ==\u003e 解密 type Student struct { Id int Name string Age int gender string // 注意此处是小写 看区别 小写开头的，json编码时会忽略掉 } func main() { lily := Student{ Id: 1, Name: \"lily\", Age: 18, gender: \"女\", } // 编码（序列化），结构 =\u003e 字符串 // func Marshal(v interface{}) ([]byte, error) encodeInfo, err := json.Marshal(\u0026lily) if err != nil { fmt.Println(\"json.Marshal err: \", err) return } fmt.Println(\"encodeInfo: \", string(encodeInfo)) // encodeInfo: {\"Id\":1,\"Name\":\"lily\",\"Age\":18} // 对端接收到数据 // 反序列化（解码）：字符串 ==\u003e 结构体 var lily2 Student // func Unmarshal(data []byte, v interface{}) error err = json.Unmarshal([]byte(encodeInfo), \u0026lily2) if err != nil { fmt.Println(\"json.Unmarshal err: \", err) return } fmt.Println(\"name: \", lily2.Name) fmt.Println(\"gender: \", lily2.gender) // 打印空白 fmt.Println(\"id: \", lily2.Id) fmt.Println(\"age: \", lily2.Age) } **注：**struct中小写字母开头的，json编码时会自动忽略掉！！！ 结构体标签 type Teacher struct { Name string `json:\"-\"` // 在使用json编码时，这个不参与编码 注意此处是反引号`` Subject string `json:\"Subject_name\"` // 在json编码时，这个字段会编码成Subject_name Age int `json:\"age,string\"` // 在json编码中，将名字转换成age并转换成string类型 Address string `json:\"address,omitempty\"` // 在json编码中，如果这个字段为空，那么忽略掉，不参与编码 gender string // 在json编码中，小写字母的不参与编码 } func main() { t1 := Teacher{ Name: \"Duke\", Subject: \"Golang\", Age: 18, Address: \"北京\", gender: \"男\", } fmt.Println(\"t1: \", t1) encodeInfo, _ := json.Marshal(\u0026t1) fmt.Println(\"encodeInfo: \", string(encodeInfo)) } 总结： 对于结构体进行编码时，字段首字母必须是大写，否则不参与编码 如果json格式要求key小写，那么可以通过标签（tag）来解决 tag细节： Name string `json:\"-\"` // 在json编码时，这个不参与编码 注意此处是反引号`` Subject string `json:\"Subject_name\"` // 在json编码时，这个字段会编码成Subject_name Age int `json:\"age,string\"` // 在json编码中，将名字转换成age并转换成string类型 Address string `json:\"address,omitempty\"` // 在json编码中，如果这个字段为空，那么忽略掉，不参与编码 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:9:5","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"六、项目Demo ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:10:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"6.1 聊天室 1. 功能分析 实现一个网络聊天室（群）： 上线下线 聊天，其他人、自己都可以看到聊天信息 查询当前聊天室用户名字 可以修改自己的名字 超时踢出 2. 技术分析 技术点分析： socket tcp编程 map结构： 存储所有用户 map遍历 map删除 go程、channel select（超时退出，主动退出） timer定时器 3. 实现基础 思路分析 tcp socket，建立多连接 for { fmt.Println(\"主go程监听中...\") // 监听连接 conn, err := listener.Accept() if err != nil { fmt.Println(\"listener.Accept err: \", err) return } fmt.Println(\"建立连接成功!\") // 业务处理 go handle(conn) } 定义User/map结构 newuser := User{ name: clientAddr, id: clientAddr, msg: make(chan string), // 需要make空间 否则无法写入数据 } // 将user添加到map allUsers[newuser.id] = newuser 定义message通道 // 定义一个message全局通道，用于接收任何人发送来的消息 var message = make(chan string, 10) 创建监听广播过程函数 // 向所有的用户广播消息，启动一个全局唯一的go程 func broadcast() { fmt.Println(\"广播go程启动成功! \") // 1. 从message中读取数据 info := \u003c-message for _, user := range allUsers { user.msg \u003c- info } } 启动，全局唯一 // 启动全局唯一的go程，负责监听message通道，写给所有的用户 go broadcast() fmt.Println(\"服务器启动成功! \") 写入上线信息 // 将用户上线的消息写入message，用于广播给所有用户 loginInfo := fmt.Sprintf(\"[%s]:[%s] ===\u003e 上线了login! \", newuser.id, newuser.name) // 拼接字符串时，最好都用这种 少用 + message \u003c- loginInfo user监听通道 每个用户还需要一个用来监听各自msg通道的go程，负责将数据返回给客户端 func writeBackToClient(user *User, conn net.Conn) { //TODO fmt.Printf(\"user: %s 的go程正在监听自己的msg管道: \\n\", user.name) for data := range user.msg { fmt.Printf(\"user: %s 写回给客户端的数据为: %s\\n\", user.name, data) // Write(b []byte) (n int, err error) _, _ = conn.Write([]byte(data)) } } 4. 增加功能 1. 查询用户 查询命令：who ==\u003e 将当前所有登录的用户，展示出来，id，name 2. 重命名 规则：rename|Duke 读取数据判断长度7，判断字符是rename 使用 | 进行分割，获取 | 后面的部分作为名字 更新用户名字newUser.name = Duke 通知客户端，更新成功 else if len(userInput) \u003e 8 \u0026\u0026 userInput[:7] == \"\\\\rename\" { /* 1. 读取数据判断长度7，判断字符是rename 2. 使用 | 进行分割，获取 | 后面的部分作为名字 */ //arry := strings.Split(userInput, \"|\") //name := arry[1] /* 3. 更新用户名字newUser.name = Duke 4. 通知客户端，更新成功 */ newUser.name = strings.Split(userInput, \"|\")[1] allUsers[newUser.id] = newUser // 更新map中的user newUser.msg \u003c- \"rename success! \" 3. 主动退出 两种形式：==\u003e quit，ctrl+c 用户退出：清理工作 从map中删除 对应的conn要close 每个用户都有自己的watch go程，负责监听退出信号 // 启动一个go程负责监听退出信号，触发后，进行清零工作: delete map, close conn都在这里进行处理 func watch(user *User, conn net.Conn, isQuit \u003c-chan bool) { fmt.Println(\"-2- 启动监听退出信号的go程...\") defer fmt.Println(\"watch go程退出! \") for { select { case \u003c-isQuit: logoutInfo := fmt.Sprintf(\"%s exit already! \", user.name) fmt.Println(\"删除当前用户: \", user.name) delete(allUsers, user.id) message \u003c- logoutInfo conn.Close() return // 防止内存泄露 } } } 在handle中启动watch go程 // 定义一个退出信号，用于监听client的状态 var isQuit = make(chan bool) // 启动go程，负责监听退出信号 go watch(\u0026newUser, conn, isQuit) 在read之后，通过读取的cnt判断用户退出，向isQuit中写入信号： // 读取客户端发来的数据 cnt, err := conn.Read(buf) if cnt == 0 { fmt.Println(\"客户端主动关闭ctrl+c, 准备退出! \") // map删除，conn close掉 // 服务器还可以主动退出 // 在这里不进行真正的退出动作，而是发出一个退出信号，统一做退出处理，可以使用新的管道来做信号传递 isQuit \u003c- true } 4. 超时退出 使用定时器来进行超时管理 如果60s内没有发送任何数据，那么直接将这个连接关闭掉： \u003c- time.After(60 * time.second) // chan time 创建restTimer管道用来当作重置器： //创建一个用于重置计数器的管道，用于告知watch函数，当前用户正在输入 var restTimer = make(chan bool) // 启动go程，负责监听退出信号 go watch(\u0026newUser, conn, isQuit, restTimer) 每次写完数据后进行重置： restTimer \u003c- true // 重置 case \u003c-time.After(5 * time.Second): logoutInfo := fmt.Sprintf(\"%s exit timeout!\\n\", user.name) fmt.Println(\"删除当前用户: \", user.name) delete(allUsers, user.id) message \u003c- logoutInfo conn.Close() return // 防止内存泄露 case \u003c-restTimer: fmt.Printf(\"连接%s 重置计数器!\\n\", user.name) 5.上锁 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:10:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"6.2 用户管理系统 **需求：**实现用户的插入、修改、删除，并能够打印用户明细表。 6.2.1 程序框架图 6.2.2 显示主菜单、退出软件 功能说明： 用户打开可以看到页面 6.2.3 显示客户列表 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:10:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"八、高并发与微服务 ==《Go语言高并发与微服务实战》== ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:11:0","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"1. 云原生 1.1 什么是云原生？ graph 云原生 --\u003e DevOps 云原生 --\u003e 持续集成 云原生 --\u003e 微服务架构 云原生 --\u003e 容器化 ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:11:1","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["Go"],"content":"1.2 微服务 1.2.1 系统架构的演进 graph LR 单体架构 --\u003e 垂直分层架构 --\u003e SOA面向服务架构 --\u003e 微服务架构 --\u003e 云原生架构 单体架构 缺点：局部改动就需要重新部署，不易扩展，不支持多语言技术栈。 垂直分层架构 1.2.2 常见微服务框架 Java Spring Cloud Dubbo Go Go Kit Go Micro NodeJS Seneca ","date":"2023-01-10","objectID":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:11:2","tags":["Go","基础操作"],"title":"Go浅析-基础操作","uri":"/go%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"},{"categories":["通用","python"],"content":"爬虫 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:0:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"一、概述 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:1:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"1.1 requests入门 安装requests conda install requests # windows 需要加上 encoding=\"utf-8\", mac是默认的 with open(\"mybaidu.html\", mode=\"w\", encoding=\"utf-8\") as f: f.write(resp.read().decode(\"utf-8\")) 在地址栏中输入搜索的内容，这种方式都是get 若被发现是自动设备发出的请求而被拒绝，可以通过添加agent，如下图中： # 添加agent 防止被识别为自动化请求 dic = { \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\" } resp = requests.get(url, headers=dic) # 处理了一个小反爬 实现翻译功能 寻找下图中的请求： 其请求方式为post方式，从载荷中查看提交的数据，并构造json进行提交： url = \"https://fanyi.sogou.com/reventondc/suggV3\" s = input(\"请输入你要查询的单词:\") dat = { \"from\": \"auto\", \"to\": \"zh-CHS\", \"client\": \"web\", \"text\": s, \"uuid\": \"da793e6d-1a41-4448-8df5-ae35fc402c3a\", \"pid\": \"sogou-dict-vr\", \"addSugg\": \"on\" } resp = requests.post(url, json=dat) # 将服务器返回的内容直接处理成json() ==\u003e dict格式 dic = resp.json() print(dic['sugg']) 爬取豆瓣电影榜单 查看载荷，发现每次新刷新内容，只有start+20，所以可以通过改变请求中的start数据来爬取所有榜单信息。 url = \"https://movie.douban.com/j/chart/top_list\" count = 0 info = [] header = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\" } for count in range(0, 81, 20): param = { \"type\": 24, 'interval_id': \"100:90\", \"action\": \"\", \"start\": count, \"limit\": 20 } resp = requests.get(url, params=param, headers=header) info.append(resp.json()) resp.close() # 关掉resp print(info) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:1:1","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"二、数据解析 提供三种解析方式： re解析 bs4解析（使用方便，但解析速度较慢） xpath解析 掌握之后，再考虑性能问题。 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:2:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"2.1 Re解析 Re，正则表达式。 语法：使用元字符进行排列组合用来匹配字符串，在线测试正则表达式：https://tool.oschina.net/regex 元字符：具有固定含义的特殊符号 常用元字符：https://cloud.tencent.com/developer/article/1337734 . 匹配除换行符以外的任意字符 \\w 匹配字母、数字、下划线 \\s 匹配任意的空白符 \\d 匹配数字 \\n 匹配一个换行符 \\t 匹配一个制表符 ^ 匹配字符串的开始 $ 匹配字符串的结尾 \\W 匹配非字母、非数字、非下划线 \\D 匹配非数字 \\S 匹配非空白符 a|b 匹配字符a或字符b () 匹配括号内的表达式，也表示一个组 [...] 匹配字符组中的字符 [^...] 匹配除了字符组中字符的所有字符 量词：控制前面的元字符出现的次数。 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或不出现 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 贪婪匹配和惰性匹配 .* 贪婪匹配 (玩儿吃鸡游戏，玩什么游戏) .*? 找最短的，?使尽可能少的*，尽可能少的匹配 (玩儿吃鸡游戏) 例： \u003cdiv class=\"jay\"\u003e周杰伦\u003c/div\u003e\u003cdiv class=\"jj\"\u003e林俊杰\u003c/div\u003e 使用：\u003c.*?\".*?\"\u003e.*?\u003e 或 .*?\u003c/div\u003e 结果：\u003cdiv class=\"jay\"\u003e周杰伦\u003c/div\u003e \u003cdiv class=\"jj\"\u003e林俊杰\u003c/div\u003e 我们爬虫用的最多的就是==惰性匹配== ==重点==： 以下几个功能就足够使用： finditer 和findall功能相似（查找所有），但是返回迭代器，效率高 findall 查找所有，返回list search 能够进行全文匹配，但检索到第一个就停止并返回 match 只能从字符串的头部开始匹配 预加载正则： obj = re.compile(r\"正则\") 从迭代器中拿到内容需要： 返回的迭代器对象.group() 提取有用的数据： (?P\u003cgroup\u003e正则) import re # 最重要*** finditer: 匹配字符串中所有的内容[返回的是迭代器] it = re.finditer(r\"\\d+\", \"我的电话号是:10086, 我女朋友的电话是:10010\") print(it) # 从迭代器中拿到内容需要 .group() for i in it: print(i.group()) # 预加载正则 可以提高效率 obj = re.compile(r\"\\d+\") # 可以多次使用 ret = obj.finditer(\"我的电话号是:10086, 我女朋友的电话是:10010\") for i in ret: print(i.group()) # 非常非常重要的点 ******** s = \"\"\" \u003cdiv class='jay'\u003e\u003cspan id='1'\u003e郭麒麟\u003c/span\u003e\u003c/div\u003e \u003cdiv class='jj'\u003e\u003cspan id='2'\u003e宋铁\u003c/span\u003e\u003c/div\u003e \u003cdiv class='jolin'\u003e\u003cspan id='3'\u003e大聪明\u003c/span\u003e\u003c/div\u003e \u003cdiv class='sylar'\u003e\u003cspan id='4'\u003e范思哲\u003c/span\u003e\u003c/div\u003e \u003cdiv class='tory'\u003e\u003cspan id='5'\u003e胡说八道\u003c/span\u003e\u003c/div\u003e \"\"\" obj = re.compile(r\"\u003cdiv class='.*?'\u003e\u003cspan id='\\d+'\u003e.*?\u003c/span\u003e\u003c/div\u003e\") ret = obj.finditer(s) for i in ret: print(i.group()) # 提取有用的数据 (?P\u003cgroup\u003e正则) obj = re.compile(r\"\u003cdiv class='(?P\u003cclass\u003e.*?)'\u003e\u003cspan id='(?P\u003cid\u003e\\d+)'\u003e(?P\u003cname\u003e.*?)\u003c/span\u003e\u003c/div\u003e\") ret = obj.finditer(s) for i in ret: print(\"class:\", i.group(\"class\"), \"id:\", i.group(\"id\"), \"name:\", i.group(\"name\")) # findall: 匹配字符串中所有的符合正则的内容[返回的是数组] (不经常用 数组效率低) lst = re.findall(r\"\\d+\", \"我的电话号是:10086, 我女朋友的电话是:10010\") print(lst) # search: 全文进行匹配，找到一个结果就返回，不会全都找到。 # 返回的结果是match对象, 拿数据需要 .group() s = re.search(r\"\\d+\", \"我的电话号是:10086, 我女朋友的电话是:10010\") print(s.group()) # match: 从头开始匹配， s = re.match(r\"\\d+\", \"10086, 我女朋友的电话是:10010\") print(s.group()) 2.1.1 Re-豆瓣Top250 # 拿到页面源代码——requests # 通过re来提取想要的有效信息——re import re import requests # 存储数据 import csv num = 0 headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\", \"x-client-data\": \"CJe2yQEIo7bJAQjEtskBCKmdygEInvnLAQjmhMwBCNKPzAEIrZzMAQ==\" # # 由于被限制，不被限制就不加 需要更新 } # 解析数据 obj = re.compile(r'\u003cem class=\"\"\u003e(?P\u003cnum\u003e.*?)\u003c/em\u003e.*?' r'\u003cdiv class=\"info\"\u003e.*?\u003cspan class=\"title\"\u003e(?P\u003cname\u003e.*?)\u003c/span\u003e.*?' r'\u003cp class=\"\"\u003e.*?\u003cbr\u003e(?P\u003cyear\u003e.*?)\u0026nbsp.*?' r'property=\"v:average\"\u003e(?P\u003crate\u003e.*?)\u003c/span\u003e.*?' r'\u003cspan\u003e(?P\u003cpeople\u003e.*?)\u003c/span\u003e.*?', re.S) # re.S 是允许跨行识别 # 如果不使用re.S参数，则只在每一行内进行匹配，如果一行没有，就换下一行重新开始，不会跨行。 # 而使用re.S参数以后，正则表达式会将这个字符串作为一个整体，将“\\n”当做一个普通的字符加入到这个字符串中，在整体中进行匹配。 # 生成csv文件 便于数据分析 f = open(\"data.csv\", mode=\"w\", encoding=\"utf-8\") csv_write = csv.writer(f) for num in range(10): # 拿到页面源代码 url = \"https://movie.douban.com/top250?start=\" + str(num*25) resp = requests.get(url, headers=headers) paper_text = resp.text # print(resp.text) # 进行匹配 rect = obj.finditer(paper_text) for i in rect: dict = i.groupdict() dict[\"year\"] = dict[\"year\"].strip() csv_write.writerow(dict.values()) f.close() print(\"over!\") # for i in rect: # print(\"num:\", i.group(\"num\")) # print(\"name:\", i.group(\"name\")) # print(\"year:\", i.group(\"year\").strip()) # print(\"rate:\", i.group(\"rate\")) # print(\"people:\", i.group(\"people\")) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:2:1","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"2.2 bs4解析 \u003c标签 属性=“属性值”\u003e被标记的内容\u003c/标签\u003e \u003ch1 align=\"center\"\u003ei love you\u003c/h1\u003e # h1: 标签 # align: 属性 # center: 属性值 \u003ca href=\"http://www.baidu.com\"\u003e周杰伦\u003c/a\u003e # a: 标签 # href: 属性 # http: 属性值 把页面源代码交给BeautifulSoup处理，生成bs对象 page = BeautifulSoup(resp.text, \"html.parser\") # 指定html解析器 从bs对象中查找数据 # find(标签, 属性=值) # find_all(标签, 属性=值) import time import requests from bs4 import BeautifulSoup url = \"https://movie.douban.com/top250\" headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\", \"x-client-data\": \"CJe2yQEIo7bJAQjEtskBCKmdygEInvnLAQjmhMwBCNKPzAEIrZzMAQ==\" # # 由于被限制，不被限制就不加 需要更新 } resp = requests.get(url, headers=headers) # print(resp.text) page_text = BeautifulSoup(resp.text, \"html.parser\") pic_list = page_text.find_all(\"div\", class_=\"pic\") for i in pic_list: img_list = i.find_all(\"img\") for img in img_list: # print(img) name = img.get(\"alt\") # 拿到名字 src = img.get(\"src\") # 直接通过get就可以拿到属性的值, 刚好是子页面的下载路径 # 下载图片 img_resp = requests.get(src) img_byte = img_resp.content # 这里拿到的是字节 img_name = name + \".jpg\" with open(\"img/\" + img_name, mode=\"wb\") as f: # 对文件夹mark directory as exclude 可以避免pycharm一直对文件进行索引 f.write(img_byte) print(\"over!!\", img_name) time.sleep(1) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:2:2","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"2.3 Xpath解析 xpath是在xml文档中搜索内容的一门语言，html是xml的一个子集。 安装lxml模块： conda install lxml from lxml import etree 可以把各级标签模拟为各级目录 使用 / 表示层级关系，第一个/表示根节点 使用 // 取出所有的后代 /*/ *表示通配符 任意的节点 /text() 取出其中的文本内容 xpath下标从1开始 [1] 读取html文件： etree.parse(\"xxx.html\") 筛选属性： .xpath(\"/html/body/ul/li[1]/a/text()\") # 可以拿出第一个li标签中a标签的文本 .xpath(\"/html/body/ul/li/a[@href='dapao']/text()\") # 可以拿出a标签中属性href=dapao的文本 .xpath(\"/html/body/ul/li/a/@href\") # 拿出标签a的所有href属性 返回列表： ol_li_list = tree.xpath(\"/html/body/ol/li\") # 返回li标签列表 for li in ol_li_list: # 使用 .表示相对路径 相当于li其实 result = li.xpath(\"./a/text()\") # 取li中a标签的文本，相对查找 result = li.xpath(\"./a/@href\") # 拿到属性值: @属性 # 拿到页面源代码 # 提取和解析数据 import requests from lxml import etree url = \"https://nanjing.zbj.com/search/f/?kw=saas\" resp = requests.get(url) # print(resp.text) # 解析 html = etree.HTML(resp.text) div_list = html.xpath(\"/html/body/div[6]/div/div/div[2]/div[5]/div[1]/div\") # 拿到每一个服务商的div标签 for div in div_list: price = div.xpath(\"./div/div/a[2]/div[2]/div[1]/span[1]/text()\")[0].strip(\"¥\") # price: ['¥898'] 使用strip()处理数据 title = \"SaaS\".join(div.xpath(\"./div/div/a[2]/div[2]/div[2]/p/text()\")) # ['软件开发/OA/软件定制开发/', '软件/原生混合/物联网'] 中间应该是有SasS的 但是没有提取出来 因此用join进行拼接 company = div.xpath(\"./div/div/a[1]/div[1]/p/text()\")[1].strip() # company: ['\\n\\n', '\\n\\n彬达科技'] 使用strip()可以直接去掉\\n location = div.xpath(\"./div/div/a[1]/div[1]/div/span/text()\")[0] print(\"title:\", title, \"price:\", price, \"company:\", company, \"location:\", location) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:2:3","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"三、request进阶 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:3:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"3.1 模拟登录-cookie 发现访问该网站可以得到cookie，注意：cookie一般不会在 预览 中， 一般在 响应标头 中 因此可以POST该网站得到cookie # 获得cookie，构造headers def get_cookie(self): cookie_url = \"http://ehall.seu.edu.cn/ygfw/sys/swpubapp/xxx\" cookie_response = self.session.post(cookie_url, data={\"USERID\": self.user_info.user_id}) # 将cookies转化为字典格式 print(cookie_response.cookies.get_dict()) $ python main.py 得到Cookie { NSC_ESNS=57d88235-1b4a-127e-9678-00e0ed9d66bd_2375465377_1978659927_00000000005768517823; NSC_JOqgyvhaegq01uld2umxhgbeip03kb0=ffffffff09489f1745525d5f4f58455e445a4a423660; _WEU=tbZT ZDIpO9DfzKWosRmHWCxuajrVVDsuty8Dy6k2GDK0hXp7irsDDNISCgMQIZQTK*DeyDKn7eS0h2lzXOQEjo..; } 但此时的Cookie不够，还缺少 当重新登录并抓包，可以发现红色框中的Cookie在首次登陆时获得： 因此在login的时候，就应该保存该Cookie。 提交表单需要编码： self.header['Content-Type'] = 'application/x-www-form-urlencoded; charset=UTF-8' data = parse.urlencode(post_info) self.session.post(url=url, data=data, headers=self.header) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:3:1","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"3.2 防盗链 Referer: “” 用于验证你的资源链接是从哪来的？ 相当于溯源 从梨视频网站下载视频 流程： 拿到请求网址和contID 拿到videoStatus返回的.json –\u003e srcUrl 修正srcUrl 下载视频 # 1. 拿到contID # 2. 拿到videoStatus返回的.json --\u003e srcUrl # 3. 修正srcUrl # 4. 下载视频 import requests # 拉取视频资源网站 url = \"https://www.pearvideo.com/video_1752547\" url_cont = url.split(\"_\")[1] # 以 _ 分割为两个元素，取第二个 video_url = f\"https://www.pearvideo.com/videoStatus.jsp?contId={url_cont}\" headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\", \"Referer\": url } # 拿到响应包 resp = requests.get(video_url, headers=headers) # 从网络响应包中找到网络资源地址： # https://video.pearvideo.com/mp4/adshort/20220222/1646013336252-15830346_adpkg-ad_hd.mp4 # 从https://www.pearvideo.com/video_1658861的页面元素中找到视频地址为： # https://video.pearvideo.com/mp4/adshort/20220222/cont-1752547-15830346_adpkg-ad_hd.mp4 dic = resp.json() srcUrl = dic['videoInfo']['videos']['srcUrl'] # 拿到的网址并不能直接使用，通过以上的对比进行修改 sysTime = dic['systemTime'] # 修改srcUrl srcUrl = srcUrl.replace(sysTime, f\"cont-{url_cont}\") print(srcUrl) # 请求video资源 video = requests.get(srcUrl) with open(\"a.mp4\", mode=\"wb\") as f: f.write(video.content) print(\"Over!!\") 通过对比，发现只有 cont-1658861 不一样，并且cont后面的数字和原链接最后的数字相同，因此对响应包中的资源url进行修正。 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:3:2","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"3.3 代理 原理： 通过第三方的机器去发送请求 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:3:3","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"3.4 网易云评论 里边用到加密算法，需要安装： conda install pycrypto from Crypto.Cipher import AES 考虑过程为： 找到未加密的参数 想办法对参数进行加密（按照网易的加密方法），params和encSecKey 请求到网易，拿到评论信息 找到评论所在请求： 找到请求评论的链接： 因为请求方法是Post，发现表单数据被加密： 查看程序调用堆栈。选取最上面那个。因为他是最后执行的，也就是发送数据的： 完事进去之后发现程序停留在这一行，刚好是send，在这一行设置程序断点： 查看当前请求的url，发现和我们想要的评论url不同： 继续执行，直到我们想要的url为止，此时data里的param被加密： 需要往回找未加密的，通过 调用堆栈 往上找： 打开之后发现依然是加密的： 那么需要再往上找，直到找到未加密的参数，也就是说在下一层t0x.be0x中数据才被加密： 那么回到上一层中，找到集体在何处被加密： 在函数中逐行设置断点，慢慢检测在何处数据被加密： 使用图中按钮可以逐行检测代码结果，在window…这一行还是明文： 到了下一行，参数被加密，因此可以断定加密函数是window…，并可以得到原文： 可以看出，params ==\u003e encText，encSecKey ==\u003e encSecKey： 取加密函数： 注意原函数里面的参数，需要给他配齐，对应着调用处的实参，可以对其进行赋值： 通过在控制台运行，可以得到其他参数： 或者通过以下方式也可以得到参数： 设置断点拿到以下参数： # 找到未加密的参数 # 想办法把参数进行加密（必须参考网易的逻辑），params，encSecKey # 请求到网易 拿到评论信息 import requests from Crypto.Cipher import AES from base64 import b64encode import json url = \"https://music.163.com/weapi/comment/resource/comments/get?csrf_token=\" # 请求方法是POST # 找到真实参数 e = '010001' f = '00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341' \\ 'f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82' \\ '047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7' g = '0CoJUm6Qyw8W8jud' # i是个随机值，因此我们只能去响应包中拿取i i = '9bdHkFpLbUCNTAnl' # 为了简化运算（不想处理c函数），设置为固定的 i固定 则它也固定 def get_encSecKey(): return \"1eb5a1efb12baafd580884b5c41b0a5bbbaee1c0de49f9d0470f05aa2a9215c25563b0ad5da008dacd85f65e0406addbd\" \\ \"a43bbe77716896089f607826000aa4797f34e03e8eb822096c166ec8ae4463ec1f7dab60c045eff18dfdef9f78555301f\" \\ \"3107d521918fea66940b6589749b9db575afa03f74ec04d01f1726f22ba1d2\" def get_params(data): # 此处的data需要是字符串格式，不能是字典格式，因此需要使用json转换 first = enc_params(data, g) params = enc_params(first, i) return params def enc_params(data, key): # 加密过程 iv = \"0102030405060708\" aes = AES.new(key=key.encode(\"utf-8\"), IV=iv.encode(\"utf-8\"), mode=AES.MODE_CBC) # 创建一个AES对象 bs = aes.encrypt(to_16(data)) # 加密，加密内容必须是16的倍数 # 由于加密结果是不能直接转为字符串的，需要先转化为base64才行，然后再转化为字符串 return str(b64encode(bs), \"utf-8\") def to_16(data): pam = 16 - len(data) % 16 data += chr(pam) * pam return data # 进行加密过程 \"\"\" function a(a = 16) { # 随机产生16位随机码 var d, e, b = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\", c = \"\"; for (d = 0; a \u003e d; d += 1) # 随机16次 e = Math.random() * b.length, # 随机数 e = Math.floor(e), # 取整 c += b.charAt(e); # 去字符串中的xxx位置 b return c } function b(a, b) { var c = CryptoJS.enc.Utf8.parse(b) , d = CryptoJS.enc.Utf8.parse(\"0102030405060708\") , e = CryptoJS.enc.Utf8.parse(a) , f = CryptoJS.AES.encrypt(e, c, { # AES算法 e原文，c是密钥 iv: d, # 偏移量 mode: CryptoJS.mode.CBC # 模式：CBC }); return f.toString() } function c(a, b, c) { var d, e; return setMaxDigits(131), d = new RSAKeyPair(b,\"\",c), e = encryptedString(d, a) } function d(d, e, f, g) { # d:data, e:'010001', f:很长, g:'0CoJUm6Qyw8W8jud' var h = {} # 设置一个空对象 , i = a(16); # i就是一个随机值 return h.encText = b(d, g), # g 当作密钥 h.encText = b(h.encText, i), # 返回的就是params h.encSecKey = c(i, e, f), # 返回的就是encSecKey 其中e、f都是定死的，只有i是变量，若固定i，则得到的key一定是固定的 h } function e(a, b, d, e) { var f = {}; return f.encText = c(a + e, b, d), f } \"\"\" def get_comments(url, song_id, page_num): rid = \"R_SO_4_\" + song_id threadId = \"R_SO_4_\" + song_id data = { \"cursor\": \"-1\", # 这个和paperNo共同决定哪一页的评论1610629253639 1621187632097 \"offset\": page_num * 20 % 200, # 代表最新评论的页数 \"orderType\": \"1\", \"pageNo\": page_num + 1, # 代表热评的页数 \"pageSize\": \"20\", \"rid\": rid, \"threadId\": threadId, } resp = requests.post(url, data={ \"params\": get_params(json.dumps(data)), \"encSecKey\": get_encSecKey() }) source = resp.json()[\"data\"] # print(source) if source[\"hotComments\"] != None and page_num == 0: print(\"=====hotComments=====\") for hot_comment in source[\"hotComments\"]: print(hot_comment[\"user\"][\"nickname\"], \":\", hot_comment[\"content\"], \"\\ntime:\", hot_comment[\"timeStr\"], \"点赞数:\", hot_comment[\"likedCount\"]) print(\"-\"*10) elif source[\"comments\"] != None: print(\"=====latestComments=====\") for latest_comment in source[\"comments\"]: print(latest_comment[\"u","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:3:4","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"四、加速 进程是一个资源单位，线程是一个执行单位 eg: xxx进程包含多个线程；一个项目组（进程）包含多个工作人员（线程）； ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.1 多线程 # 多线程 from threading import Thread class MyThread(Thread): def run(self): # 固定的， -\u003e 当线程被执行的时候，被执行的就是run() for i in range(1000): print(\"子线程: \", i) if __name__ == \"__main__\": t = MyThread() # t.run() # 这种方法是调用方法，依然是单线程 t.start() # 开启线程，线程此时可以开始工作，但不必须，具体执行时间由CPU决定 for i in range(1000): print(\"主线程:\", i) # =========重命名========= class MyThread(Thread): def __init__(self, name): Thread.__init__(self, name=name) def run(self): # 固定的， -\u003e 当线程被执行的时候，被执行的就是run() for i in range(1000): print(self.getName(), i) time.sleep(1) if __name__ == \"__main__\": t1 = MyThread(\"wlh\") # t.run() # 这种方法是调用方法，依然是单线程 t1.start() # 开启线程，线程此时可以开始工作，但不必须，具体执行时间由CPU决定 t2 = MyThread(\"zjl\") # t.run() # 这种方法是调用方法，依然是单线程 t2.start() # 开启线程，线程此时可以开始工作，但不必须，具体执行时间由CPU决定 # # for i in range(1000): # print(\"主线程:\", i) 由于主线程和子线程同时执行，共同输出在工作台，所以会造成图中的情况： ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:1","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.2 多进程 import time from multiprocessing import Process def func(): for i in range(1000): print(\"子进程:\", i) time.sleep(1) if __name__ == '__main__': p = Process(target=func) p.start() for i in range(1000): print(\"主进程:\", i) time.sleep(1) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:2","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.3 线程池\\进程池 线程池：一次性开辟一些线程，用户直接给线程池提交任务，线程的任务调度交给线程池完成 创建线程池： from concurrent.futures import ThreadPoolExecutor with ThreadPoolExecutor(num) as t: t.submit() # 线程池外的叫做守护，需要等待线程池内的任务执行完毕，才能继续执行 如何提取单个页面 的数据 利用线程池，进行多个页面同时抓取 北京新发地举例： import requests import csv from concurrent.futures import ThreadPoolExecutor f = open(\"xfd_list.csv\", mode=\"w\", encoding=\"utf-8\", newline='') # newline 是为了过滤掉换行符 csv_writer = csv.writer(f) def download_one_page(url, page_num): data = { \"current\": page_num } html_page_json = requests.post(url, data=data).json() price_list = html_page_json['list'] for item in price_list: # print(item) # txt = [0 for _ in range(7)] txt = [None] * 7 txt[0] = item['prodName'] txt[1] = item['lowPrice'] txt[2] = item['highPrice'] txt[3] = item['avgPrice'] txt[4] = item['place'] txt[5] = item['unitInfo'] txt[6] = item['pubDate'] # txt.append(item['prodName']) # txt.append(item['lowPrice']) # txt.append(item['highPrice']) # txt.append(item['avgPrice']) # txt.append(item['place']) # txt.append(item['unitInfo']) # txt.append(item['pubDate']) # print(info) csv_writer.writerow(txt) print(page_num, \"提取完毕！！！\") if __name__ == '__main__': with ThreadPoolExecutor(30) as f: # 开多了有可能出格式问题 for num in range(1, 200): f.submit(download_one_page, \"http://www.xinfadi.com.cn/getPriceData.html\", num) print(\"全部下载完毕!!!\") # for num in range(1, 200): # download_one_page(\"http://www.xinfadi.com.cn/getPriceData.html\", num) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:3","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.4 协程 要达到异步效果，需要将同步操作写为协程操作： （同步操作） （异步操作） python不太希望上述写法，因为主进程里线程过多，建议下述写法： # python不希望上面那种写法，因为主进程的线程过多 async def func1(): print(\"你好！我是李雪琴！\") await asyncio.sleep(3) # 将异步操作挂起 print(\"你好！我是李雪琴！\") async def func2(): print(\"你好！我是王建国！\") await asyncio.sleep(2) # 将异步操作挂起 print(\"你好！我是王建国！\") async def func3(): print(\"你好！我是黎明！\") await asyncio.sleep(4) # 将异步操作挂起 print(\"你好！我是黎明！\") async def main(): # 第一种写法 # f1 = func1() # await f1 # 一般wait挂起操作放在协程对象前面 # 第二种写法（推荐） # 一次性启动多个任务（协程） tasks = { asyncio.create_task(func1()), # 创建成task对象 asyncio.create_task(func2()), asyncio.create_task(func3()) } await asyncio.wait(tasks) # 挂起 if __name__ == '__main__': t1 = time.time() asyncio.run(main()) t2 = time.time() print(t2 - t1) 模拟爬虫应用： # 模拟爬虫应用 async def download(url): print(url, \"准备开始下载\") await asyncio.sleep(2) # 模拟网络请求 实际中 只需在此处将爬虫网络请求语句写为协程形式即可 print(url, \"下载完毕\") async def main(urls): tasks = [] for url in urls: tasks.append(download(url)) # tasks = [asyncio.create_task(download(url)) for url in urls] # 这样也可以 效果一样的 更加简洁 await asyncio.wait(tasks) if __name__ == '__main__': urls = { \"https://www.google.com/webhp\", \"https://www.baidu.com/\", \"https://www.bilibili.com/\" } asyncio.run(main(urls)) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:4","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.5 aiohttp模块应用 requests.get() 同步的代码 —\u003e 异步操作aiohttp conda install aiohttp import aiohttp # aiohttp.ClientSession() \u003c==\u003e requests 几乎一模一样 async def download(url): name = url.rsplit('/', 1)[1] # 从右边切片，切一次，取第二个元素 async with aiohttp.ClientSession() as Session: # Session现在相当于requests async with Session.get(url) as resp: # resp = requests.get(url) with open(name, mode='wb') as f: # 当请求返回，就可以开始写入文件 此处可以延申 aiofiles 异步写入文件 f.write(await resp.content.read()) # 读取内容是异步的，因此需要await挂起 print(name, \"下载完毕！\") async def main(urls): tasks = [asyncio.create_task(download(url)) for url in urls] await asyncio.wait(tasks) if __name__ == '__main__': urls = { \"https://img.syt5.com/2021/0907/20210907082121262.jpg\", \"https://img.syt5.com/2021/0907/20210907082121629.jpg\", \"https://img.syt5.com/2021/0907/20210907082121801.jpg\" } # asyncio.run(main(urls)) # 会报错，RuntimeError: Event loop is closed 改为如下： loop = asyncio.get_event_loop() loop.run_until_complete(main(urls)) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:5","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.6 抓取小说 import requests import asyncio import aiohttp import aiofiles import json # 所需网址 # http://dushu.baidu.com/api/pc/getCatalog?data={\"book_id\":\"4306063500\"} # 小说章节 # http://dushu.baidu.com/api/pc/getChapterContent?data={\"book_id\":\"4306063500\",\"cid\":\"4306063500|1569782244\",\"need_bookinfo\":1} # 小说章节内容 async def get_catalog(url): resp = requests.get(url) dict = resp.json() book_id = dict['data']['novel']['book_id'] tasks = [] for item in dict['data']['novel']['items']: title = item['title'] cid = item['cid'] # 此处可以开始进行获取小说内容 # 准备异步任务 tasks.append(get_content(book_id, title, cid)) # 开始执行异步任务 await asyncio.wait(tasks) print(\"下载完毕！！！\") async def get_content(book_id, title, cid): data = { \"book_id\": book_id, \"cid\": f\"{book_id}|{cid}\", \"need_bookinfo\": 1 } data = json.dumps(data) url = f'http://dushu.baidu.com/api/pc/getChapterContent?data={data}' async with aiohttp.ClientSession() as session: async with session.get(url) as resp: dict = await resp.json() # 异步写入 aiofiles async with aiofiles.open('西游记/' + title + '.txt', mode='w', encoding='utf-8') as f: await f.write(dict['data']['novel']['content']) if __name__ == '__main__': book_id = '4306063500' url = 'http://dushu.baidu.com/api/pc/getCatalog?data={\"book_id\":\"' + book_id + '\"}' # print(url) asyncio.run(get_catalog(url)) 新建文档： ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:6","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"4.7 视频抓取 首先，视频不可能直接加载到页面，因为这样会导致网页速度极慢……不可能一次性加载完毕！！！ 那视频网站一般怎么做呢？？？ 答：用户上传 –\u003e 转码（把视频做处理，2k，1080，标清） –\u003e 切片处理（把单个的文件进行拆分） 需要一个文件记录：1. 视频播放顺序，2. 视频存放路径。 M3U8 txt json ==\u003e 文本 想要抓取一个视频： 找到m3u8文件（各种手段） 通过m3u8下载到ts文件 可以通过各种手段（不仅是编程手段） 把ts文件合并为一个mp4文件 4.7.1 简单难度 流程： 针对页面源代码中含有m3u8的视频，采用以下方法抓取到m3u8文件： if __name__ == '__main__': url = 'https://91kju.com/vod-play-id-1039-sid-1-pid-1.html' headers = { \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\", \"origin\": \"https://91kju.com\" } resp = requests.get(url, headers=headers) # obj = re.compile(r\"\\\"url\\\":(?P\u003curl\u003e.*?),\", re.S) # 注意！！！这样提取出来的网址是带引号的！必然是无法访问的，要提取不带引号的网址！！！ obj = re.compile(r\"\\\"url\\\":\\\"(?P\u003curl\u003e.*?)\\\",\", re.S) # 此处一定要注意！！！ # print(resp.text) m3u8_url = obj.search(resp.text).group('url').replace('\\\\', '') # print(m3u8_url) # 下载m3u8文件 path = m3u8_url.rsplit('/', 1)[1] resp.close() headers = { \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\", \"origin\": \"https://91kju.com\", \"path\": f\"/{path}\", \"authority\": \"m3api.awenhao.com\" } resp2 = requests.get(m3u8_url) with open(\"火星救援.m3u8\", mode='wb') as f: f.write(resp2.content) print('m3u8下载完毕！') f.close() resp2.close() 拿到m3u8文件后才可以开始下载视频 图中红框示例部分就是视频资源的链接，可以从其中下载视频片段 下载视频片段 # 拿到m3u8后，就可以开始下载视频了 num = 1 with open(\"火星救援.m3u8\", mode='r', encoding='utf-8') as f: for line in f: line = line.strip() # 去掉空格，空白，换行符 if line.startswith('#'): # 若行开头为 # , 不要 continue # print(line) with open(f\"video/{num}.mp4\", mode='wb') as f: resp = requests.get(line) f.write(resp.content) f.close() resp.close() num += 1 print(f\"片段{num}下载完毕！！！\") 最后需要软件将视频片段合成为完整的视频 4.7.2 复杂91 思路： 拿到主页面的页面源代码，找到iframe 从iframe的页面源代码中拿到m3u8文件 下载第一层m3u8文件 –\u003e 下载第二层m3u8文件（视频存放路径） 下载视频 下载密钥，进行解密操作 将片段合成视频 暂未实施 异步下载视频： def get_m3u8(url): resp = requests.get(url) page_code = resp.text # print(resp.text) # 取m3u8的url obj = re.compile(r'\"url\":\"(?P\u003cm3u8_url\u003e.*?)\",\"', re.S) m3u8_url = obj.search(page_code).group('m3u8_url').replace('\\\\', '') # print(m3u8_url) m3u8 = requests.get(m3u8_url).content # print(m3u8) # 取title page_bs = BeautifulSoup(page_code, \"html.parser\") obj = re.compile(r'《(?P\u003ctitle\u003e.*?)》', re.S) title = obj.search(page_bs.find('title').text).group('title') # print(title.text) with open(f'{title}.m3u8', mode='wb') as f: f.write(m3u8) print(f'{title}.m3u8 下载完毕！') return f'{title}.m3u8' # # # 拿到m3u8后，就可以开始下载视频了 异步 async def dowaload(url, name, session): async with session.get(url) as resp: async with aiofiles.open(f\"video/{name}\", mode='wb') as f: await f.write(await resp.content.read()) # 异步把下载的视频片段写入文件 print(f'{name}下载完毕！') # # async def aio_download(url): tasks = [] m3u8= get_m3u8(url) # 在此处创建session比在download里面创建session好，因为只需要创建一次，若是在download中创建session，则每个人物都需要重新创建session async with aiohttp.ClientSession() as Session: # async with aiofiles.open(m3u8, mode='r', encoding='utf-8') as f: async with aiofiles.open(m3u8, mode='r', encoding='utf-8') as f: # 为了异步也可以按顺序排列视频片段，可以使用片段所在的行号进行命名 # for num, line in enumerate(f, 1): async for line in f: line = line.strip() if line.startswith('#'): continue else: # print(line) num = time.time() # print(num) name = f'{num}.mp4' # print(name, line) task = asyncio.create_task(dowaload(line, name, Session)) tasks.append(task) await asyncio.wait(tasks) # 此处不能往前拉，只能写在for循环后 print(f'{name}下载完毕！！！') if __name__ == '__main__': url = 'https://91kju.com/vod-play-id-61412-sid-1-pid-1.html' # # get_m3u8(url) loop = asyncio.get_event_loop() loop.run_until_complete(aio_download(url)) print('搞定！') 但其实这个方案无法按照片段顺序下载，所以可以得到行号以便进行排序，并且！！！行38和41根本不用异步吧？？？效果根本没有差别！！！可以用以下函数进行下载： async def aio_download(url): tasks = [] m3u8= get_m3u8(url) # 在此处创建session比在download里面创建session好，因为只需要创建一次，若是在download中创建session，则每个人物都需要重新创建session async with aiohttp.ClientSession() as Session: # async with aiofiles.open(m3u8, mode='r', encoding='utf-8') as f: with open(m3u8, mode='r', encoding='utf-8') as f: # 为了异步也可以按顺序排列视频片段，可","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:4:7","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"五、selenium ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:5:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"5.1 概述 问题： 能不能让我的程序连接到浏览器，让浏览器里来完成各种复杂的操作，我们只需要接受最后的结果 selenium： 自动化测试工具，可以打开浏览器，然后像人一样去操作浏览器，我们可以从selenium中直接提取网页上的各种信息 环境搭建： conda install selenium 下载浏览器驱动：https://chromedriver.storage.googleapis.com/index.html ​ 把解压缩的浏览器驱动 chromedriver 放在python解释器所在的文件夹 让selenium启动谷歌浏览器！！！ 查找浏览器的版本号： 去给的网站里找对应的版本号： 把解压缩的浏览器驱动 chromedriver 放在python解释器所在的文件夹，python解释器的路径如下： 粘贴进去： 让selenium启动浏览器： from selenium.webdriver import Chrome # 1. 创建浏览器对象 web = Chrome() # 2. 打开一个网址 web.get(\"https://www.baidu.com\") 案例，抓取拉勾网信息： 要注意的是！！！一定要加等待时间，否则有可能发生 未加载完就点击（或者拉取信息）导致失败（或信息不全）！！！ web.implicitly_wait(30) # （智能）隐式等待，5秒内加载完就直接执行下一条指令，若超过5秒，报错 # WebDriverWait(你的chrome()对象, maxWaitTime(s), checkInterval(s)) # 后面的 .until的意思是 直到括号内的lambda表达式成立，例如此处lambda的意思就是：加载出name为'DZ_JSDTCJTW'的element。 # 整行完整意思就是：每过0.2s就检查一下是否加载出名为'DZ_JSDTCJTW'的元素，若加载出，就执行下一行，若还无，最长等待10s。 WebDriverWait(driver, 10, 0.2).until(lambda x: x.find_element_by_name('DZ_JSDTCJTW')) driver.find_element_by_name('DZ_JSDTCJTW').send_keys(self.random_temp()) import time from selenium.webdriver import Chrome from selenium.webdriver.common.keys import Keys web = Chrome() web.get(\"https://lagou.com\") # 找到某个元素，点击它 el = web.find_element_by_xpath('//*[@id=\"changeCityBox\"]/p[1]/a') el.click() # 点击事件 web.implicitly_wait(30) # （智能）隐式等待，5秒内加载完就直接执行下一条指令，若超过5秒，报错 # 在搜索框中 搜索python el = web.find_element_by_xpath('//*[@id=\"search_input\"]').send_keys(\"python\", Keys.ENTER) # 找到输入框 输入python并回车 web.implicitly_wait(30) # 防止未加载完，导致输出不全 *****很重要！！！ # 找到信息所在位置 elements 是找到所有的 job_list = web.find_elements_by_xpath('//*[@id=\"jobList\"]/div[1]/div') for item in job_list: # job_name = item.find_element_by_tag_name(\"a\").text # 查找 item中 a标签的值 # print(job_name) job_name = item.find_element_by_xpath('./div/div/div/a').text job_price = item.find_element_by_xpath('./div/div/div[2]/span').text # ./ 相对路径 job_company = item.find_element_by_xpath('./div/div[2]/div/a').text print(job_name, job_price, job_company) 获取标签内元素的值： detail1 = web.find_element_by_xpath('//*[@id=\"zpid_19506994\"]/div[2]/a') print(detail1.get_attribute('href'), detail1.get_attribute('class')) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:5:1","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"5.2 窗口切换 如何进入到新窗口中进行提取 注意：在selenium眼中，新窗口默认是不切换过来的 web.switch_to.window(web.window_handles[-1]) # -1代表最后一个窗口（从右往左） 也可以切换到其他窗口！ ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:5:2","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"5.3 无头浏览器 from selenium.webdriver.chrome.options import Options opt = Options() opt.add_argument(\"--headless\") opt.add_argument(\"--disable-gpu\") web = Chrome(options=opt) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:5:3","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"5.4 验证码识别 **超级鹰！**或 ddddocr 哪里用就往哪里搬！ 1. chaojiying # 用户中心\u003e\u003e软件ID 生成一个替换 96001 chaojiying = Chaojiying_Client('15237174980', '12345678', '930009') # 本地图片文件路径 来替换 a.jpg 有时WIN系统须要// im = open('a.jpg', 'rb').read() # im就是图片的所有字节 # 1902 验证码类型 官方网站\u003e\u003e价格体系 3.4+版 print 后要加() print(chaojiying.PostPic(im, 1902)) 2. ddddocr pip install ddddocr def identifyCode(imgPath) -\u003e str: ocr = ddddocr.DdddOcr() img = open(imgPath, 'rb').read() return ocr.classification(img) # 上述是读取图片路径的方式，结合selenium也可以 img = web.find_element_by_xpath('图片的xpath').screenshot_as_png ocr.classification(img) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:5:4","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"5.5 防止自动化被屏蔽 这样有时会被屏蔽掉！！！ 解决方法！其实和无头浏览器很相似！！！ Chrome版本号大于88时： from selenium.webdriver.chrome.options import Options opt = Options() opt.add_argument('--disable-blink-features=AutomationControlled') web = Chrome(option=opt) ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:5:5","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"六、Js逆向 本地运行JS，得到和浏览器一样的加密数据，发送给服务器 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:6:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"6.1 断点 网站代码运行的时间轴： 加载html-\u003e加载js-\u003e运行js初始化-\u003e用户触发某个事件-\u003e调用了某段js-\u003e加密函数-\u003e给服务器发送信息（XHR-\u003eSEND）-\u003e 接受到服务器的数据-\u003e 解密函数-\u003e刷新网页渲染 分类： DOM断点：当渲染的时候（样子发生改变的时候），才有用；在加密过程中，其实是比较靠前的执行步骤，距离加密函数比较远，无法根据栈去快速定位，不太推荐用DOM断点 DOM事件断点：和DOM类似，如果不能用DOM下断，则考虑用DOM事件 XHR断点：执行的比较靠后，距离加密函数比较近，可以根据栈快速定位，非XHR发送的就无法断住 代码行断点 代码的断点 debugger 全局事件断点（浏览器事件断点） 异常捕获断点 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:6:1","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"},{"categories":["通用","python"],"content":"七、Scrapy框架 框架就是集成了很多功能并且具有很强通用性的一个项目模板，学习框架封装的各种功能的详细用法。 Scrapy是爬虫中封装好的一个明星框架，功能：高性能的持久化存储，异步数据下载，高性能的数据解析，分布式 基本使用： 安装环境： conda install wheel 下载twisted，下载地址为：http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted 安装twisted：conda install Twisted-... conda install pywin32 conda install scrapy python生成exe文件 Pyinstaller -F setup.py 打包exe Pyinstaller -F -w setup.py 不带控制台的打包 Pyinstaller -F -i xx.ico setup.py 打包指定exe图标打包 git bash 使用conda切换环境 将anaconda的图示的几个路径添加进去 创建环境 conda create -n your_env_name python=3.7 删除环境 conda remove -n your_env_name --all 激活自定义的环境 source activate your_env_name 退出环境 source deactivate conda deactivate//或者这样 列出所有的环境 conda env list conda info --envs//或者这样 conda安装包和卸载包 conda install x //安装x包 conda uninstall x //卸载x包 ","date":"2022-07-18","objectID":"/%E7%88%AC%E8%99%AB/:7:0","tags":["计算机基础","爬虫","python"],"title":"爬虫","uri":"/%E7%88%AC%E8%99%AB/"}]
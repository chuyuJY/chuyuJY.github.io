[{"categories":["关于"],"content":" Name Chuyu Education Southeast University Research Direction Blockchain \u0026 Golang QQ 1205667742 Mail jyzhangis12@gmail.com Phone +86 15237174980 ","date":"2023-07-27","objectID":"/about/about/:0:0","tags":["关于"],"title":"About Me","uri":"/about/about/"},{"categories":null,"content":" 公司 投递状态 进度 携程 2023/03/13 已投递 😢测评挂 03/17 米哈游 2023/03/13 已投递 😢笔试挂 03/28 拼多多 2023/03/08 已投递 😢笔试挂 03/16 美团 2023/03/10 已投递 😢一面挂 03/28 快手 2023/03/21 已投递 😢简历挂 极智嘉 2023/04/05 已投递 一面挂 SHEIN 2023/03/30 已投递 一面挂(?) 莉莉丝 2023/04/10 已投递 简历挂 网易雷火 2023/03/08 已投递 放弃笔试 腾讯音乐 2023/03/14 已投递 已笔试 美的 2023/04/04 已投递 笔试AC 笔试挂 小红书 2023/03/13 已投递 已笔试 恒生 2023/03/08 已投递 一面挂 京东 2023/03/13 已投递 测评挂 联想 2023/03/16 已投递 已测评 OPPO 2023/03/31 已投递 简历挂 格灵深瞳 [2023/04/04 已投递] 已笔试 中国银行 2023/04/04 已投递 等面试 华泰 2023/03/26 已投递 蚂蚁 2023/04/19 已投递 阿里 2023/04/14 已投递 一面挂 腾讯 2023/04/20 已投递 一面挂 字节跳动 2023/04/17 已投递 一面挂 华为 2023/03/08 已投递 等二面 百度 2023/03/13 已投递 05/08 二面挂 七牛云 2023/03/08 已投递 旷世 2023/03/08 已投递 完美世界 2023/03/09 已投递 泰康保险 2023/03/09 已投递 浪潮 2023/03/10 已投递 知乎 2023/03/13 已投递 哔哩哔哩 2023/03/20 已投递 招商银行 2023/04/05 已投递 招商证券 2023/04/05 已投递 荣耀 2023/04/10 已投递 滴滴 2023/04/10 已投递 菜鸟 https://talent.cainiao.com/positiondetail/2015602/internship 360 2023/04/12 已投递 趣加 2023/04/13 已投递 网易云音乐 2023/04/14 已投递 奇安信 2023/04/27 已投递 小米 2023/04/27 已投递 2023/03/15 会议纪要： 第一个图，block 小的为啥不在最下边？ 补充只有 UE 参加共识的场景； 先跑两个极端的，只有基站和只有UE的； 补充空口的传输时延； 最大 TPS ，单位换成 Bytes/s； 移动速度比较小的时候，需要再跑跑； 只有UE的场景中的基站数目 要和 只有基站的场景中的基站数目 相等； 排除客户端发送Tx出现抖动的影响；找一个基站发送请求，不用UE发送； 2023/03/30 会议纪要： 拓扑排列图片应该和实际排列一致（改成蜂窝网，直线似乎也行？）； 24 基站多了，整少点，到16就行，然后间隔减小点：4 6 10 12 14 16； 无线传输时延为什么随着UE数目增多而变大； 尝试UDP和TCP两种方式，对比无线传输时延有啥变化； 从物理层和MAC层抓包统计时延，对比从应用层统计时延； 把上下行分开； 按照共识消息长短也分开。 从应用层，细分一下统计时延。TCP缓冲窗口，看看数据是不是堆在那里（zjy）； 从物理层和MAC层，细分一下统计时延（ys）。 ./ns3 run “scratch/nr_pbft.cc –blockSize=10 –txSize=500 –log=false –saveFileName=\"results/shiwu_10_500.txt\"” ./ns3 run “scratch/nr_pbft.cc –blockSize=100 –txSize=100 \" 100 200 10 50 ","date":"0001-01-01","objectID":"/01-%E7%AE%80%E5%8E%86%E6%8A%95%E9%80%92%E8%AE%B0%E5%BD%95/:0:0","tags":null,"title":"","uri":"/01-%E7%AE%80%E5%8E%86%E6%8A%95%E9%80%92%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Go 读取超长的单行非常有病，看这个链接吧：https://aimuke.github.io/go/2020/06/18/go-readline/ 输入： 建议一旦开始用sc，之后所有的就都用sc.ReadString读取，如果中间你又用fmt.Scanf()这种方式，有可能会出错！ func main() { sc := bufio.NewReader(os.Stdin) // 当用 sc.ReadString('\\n') 读取输入的一行数据时，长度其实是输入数据的len+2，这是因为末尾有\\r和\\n，所以要去除末尾的\\r和\\n // 1. 获取字符串 str, _ := sc.ReadString('\\n') str = strings.TrimRight(str, \"\\r\\n\") // 去掉回车+换行 非常非常重要的一步!!! //此时, str 才是真正的输入字符 fmt.Println(len(str)) fmt.Println(str + \" world\") // 2. 获取单个数字 // 方法一 str, _ = sc.ReadString('\\n') str = strings.TrimRight(str, \"\\r\\n\") num, _ := strconv.Atoi(str) fmt.Println(num) // 方法二(建议，g) var n, m int64 fmt.Scanf(\"%v %v\\n\", \u0026n, \u0026m) fmt.Println(n, m) var x, y int fmt.Scanf(\"%v %v\\n\", \u0026x, \u0026y) fmt.Println(x, y) // 3. 获取数组 str, _ = sc.ReadString('\\n') str = strings.TrimRight(str, \"\\r\\n\") nums := []int64{} strs := strings.Split(str, \" \") for _, str := range strs { num, _ := strconv.ParseInt(str, 10, 64) nums = append(nums, num) } fmt.Println(nums) } 注意：Unix 和 Windows 的行结束符是不同的！Unix 似乎是 \\n，Windows 是 \\r\\n。 字符串转换： func main() { sc := bufio.NewReader(os.Stdin) str, _ := sc.ReadString('\\n') str = strings.TrimRight(str, \"\\r\\n\") // 1. string 转 int int 转 string numInt, _ := strconv.Atoi(str) numStr := strconv.Itoa(numInt) fmt.Println(numStr) // 2. string 转 int64 int64 转 string numInt64, _ := strconv.ParseInt(str, 10, 64) numStr = strconv.FormatInt(numInt64, 10) fmt.Println(numStr) // 3. string 转 float64 float64 转 string numFloat64, _ := strconv.ParseFloat(str, 64) numStr = strconv.FormatFloat(numFloat64, 'f', -1, 64) fmt.Println(numStr) } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:0:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"美团 滑动窗口 二维前缀和 **题目：**小美在玩一项游戏，该游戏的目标是尽可能抓获敌人。敌人的位置将被一个二维坐标(x, y) 所描述。小美有一个全屏技，该技能能一次性将若干敌人一次性捕获。捕获的敌人之间的横坐标的最大差值不能大于A，纵坐标的最大差值不能大于B。 现在给出所有敌人的坐标，你的任务是计算小美一次性最多能使用技能捕获多少敌人。 输入描述： 第一行三个整数N,A,B，表示共有N个敌人，小人的全屏技能的参数A和参数B。接下来N行，每行两个数字x,y，描述一个敌人所在的坐标1 \u003c= N \u003c= 500，1 \u003c= A, B \u003c= 1000，1 \u003c= x, y \u003c= 1000. func count(coords [][2]int, A, B int) int { // 1. 把这些点放到矩阵中 matrix := make([][]int, 1001) for i := 0; i \u003c len(matrix); i++ { matrix[i] = make([]int, 1001) } for _, coord := range coords { matrix[coord[0]][coord[1]] = 1 } // 2. 计算前缀和 for i := 1; i \u003c len(matrix); i++ { for j := 1; j \u003c len(matrix[0]); j++ { matrix[i][j] += matrix[i-1][j] + matrix[i][j-1] - matrix[i-1][j-1] } } // 3. 计算子矩阵 ans := 0 for i := A + 1; i \u003c len(matrix); i++ { for j := B + 1; j \u003c len(matrix[i]); j++ { ans = max(ans, matrix[i][j]-matrix[i-A-1][j]-matrix[i][j-B-1]+matrix[i-A-1][j-B-1]) } } return ans } func max(a, b int) int { if a \u003e b { return a } return b } func main() { coords := [][2]int{{1, 1}, {2, 2}, {3, 3}, {1, 3}, {1, 4}} fmt.Println(count(coords, 1, 2)) } 滑动窗口 **题目：**塔子哥是一名设计师，最近接到了一项重要任务：设计一个新款的生日蜡烛，以庆祝公司成立20周年。为了使蜡烛看起来更加炫目，塔子哥计划在蜡烛上缠绕彩带。他买了一串长度为 N 的非常漂亮的彩带，每一厘米的彩带上都是一种色彩，但是当他拿到彩带后才发现，彩带上的颜色太多了，超出了他设计中所需要的颜色种类数量。 于是，塔子哥决定从彩带上截取一段，使得这段彩带上的颜色种类不超过K种。但是，他希望这段彩带尽量长，这样才能在蜡烛上缠绕出更加炫目的效果。为了尽快完成设计，他来找你求助，希望你能帮他设计出一种截取方法，使得截取出来的彩带尽可能长，并且颜色种类不超过K种。 输入描述 第一行两个整数�,�N,K，以空格分开，分别表示彩带有�N厘米长，你截取的一段连续的彩带不能超过�K种颜色。接下来一行�N个整数，每个整数表示一种色彩，相同的整数表示相同的色彩。 1≤�,�≤50001≤N,K≤5000，彩带上的颜色数字介于[1,2000][1,2000]之间 输出描述 一行，一个整数，表示选取的彩带的最大长度。 样例1 输入 8 3 1 2 3 2 1 4 5 1 输出 5 说明： 最长的一段彩带是[1，2，3，2，1][1，2，3，2，1]，共55厘米。 package main import ( \"bufio\" \"fmt\" \"os\" \"strconv\" \"strings\" ) func main() { sc := bufio.NewReader(os.Stdin) var n, k int fmt.Fscanln(sc, \u0026n, \u0026k) nums := []int{} str, _ := sc.ReadString('\\n') strs := strings.Split(strings.TrimRight(str, \"\\r\\n\"), \" \") for _, str := range strs { num, _ := strconv.Atoi(str) nums = append(nums, num) } fmt.Println(test(n, k, nums)) } func test(n, k int, nums []int) int { res := 0 hashMap := map[int]int{} count := 0 left, right := 0, 0 for right \u003c n { for left \u003c right \u0026\u0026 count \u003e k { hashMap[nums[left]]-- if hashMap[nums[left]] == 0 { count-- } left++ } res = max(res, right-left) if val, exist := hashMap[nums[right]]; !exist || val == 0 { count++ } hashMap[nums[right]]++ right++ } if count \u003c= k { res = max(res, right-left) } return res } func max(a, b int) int { if a \u003e b { return a } return b } 贪心算法 **题目：**现在小美获得了一个字符串。小美想要使得这个字符串是回文串。小美找到了你。你可以将字符串中至多两个位置改为任意小写英文字符’a’-‘z’。 你的任务是帮助小美在当前制约下，获得字典序最小的回文字符串。数据保证能在题目限制下形成回文字符串。 注：回文字符串：即一个字符串从前向后和从后向前是完全一致的字符串。 例如字符串abcba, aaaa, acca都是回文字符串。字符串abcd, acea都不是回文字符串。 **输入描述：**一行，一个字符串。字符串中仅由小写英文字符构成。保证字符串不会是空字符串。字符串长度介于 [1, 100000] 之间。 func count(str string) string { strByte := []byte(str) left, right := 0, len(strByte)-1 pos := [][]int{} // 统计不相同的位置对 for left \u003c right { if strByte[left] != strByte[right] { pos = append(pos, []int{left, right}) } left++ right-- } if len(pos) == 0 { for i := 0; i \u003c len(strByte); i++ { if strByte[i] != 'a' { strByte[i], strByte[len(strByte)-1-i] = 'a', 'a' } } } else if len(pos) == 1 { if strByte[pos[0][0]] == 'a' || strByte[pos[0][1]] == 'a' { if len(strByte)\u00261 == 1 { strByte[len(strByte)/2] = 'a' } } strByte[pos[0][0]], strByte[pos[0][1]] = 'a', 'a' } else if len(pos) == 2 { mb := min(strByte[pos[0][0]], strByte[pos[0][1]]) strByte[pos[0][0]], strByte[pos[0][1]] = mb, mb mb = min(strByte[pos[1][0]], strByte[pos[1][1]]) strByte[pos[1][0]], strByte[pos[1][1]] = mb, mb } return string(strByte) } func min(a, b byte) byte { if a \u003c b { return a } return b } 贪心算法/动态规划 **题目：**现在商店里有 N 个物品，每个物品有原价和折扣价小美想要购买商品。小美拥有 X 元，一共 Y 张折扣券。小美需要最大化购买商品的数量，并在所购商品数量尽量多的前提下，尽量减少花费。 你的任务是帮助小美求出最优情况下的商品购买数量和花费的钱数。 输入描述： 第一行三个整数，以空格分开，分别表示 N，X，Y。 接下来 N 行，每行两个整数，以空格分开，表示一个的原价和折扣价。1 \u003c= N \u003c= 100，1 \u003c= X \u003c= 5000，1 \u003c= Y \u003c= 50，每个商品原价和折扣价均介于[1,50]之间。 输出描述： 一行，两个整数，以空格分开。第一个数字表示最多买几个商品，第二个数字表示在满足商品尽量多的前提下所花费的最少的钱数。 // 不会写，先写个dfs func count(oriPrices, disPrices []int, money, k int) (int, int) { // 返回 使用的钱，买到物品的数量 var ba","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:1:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"米哈游 图 **题目：**米小游拿到了一个矩阵，矩阵上有一格有一个颜色，为红色( R )。绿色( G )和蓝色( B )这三种颜色的一种。 然而米小游是蓝绿色盲，她无法分游蓝色和绿色，所以在米小游眼里看来，这个矩阵只有两种颜色，因为蓝色和绿色在她眼里是一种颜色。 米小游会把相同颜色的部分看成是一个连通块。请注意，这里的连通划是上下左右四连通的。 由于色盲的原因，米小游自己看到的连通块数量可能比真实的连通块数量少。 你可以帮米小游计算连通块少了多少吗？ 输入描述： 第一行输入两个正整数 n 和 m ，代表矩阵的行数和列数。 接下来的 n 行，每行输入一个长度为 m 的，仅包含 R 、G 、B 三种颜色的字符串，代表米小游拿到的矩阵。 1 ≤ n, m ≤ 1000 输出描述： 一个整数，代表米小游视角里比真实情况少的连通块数量。 输入 2 6 RRGGBB RGBGRR 输出 3 **BFS：**不知道是否会超时 package main import ( \"fmt\" ) func main() { //var n, m int //fmt.Scanf(\"%v %v\\n\", \u0026n, \u0026m) //sc := bufio.NewScanner(os.Stdin) //matrix := []string{} //if sc.Scan() { // str := sc.Text() // matrix = append(matrix, str) //} matrix := []string{\"RRGGBB\", \"RGBGRR\"} fmt.Println(count(matrix)) } func count(matrix []string) int { sig, both := 0, 0 hashMap := map[byte]int{'G': 0, 'B': 1} visitedMap := make([][]bool, len(matrix)) for i := 0; i \u003c len(visitedMap); i++ { visitedMap[i] = make([]bool, len(matrix[0])) } for i := 0; i \u003c len(matrix); i++ { for j := 0; j \u003c len(matrix[i]); j++ { if !visitedMap[i][j] \u0026\u0026 (matrix[i][j] == 'G' || matrix[i][j] == 'B') { sig++ bfs(matrix, hashMap[matrix[i][j]], visitedMap, i, j) } } } for i := 0; i \u003c len(visitedMap); i++ { for j := 0; j \u003c len(visitedMap[i]); j++ { visitedMap[i][j] = false } } for i := 0; i \u003c len(matrix); i++ { for j := 0; j \u003c len(matrix[i]); j++ { if !visitedMap[i][j] \u0026\u0026 (matrix[i][j] == 'G' || matrix[i][j] == 'B') { both++ bfs(matrix, 2, visitedMap, i, j) } } } return sig - both } func bfs(matrix []string, k int, visitedMap [][]bool, i, j int) { // 0, 1, 2 var color byte if k == 0 { color = 'G' } else if k == 1 { color = 'B' } else if k == 2 { color = 'A' } queue := [][]int{{i, j}} visitedMap[i][j] = true dirs := [][]int{{-1, 0}, {1, 0}, {0, -1}, {0, 1}} for len(queue) \u003e 0 { curNode := queue[0] queue = queue[1:] for _, dir := range dirs { newX, newY := curNode[0]+dir[0], curNode[1]+dir[1] if 0 \u003c= newX \u0026\u0026 newX \u003c len(matrix) \u0026\u0026 0 \u003c= newY \u0026\u0026 newY \u003c len(matrix[0]) \u0026\u0026 !visitedMap[newX][newY] { if color != 'A' \u0026\u0026 matrix[newX][newY] == color { queue = append(queue, []int{newX, newY}) visitedMap[newX][newY] = true } if color == 'A' \u0026\u0026 (matrix[newX][newY] == 'G' || matrix[newX][newY] == 'B') { queue = append(queue, []int{newX, newY}) visitedMap[newX][newY] = true } } } } } DFS： func count(matrix []string) int { sig, both := 0, 0 hashMap := map[byte]int{'G': 0, 'B': 1} visitedMap := make([][]bool, len(matrix)) for i := 0; i \u003c len(visitedMap); i++ { visitedMap[i] = make([]bool, len(matrix[0])) } for i := 0; i \u003c len(matrix); i++ { for j := 0; j \u003c len(matrix[i]); j++ { if !visitedMap[i][j] \u0026\u0026 (matrix[i][j] == 'G' || matrix[i][j] == 'B') { sig++ dfs(matrix, hashMap[matrix[i][j]], visitedMap, i, j) } } } for i := 0; i \u003c len(visitedMap); i++ { for j := 0; j \u003c len(visitedMap[i]); j++ { visitedMap[i][j] = false } } for i := 0; i \u003c len(matrix); i++ { for j := 0; j \u003c len(matrix[i]); j++ { if !visitedMap[i][j] \u0026\u0026 (matrix[i][j] == 'G' || matrix[i][j] == 'B') { both++ dfs(matrix, 2, visitedMap, i, j) } } } return sig - both } func dfs(matrix []string, k int, visitedMap [][]bool, i, j int) { var color byte if k == 0 { color = 'G' } else if k == 1 { color = 'B' } else { color = 'A' } dirs := [][]int{{-1, 0}, {1, 0}, {0, -1}, {0, 1}} visitedMap[i][j] = true for _, dir := range dirs { newX, newY := i+dir[0], j+dir[1] if 0 \u003c= newX \u0026\u0026 newX \u003c len(matrix) \u0026\u0026 0 \u003c= newY \u0026\u0026 newY \u003c len(matrix[0]) \u0026\u0026 !visitedMap[newX][newY] { if color != 'A' \u0026\u0026 matrix[newX][newY] == color { dfs(matrix, k, visitedMap, newX, newY) } if color == 'A' \u0026\u0026 (matrix[newX][newY] == 'G' || matrix[newX][newY] == 'B') { dfs(matrix, k, visitedMap, newX, newY) } } } } **题目：**米小游拿到了一个字符串 s 。她可以进行任意次以下两种操作： 删除 s 的一个 \"mhy\" 子序列。 添加一个 \"mhy\" 子序列在 s 上。 例如，给定 s 为 \"mhbdy\" ，米小游进行一次操作后可以使 s 变成 \"bd\" ，或者变成 \"mhmbhdyy\" 。 米小游想知道，经过若干次操作后 s 是否可以变成 t ？ 注：子序列在原串中的顺序也是从左到右，但可以不连续。 输入描述： 第一行输入一个正整数 q ，代表询问的次数。 接下来每两行为一次询问：每行均为一个字符串，分别代表 s 和 t 。 1≤�≤1031≤q≤103 字符串的长度均不超过 103103 。 输出描述： 输出 q 行，每行输入一行答案。若可以使 s 变成 t ，则输出 \"Yes\" 。否则输出 \"No\" 。 输入 3 mhbdy bd mhbdy mhmbhdyy mhy ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:2:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"阿里 **题目：**给定一个字符串，判断是否为“ali”型字符串。字符串满足以下条件： （1）字符串仅包含a、l、i三种字母， (包括大写和小写) （2）字符串的开头为仅包含a或者“A\"的连续子串 （3）在该子串后面，为仅包含l或者L的连续子申 （4）在该子串后面，为仅包含i或者I的连续子甲。该子审结束后将直接到达字符串的结尾 输入AAaLlLLiili，输出Yse； 输入aAiIlL，输出No 输入alIali，输出No func isValid(str string) bool { flagA, flagB, flagC := false, false, false for i := 0; i \u003c len(str); i++ { cur := str[i] | 32 if cur == 'a' { if flagB || flagC { return false } flagA = true } if cur == 'l' { if !flagA || flagC { return false } flagB = true } if cur == 'i' { if !flagA || !flagB { return false } flagC = true } } return flagA \u0026\u0026 flagB \u0026\u0026 flagC } func main() { fmt.Println(isValid(\"AAaLlLLiiIi\")) fmt.Println(isValid(\"ail\")) fmt.Println(isValid(\"aliali\")) } DFS **题目：**给定一个n层的满二叉树，一共2^n^ - 1个节点，编号从1到2^n^ -1。对于编号为i的节点，它的左儿子为2i，它的右儿子为2i+ 1.有q次操作，每次操作我们选择一个节点，将该节点的子树的所有节点全部染红。每次操作后，你需要输出当前二叉树红色节点的数量。我们定义一棵二叉树是满二叉树，当且仅当每一层的节点数量都达到了最大值(即无法在这一层添加新节点)。 type TreeNode struct { Color int // 0: 未染色, 1: 染色 Left *TreeNode Right *TreeNode } func buildTree(height int) *TreeNode { if height == 0 { return nil } return \u0026TreeNode{0, buildTree(height - 1), buildTree(height - 1)} } type Tree struct { count int // 保存已染色节点数量 root *TreeNode } func main() { var n, q int fmt.Scanf(\"%v %v\\n\", \u0026n, \u0026q) tree := \u0026Tree{ count: 0, root: buildTree(n), } sc := bufio.NewScanner(os.Stdin) for i := 0; i \u003c q; i++ { if sc.Scan() { str := sc.Text() num, _ := strconv.Atoi(str) fmt.Println(tree.RanSe(num)) } } } // RanSe 返回染色后共有多少染色节点 func (t *Tree) RanSe(i int) int { node := getNode(i, t.root) t.count += dfs(node) return t.count } func getNode(i int, node *TreeNode) *TreeNode { if i == 1 { return node } stack := []int{} for i \u003e 1 { stack = append(stack, i) i \u003e\u003e= 1 } for len(stack) \u003e 0 { num := stack[len(stack)-1] stack = stack[:len(stack)-1] if num\u00261 == 0 { node = node.Left } else { node = node.Right } } return node } func dfs(node *TreeNode) int { if node == nil || node.Color == 1 { return 0 } res := 1 node.Color = 1 res += dfs(node.Left) res += dfs(node.Right) return res } import java.util.Scanner; import java.util.Stack; class TreeNode { int color; TreeNode left; TreeNode right; public TreeNode(int color, TreeNode left, TreeNode right) { this.color = color; this.left = left; this.right = right; } } class Tree { int count; TreeNode root; public Tree(int count, TreeNode root) { this.count = count; this.root = root; } public int ranSe(int i) { TreeNode node = getNode(i, root); count += dfs(node); return count; } private TreeNode getNode(int i, TreeNode node) { if (i == 1) { return node; } Stack\u003cInteger\u003e st = new Stack\u003c\u003e(); while (i \u003e 1) { st.push(i); i \u003e\u003e= 1; } while (!st.empty()) { int num = st.pop(); if ((num \u0026 1) == 0) { node = node.left; } else { node = node.right; } } return node; } private int dfs(TreeNode node) { if (node == null || node.color == 1) { return 0; } int res = 1; node.color = 1; res += dfs(node.left); res += dfs(node.right); return res; } } public class Main { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); int q = scanner.nextInt(); Tree tree = new Tree(0, buildTree(n)); for (int i = 0; i \u003c q; i++) { int num = scanner.nextInt(); System.out.println(tree.ranSe(num)); } } private static TreeNode buildTree(int height) { if (height == 0) { return null; } return new TreeNode(0, buildTree(height - 1), buildTree(height - 1)); } } 2023.3.15-第一题-满二叉树计数 **题目：**在一个遥远的国度，有一个古老的神秘森林，被认为是森林之王的家园。传说森林之王是一只拥有巨大力量和智慧的生物，掌管着整个森林的命运。为了探索森林之王的秘密，许多勇敢的探险家一直在进入这片神秘的森林中。然而，进入森林之后，他们都没有回来过，因此这个秘密依然没有被解开。 有一天，一位名叫塔子哥的年轻探险家也进入了森林。他翻越了陡峭的山峰，穿过了茂密的丛林，终于到达了一处古老的废墟。在废墟的中心，塔子哥发现了一棵神奇的二叉树。这棵二叉树是如此的美丽，以至于塔子哥不禁驻足观赏，他想知道这棵二叉树有多少个节点满足以该节点为根的子树是满二叉树。于是，他开始了他的计算，希望能够揭开这个森林之王的秘密。 我们定义一棵树是满二叉树，当且仅当每一层的节点数量都达到了最大值(即无法在这一层添加新节点)。 输入描述 第一行输入一个正整数n，代表节点的数量。 接下来的n行，第i行输入两个整数l_i和r_i，代表i号节点的左儿子和右儿子。请注意，如果一个节点没有左儿子/右儿子，则对应的l_i/r_i为-1。 1≤n≤10^5^ 输出描述 子树为满二又树的节点数量。 样例11 输入 5 2 3 4 5 -1 -1 -1 -1 -1 -1 输出 4 说明 22、33、44、55号节点的子树都是满二叉树 func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) nodes := m","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:3:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"腾讯音乐 贪心（不想写贪心！） 小红拿到了一个二叉树，二叉树共有n个节点。小红希望你将所有节点赋值为1到n的正整数，且没有两个节点的值相等。需要满足：奇数层的权值和与偶数层的权值和之差的绝对值不超过1。 如果有多种赋值方案，请返回任意—种方案。如果无解，请返回空树。数据范围: 1 \u003c n ≤ 10^5^。给定的二叉树节点初始权值默认为-1。 示例1 输入 {-1,-1,-1} 输出 {3,1,2} 示例2 输入 {-1,-1,#,-1,-1} 输出 {} 示例3 输入 {-1,-1,-1,#,-1,-1} 输出 {1,3,4,#,2,5} 二分查找 这题能用二分真么想到啊，写了一个小时，DP只能过40%。 动态规划： 二分查找： 2023.04.13-第二题-价值二叉树 **题目：**塔子哥是一位著名的计算机科学家，在一次采集森林中的植物时，偶然发现了一棵非常特殊的树。这棵树是一棵二叉树，其节点上都标有不同的数字。 在细心观察后，塔子哥意识到这棵二叉树是由多个相同的子树组成的，每个子树的根节点都是同一个数字。他对这个发现感到非常兴奋，并且开始研究如何计算这些子树的价值。 他定义每个节点的价值为其子树节点乘积的末尾 0 的数量。因此，如果一个节点的子树中有 k 个数末尾带有 0，那么该节点的价值为 k。 塔子哥想编写一个程序来计算每个节点的价值，以便能够更好地研究这棵树的特性。他请求您的帮助来实现这个程序，您需要返回一棵二叉树，树的结构和给定的二叉树相同，将每个节点的权值替换为该节点的价值。 二又树节点数不超过 105 。 二又树每个节点的权值都是不超过 109 的正整数。 输入描述 第一行为一个整数 n ，表示这棵树的节点个数。 第二行为 n 个整数，第 i 个整数为 ai ，表示这 n 个节点的取值。 接下来的 n−1 行，每行输入两个正整数 u 和 v ，代表节点 u 和节点 v 有一条边相连。 根为1 1≤n≤10^5^，1≤ai≤10^9^ 。 输出描述 输出一行 n 个正整数，分别代表 1 号节点到 n 号节点，每个节点的子树权值乘积尾零的数量。 样例 输入 5 2 5 10 4 5 1 2 1 3 3 4 3 5 输出 3 0 2 0 0 似乎可以用树形 DP。 这里用的二叉树的后序遍历。 type TreeNode struct { Id int Nums []int // 存储 2 和 5 的个数, 直接存乘积可能会溢出 Left, Right *TreeNode } func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) a := []int{0} for i := 1; i \u003c= n; i++ { var ai int fmt.Fscan(sc, \u0026ai) a = append(a, ai) } fmt.Fscanln(sc) edges := [][]int{} for i := 1; i \u003c n; i++ { var u, v int fmt.Fscanln(sc, \u0026u, \u0026v) edges = append(edges, []int{u, v}) } test2(a, edges) } func test2(a []int, edges [][]int) { // 1. 建树 tree := make([]*TreeNode, len(a)) for _, edge := range edges { if tree[edge[0]] == nil { tree[edge[0]] = \u0026TreeNode{} } if tree[edge[1]] == nil { tree[edge[1]] = \u0026TreeNode{} } tree[edge[0]].Id, tree[edge[1]].Id = edge[0], edge[1] tree[edge[0]].Nums = calZero(a[edge[0]]) tree[edge[1]].Nums = calZero(a[edge[1]]) if tree[edge[0]].Left == nil { tree[edge[0]].Left = tree[edge[1]] } else { tree[edge[0]].Right = tree[edge[1]] } } root := tree[1] // 2. 后序遍历 res := make([]int, len(a)) var sufOrder func(curNode *TreeNode) sufOrder = func(curNode *TreeNode) { if curNode.Left == nil \u0026\u0026 curNode.Right == nil { res[curNode.Id] = min(curNode.Nums[0], curNode.Nums[1]) return } if curNode.Left != nil { sufOrder(curNode.Left) curNode.Nums[0] += curNode.Left.Nums[0] curNode.Nums[1] += curNode.Left.Nums[1] } if curNode.Right != nil { sufOrder(curNode.Right) curNode.Nums[0] += curNode.Right.Nums[0] curNode.Nums[1] += curNode.Right.Nums[1] } res[curNode.Id] = min(curNode.Nums[0], curNode.Nums[1]) } sufOrder(root) for i := 1; i \u003c len(res); i++ { fmt.Printf(\"%v \", res[i]) } } func calZero(val int) []int { nums := make([]int, 2) for val \u003e 0 \u0026\u0026 val%2 == 0 { nums[0]++ val /= 2 } for val \u003e 0 \u0026\u0026 val%5 == 0 { nums[1]++ val /= 5 } return nums } func min(a, b int) int { if a \u003c b { return a } return b } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:4:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"恒生 动态规划/DFS 给定m初始金额，a 为每天的股价，k为一共可买卖多少次，求最大利润(主要要减去本金！) func getMaxProfit(m float64, n int, a []float64, k int) float64 { dp := make([][][2]float64, n) for i := 0; i \u003c len(dp); i++ { dp[i] = make([][2]float64, k+1) } // 初始化 dp[0][0][0] = m dp[0][0][1] = m / a[0] for i := 1; i \u003c len(dp); i++ { for j := 0; j \u003c= k; j++ { if j == 0 { dp[i][j][0] = dp[i-1][j][0] dp[i][j][1] = dp[i-1][j][0] / a[i] } else { dp[i][j][0] = max(dp[i-1][j][0], dp[i-1][j-1][1]*a[i]) // 第j次 不持有 dp[i][j][1] = max(dp[i-1][j][1], dp[i-1][j][0]/a[i]) // 第j次 持有 } } } return dp[n-1][k][0] - m } func max(a, b float64) float64 { if a \u003e b { return a } return b } func main() { historyPrices := []float64{1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0} fmt.Println(getMaxProfit(10000, 7, historyPrices, 2)) } public class Main { public static double get_max_profit(double M, int N, double[] historyPrices, int K) { return dfs(M, 0, 0, historyPrices, K) - M; } public static double dfs(double profit, int gu, int index, double[] historyPrices, int k) { if (index == historyPrices.length) { return profit; } double res = profit; // 持有股票，卖出 if (gu \u003e 0) { res = Math.max(res, dfs(profit + gu * historyPrices[index], 0, index + 1, historyPrices, k)); } // 没持有股票，买入 if (gu == 0 \u0026\u0026 k \u003e 0) { int nextGu = (int) (profit / historyPrices[index]); res = Math.max(res, dfs(profit - nextGu * historyPrices[index], nextGu, index + 1, historyPrices, k - 1)); } // 不买也不卖 res = Math.max(res, dfs(profit, gu, index + 1, historyPrices, k)); return res; } public static void main(String[] args) { double[] historyPrices = new double[]{1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0}; System.out.println(get_max_profit(10000, 7, historyPrices, 2)); // 50000 } } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:5:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"蚂蚁 2022.10.27-括号匹配 **题目：**给定个仅包含 ( 、 ) 和 ? 三种字符构成的字符串，? 字符可以代替左括号或者右括号。请问该字符串可以代表多少种不同的合法括号序列? 输入描述 一个仅包含( 、) 和 ? 的字符串，长度不超过 20002000 。 输出描述 合法序列的数量。由于数量可能过大，请对 109+7109+7 取模。 样例 输入 ????(? 输出 2 样例解释 共有 22 种不同的合法括号序列， () () () 或 (()) () 假设字符串长度为 n，可以考虑使用动态规划求解。令 dp[i][j] 表示前 i 个字符中，左括号比右括号多 j 个的方案数。考虑第 i+1 个字符： 如果是左括号，则 dp[i+1][j+1] = dp[i][j]。 如果是右括号，则 dp[i+1][j-1] = dp[i][j]。 如果是问号，则既可以代表左括号，也可以代表右括号，因此 dp[i+1][j+1] = dp[i][j] + dp[i+1][j-1]。 最终答案即为 dp[n][0]，表示左右括号数量相等的方案数。 需要注意的是，由于原始字符串中可能存在 ? 字符，因此需要初始化 dp[0][0] = 1，并将剩余的 dp[0][j] 和 dp[i][j] 的值都设为 0。 package main import ( \"bufio\" \"fmt\" \"os\" ) var mod int = 1e9 + 7 func main() { sc := bufio.NewScanner(os.Stdin) sc.Scan() str := sc.Text() fmt.Println(test1(str)) } func test1(str string) int { dp := make([][]int, len(str)+1) for i := 0; i \u003c len(dp); i++ { dp[i] = make([]int, i+1) } str = \"#\" + str dp[0][0] = 1 for i := 1; i \u003c len(dp); i++ { for j := 0; j \u003c= i; j++ { if str[i] == '(' \u0026\u0026 j \u003e 0 { dp[i][j] = dp[i-1][j-1] % mod } if str[i] == ')' \u0026\u0026 j \u003c i-1 { dp[i][j] = dp[i-1][j+1] % mod } if str[i] == '?' { if j \u003e 0 { dp[i][j] += dp[i-1][j-1] % mod } if j \u003c i-1 { dp[i][j] += dp[i-1][j+1] % mod } } } } return dp[len(dp)-1][0] } 可以简化一下for循环里的逻辑： func test1(str string) int { dp := make([][]int, len(str)+1) for i := 0; i \u003c len(dp); i++ { dp[i] = make([]int, i+1) } str = \"#\" + str dp[0][0] = 1 for i := 1; i \u003c len(dp); i++ { for j := 0; j \u003c= i; j++ { if (str[i] == '(' || str[i] == '?') \u0026\u0026 j \u003e 0 { dp[i][j] = dp[i-1][j-1] % mod // 这边是 = } if (str[i] == ')' || str[i] == '?') \u0026\u0026 j \u003c i-1 { dp[i][j] += dp[i-1][j+1] % mod // 这边是 +=, 主要是应对 '?' d } } } return dp[len(dp)-1][0] } 2023.03.21-第二题-红白染色树 **题目：**曾经有一个名叫塔子哥的年轻人，他喜欢探索和解决各种难题。有一天，他发现了一棵神奇的树。树上已经有一些点被染成了红色，另一些点被染成了白色。 但是塔子哥想让相邻的两个点不能够颜色相同，因此他想知道最少需要进行多少次操作才能让树上所有相邻两个点的颜色不同，每次操作塔子哥可以选择一个点改变它的染色状态（红色变白色或者白色变红色）。 这个问题困扰着他很长一段时间，但是他决定不放弃，你能帮塔子哥想一想怎么解决这个问题吗？ 输入描述 第一行输入一个正整数 n ，代表节点的数量。 第二行输入一个长度为 n 的、仅由 'R' 、 'W' 两种字符组成的字符串，第 i 个字符为 'R' 代表 i 号节点被染成红色， 'W' 代表被染成白色。 接下来的 n−1 行，每行输入两个正整数 u 和 v ，代表节点 u 和节点 v 有一条路径相连。 1 ≤ n ≤ 10^5^ 1 ≤ u,v ≤ n 输出描述 一个整数，代表最小的操作次数。 样例 输入 4 RWWW 1 2 2 3 2 4 输出 2 样例解释 对 11 号和 22 号节点各操作一次即可。 思路： 拓扑排序 func main() { var n int fmt.Scanf(\"%v\\n\", \u0026n) sc := bufio.NewReader(os.Stdin) str, _ := sc.ReadString('\\n') colors := strings.TrimRight(str, \"\\r\\n\") edges := [][]int{} for i := 0; i \u003c n-1; i++ { var u, v int fmt.Fscanln(sc, \u0026u, \u0026v) edges = append(edges, []int{u - 1, v - 1}) } fmt.Println(test2(colors, edges)) } func test2(colors string, edges [][]int) int { graph := map[int][]int{} inDegrees := make([]int, len(colors)) for _, edge := range edges { graph[edge[0]] = append(graph[edge[0]], edge[1]) inDegrees[edge[1]]++ } return min(updateColor(graph, inDegrees, colors, 0), updateColor(graph, inDegrees, colors, 1)) } func updateColor(graph map[int][]int, inDegrees []int, colors string, startColor int) int { res := 0 colorMap := []byte{'R', 'W'} tmpInDegrees := make([]int, len(inDegrees)) copy(tmpInDegrees, inDegrees) queue := []int{} nextQueue := []int{} for i, inDegree := range tmpInDegrees { if inDegree == 0 { queue = append(queue, i) } } curColor := startColor for len(queue) \u003e 0 { cur := queue[0] queue = queue[1:] if colors[cur] != colorMap[curColor] { res++ } for _, node := range graph[cur] { tmpInDegrees[node]-- if tmpInDegrees[node] == 0 { nextQueue = append(nextQueue, node) } } if len(queue) == 0 { queue = nextQueue nextQueue = []int{} curColor ^= 1 } } return res } func min(a, b int) int { if a \u003c b { return a } return b } 2023.04.11-蚂蚁-第一题 **题目：**塔子哥是一位年轻的数学家，他一直对数学理论充满热情和好奇心。有一天，他在研究数学理论时发现了一个有趣的问题。他偶然间发现了一个古老的书卷，上面记载着一些神秘的数学定理和公式，其中有一个问题深深吸引了他的注意力。 这个问题涉及到一个长度为n的整数数组，其中每个元素都是一个正整数。 塔子哥很感兴趣的是，有多少个奇数出现了奇数次。 注：出现多次的元素也都要计算在内。 输入描述 第一行输入一个正整数 n ，代表数组的大小。 第二行输入 n 个正整数 ai ，代表数组的元素。 1≤n≤200000 1≤ai≤109 输出描述 一个整数，代表最终出现次数是奇数的奇数数量。 样例 输入 5 1 2 3 3 5 输出 2 样例解释 1 出现了一次， 2 出现了一次， 3 出现了两次， 5 出来了一次，符合条件的只有一个 1 和一个 5 。 **思路：**滑动窗口 func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) a := []int{} for i := 0; ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:6:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"百度 2023.3.13-第二题-构造回文串 **题目：**有一个神话传说，说在很久以前，红色的守护者曾经来到人间，为了保护人们免受邪恶的侵害，他留下了一个强大的魔法。这个魔法被传说中的红宝石所承载，只有能够创造出特定数量回文子串的字符串才能够揭示出它的秘密。 为了获得这个神秘的魔法，有一个名叫塔子哥的人在神秘的传说中展开了他的冒险。他在一本古老的书籍中找到了一篇有关于这个魔法的描述： 在所有由‘r’,‘e’和‘d’这三种字符构成的字符串中，只有当回文子串的数量为特定数量时，才能揭示红宝石的魔法。这个特定数量由一个神秘的整数 x 所定义。 为了获得这个强大的魔法，塔子哥开始思考如何创造出刚好有 x 个回文子串的字符串。他发现，如果想要获得这个魔法，就必须要先找到这个特定的字符串，因此他开始了漫长的冒险之旅。 字符串的长度不得超过10^5^ 输入描述 一个正整数x. 1≤x≤10^9^ 样例 输入 3 输出 red 说明 输出\"dd\"也可以通过本题 package main import ( \"fmt\" \"sort\" ) func main() { var x int fmt.Scanf(\"%v\\n\", \u0026x) fmt.Println(test4(x)) } func test4(x int) string { res := []byte{} chars := []byte{'r', 'e', 'd'} cur := 0 for x \u003e 0 { num := sort.Search(x+1, func(i int) bool { return (i*i+i)/2 \u003e x }) num -= 1 ch := make([]byte, num) for i := 0; i \u003c len(ch); i++ { ch[i] = chars[cur] } cur = (cur + 1) % 3 res = append(res, ch...) x -= (num*num + num) / 2 } return string(res) } 2023.03.28-第三题-塔子的有根树 **题目：**在一个偏远的山区里，有一个叫做塔子哥的数学家。他热爱数学，对树这种数据结构也有着浓厚的兴趣。 有一天，他在森林中漫步时发现了一棵美丽的大树。这棵树非常漂亮，每个节点 i 都是独特的，有着它自己的权值 vali ，并且规定 1 号点为这棵树的根节点。 塔子哥对这棵树产生了浓厚的兴趣，他开始研究这棵树的性质，并思考一些问题。他想知道如果对于树上的某个节点 t ，以 t 为根的子树中所有节点的权值都乘上一个 g ，会对整棵树产生什么影响。 为了更好地研究这个问题，他进行了 q 次操作，每次选择了一个节点 t ，并将以 t 为根的子树中所有节点的权值都乘上了一个 g 。这个过程中，他记录了每个节点的最终权值，但他还想知道一个更有趣的问题：在 q 次操作结束以后，以节点 i 为根的子树中所有节点的权值的乘积的末尾有多少个0。 这个问题非常有趣，因为它不仅涉及到树的结构，还需要考虑数学中数字的性质。塔子哥非常期待你能帮他解决这个问题。 输入描述 第一行输入一个正整数n，代表这颗树的节点的数量。 第二行输入n个正整数vali，代表每个节点的权值。 接下来的n−1行，每行输入两个正整数u和v，代表节点u和节点v有一条边相连。 接下来的一行输入一个正整数q，代表操作次数。 接下来的q行，每行输入两个正整数t和g，代表塔子哥的一次操作。 1⩽n,q⩽10^5^ 1⩽vi,g⩽10^9^ 1⩽t,u,v⩽n 输出描述 输出一行n个正整数，分别代表1号节点到n号节点，每个节点的子树权值乘积尾零的数量。 样例 输入 6 1 2 3 4 5 6 1 2 2 3 1 4 2 5 4 6 2 2 5 4 5 输出 4 1 0 2 0 1 跟腾讯音乐那个很像，只不过不是二叉树了，也带来了点启发：不用建树，就按图写就行。直接对下一层的所有节点dfs，也可以实现先序、后序遍历。 func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) vals := []int{0} for i := 0; i \u003c n; i++ { var v int fmt.Fscan(sc, \u0026v) vals = append(vals, v) } fmt.Fscanln(sc) graph := map[int][]int{} for i := 0; i \u003c n-1; i++ { var u, v int fmt.Fscanln(sc, \u0026u, \u0026v) graph[u] = append(graph[u], v) } var q int fmt.Fscanln(sc, \u0026q) opts := [][]int{} for i := 0; i \u003c q; i++ { var t, g int fmt.Fscanln(sc, \u0026t, \u0026g) opts = append(opts, []int{t, g}) } test5(graph, vals, opts) } func test5(graph map[int][]int, vals []int, opts [][]int) { // 1. 得到初始化状态各节点的 [2, 5] dp := make([][]int, len(vals)) for i := 1; i \u003c len(dp); i++ { dp[i] = make([]int, 2) getTwoFive(vals[i], dp[i]) } // 2. dfs 执行操作 var dfsOpt func(cur int, val int) dfsOpt = func(cur int, val int) { getTwoFive(val, dp[cur]) for _, next := range graph[cur] { dfsOpt(next, val) } } for _, opt := range opts { dfsOpt(opt[0], opt[1]) } // 3. dfs 计算所有节点的0 var dfsAdd func(cur int) (int, int) dfsAdd = func(cur int) (int, int) { for _, next := range graph[cur] { twoNext, fiveNext := dfsAdd(next) dp[cur][0] += twoNext dp[cur][1] += fiveNext } return dp[cur][0], dp[cur][1] } dfsAdd(1) // 4. 输出结果 for i := 1; i \u003c len(dp); i++ { if i != len(dp)-1 { fmt.Printf(\"%v \", min(dp[i][0], dp[i][1])) } else { fmt.Printf(\"%v\", min(dp[i][0], dp[i][1])) } } } func getTwoFive(val int, nums []int) { two, five := 0, 0 for val \u003e 0 \u0026\u0026 val%2 == 0 { two++ val /= 2 } for val \u003e 0 \u0026\u0026 val%5 == 0 { five++ val /= 5 } nums[0] += two nums[1] += five } func min(a, b int) int { if a \u003c b { return a } return b } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:7:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"小红书 2023.04.09-第一题-拆分树 **题目：**塔子哥是一个聪明勇敢的探险家。他听说有一棵神秘的树，据说在它的某个节点上藏有一个宝藏。为了寻找这个宝藏，塔子哥决定前往这棵树所在的深山探险。 经过漫长的征途，塔子哥终于到达了这棵树的附近。他仔细观察这棵树，发现它非常美丽，树干粗壮，树叶繁茂，枝干交错。但是，他也发现了一个问题：这棵树的某个节点上藏有宝藏，但是这个节点与其他节点之间的连接关系非常复杂，很难直接找到宝藏。 经过一番思考之后，塔子哥决定采用一种特殊的方法来寻找宝藏。他发现，如果他能够找到树上的某一条边，并删除它，那么这棵树就会被分成两个部分 A 和 B，而宝藏可能就在其中的某一部分中。 但是，塔子哥也知道，他不能随便删除一条边，因为他需要保证两个部分的节点数的差的绝对值 ∣∣A∣−∣B∣∣ 尽可能小，才能有更大的机会找到宝藏。因此，他需要找到最优的划分方案。 现在，他想请你输出最小的 ∣∣A∣−∣B∣∣ 和最优方案的数量，使得他有更大的机会找到宝藏。 输入描述 第一行一个整数 n 表示节点的数量，节点从 1 到 n 编号。 接下来 n*−1 行每行两个正整数 s ， t ，表示 s 的父亲是 t 。 输入保证是一棵树。 对于所有数据 1≤n≤100000 。 输出描述 输出一行两个整数，用空格分开，分别表示最优解和最优方案数。 样例 输入 3 2 1 3 1 输出 1 2 func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) edges := [][]int{} for i := 0; i \u003c n-1; i++ { var s, t int fmt.Fscanln(sc, \u0026s, \u0026t) edges = append(edges, []int{s - 1, t - 1}) } test5(n, edges) } func test5(n int, edges [][]int) { nodes := make([]int, n) graph := make([][]int, n) fathers := make([]int, n) inDegrees := make([]int, n) for _, edge := range edges { inDegrees[edge[1]]++ graph[edge[1]] = append(graph[edge[1]], edge[0]) fathers[edge[0]] = edge[1] } queue := []int{} for i, inDegree := range inDegrees { if inDegree == 0 { queue = append(queue, i) } } for len(queue) \u003e 0 { cur := queue[0] queue = queue[1:] nodes[cur] = 1 for _, i := range graph[cur] { nodes[cur] += nodes[i] } inDegrees[fathers[cur]]-- if inDegrees[fathers[cur]] == 0 { queue = append(queue, fathers[cur]) } } res, count := n, -1 for _, node := range nodes { cur := abs(n-node, node) if res \u003e cur { res = cur count = 1 } else if res == cur { count++ } } fmt.Println(res, count) } func abs(a, b int) int { if a \u003e b { return a - b } return b - a } 2023.04.09-第二题-融合试剂 **题目：**塔子哥是一位优秀的化学家，他的研究领域是配制各种化学试剂。今天，他的研究重点是一种特殊的化学溶液。这种溶液需要通过合并其他的多种溶液来制备，以达到理想的浓度和体积。 在实验室里，塔子哥看到了 n 种溶液，每一种都有无限多瓶，第 i 种的溶液体积为 x_i ，里面含有 y_i 单位的该物质。他想要用这些溶液来制备出一个体积恰好为 C 的溶液，且尽量浓，使得其中所含有的该物质数量尽可能多。 但是，这个过程并不容易。因为当两个瓶子的体积相等时，他们合并的过程中会发生化学反应，导致物质含量增加 X 单位。这也就意味着，如果选择了某两种体积相等的溶液进行合并，可能会获得更高的物质含量。因此，为了制备出更浓的溶液，塔子哥需要仔细考虑每一步的操作。 最终，经过反复的试验和计算，塔子哥终于成功地制备出了体积恰好为 C 的溶液，并且其中所含有的该物质数量也达到了最大值。他非常开心，因为他的努力得到了回报。现在，他想请你告诉他，这个溶液中所含有的该物质数量最多是多少。 输入描述 第一行三个正整数 �n ， �X ， �C ； 第二行 �n 个正整数 �1,�2,…,��x1,x2,…,x**n ，中间用空格隔开； 第三行 �n 个正整数 �1,�2,…,��y1,y2,…,y**n ，中间用空格隔开。 对于所有数据， 1≤�,�,�,��≤10001≤n,X,C,y**i≤1000 ， 1≤��≤�1≤x**i≤C 数据保证至少存在一种方案能够配制溶液体积恰好等于 �C 的溶液。 输出描述 输出一个整数，表示物质含量最多是多少。 样例 输入 3 4 16 5 3 4 2 4 1 输出 29 func main() { sc := bufio.NewReader(os.Stdin) var n, X, C int fmt.Fscanln(sc, \u0026n, \u0026X, \u0026C) xs := make([]int, n) for i := 0; i \u003c n; i++ { var xi int fmt.Fscan(sc, \u0026xi) xs[i] = xi } fmt.Fscanln(sc) ys := make([]int, n) for i := 0; i \u003c n; i++ { var yi int fmt.Fscan(sc, \u0026yi) ys[i] = yi } fmt.Fscanln(sc) test5(X, C, xs, ys) } func test5(X, C int, xs, ys []int) { dp := make([]int, C+1) for j := 0; j \u003c len(xs); j++ { dp[xs[j]] = max(dp[xs[j]], ys[j]) } for i := 1; i \u003c len(dp); i++ { for j := 1; j \u003c i; j++ { // 体积为 j 和 i-j 的方案都得存在才能继续 if dp[j] == 0 || dp[i-j] == 0 { continue } if i-j == j { dp[i] = max(dp[i], dp[j]+dp[i-j]+X) } else { dp[i] = max(dp[i], dp[j]+dp[i-j]) } } } fmt.Println(dp[C]) } func max(a, b int) int { if a \u003e b { return a } return b } 2023.04.09-第三题-神奇的盒子 没啥意思，简单记下： func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) nums := make([]int, n+1) for i := 1; i \u003c= n; i++ { var temp int fmt.Fscan(sc, \u0026temp) nums[i] = temp } sc.ReadString('\\n') str, _ := sc.ReadString('\\n') colors := \"#\" + strings.TrimRight(str, \"\\r\\n\") var m int fmt.Fscanln(sc, \u0026m) times := make([]int, m+1) for i := 1; i \u003c= m; i++ { var temp int fmt.Fscan(sc, \u0026temp) times[i] = temp } opts := make([]int, m+1) for i := 1; i \u003c= m; i++ { var temp int fmt.Fscan(sc, \u0026temp) opts[i] = temp } test4(nums, times, opts, colors) } func test4(nums, times, opts []int, colors string) { res := []int64{} var cur int64 flag := 0 inTimes := map[int]int{} // 记录物品进入的时间 for i := 1; i \u003c len(opts); i++ { cur += int64(flag * (times[i] - times[i-1])) if opts[i] == 0 { res = append(res, cur) } else if opts[i] \u003e 0 { inTimes[opt","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:8:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"腾讯 2023.03.26-第二题-重组字符串 题目： 塔子哥有 N 个小写字母字符串，每个最长 8 个字母。他想玩一个游戏，从每个字符串里选一个字母，拼成一个重组字符串。重组字符串不能有重复的字母。问塔子哥能拼出多少种不同的重组字符串？ 输入描述 第一行输入整数为N 第二行到第N+1行输入N个字符串，全部由小写字母组成 2≤N≤6 1≤len(字符串)≤8 输出描述 输出一个整数，代表总共能组成多少个重组字符串 样例 输入 3 ab ca ccb 输出 2 样例解释 能有acb和bac这2个重组字符串 回溯： func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) strs := [][]byte{} for i := 0; i \u003c n; i++ { str, _ := sc.ReadString('\\n') str = strings.TrimRight(str, \"\\r\\n\") strs = append(strs, []byte(str)) } test2(strs) } func test2(strs [][]byte) { res := 0 for s := 0; s \u003c len(strs); s++ { sort.Slice(strs[s], func(i, j int) bool { return strs[s][i] \u003c strs[s][j] }) } hashMap := map[byte]bool{} var backTrack func(height int) backTrack = func(height int) { if height == len(strs) { res++ return } for i := 0; i \u003c len(strs[height]); i++ { if !hashMap[strs[height][i]] \u0026\u0026 (i == 0 || strs[height][i-1] != strs[height][i]) { hashMap[strs[height][i]] = true backTrack(height + 1) delete(hashMap, strs[height][i]) } } } backTrack(0) fmt.Println(res) } 2023.03.26-第三题-构造最小值数组 **题目：**塔子哥有两个长度为 N 的整数数组 A 和 B。B 是一个权值数组，每个元素都是 0，1 或 2。 他想玩一个游戏，找一个 1 到 N 的排列 C，满足以下条件： 若 bi\u003ebj ，则 ci*\u003e*cj 。 C 和 A 的每个元素之差的绝对值之和 x 要最小 。 问 x 的最小值为多少。 输入描述 第一行输入一个整数N 第二行输入N个正整数，每个数代表数组A的元素 第三行输入N个整数，每个数代表数字B的元素，范围为[0，2] 1⩽N⩽2∗105 1⩽A[i]⩽109 0⩽B[i]⩽2 输出描述 输出 x 的最小值。 样例 样例 1 输入 2 1 10 1 0 输出 10 样例解释 当 i=0,j=1 时，i\u003cj，B[i]=1\u003eB[j]=0，所以只能为 C[i]=2,C[j]=1，故∣1−2∣+∣10−1∣=10，x=10 样例 2 输入 4 2 1 4 2 2 2 2 2 输出 1 样例解释 C 数组可以为 [2,1,4,3] ，故 x=1 样例 3 输入 6 100 2 3 1 5 6 0 1 2 0 2 1 输出 104 贪心： func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) aNums, bNums := []int{}, []int{} for i := 0; i \u003c n; i++ { var num int fmt.Fscan(sc, \u0026num) aNums = append(aNums, num) } fmt.Fscanln(sc) for i := 0; i \u003c n; i++ { var num int fmt.Fscan(sc, \u0026num) bNums = append(bNums, num) } fmt.Fscanln(sc) test3(n, aNums, bNums) } func test3(n int, aNums, bNums []int) { v := [3][]int{} // 按 b 数组 0、1、2 分组 for i := 0; i \u003c n; i++ { v[bNums[i]] = append(v[bNums[i]], aNums[i]) } res := 0 c := 0 for i := 0; i \u003c 3; i++ { sort.Ints(v[i]) for j := 0; j \u003c len(v[i]); j++ { c++ res += abs(v[i][j], c) } } fmt.Println(res) } func abs(a, b int) int { if a \u003c b { return b - a } return a - b } 2023.03.26-第四题-子数组异或和 **题目：**塔子哥有一个正整数数组 A ，他想玩一个游戏，找出数组中有多少个连续的子数组，满足以下条件： 子数组中的所有数字相乘的结果和相异或的结果相等。 每有一个满足条件的子数组即得一分，问塔子哥最多能得到多少分？ 一个数组的子数组指数组中非空的一段连续数字。 输入描述 第一行一个正整数 n，代表给出数组长度 第二行 n 个空格分隔的正整数 A; 1⩽n⩽10^5^ 1⩽Ai⩽10^9^ 输出描述 输出一个正整数代表答案 样例 输入 3 1 2 1 输出 4 样例解释 数组 [1],[2],[1],[1,2,1],[2],[1],[1,2,1] 都是满足条件的。 思路： 乘法的增长要比异或快得多，a * 1 = a，a ^ 1 = a + 1、a - 1，这就要求这几个数字中只能由 1 个数字和偶数个 1 组成。 滚吧，不知道怎么写，下边的代码有问题，有时间看看吧。 package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) nums := []int64{} for i := 0; i \u003c n; i++ { var num int64 fmt.Fscan(sc, \u0026num) nums = append(nums, num) } test4(nums) } func test4(nums []int64) { t := []int{} index := 0 for index \u003c len(nums) { count := 0 if nums[index] == 1 { for index \u003c len(nums) \u0026\u0026 nums[index] == 1 { count++ index++ } } else { index++ } t = append(t, count) // 0: 表示该位置是 \u003e1 的数字, \u003e0 : 表示该位置是连续 1 的个数 } res := 0 for i := 0; i \u003c len(t); i++ { temp := 0 if t[i] == 0 { pre, suf := 0, 0 // 统计前后的 1 的个数 if i \u003e 0 { pre = t[i-1] } if i+1 \u003c len(t) { suf = t[i+1] } temp = (pre/2+1)*(suf/2+1) + (pre+1)/2*(suf+1)/2 // 左边的偶数*右边的偶数 + 左边的奇数*右边的奇数 } else { if t[i]\u00261 == 0 { temp = (t[i] + 2) / 2 * t[i] / 2 } else { temp = (t[i] + 1) / 2 * (t[i] + 1) / 2 } } res += temp } fmt.Println(res) } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:9:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"华为 2022.11.9-华为-攻城战⭐ **题目：**现在塔子哥有火药枪若干， 以及数量有限的火药，每种火药枪的威力不尽相同，且在每次开火之前都需要一定时间填充火药， 请你帮助塔子哥在给定的时间结束之前或者火药存量耗尽之前给予敌人最大的伤害。 限制: 火药枪每次开火的威力一样； 火药剩余量不小于火药枪的消耗量，该火药枪才能开火； 填充火药之外的时间忽略不计； 不同种火药枪可以同时开火。 输入描述 第一行，整数 N ， M ， T ， N 表示火药枪种类个数， M 表示火药数量， T 表示攻城时间，1≤N,M,T≤1000。 接下来 N 行，每一行三个整数 A ， B ， C 。分别表示火药枪的威力，火药枪每次攻击消耗的火药量，火药枪每次攻击填充火药的时间，0≤A,B,C≤100000。 输出描述 输出在给定的时间结束之前或者火药存量耗尽之前给予敌人最大的伤害。 样例 样例一： 输入 3 88 30 10 7 5 5 3 1 4 4 8 输出 145 样例解释 总共有 33 种火药枪，火药存量 8888 ， 攻城时间 3030 ; 第 11 种火药枪威力 1010 ，每次攻击消耗火药 77 ，每次攻击填充火药时间 55 ； 第 22 种火药枪威力 55 ，每次攻击消耗火药 33 ，每次攻击填充火药时间 11 ； 第 33 种火药枪威力 44 ，每次攻击消耗火药 44 ，每次攻击填充火药时间 88 ； 样例二： 输入 2 10 15 2 2 2 3 3 3 输出 10 样例解释 总共有 22 种火药枪，火药存量 1010 ，攻城时间 1515 ； 第 11 种火药枪威力 22 ，每次攻击消耗火药 22 ，每次攻击填充火药时间 22 ； 第 22 种火药枪威力 33 ，每次攻击消耗火药 33 ，每次攻击填充火药时间 33 ； 思路： 若不能同时开炮，就是完全背包；若能同时开炮，就是多重背包。 package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { sc := bufio.NewReader(os.Stdin) var n, m, t int fmt.Fscanln(sc, \u0026n, \u0026m, \u0026t) guns := [][3]int{} for i := 0; i \u003c n; i++ { var a, b, c int fmt.Fscanln(sc, \u0026a, \u0026b, \u0026c) guns = append(guns, [3]int{a, b, c}) } test3(m, t, guns) } // 一个大炮可以发射若干枚，并且不同大炮可以同时发射，若该条件是不同大炮不能同时发射，转换为二维完全背包问题，时间和弹药是消耗量。 // 完全背包 //func test3(m, t int, guns [][3]int) { // dp := make([][]int, m+1) // for i := 0; i \u003c len(dp); i++ { // dp[i] = make([]int, t+1) // } // for _, gun := range guns { // for i := gun[1]; i \u003c len(dp); i++ { // for j := gun[2]; j \u003c len(dp[i]); j++ { // dp[i][j] = max(dp[i][j], dp[i-gun[1]][j-gun[2]]+gun[0]) // } // } // } // fmt.Println(dp[m][t]) //} // 因为能同时开炮，时间就只能对单个炮进行约束了，进而转换成多重背包(01背包) func test3(m, t int, guns [][3]int) { dp := make([]int, m+1) for _, gun := range guns { for i := m; i \u003e= gun[1]; i-- { // 01背包从后往前，完全背包从前往后 times := min(i/gun[1], t/gun[2]) // 得到该炮的最大发射次数 for j := 1; j \u003c= times; j++ { dp[i] = max(dp[i], dp[i-j*gun[1]]+j*gun[0]) } } } fmt.Println(dp[m]) } func min(a, b int) int { if a \u003c b { return a } return b } func max(a, b int) int { if a \u003e b { return a } return b } 2023.04.12-第一题-购物系统的降级策略 **题目：**在一个购物APP中，有一个核心购物系统，它的接口被 N 个客户端调用。这些客户端负责处理来自不同渠道的交易请求，并将这些请求发送给核心购物系统。每个客户端有不同的调用量 R=[R1,R2,…,RN]，表示在一定时间内，这个客户端向核心购物系统发送的交易请求的数量。核心购物系统必须能够及时响应所有的请求，以确保交易顺利进行。 然而，最近核心购物系统出现了集群故障，导致交易请求的处理速度变慢。为了避免系统崩溃，必须临时降级并限制调用量。具体而言，核心购物系统能接受的最大调用量为 cnt，如果客户端发送的请求总量超过 cnt，则必须限制一些系统的请求数量，以确保核心购物系统不会超负荷工作。 现在需要一个降级规则，来限制客户端的请求数量。规则如下： 如果 sum(R1,R2,…,RN) 小于等于 cnt ，则全部可以正常调用，返回 −1； 如果 sum(R1,R2,…,RN) 大于 cnt，则必须设定一个阈值 value，如果某个客户端发起的调用量超过 value，则该客户端的请求数量必须限制为 value。其余未达到 value 的系统可以正常发起调用。要求求出最大的 value（value 可以为0）。 为了保证交易的顺利进行，必须保证客户端请求的数量不会超过核心购物系统的最大调用量，同时最大的 value 要尽可能的大。需要高效地解决这个问题，以确保购物系统的高效性。 输入描述 第一行：每个客户端的调用量(整型数组) 第二行：核心购物系统的最大调用量 0\u003cR.length≤10^5^，0≤R[i]≤10^5^，0≤cnt≤10^9^ 输出描述 调用量的阈值 value 样例 样例一 输入 1 4 2 5 5 1 6 13 输出 2 样例解释 因为 1+4+2+5+5+1+6\u003e13 ，将 value 设置为 22 ，则 1+2+2+2+2+1+2=12\u003c13 。所以 value 为 22 。 样例二 输入 1 7 8 8 1 0 2 4 9 7 输出 0 样例解释 因为即使 value 设置为 1 , 1+1+1+1+1+1+1+1=8\u003e7 也不满足，所以 value 只能为 0 。 二分查找： func main() { sc := bufio.NewReader(os.Stdin) rs := []int{} str, _ := sc.ReadString('\\n') strs := strings.Split(strings.TrimRight(str, \"\\r\\n\"), \" \") for _, str := range strs { num, _ := strconv.Atoi(str) rs = append(rs, num) } var cnt int fmt.Fscanln(sc, \u0026cnt) test1(cnt, rs) } func test1(cnt int, rs []int) { sort.Ints(rs) prefix := 0 prefixs := []int{} for i := 0; i \u003c len(rs); i++ { prefix += rs[i] prefixs = append(prefixs, prefix) } var isValid func(val int) bool isValid = func(val int) bool { index := sort.Search(len(rs), func(i int) bool { return val \u003c rs[i] }) sum := 0 if index == 0 { sum = len(rs) * val } else { sum = prefixs[index-1] + (len(rs)-index)*val } return sum \u003c= cnt } left, right := 0, cnt+1 for left \u003c right { mid := (right-left)/2 + left if isValid(mid) { left = mid + 1 } else { right = mid } } if right == cnt+1 { right = 0 } fmt.Println(right - 1) } 2023.04.13-第二题-获取最多食物 **题目：**塔子哥设计的这个游戏是一个冒险类游戏，参与者需要在地图上寻找食物并获得尽可能多的食物，同时需要注意在游戏过程中所处的位置，因为不同的位置可以通过传送门到达其他位置，可能会影响食物获取的数量。 在游戏开始时，参与者会出发点选择一个方格作为起点，每个方格上至多 22 个传送门，通过传送门可将参与者传送至指定的其它方格。每个方格上都标注了三个数字：id 、 parent-id 和 ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:10:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"华为 od ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:11:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"字节跳动 2023.03.24-第一题-罐装知识 **题目：**多莉的罐装知识自选零元购活动开始啦！未来的骑士艾琳想要趁机入手一波罐装知识来提升自己的战力。但是多莉做生意一向狡诈，只有按照她规定的方式才能零元带走罐装知识。 在多莉的地摊上，有n瓶罐装知识排成一列，每瓶罐装知识有两个属性，用 (weighti,skipi) 标识，weighti 表示第i瓶罐装知识的重量（单位坷垃），skipi表示拿完第i瓶罐装知识后，就必须跳过接下来的skipi瓶罐装知识（即 [i+1，skipi+i] 范围罐装知识），不能将它们收入口袋，但是你也可以选择不拿某瓶罐装知识。而且我们经过每瓶罐装知识的时候都必须做出拿走或者不拿的选择，不能回头。 举个例子，给你罐装知识＝［［2,2］，［1,1］，［1,1］］：如果罐装知识0被拿起了，那么你可以获得2坷垃的罐装知识，但是你不能拿走罐装知识1和2。 如果你不拿罐装知识0，把罐装知识1拿起了，你可以得到1坷垃罐装知识，但是你不能带走罐装知识2了。当然你可以跳过罐装知识0和1，直接拿走罐装知识2，那么你获得的也是1坷垃的罐装知识。 艾琳认为知识是有重量的，越重一定越有价值，她希望聪明的你帮她算一下她最多能带走多重的罐装知识呢？ 输入描述 首先输入一个(1⩽n⩽100000)代表罐装知识的数量 然后是 n 瓶罐装知识的(weighti,skipi) (1⩽weighti,skipi⩽100000) 输出描述 输出艾琳能带走的罐装知识的最大重量 样例 输入 3 2 2 1 1 1 1 输出 2 思路： 倒序 DP package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { sc := bufio.NewReader(os.Stdin) var n int fmt.Fscanln(sc, \u0026n) acks := [][]int{} for i := 0; i \u003c n; i++ { var weight, skip int fmt.Fscanln(sc, \u0026weight, \u0026skip) acks = append(acks, []int{weight, skip}) } test1(acks) } func test1(acks [][]int) { dp := make([]int, len(acks)+1) // dp[i] 表示 [i: ] 最大结果 for i := len(dp) - 2; i \u003e= 0; i-- { next := i + acks[i][1] + 1 if next \u003c len(dp) { dp[i] = max(dp[i+1], dp[next]+acks[i][0]) } else { dp[i] = max(dp[i+1], acks[i][0]) } } fmt.Println(dp[0]) } func max(a, b int) int { if a \u003e b { return a } return b } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:12:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"携程 2023.04.15-第二题-最小公倍数 **思路：**很久很久以前，有一个古老的国度，国王和王后十分仁慈，善于施行公正。然而，这个国度一直存在着一个问题：财政困难。于是，国王决定组织一场大规模的征税行动，以减轻财政压力。 为了避免对民众造成过大的负担，国王命令在每个家庭中只征收一次税款，而且税款数额应该尽可能的小，以不影响民生。因此，国王命令他的财务大臣塔子哥，设计一种算法，使得征税的税款尽可能小，但仍能够收取足够的财政收入。 塔子哥经过多次思考和试验，最终发现，如果每个家庭的税款数额为该家庭两个人的年龄之和，那么所得税款总和最小，这是因为家庭中年龄相近的人往往收入也相近。然而，由于不同家庭的人的年龄各不相同，为了使征税的税款尽可能小，塔子哥希望在每个家庭中选择两个年龄差距最小的人，作为该家庭的代表，计算出税款数额。 在进行计算的时候，塔子哥面临着一个问题：如何选取两个数，使得这两个数的和为n，且它们的最小公倍数尽可能大？ 输入描述 第一行输入一个正整数 t ，代表询问的次数。 对于每组询问，输入一行一个正整数 n 。 1≤t≤105，2≤n≤1013 输出描述 共输出 t 行。对于每组询问，输出一行两个正整数 a 和 b ，用空格隔开。 样例 输入 5 2 5 4 7 10 输出 1 1 2 3 1 3 3 4 3 7 思路： package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { sc := bufio.NewReader(os.Stdin) var t int fmt.Fscanln(sc, \u0026t) for i := 0; i \u003c t; i++ { var n int64 fmt.Fscanln(sc, \u0026n) test1(n) } } func test1(n int64) { left, right := n/2, (n+1)/2 for 0 \u003c left \u0026\u0026 right \u003c n { if gcd(left, right) == 1 { break } left-- right++ } fmt.Println(left, right) } func gcd(a, b int64) int64 { if b == 0 { return a } return gcd(b, a%b) } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:13:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"杂项 圣诞树 func main() { var n int fmt.Scanln(\u0026n) test(n) } func test(n int) { // 打印 n 层树 for i := 0; i \u003c n; i++ { d := 3 * (n - i) // d 标记每行最开始的空格数 // 打印树的第 1 层 fmt.Println(strings.Repeat(\" \", d-1) + strings.Repeat(\"* \", i+1)) // 5 个空格 // 打印树的第 2 层 fmt.Println(strings.Repeat(\" \", d-2) + strings.Repeat(\"* * \", i+1)) // 3 个空格 // 打印树的第 3 层 fmt.Println(strings.Repeat(\" \", d-3) + strings.Repeat(\"* * * \", i+1)) // 1 个空格 } // 打印树根 for i := 0; i \u003c n; i++ { fmt.Println(strings.Repeat(\" \", 3*n-1) + \"*\") } } ","date":"0001-01-01","objectID":"/02-%E7%AC%94%E8%AF%95/:14:0","tags":null,"title":"","uri":"/02-%E7%AC%94%E8%AF%95/"},{"categories":null,"content":"一、华为 ","date":"0001-01-01","objectID":"/03-%E9%9D%A2%E8%AF%95/:1:0","tags":null,"title":"","uri":"/03-%E9%9D%A2%E8%AF%95/"},{"categories":null,"content":"主管面 问：如何看待互联网行业？ 互联网行业是一个极具创新和变革的行业，它不断地推出新的产品和服务，打破传统产业的边界，给人们带来更加便利和高效的生活体验。比如， 区块链的应用，打破了传统依赖第三方信任的流程，实现了弱信任环境低成本建立信任的新范式。 chatgpt的出现，改变了人与机器的交互方式。 同时，互联网行业也是一个高度敏感的行业，监管的规范和完善是保障行业健康发展的重要条件。随着互联网对社会经济生活的影响越来越大，国家对互联网行业加强了反垄断、数据安全、内容审核、用户权益等方面的监管，为行业提供了新的法律框架和道德标准。比如，ChatGPT的出现也引发了对数据隐私和安全问题的关注。大型语言模型需要大量的数据进行训练，而这些数据可能包含个人隐私信息。 问：职业规划？/未来想走哪个技术方向？⭐ 实话说，个人认为目前我并没有一个很清晰的职业规划，只能谈谈当下的一些想法。 一方面，在学校里面，接触到企业级项目的机会很少，只是在网上的一些博客或者书籍了解到行业的动态，比如我现在可能是对微服务，高并发、分布式系统比较感兴趣，以至于我去深入学习了Go的底层原理，知道了Go为什么可以应对高并发，可能之后还会去接触容器，比如 docker、k8s 这些；我现在还对系统的底层框架比较感兴趣，也去动手尝试实现过一些，我觉得搭建这些基础平台也是非常有意义的。 另一方面，我觉得去企业实习非常有意义，因为可以接触到目前行业内企业级的应用，以及接触到各领域的专家，也可能接触到更多的领域，这些都可以帮助充实、清晰自己的职业规划。 总之，我觉得，职业规划是一个长期、持续的过程，需要不断地学习和提升自己的能力、提高自己的眼界，了解技术领域和管理领域的发展方向。 问：谈谈华为的企业文化？⭐ 创新：华为重视学习和创新，通过在研究与创新领域加大投资，2022年研发投入达到1615亿人民币，占全年收入的25.1%，十年累计投入的研发费用超过9773亿人民币；并且由于制裁，软硬件均开启自研工作，并且取得一定成果，比如麒麟、鸿蒙、人工智能芯片昇腾、5G终端和5G基站的芯片； 奉献/担当：华为坚持以客户为中心、以奋斗者为本，不断优化公司治理架构、组织、流程和考核机制，使公司长期保持有效增长。华为在全球积极推进5G，并且在疫情期间，华为还积极参与抗疫工作，为医院、学校、社区等提供了ICT基础设施和智能终端的支持； 开放合作：华为同全球 接纳人才：华为很舍得对人才进行投资，比如说华为的天才少年，还有一大批数学、物理等基础学科的学者。 分享：华为注重员工与公司共同成长，实行员工持股制度，让员工分享公司发展带来的利润。 问：研究生方向介绍，该方向最前沿的技术介绍？ 区块链是一种去中心化的、公开透明的分布式账本技术，它通过密码学和共识算法保证了账本的安全和可靠性，使得交易的记录和验证可以在全网范围内进行，而无需信任中心化的机构或个人。 多方维护：区块链中的数据以分布式方式存储，无中心节点，所有节点须对区块信息达成一致共识并进行联合维护。 数据不可篡改：所有区块都保存了其前一个区块的哈希值，形成链式结构。篡改区块链中的某一条记录须付出极大代价；区块链保存的交易数据中不仅含有哈希值，还有交易双方的签名以及验证方的群签名，可有效防止伪造。 可追溯：数据来源可验证，每一笔交易的输入都是前一笔交易的输出，每一笔交易的输出又是下一笔交易的输入，确保了历史操作可追溯性；信息数据可验证，即全网节点可共同参与信息验证，确保每一笔资金与上链数据的可靠性。 自动执行：智能合约可在有效保障数据指令完整性及安全性的同时。 区块链的应用非常广泛，以下是一些典型的应用场景：资源管理、无线接入、认证授权、数据交互、信息监管、隐私保护等。 可信接入：运营商间 版权保护：区块链技术可以用于版权保护，通过记录和验证数字作品的版权信息，保护作者的权益。因为作品信息一经上链就是全网公示，且不可篡改。 数据共享： 隐私保护： 最前沿的技术： 更高效的共识算法：分布式共识机制建立了多参与方信任，解决了各个节点间数据同步一致性的问题，可以说是区块链最核心的机制。比如比特币用的PoW，非常耗费资源，现在都在寻找更加清洁的共识算法，比如PoS、PBFT、HotStuff等；以前的 以太坊用的就是PoW，今年已经改成了PoS+PBFT。 问：遇到一个不熟悉的项目怎么入手？⭐ 阅读相关文档：寻找项目的手册、API文档、技术白皮书等，了解项目的基本概念、架构、功能、特性、工作流程等。 把代码pull到本地：如果项目是开源的，可以在代码托管平台（如GitHub、GitLab等）上寻找项目的代码仓库，并对代码仓库进行浏览，了解项目的代码结构、依赖关系、开发者贡献等。 进行单元测试：通过写一些单元测试来了解项目的基本功能，掌握项目的业务逻辑和数据流动情况。可以在代码仓库中找到测试脚本或编写测试脚本进行测试。 调试代码：通过调试代码来进一步了解项目的执行流程、代码实现和调用关系。可以在本地搭建项目的运行环境，通过IDE或命令行进行调试。 请教他人：与项目相关的人员进行交流，向他们请教项目的开发历程、技术细节、难点解决等，从中获取经验和知识。 问：平时怎么学习新技术的，会看哪些文档？ 比如之前学习gRPC： 官方文档：查看官方文档是学习新技术的关键，官方文档通常包含了该技术的用途、特性、API、示例、配置文件等内容，对学习和实践都非常有帮助。比如之前学习gRPC，可以从官方文档的quick start开始，遇到不会的或不理解的，就跳转到 2。再比如学习以太坊，可能就会看以太坊的白皮书。 优质博客：从优质博客，比如各大公司的技术公众号，里边也有一些优质内容；还有业界比较知名的大牛的个人博客。 开源代码：如果该技术是开源的，可以通过查看开源代码、提交记录、issues等来了解技术的实现细节和问题解决方式。 视频教程：有些技术的学习可以通过视频教程来加深理解，可以在网上搜索相关视频资源或在线课程。 实践项目：实践是学习新技术的关键，可以通过开发项目、参与开源项目等方式来实践新技术，加深理解和掌握技术。 问：介绍团队合作的经历？怎样进行团队合作的？团队合作有分歧怎么办？⭐ 我们实验室最开始就是通过微信，一个大任务，在群里分配、沟通，后来常常会发生某个模块出现问题找不到负责的同学，而且协作的记录追溯起来也非常麻烦。 后来我们搭建了一套系统，通过bcollie进行协作。任务开始时，首先leader会在dashboard上创建很多task，task会写明任务描述、分配给谁、时间、deadline、状态等信息。然后执行过程中有问题我们也会在这个平台上进行交流。协作的记录也就记录下来了，而且彼此之间都能看到其他人的任务进度，就会形成一种互相提醒工作的效果，但是我们之前微信发通知的话，就很难知道其他人的工作进度，导致团队效率很低。 有分歧，我之前和leader在某个bug的修复上有分歧，他写了一版代码，我也写了一版，然后最终我们为了能按时交付，我就先创建了branch，暂时先用leader提供的，事后我们又仔细分析了两种方式的优缺点，然后选择一版。 问：令你兴奋、痛苦的事？ 我觉得最让我兴奋的是能够从事自己热爱的工作，并在其中感受到不断地挑战自己、学习和成长。我喜欢接受新的挑战和任务，通过解决问题和实现目标来提高自己的能力和技术水平。我也非常喜欢与团队合作，共同完成任务和项目，通过协作和知识分享来提升团队的整体水平和成就感。 对于令我痛苦的事情，我认为最让我痛苦的是无法充分发挥自己的能力和价值，或者工作环境和氛围不够良好，无法得到充分的支持和认可。此外，如果工作任务过于重复或枯燥，缺乏挑战和成长空间，也会让我感到痛苦和不满。 问：项目遇见的难点，怎样解决的？⭐ 就比如：丢弃消息、TCP粘包。 多思考，多沟通。思考可以加深自己的理解，沟通可以让自己不偏离正确的轨道。 与团队成员进行讨论：将问题与团队成员进行讨论，分享彼此的看法和经验，有可能别的人也遇到过这个问题，从中找到解决问题的最佳方法。 查找相关文档和资料：查找相关文档、技术论坛、博客等，寻找相关的解决方案和经验，从中获取灵感和启发。 进行尝试和实验：在开发环境中进行尝试和实验，debug也是一种个人能力。找到可能的解决方案，并进行测试和验证，从中找到最佳解决方案。 问：人生中比较大的挑战，失败经历，是怎样的？如何度过的？ 保研、考研 问：你觉得你有哪些优势呢，以及有哪些缺点呢，客观评价一下自己？ 我认为我的优势是我有很强的学习能力和沟通能力、动手实践能力。我在实验室积极参与项目，和团队其他成员进行沟通，并且在这个过程中不断地拓展自己的知识和技能。我也喜欢与人合作，我能够倾听他人的意见和建议，也能够清楚地表达自己的想法和观点。我觉得这些优势对于这个岗位是非常重要的，因为它需要不断地学习新的知识和技术，也需要与团队成员和客户有效地沟通。 我认为我的缺点是我有时候会过于追求完美，导致工作效率降低或压力增大。比如说，在做一个报告的时候，我会反复地修改格式、内容和语言，直到我觉得没有任何问题。虽然这样可以保证质量，但是也会占用很多时间和精力。我意识到这个问题后，我就开始尝试改进。我会给自己设定一个合理的时间限制，在完成一个任务后，及时地向别人征求反馈，而不是一直纠结于细节。我觉得这样可以提高我的工作效率和效果，也可以减轻我的压力。 问：你在学校内的团队中一般扮演什么样的角色呢，或者是做什么样的分工？ 在不同的团队中，我可能扮演的角色不同。比如我本科的时候，和同学一起在学校的创新创业基地组建了团队，我们就会一起讨论一些要做的方向，分配任务、","date":"0001-01-01","objectID":"/03-%E9%9D%A2%E8%AF%95/:1:1","tags":null,"title":"","uri":"/03-%E9%9D%A2%E8%AF%95/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:0:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"一、TCP 与 UDP 问：TCP 与 UDP 的区别⭐ 是否面向连接：UDP 在传送数据之前不需要先建立连接；而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。 是否是可靠传输：UDP 提供不可靠的传输服务，收到报文无需确认，不保证数据不丢失，不保证按序到达；TCP 提供可靠的传输服务，TCP 通过三次握手和四次挥手来建立和释放连接，数据传递时，有确认、窗口、重传、拥塞控制机制，确保传输的数据，无差错、不丢失、不重复、并且按序到达。 传输形式：TCP 是面向字节流的，UDP 是面向报文的。 是否提供广播或多播服务：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多。 首部开销：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。 传输效率：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。 **问：**什么时候选择 TCP，什么时候选 UDP? UDP 一般用于即时通信，比如：语音、视频、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。 TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等。 问：HTTP 基于 TCP 还是 UDP？ HTTP 3.0 之前是基于 TCP 协议的，而 HTTP3.0 将弃用 TCP，改用 基于 UDP 的 QUIC 协议 。此变化主要为了解决 HTTP/2 中存在的队头阻塞问题。由于 HTTP/2 在单个 TCP 连接上使用了多路复用，受到 TCP 拥塞控制的影响，少量的丢包就可能导致整个 TCP 连接上的所有流被阻塞。 问：基于 TCP、UDP 的协议？ ==基于 TCP 的协议== HTTP 协议：超文本传输协议(HTTP，HyperText Transfer Protocol)主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 HTTPS 协议：更安全的超文本传输协议(HTTPS，Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议 FTP 协议：文件传输协议 FTP(File Transfer Protocol)，提供文件传输服务，基于 TCP 实现可靠的传输。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。 SMTP 协议：简单邮件传输协议(SMTP，Simple Mail Transfer Protocol)的缩写，基于 TCP 协议，用来发送电子邮件。注意⚠️：接受邮件的协议不是 SMTP 而是 POP3 协议。 POP3/IMAP 协议：POP3 和 IMAP 两者都是负责邮件接收的协议。 Telnet 协议：远程登陆协议，通过一个终端登陆到其他服务器。被一种称为 SSH 的非常安全的协议所取代。 SSH 协议：SSH(Secure Shell)是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。 ==基于 UDP 的协议== DHCP 协议：动态主机配置协议，动态配置 IP 地址； DNS：域名系统(DNS，Domain Name System)将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。 我们可以将其理解为专为互联网设计的电话薄。实际上 DNS 同时支持 UDP 和 TCP 协议。 问：如何理解 TCP 是面向字节流的？ 之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的发送方的机制不同。 为什么 UDP 是面向报文的？ 当用户消息通过 UDP 协议传输时，操作系统不会对消息进行拆分，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。 为什么 TCP 是面向字节流的？ 当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。 这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。 例如，发送方准备发送 「Hi.」和「I am Xiaolin」这两个消息。 在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。至于什么时候真正被发送，取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去。 实际发送有如下可能的情况： 因此，我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。 当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。 要解决这个问题，要交给应用程序。 问：TCP 的粘包问题是啥？咋解决呢？UDP 有吗？ TCP 粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。其实就是消息边界模糊造成的。 产生原因： 由TCP连接复用造成的粘包问题。 因为TCP默认会使用 Nagle 算法，此算法会导致粘包问题：合并相连的小数据包，再一次性发送，以达到提升网络传输效率的目的。但接收方又不知道你合并了。 接收方来不及接收缓冲区的包，导致缓冲区有多个包，而一次性读取时，就发生了粘包 解决问题：tcp 协议的包头有 20 字节，ip 协议的包头也有 20 字节，如果仅仅传输 1 字节的数据，在网络上传输的就有 20 + 20 + 1 = 41 字节，其中真正有用的数据只有 1 个字节，这对效率和带宽是极大的浪费。 Nagle 算法：如果是连续的小数据包，大小没有一个 MSS（Maximum Segment Size，最大分段大小），并且还没有收到之前发送的数据包的 Ack 信息，那么这些小数据包就会在发送端暂存起来，直到小数据包累积到一个 MSS，或者收到一个 Ack 为止。 这个算法虽然减少了不必要的网络传输，但既导致了延迟，也导致了粘包。 解决方法： 以指定字符串为包结束标志，比如\\n等，比如HTTP； 添加一个自定义的包头，记录本包的数据长度，然后自己写个buffer缓冲一下，等收到指定长度了再交付处理；(你不就是用的这个吗？hhh) 比如，固定前 8 个字节，定义为数据长度，真正的数据在后面。 固定每个包的长度(太不灵活了)。 UDP 是面向报文的(具有长度字段)，具有消息边界，每个包都是独立的，因此不会。而TCP首部里是没有长度这个信息的，TCP 发送端在发的时候就不保证发的是一个完整的数据报，仅仅看成一连串无结构的字节流，这串字节流在接收端收到时哪怕知道长度也没用，因为它很可能只是某个完整消息的一部分。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:1:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"二、TCP 三次握手和四次挥手 问：TCP 三次握手和四次挥手⭐⭐⭐🚩 ==三报文握手：== 首先，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态； 客户端会随机初始化序号(client_isn)，将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态； 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号(server_isn)，将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。 注意： TCP 规定携带 SYN 的确认报文段不携带数据，但也要消耗序号； TCP 规定普通 TCP 确认报文段可以携带数据，若不携带数据，则不消耗序号。即上图传输的第一个数据报文段序号seq=x+1。即第三次握手是可以携带数据的，前两次握手是不可以携带数据的。 ==四报文挥手：== 问：用什么数据结构管理半连接队列和全连接队列？ 问：全连接队列和半连接队列满了分别会发生什么？ 全连接队列满了之后，再收到新的连接，就会丢弃； 半连接队列满了之后，再收到新的连接，也会丢弃。 但半连接队列满了，不意味着无法建立连接了。通过开启syncookies，就可以在不使用 SYN 半连接队列的情况下成功建立连接。 syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功： 问：TCP 连接建立解决的问题？ 解决了以下三个问题： 使 TCP 双方能够确认对方的存在； 使 TCP 双方能够协商一些参数(如：最大窗口值、是否使用窗口扩大选项和时间戳选项以及服务质量等)； 使 TCP 双方能够对运输实体资源(如：缓存大小、连接表中的项目等)进行分配。 问：为什么要三次握手？⭐🚩 从三个方面讲： 三次握手才可以阻止重复历史连接的初始化（主要原因）； 三次握手才可以同步双方的初始序列号； 三次握手才可以避免资源浪费。 三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。 如果是两次握手连接，就无法阻止历史连接： **避免过期连接的建立。**若为两次握手，客户端先第一次握手，然而阻塞了，然后重新发起第一次握手，此时第一次握手数据报已经到了，然后服务端第二次握手，连接就建立了，就可以发数据了，但是客户端会通通丢弃！！！造成资源浪费！！！ 三次握手第二主要的目的就是双方确认自己与对方的发送与接收是正常的，并同步双方的初始序列号。若为两次，则只有一方能确定对方的序列号： 第一次握手 ：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手 ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手 ：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 问：每次建立 TCP 连接时，初始化的序列号有啥讲究？⭐🚩 每次初始化的序列号都要求不一样，主要有以下原因： 为了防止历史报文被下一个相同四元组的连接接收（主要方面）； 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收。 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接； 在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。 可以看到，如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。如果每次建立连接客户端和服务端的初始化序列号都**「不一样」**，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文。 问：初始序列号是如何随机产生的？⭐ 起始 ISN 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。 RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。 M 是一个计时器，这个计时器每隔 4 微秒加 1。 F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。 可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。 问：为什么要四次挥手？ 因为 TCP 是全双工通信，可以双向传输数据。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。 举个例子：A 和 B 打电话，通话即将结束后。 第一次挥手 ：A 说“我没啥要说的了” 第二次挥手 ：B 回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话 第三次挥手 ：于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了” 第四次挥手 ：A 回答“知道了”，这样通话才算结束。 问：四次挥手中，最后客户端要等待2MSL，有必要吗？为什么不直接关闭呢？ MSL：报文最大生存时间。 MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。2MSL 就相当于一来一回的最大时间。 ==回答：== 有必要。如果客户端最后一次ACK报文段丢失了，服务端就会重发 FIN，如果客户端在 2MSL 的时间内收到了 FIN，就会重新发送 ACK 并再次等待 2MSL，防止 Server 没有收到 ACK 而不断重发 FIN。 等待 2MSL 是为了保证本次连接中产生的所有报文段都从网络中消失，避免影响之后的 TCP 连接。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:2:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"三、TCP 传输可靠性 问：TCP 如何保证数据传输可靠性？⭐ TCP 基于以字节为单位的滑动窗口来实现可靠传输； TCP 拥有校验和机制。如果收到报文段的检验和有差错，TCP 将丢弃这个报文段； TCP 通过序号机制保证数据的按序交付。会将不按序到达的数据放在接收窗口，待接收完毕再按序交付给应用层； TCP 要求接收方必须有累计确认和捎带确认机制； TCP 拥有超时重传机制。会对发送的报文段启动定时器，未接收到接收端发来的确认报文会导致定时器超时，从而重新发送该报文段； 流量控制。接收端根据自身情况，当来不及处理接收到的数据时，降低发送端的发送速率，防止包丢失。 拥塞控制。网络拥塞时，缩减发送端的拥塞窗口，降低数据发送速率，防止包丢失。 问：TCP 如何实现流量控制？⭐ 接收方通过 TCP 头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题，所以流量控制是点对点控制。 过程自己想想说叭。 问：流量控制中，死锁的局面？ 问：TCP 拥塞控制如何实现？⭐🚩 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送窗口 = min(拥塞窗口, 接收窗口) TCP 的拥塞控制采用了四种算法，即慢开始、拥塞避免、快重传和快恢复。 慢开始：cwnd 初始值为 1，还未到慢开始门限时，每经过一个传播轮次，cwnd 加倍； 拥塞避免：到达慢开始门限时，cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的cwnd加 1。当重传计时器超时，很大概率发生拥塞： 慢开始门限 = 拥塞时的cwnd / 2； cwnd = 1，重新开始慢开始算法。 但是，个别报文段的丢失也会引起计时器超时，但是此时网络可能并没有拥塞，如果从慢开始再次开始，就降低了网络效率。==针对这种情况，新产生了快重传和快恢复。== 快重传：接收方不要等到自己有数据发送时才进行捎带确认，而是要立即发送确认；发送方一旦收到3个重复确认，就对相应报文段立即重传，不要等超时计时器超时。 快恢复：一旦收到3个重复确认，就知道只是丢失了个别的报文段，于是执行快恢复算法：将cwnd = 拥塞时的cwnd / 2，慢开始门限 = 拥塞时的cwnd / 2。 问：流量控制与拥塞控制的区别？ 拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。 相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，确保接收端来得及接收。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:3:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"四、HTTP 和 HTTPS ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"4.1 基础概念 HTTP 协议，全称超文本传输协议(Hypertext Transfer Protocol)，也就是传输网络上的包括文本在内的各式各样的消息。HTTP 是一个无状态(stateless)协议，也就是说服务器不维护任何有关客户端过去所发请求的消息。HTTP 是应用层协议，它以 TCP（传输层）作为底层协议。默认端口为 80。 HTTPS 协议(Hyper Text Transfer Protocol Secure)，是 HTTP 的加强安全版本。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并额外使用 SSL/TLS 协议用作加密和安全认证。默认端口号是 443。 HTTPS 协议中，SSL 通道通常使用基于密钥的加密算法，密钥长度通常是 40 比特或 128 比特。 问：HTTP 的报文格式？ HTTP 有两类报文：请求报文 和 响应报文。 HTTP 请求/响应报文由以下内容组成： 请求头 HTTP 头部字段 空行 可选的 HTTP 报文主体数据 请求报文 HTTP 的请求报文分为三个部分： 请求行 请求方法 请求地址 URL HTTP 协议版本 GET /index.html HTTP/1.1 请求头(首部行) Accept: */* Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Connection: keep-alive Content-Length: 21429 Content-Type: application/json Host: api.github.com Origin: https://github.com Referer: https://github.com/ User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36 请求头 说明 Accept 表示浏览器接受的数据类型 Accept-Encoding 表示浏览器接受的数据压缩格式 Host 表示当前请求访问的目标地址 Authorization 表示用户身份认证信息 User-Agent 表示浏览器类型 If-Modified-Since 表示当前请求资源最近一次更新时间 If-None-Match 表示当前请求资源最近一次标识的 ETag 值 Cookie 表示浏览器保存的 Cookie 信息 Referer 表示标识请求引用自哪个地址 消息体 请求体是 POST 请求方式中的请求参数，以 key = value 形式进行存储，多个请求参数之间用 \u0026 连接，如果请求当中请求体，那么在请求头当中的 Content-Length 属性记录的就是该请求体的长度。 pageNo=0\u0026pageSize=10\u0026orderNum=306735659327926273\u0026customerMobile=15626000000\u0026startTime=2019-02-01%2000:00:00\u0026endTime=2019-02-25%2014:54:20\u0026status=SUCCESS\u0026source=WECHAT_SHOPPING\u0026canteenId=104\u0026refundStatus=REFUNDED\u0026startPayTime=2019-02-01%2000:00:00\u0026endPayTime=2019-02-25%2014:54:47 响应报文 一个 http 响应报文也由三个部分组成： 状态行 http 协议版本 状态码 状态码的文本描述 标记响应状态。 HTTP/1.1 200 OK 响应头 和请求头部类似，就是两者之间有一些不同的头部字段。 HTTP/1.0 200 ok content-type: application/javascript;charset=utf-8 date: Tue, 07 Mar 2017 03:06:14 GMT sever: Domain Reliability Searver content-length: 0 x-xss-protection: 1, mode=bloack x-frame-options: SAMEORIGIN alt-svc: quic=\":443\";ma=2592000;v=\"36,35,34\" 名称 作用 Date 表示当前相应资源发送的服务器日期和时间 Last-Modified 表示当前响应资源最后被修改的服务器时间，用于协商缓存 Transfer-Encoding 表示当前响应资源传输实体的编码格式 Set-Cookie 表示设置 Cookie 信息 Location 在重定向中或者创建新资源时使用 Server 表示服务器名称 消息体 正文内容，一般在响应头中会用 Content-Length 来明确响应体的长度。 问：解释下超文本传输协议？ HTTP 的名字「超文本协议传输」，它可以拆成两个部分： 超文本 传输协议 传输协议：就是计算机之间传输数据的一种行为规范和约定； 超文本：文本是文字，但超文本涵盖了文字、图片、视频、链接等，是这些的混合体。 综上所述，HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 问：HTTP 协议的通信过程？ 通信过程主要如下： 服务器在 80 端口等待客户的请求。 浏览器发起到服务器的 TCP 连接（创建套接字 Socket）。 服务器接收来自浏览器的 TCP 连接。 浏览器（HTTP 客户端）与 Web 服务器（HTTP 服务器）交换 HTTP 消息。 关闭 TCP 连接。 问：HTTP 常见的状态码？⭐ 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。 问：打开一个网页，过程？⭐ 浏览器解析 URL：浏览器会解析 URL 确定要请求的资源所在 Web 服务器及文件名，构建 HTTP 请求报文； 域名解析：发送 HTTP 请求报文之前，会通过 DNS 将域名转换为对应的 IP 地址：首先会检查本地缓存，如果未命中则会向 本地 DNS 服务器发送查询请求，然后递归的查询； 建立 TCP 连接：浏览器根据 IP 地址和端口号，与目标服务器建立 TCP 连接(三次握手)，然后对 HTTP 请求报文进行封装，也就是加一层 TCP 报头，TCP 报文的数据部分就是 HTTP 请求报文了； 封装 IP：TCP 报文还需要通过 IP 传输到服务器，所以要在 TCP 报文前加一层 IP 头，指明目的地址和源地址，生成 IP 报文； 封装 MAC：生成 IP 报文后，还需要封装成 MAC 帧。通过 ARP 协议查询要到达目的 IP 的下一跳的 MAC 地址，MAC 头部携带发送方 MAC 地址和接收方目标 MAC 地址，用于两点间传输； 通过不断到达新的路由器，进而更新目的 MAC 地址，最终达到目的 IP 地址； 服务器处理 HTTP 请求：服务器将数据包","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:1","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"4.2 缓存 问：HTTP 缓存技术？ 对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，可以把这对「请求-响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，HTTP 有以下实现方法： 强制缓存：指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在浏览器这边。 强制缓存利用 HTTP 响应头部中的两个字段实现，用来表示资源在客户端缓存的有效期： Cache-Control，是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires，建议使用 Cache-Control(选项更多)： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 协商缓存：通过服务端告知客户端是否可以使用缓存。比如某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源。 当第一次请求静态的资源时，比如一张图片，服务端除了返回图片信息，在响应头里面还有一个 Etag 的字段； 浏览器会缓存图片信息以及这个字段的值； 当下一次再请求这个图片的时候，浏览器发起的请求头里面会有一个 If-None-Match 的字段，并且把缓存的 Etag 的值写进去发给服务端； 服务端比对图片信息是否有变化，如果没有，则返回浏览器一个 304 的状态码，浏览器会继续使用缓存的图片信息。 通过浏览器缓存的方式，可以减少网络传输的数据大小，从而提升页面展示的性能。 问：强制缓存和协商缓存是什么？ 强制缓存：指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存。决定是否使用缓存的主动性在于浏览器； 实现：主要利用两个 HTTP 响应头部字段实现，它们都用来表示资源在客户端缓存的有效期： Cache-Control，是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires 。建议使用 Cache-Control，具体的实现流程如下： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 协商缓存：服务端告知客户端是否可以使用缓存的方式被称为协商缓存。 实现：可以基于两种头部来实现。 第一种：利用请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是： 响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是： 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。 注意，协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。 当使用 ETag 字段实现的协商缓存的总过程： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的； 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期： 如果没有过期，则直接使用本地缓存； 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识； 服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较： 如果值相等，则返回 304 Not Modified，不会返回资源； 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识； 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:2","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"4.3 HTTPS 问：HTTPS 协议的通信过程？ 客户端发送https请求，把自身支持的秘钥算法套件（SSL指定版本、加密组件列表）发送给服务器； 服务器判断自身是否支持该算法套件，如果支持则返回证书信息，否则断开连接； 客户端解析证书(通过TLS协议来完成)，验证证书是否有效。如果异常，则会提示是否安装证书，常见的就是浏览器搜索栏左侧出现“X”告警按钮等。 如果证书有效、或者是授信安装证书后，开始传送用服务端公钥加密后的私钥； 服务端通过私钥解密加密信息，得到客户端发送来的会话私钥； 进行会话。 问：SSL/TLS 工作原理？ SSL/TLS 的核心要素是公钥加密和对称加密。利用公钥加密协商密钥，利用对称加密算法快速加解密数据。 其中，为防止中间人攻击，公钥由CA颁发。当客户端（浏览器）向服务器发送 HTTPS 请求时，一定要先获取目标服务器的证书，并根据证书上的信息，检验证书的合法性。一旦客户端检测到证书非法，就会发生错误。 问：CA 证书签发过程？ 服务方 S 生成公私钥，然后向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证； CA 通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等；如信息审核通过，CA 会向申请者签发认证文件-证书。证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA的信息、有效时间、证书序列号等信息的明文，同时包含一个CA的签名；签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名； 客户端 C 向服务器 S 发出请求时，S 返回证书文件； 客户端 C 对证书进行验签：读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA 的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即公钥合法； 客户端然后验证证书相关的域名信息、有效时间等信息； 客户端会内置信任 CA 的证书信息(包含公钥)，如果CA不被信任，则找不到对应 CA 的证书，证书也会被判定非法。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:4:3","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"五、HTTP 各版本 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"基础 问：HTTP 1.0 和 HTTP 1.1 区别？ 连接方式：HTTP 1.0 为非持续连接，每次浏览器要请求一个文件都要与服务器建立TCP链接，当收到响应后就立即关闭连接；HTTP 1.1 支持持续连接，浏览器收到响应后，仍可以保持该连接传输后续的请求和响应报文。 请求方式：HTTP 1.1 支持请求的流水线处理方式。 状态响应码：HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，100 (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址。 缓存处理：在 HTTP1.0 中主要使用 header 里的 If-Modified-Since，Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since，If-Match，If-None-Match 等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用：HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 Host头处理：HTTP/1.1在请求头中加入了Host字段。 问：HTTP 1.1 的性能问题？⭐ 队头阻塞：HTTP 1.1 可以通过流水线的方式请求，即后续请求不需要等前边的请求被响应就可以发出，这解决了请求的队头阻塞。但是，服务器必须按照接收请求的顺序发送响应，如果某个请求处理时间很长，那么后续的就只能阻塞，导致响应的队头阻塞。 不支持服务器推送：当客户端需要获取通知时，只能通过定时器不断地拉取消息，这无疑浪费大量了带宽和服务器资源； HTTP 头部巨大且重复：由于 HTTP 协议是无状态的，每一个请求都得携带 HTTP 头部，特别是对于有携带 Cookie 的头部，而 Cookie 的大小通常很大； 并发数量有限。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:1","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"HTTP 2.0 问：HTTP 1.1 和 HTTP 2.0 有啥区别？ HTTP/2 相比 HTTP/1.1 性能上的改进： 头部压缩 二进制格式 并发传输 服务器主动推送资源 头部压缩 HTTP/2 会压缩头(Header)，如果你同时发出多个请求，他们的头是一样的或是相似的，那么就会消除重复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 二进制帧 节省空间：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，这会节省很多字节，比如之前状态码200，之前是用 ‘2’‘0’‘0’ 3 个字符来表示(00110010 00110000 00110000)，共用了 3 个字节；现在就只需 1 个字节(10001000)。 节省时间：Header 和 Body 都是二进制，并且统称为帧(frame)：头信息帧(Headers Frame)和数据帧(Data Frame)。帧头一共就 9 字节。由于收到报文后，无需转换为二进制，就增加了数据传输的效率。 帧长度：帧数据的长度； 帧类型：主要分为数据帧、控制帧。数据帧主要是传递HTTP包头和包体； 帧数据：HPACK 算法压缩过的HTTP包头和包体。 并发传输⭐ HTTP/2 支持多个 Stream 复用在一条 TCP 连接。 针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。 服务器推送⭐ HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。 客户端和服务器双方都可以建立 Stream。但 Stream ID 是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。 如下图，Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:2","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"HTTP 3.0(未) 问：HTTP 3.0 做了哪些优化？（未） HTTP 3.0 将下层 TCP 协议改成了 UDP 协议。 基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:5:3","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"六、RPC 基础 问：什么是 RPC 协议？ RPC(Remote Procedure Call)，又叫做远程过程调用，指的是像调用本地方法一样调用远程的方法，比较有名的就是 gRPC。 举个例子，平时调用一个本地方法就像下面这样。 res = localFunc(req) 如果现在这不是个本地方法，而是个远端服务器暴露出来的一个方法 remoteFunc，如果我们还能像调用本地方法那样去调用它，这样就可以屏蔽掉一些网络细节，用起来更方便，岂不美哉？ res = remoteFunc(req) RPC 和 HTTP 的区别 问：为什么有了 HTTP 协议，还要有 RPC 协议？⭐ 从以下几点讨论。 服务发现 要向某个服务器发出请求，首先得建立连接，建立连接就得先知道服务器的IP地址和端口吧： HTTP：通过 DNS 解析域名，得到服务器的IP地址和端口； RPC：把服务器的IP地址和端口，提前注册到 ETCD 等中间件，想要访问某个服务，就去这些中间件获得 IP 和端口信息。 其实差不多，都是通过中间服务获得。 底层连接形式 HTTP：默认在建立底层 TCP 连接之后会一直保持这个连接(Keep Alive)，之后的请求和响应都会复用这条连接； RPC：建个连接池，请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用，非常环保。 但实际上，HTTP 应用的时候，也会加个连接池，所以说，也差不太多。 传输内容⭐ 基于 TCP，header没什么不同，主要是要对body中的内容进行序列化和反序列化： HTTP：主要是通过 JSON； RPC：主要是通过 Protobuf。 HTTP 示例： 二者对比： HTTP 的 Header 和 Body 都是 key-value 形式，但是key其实很多余。最明显的，像 Header 里的那些信息，其实如果我们约定好头部的第几位是 Content-Type，就不需要每次都真的把\"Content-Type\"这个字段都传过来，类似的情况其实在 body 的 JSON 结构里也特别明显。 而 RPC，可以采用体积更小的Protobuf等定制化序列化协议(详见protobuf的md)，这就是公司的微服务中使用 RPC 的==主要原因==。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:6:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"七、Cookie 和 Session 问：什么是 Cookie？为啥要有 Cookie？ HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并==保存在本地==的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。 Cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，Cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 Cookie 认出你。 问：Cookie 应用场景？ 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 问：Session 是啥？为啥要有 Session？ Session 可以存储在服务器上的文件、数据库或者内存中，也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 使用 Session 维护用户登录状态的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 问：Session 和 Cookie 的区别？⭐ Cookie Cookie是客户端保持状态的方法。 **Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。**为了保持会话，服务器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。 除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是会话Cookie，一种是持久Cookie。会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁，持久Cookie则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代理所共享的。 Session Session是服务器保持状态的方法。 首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的Session用户在客户端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。 ==两者结合，完成服务器对客户端会话状态的保持。==每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端，然后找到相应的Session来保持会话状态。 实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。 问：如果没有 Cookie ，还能用 Session 嘛？ 一般是通过 Cookie 来保存 SessionID，假如你使用了 Cookie 保存 SessionID 的方案的话， 如果客户端禁用了 Cookie，那么 Session 就无法正常工作。 但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将 SessionID 放在请求的 url 里面https://javaguide.cn/?Session_id=xxx 。这种方案的话可行，但是安全性和用户体验感降低。当然，为了你也可以对 SessionID 进行一次加密之后再传入后端。 问：多服务器节点下 Session-Cookie 方案如何做？ 举个例子：假如我们部署了两份相同的服务 A，B，用户第一次登陆的时候 ，Nginx 通过负载均衡机制将用户请求转发到 A 服务器，此时用户的 Session 信息保存在 A 服务器。结果，用户第二次访问的时候 Nginx 将请求路由到 B 服务器，由于 B 服务器没有保存 用户的 Session 信息，导致用户需要重新进行登陆。 有三种方法： 某个用户的所有请求都通过一致性哈希策略分配给同一个服务器处理。这样的话，每个服务器都保存了一部分用户的 Session 信息。服务器宕机，其保存的所有 Session 信息就完全丢失了。 单独使用一个所有服务器都能访问到的数据节点（比如缓存）来存放 Session 信息。为了保证高可用，数据节点尽量要避免是单点。 每一个服务器保存的 Session 信息都是互相同步的，也就是说每一个服务器都保存了全量的 Session 信息。每当一个服务器的 Session 信息发生变化，我们就将其同步到其他服务器。这种方案成本太大，并且，节点越多时，同步成本也越高。 问：Cookie-Session 和 Token 的区别？ Cookie-Sessioon 方案中，服务器必须保存sessionID以及该ID所代表的客户端信息。这些内容可以保存在内存，也可以保存到数据库(通常是内存数据库)；而token则可以服务器完全不用保存任何登录信息，减轻了服务器的负担。 token的流程是这样的。客户端登录通过后，服务器生成一堆客户端身份信息，包括用户名、用户组、有那些权限、过期时间等等。另外再对这些信息进行签名。之后把身份信息和签名作为一个整体传给客户端。这个整体就叫做token。之后，客户端负责保存该token，而服务器不再保存。客户端每次访问该网站都要带上这个token。服务器收到请求后，把它分割成身份信息和签名，然后验证签名，若验证成功，就直接使用身份信息(用户名、用户组、有哪些权限等等)。 token相对cookie的优势： 无状态 基于token的验证是无状态的，这也许是它相对cookie来说最大的优点。后端服务不需要记录token。每个令牌都是独立的，包括检查其有效性所需的所有数据，并通过声明传达用户信息。毕竟，查询session在进行对比可能会涉及到网络通信、数据库读取等，肯定是比做一次hash用时要多的。 服务器唯一的工作就是在成功的登陆请求上签署token，并验证传入的token是否有效。 防跨站请求伪造（CSRF），附带功能。 多站点使用 cookie绑定到单个域。foo.com域产生的cookie无法被bar.com域读取。使用token就没有这样的问题。这对于需要向多个服务获取授权的单页面应用程序尤其有用。 使用token，使得用从myapp.com获取的授权向myservice1.com和myservice2.com获取服务成为可能。 支持移动平台 好的API可以同时支持浏览器，iOS和Android等移动平台。然而，在移动平台上，cookie是不被支持的。 性能 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算的Token验证和解析要费时得多。 问：Token 的存储位置？ JWT 的保存位置，可以分为如下四种： 保存在 localStorage 保存在 sessionStorage 保存在 cookie 保存在 cookie 并设置 HttpOnly 第一种和第二种其实可以归为一类，这一类有个特点，就是该域内的 js 脚本都可以读取，这种情况下 JWT 通过 js 脚本放入 Header 里的 Authorization 字段，会存在 XSS 攻击风险。 第三种，与第四种相比，区别在于 cookie 有没有标记 HttpOnly，没有标记 HttpOnly 的 cookie ，客户端可以将 JWT 通过 js 脚本放入 Header 里的 Authorization 字段。这么看好像同时存在CSRF 攻击风险和 XSS 攻击风险，实则不然，我们虽然将 JWT 存储在 cookie 里，但是我们的服务端并没有利用 cookie 里的 JWT 直接去鉴权，而是通过 header 里的 Authorization 去鉴权，因此这种方法只有 XSS 攻击风险，而没有 CSRF 攻击风险。 而第四种，加了 HttpOnly 标记，意味着这个 cookie 无法通过js脚本进行读取和修改，杜绝了 XSS 攻击的发生。与此同时，网站自身的 js 脚本也无法利用 cookie 设置 header 的Authorization 字段，因此只能通过 cookie 里的 JWT 去鉴权，所以不可避免","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:7:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"八、ARP 问：ARP 协议是啥？有啥用？ ARP 协议，全称 地址解析协议（Address Resolution Protocol），它解决的是网络层地址和链路层地址之间的转换问题。 问：寻址原理？ 记住几个关键词：ARP 表、广播问询、单播响应。 ARP 的工作原理应分两种场景讨论： 同一局域网内的 MAC 寻址； 从一个局域网到另一个局域网中的网络设备的寻址。 很简单，看下就会了 如果ARP协议无法获取MAC地址，通常会发生以下两种情况： 目标主机不可达：如果ARP协议无法获取目标主机的MAC地址，通常说明目标主机不可达，可能是因为目标主机已经关机、网络故障、网络拥堵等原因导致数据无法到达目标主机。在这种情况下，通常需要对网络进行故障排除，找出问题所在并进行修复。 目标主机在不同的网络中：如果ARP协议无法获取目标主机的MAC地址，但是目标主机确实存在，可能是因为目标主机和发送数据的主机在不同的网络中，需要通过路由器进行通信。在这种情况下，通常需要进行路由器配置，使得数据可以从源主机到达目标主机所在的网络，并将目标主机的MAC地址映射到正确的IP地址上。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:8:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"九、网络安全 问：为什么 Cookie 无法防止 CSRF 攻击，而 Token 可以？ CSRF(Cross Site Request Forgery) 一般被翻译为 跨站请求伪造 。 当进行 Session 认证后，每次登录时，浏览器就会默认携带 Cookie，服务端通过 Cookie 中的 SessionId 标识该用户的对话。当用户浏览攻击者的页面时，若点击到构造的请求链接，就会跳转到相应页面，浏览器会把 Cookie 发送给服务端，也就相当于攻击者以用户的身份完成了一次请求。 CSRF攻击之所以能够成功，是因为服务器误把攻击者发送的请求当成了用户自己的请求。 但是，使用 Token 就不会有这个问题。 在我们登录成功获得 Token 之后，一般会选择存放在 localStorage （浏览器本地存储）中。然后我们在前端(js)通过某些方式会给每个发到后端请求的Authorization中加上这个 Token，即使有个你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 Token 的，所以这个请求将是非法的。 问：什么是 SYN 攻击？如何避免 SYN 攻击？ 攻击者伪造大量的 SYN 报文，占满服务端的半连接队列，造成拒绝服务。因为当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。 如何防御？ 设置更大的半连接队列； 减少 SYN+ACK 的重传次数，以加快处于 SYN_RECV 状态的 TCP 连接断开；这是因为处于 SYN_RECV 状态的 TCP 连接会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接； **开启 syncookies 功能。**可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接； 部署入侵检测系统IDS，识别并过滤虚假IP地址。 ","date":"0001-01-01","objectID":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/:9:0","tags":null,"title":"","uri":"/04-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:0:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"一、进程、线程、协程 问：什么是系统调用？ 进程的运行分为两个级别： 用户态(user mode)：用户态运行的进程可以直接读取用户程序的数据。 系统态(kernel mode)：系统态运行的进程几乎可以访问计算机的任何资源，不受限制。 用户写的程序基本上都运行在用户态，若想调用与系统级资源有关的操作，则必须通过系统调用向操作系统请求。 这些系统调用按功能大致可分为如下几类： **设备管理：**完成设备的请求或释放，以及设备启动等功能。 **文件管理：**完成文件的读、写、创建及删除等功能。 **进程控制：**完成进程的创建、撤销、阻塞及唤醒等功能。 **进程通信：**完成进程之间的消息传递或信号传递等功能。 **内存管理：**完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 问：进程、线程、协程的区别？⭐⭐⭐ 进程 线程 协程 定义 拥有资源的基本单位 独立调度的基本单位 用户态的轻量级线程，线程内部调度的基本单位 切换情况 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 保存和设置程序计数器、少量寄存器和栈的内容 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复 切换者 操作系统 操作系统 用户 切换过程 用户态-\u003e内核态-\u003e用户态 用户态-\u003e内核态-\u003e用户态 用户态(没有陷入内核) 调用栈 内核栈和用户栈 内核栈和用户栈 用户栈 拥有资源 CPU资源、内存资源、文件资源和句柄等 程序计数器、寄存器、栈和状态字 拥有自己的寄存器上下文和栈 并发性 不同进程之间切换实现并发，各自占有CPU实现并行 一个进程内部的多个线程并发执行 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 系统开销 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 切换时只需保存和设置少量寄存器内容，因此开销很小 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 通信方面 进程间通信需要借助操作系统 线程间可以直接读写进程数据段(如全局变量)来进行通信 共享内存、消息队列 进程的执行体-\u003e线程，线程的执行体-\u003e协程。 每个进程拥有独立的虚拟地址空间，也就是有独立的页表，因此创建大量进程时会造成内存开销显著；操作系统进行进程调度时，需要切换虚拟地址空间，也就会切换页表。CPU 通过 MMU 将逻辑地址转到物理地址，为了减少访存次数设置了 TLB，而只有一个 TLB，因此进程切换会造成 TLB 失效，进而地址转换效率降低。而线程切换不需要切换虚拟地址空间，因此出现线程。 多线程下，进程拥有的资源是被所有线程共享的，但每个线程拥有自己的内核数据结构、内核栈和用户栈。为什么要分别拥有两个栈呢？对于内核来讲，所有用户代码都被视为不安全的，操作系统不允许用户态代码访问内核数据，线程进入内核态后执行的是内核提供的代码，若跟用户态共用一个栈就会留下安全漏洞(栈上数据可能会被用户程序非法读取)，因此要给内核态单独分配栈。 线程切换时，无需切换虚拟地址空间，也就无需切换页表，TLB 缓存也就不会失效，只需要切换自己拥有的寄存器和栈，因此性能显著提升。 ==为什么要有协程呢？== 线程的切换，是抢占式的，依然需要操作系统参与，假如并发量不断增大，线程数量达到百万级别时需要大量线程，但是每个线程只需执行很短的时间片，这样的切换就显得很笨重。 也就是说，一方面，线程的内核数据结构、内核栈和用户栈会占用大量内存；另一方面，线程是操作系统基于时间片策略进行调度的，在如此庞大的线程数量下，为了尽量降低延迟，线程每次得以运行的时间片会被压缩，造成线程切换频率的大幅提高。线程切换过于频繁时，调度会占用大量CPU资源，造成性能下降。 问题明了： 要节省内存空间，让主流服务器能轻松装载百万级的轻量线程； 要降低调度代价，切换起来更加轻快。 协程是通过主动让出的，调度无需通过操作系统，而是由用户程序管理，这就降低了调度代价。并且协程只有一个用户栈，一个线程的内存在MB级别，而协程只需要KB级别，这就节省了内存空间。 任务抽象 上下文 进程 PCB 线程 TCB 协程 use-defined ==函数和协程的区别？== 函数可以看成一个特殊的协程。函数的调用其实就是： 调用者主动让出CPU，创建函数栈帧，转而执行调用函数； return时再销毁被调函数栈帧，被调函数主动让出CPU； 返回继续执行调用者函数。 这个过程中，只有函数调用时，被调函数才拥有CPU；只有函数结束时，被调函数才会主动让出。但是，协程可以多次拥有CPU、多次主动让出CPU。这就是最大的区别。 问：线程之间共享的资源有哪些？ 可以先分析一下，哪些资源是线程私有的： 栈 程序计数器 函数运行使用的寄存器 栈指针 以上可以统称为线程上下文。 那除此之外，其余的就应该是共享的了： 代码区 线程之间共享代码区，这就意味着程序中的任何一个函数都可以放到线程中去执行，不存在某个函数只能被特定线程执行的情况。 数据区 用来存储全局变量。数据区中的全局变量有且仅有一个实例，所有的线程都可以访问到该全局变量。 堆区 只要知道变量的地址，也就是指针，任何一个线程都可以访问指针指向的数据，因此堆区也是线程共享的属于进程的资源。 栈区 上边说了，栈区是私有的。但是！！！尽管是私有的，但如果一个线程拿到了另一个线程内部变量的地址，那么照样是可以修改它的！！！理应是私有的，但没有什么保护措施，导致还算是共有的。 动态链接库 问：为什么线程切换比进程切换快呢？ 每个进程都拥有一个自己的虚拟地址空间，并且独立于其他进程的地址空间。而进程切换会涉及到虚拟地址空间的切换 虚拟地址转换为物理地址需要两个东西：CPU 上的 MMU 和 内存中的页表，为了减少访问内存的次数，设计了快表(页表缓存)。 由于进程切换会涉及到虚拟地址空间的切换，这就导致内存中的页表也需要进行切换，一个进程对应一个页表是不假，但是 CPU 中的 TLB 只有一个啊！页表切换后这个 TLB 就失效了。这样，TLB 在一段时间内肯定是无法被命中的，操作系统就必须去访问内存，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢。 而线程切换不需要切换虚拟地址空间，也就不存在这个问题了。 问：进程有哪些状态？ 创建状态(new)：进程正在被创建，尚未到就绪状态。 就绪状态(ready)：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 运行状态(running)：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 阻塞状态(waiting)：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。 以上为基础状态，但是大量进程阻塞时，也会占用内存，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。 所以需要新的状态-挂起态，来描述进程没有占用实际的物理内存空间的情况。 挂起状态可以分为两种： 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 问：进程间的通信方式？ 管道：管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。管道只能承载无格式字节流以及缓冲区大小受限； 消息队列：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，并且存在用户态与内核态之间的数据拷贝开销因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程； 共享内存：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。 信号量：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 \u003c 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 \u003e= 0，则表明还有资源可使用，进程可正常继续执行。 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 \u003c= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 \u003e 0，则表明当前没有阻塞中的进程。 信号：信号是Linux系统中用于进程间互相通信或者操作的一种异步通信机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。(和信号量完全没关系！！)。比如： Ctrl+C产生Sigint信号，表示终止进程； kill pid终止进程。 套接字：主要用于在客户端和服务器之间通过网络进行通信。 问：进程调度算法有哪些？ 先到先服务(FCFS)调度算法：从就绪队列中，按照进入队列的顺序对线程分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 短作业优先(SJF)的调度算法：","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:1:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"二、同步、锁 问：线程间的同步方式？ 互斥锁(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。 信号量(Semaphore)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件(Event)：Wait/Notify：通过通知的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 问：都有哪些锁？ **互斥锁：**一次只能一个线程拥有互斥锁，其他线程只有等待，加锁失败就让出CPU； 自旋锁：如果进/线程无法取得锁，进/线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁(忙等待)，直到获取为止； **读写锁：**多个读者可同时获得，但写者互斥，若有写者，则读者必须等待； **如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**因为线程上下文切换的代价相比自旋锁来说也很大。 问：乐观锁与悲观锁是啥？ 悲观锁：互斥锁、自旋锁、读写锁都属于悲观锁。悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。 **乐观锁：**乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。 乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**比如在线文档、Git等。 问：什么是死锁？ 死锁：两个或多个线程由于相互等待对方占有的资源而永远被阻塞的情况。 问：产生死锁的四个必要条件？ **互斥条件：**一个资源每次只能被一个进程使用。 **请求与保持条件：**一个进程因请求资源而阻塞时，对已获得的资源保持不放。 **不剥夺条件：**进程已获得的资源，在末使用完之前，不能被强行剥夺。 **循环等待条件：**若干进程之间形成一种头尾相接的循环等待资源关系。 问：解决死锁的方法？ **预防：**采用某种策略，限制并发进程对资源的请求； 破坏请求与保持：进程必须在执行前就申请到它所需要的全部资源，并且直到它所要的资源都得到满足之后才开始执行； 破坏循环等待：所有的资源被分成了多个层次，一个进程得到某一层次的资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源； 避免：系统在分配资源时，根据资源的使用情况提前做出预测，从而避免死锁的发生：银行家算法。 **检测：**当死锁发生时，能够检测死锁的发生，并精确地确定与死锁有关的进程和资源； **解除：**检测到死锁的进程，释放其持有的资源。 ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:2:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"三、内存管理 操作系统的内存管理主要负责内存的分配与回收。 问：内存管理机制有哪些？ 简单分为连续分配管理方式和非连续分配管理方式这两种。 连续分配管理是指为一个用户程序分配一个连续的内存空间，常见的如分区管理方式(块式管理)。 非连续分配管理允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理 和 段式管理。 块式管理：固定分区和动态分区。前者容易有内部碎片，后者有外部碎片。过程：前者将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块。后者按照进程大小划分块，按照首次适应算法分配。 页式管理：把内存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理：页式管理是从计算机角度出发设计的，对用户完全透明，而段式管理则是从用户角度出发设计的。将进程的逻辑空间划分为代码段、数据段、栈段、堆段等，段内的内存空间是连续的，段外的内存空间是不连续的。通过段表对应逻辑地址和物理地址。 段页式管理：段页式管理机制结合了段式管理和页式管理的优点。简单来说**段页式管理机制就是把主存先分成若干段，每个段又分成若干页。**每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号。 问：页式管理中，虚拟地址和物理地址怎么转换？ 页号和页内偏移。 页号作为页表的索引，页表包含物理页每页所在物理内存的基地址。基地址与页内偏移的组合就形成了物理内存地址。 问：多级页表有啥用？ 把存储大量页表项的页表，再次分页。 引入多级页表的主要目的是为了避免把全部页表项一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。 比如，32位系统，虚拟地址空间共有 4GB，假设一个页的大小是 4KB(2^12)，那么就有大约 1024 * 1024 (2^20) 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。可以划分成二级页表，第一级是1024个页表项，每个页表项对应一个页面，这个页面中又有1024个页表项，这样的好处就是：当查找时，首先通过一级页表找到二级页面，然后将指向的页面调入内存，然后找到页表项。也就是说内存中只需要存储用到的页面即可。这将大大减少需要调入内存的页表项总数。 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？ 对于 64位系统，通常采用四级页表。 问：快表(TLB) 是啥？ 快表(TLB)：将最常访问的页表项存储到访问速度更快的Cache中。 因为若把页表全部放入内存，存取一条数据至少要访问两次内存，第一次先访问页表找到数据对应的物理地址，第二次再从该地址存取数据。对于多级页表，需要访问内存的次数会更多。 而若命中快表，则只需要一次访存。 问：段页式内存管理的实现？ 先将程序划分为多个有逻辑意义的段：栈段、堆段、BSS段、数据段、代码段，也就是分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页； 地址结构就由段号、段内页号和页内位移三部分组成： 段页式地址变换中要得到物理地址须经过三次内存访问： 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。 问：虚拟地址空间是啥？有啥用？ 虚拟地址空间是程序中使用的内存地址，实际访问时通过 内存管理单元(MMU) 和 内存中的页表 转化为物理地址。==实际上并不存在。== 每个进程都拥有一个自己的虚拟地址空间，并且独立于其他进程的地址空间。虚拟地址空间将不同进程的虚拟地址和不同内存的物理地址映射起来。 虚拟地址空间主要是为了： 避免直接操作物理地址。可能会对操作系统造成影响； 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存； 易移植性。可以屏蔽操作系统物理地址的差别。 可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 问：虚拟内存是啥？虚拟内存管理有啥用？ 虚拟内存是一种逻辑上扩充物理内存的技术，就是将硬盘的一部分作为内存来使用。==是实际存在的。== 虚拟内存技术基于一个非常重要的原理，局部性原理： 1）时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环） 2）空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的） 基于这个局部性原理： 在一个程序装入内存的时候，可以只将这个程序中很快会用到的部分装入内存，暂时用不到的部分仍然留在外存（磁盘），并且程序可以正常执行； 而在程序执行过程中，当 CPU 所需要的信息不在内存中的时候，由操作系统负责将所需信息从外存（磁盘）调入内存，然后继续执行程序； 如果调入内存的时候内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。 虚拟内存管理主要是为了： 逻辑上扩大实际的物理内存。(就这一个) 问：虚拟内存的技术实现？页面置换算法有哪些？ 请求分页管理（页式虚存系统） 请求分段管理（段式虚存系统） 请求段页式管理（段页式虚存系统） 以请求分页管理为例：请求掉页、缺页中断、页面置换。 在程序执行过程中，当所访问的页不在内存时，会产生一个缺页中断，操作系统将内存中缺失的页面从磁盘调入内存； 若此时有空闲的块，就调入空闲的块； 若无空闲的块，就需要先淘汰掉某页。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到磁盘（操作系统要提供页面置换的功能， 将暂时用不到的页面换出磁盘）。 FIFO 算法，先入先淘汰； LRU 算法，效率很高，但实现复杂； Clock 算法，效率近似 LRU，但实现简单点 改进型的 CLOCK 算法步骤如下： **两个标志位：**访问位和修改位 从指针的当前位置开始，扫描循环队列。在这次扫描过程中，对访问位不做任何修改。选择遇到的第一个是第 0 类 “未被访问，未被修改 (Referenced bit = 0，Modified bit = 0)” 的页面用于替换 如果第 1 步失败，则重新扫描，查找第一个是 “未被访问，被修改 (Referenced bit = 0，Modified bit = 1)” 的页面用于替换。在这次扫描过程中，对每个跳过的页面，和简单的 CLOCK 算法一样，把它的访问位设置成 0 如果第 2 步失败，指针将回到它的最初位置，并且集合中所有页面的访问位都已经被设置为 0 了。重复第 1 步，并且如果有必要，重复第 2 步。这样一定可以找到供替换的页面。 ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:3:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"四、文件系统（未） ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:4:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"五、网络系统 ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:5:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"网络请求处理 黑马视频 redis 最后。 阻塞IO (Bloking IO) 先讲讲阻塞 IO 的数据接收流程： 服务端进程 A 通过 socket() 函数陷入内核态进行 socket 系统调用，该内核函数会创建 socket 内核对象，包含两个重要数据结构：等待队列和接收队列。 等待队列：存放服务端进程A的进程描述符和回调函数； 接收队列：存放网卡接收到的该 socket 要处理的数据。 进程 A 调用 recv() 函数接收数据，会进入到 recvfrom() 系统调用函数，发现 socket 的接收队列没有它要接收的数据到达时，进程 A 会让出 CPU，进入阻塞状态，进程 A 的进程描述符和它被唤醒用到的回调函数 callback func 会组成一个结构体，称为等待队列项，放入 socket 的等待队列； 客户端的发送数据到达服务端的网卡； 网卡首先会将网络传输过来的数据通过 DMA 控制程序复制到内存环形缓冲区 RingBuffer 中； 网卡向 CPU 发出硬中断； CPU 收到了硬中断后，为了避免过度占用 CPU 处理网络设备请求导致其他设备如鼠标和键盘的消息无法被处理，会调用网络驱动注册的中断处理函数，进行简单快速处理后向内核中断进程 ksoftirqd 发出软中断，就释放 CPU，由软中断进程处理复杂耗时的网络设备请求逻辑； 内核中断进程 ksoftirqd 收到软中断信号后，会将网卡复制到内存的数据，根据数据报文的 IP 和端口号，将其拷贝到对应 socket 的接收队列； 并通过进程等待队列中的回调函数，唤醒要处理该数据的进程 A，进程 A 会进入 CPU 的运行队列，等待获取 CPU 执行数据处理逻辑； 进程 A 获取 CPU 后，会回到之前调用 recvfrom() 函数时阻塞的位置继续执行，这时发现 socket 内核空间的等待队列上有数据，会在内核态将内核空间的 socket 等待队列的数据拷贝到用户空间，然后才会回到用户态执行进程的用户程序，从而真的解除阻塞。 **==阻塞 IO 模型==**如下： 会出现的问题： 进程在 recv 的时候大概率会被阻塞掉，导致第一次进程切换； 当数据到达服务端的网卡、并从网卡复制到内核空间 socket 的数据接收队列时，进程会被唤醒，第二次进程切换。此时还需要将数据从内核态复制到用户态，也就是数据复制会出现两次； 一个进程同时只能等待一条连接，如果有很多并发，则需要很多进程。 总结：一次数据到达会进行两次进程切换，一次数据读取有两次阻塞(出现在两次等待数据拷贝时)，单进程只能对单连接。 非阻塞IO (Nonbloking IO) 非阻塞的 Recv() 的效果是：如果没有数据从网卡到达内核 socket 的等待队列时，系统调用会直接返回，而不是阻塞的等待。 也就是说，非阻塞 IO，只是将等待数据从网卡到达 socket 内核空间这一部分变成了非阻塞的： 用户进程调用 recvfrom() 会重复发送请求检查数据是否到达内核空间(CPU忙等待)，如果没有到，则立即返回，重复这个过程，不会阻塞。 当数据已经到达内核空间的 socket 的等待队列后，用户进程依然要等待 recvfrom() 函数将数据从内核空间拷贝到用户空间，才会从 recvfrom() 系统调用函数中返回。 **总结：**非阻塞 IO 模型将“两处阻塞”变成了“一处阻塞”，但依然存在“两次进程切换，一处阻塞，单进程对单连接”的问题。 ==花里胡哨的，没什么用，数据没来还不停的问，有什么用？== maybe 类似自旋锁的作用？ IO多路复用 (IO Multiplexing) IO 多路复用可以解决“两次进程切换，单进程对单连接”的问题。 通过一个进程处理多个 TCP 连接，只处理有数据到达的连接。当然，如果要监听的所有连接都没有数据到达，进程还是会进入阻塞状态，直到某个连接有数据到达时被回调函数唤醒。 ==问题就在于如何发现哪个连接的数据到达了？== ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:5:1","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"详解select、poll、epoll 先说明几个重要的概念： 文件描述符 fd：是一个从 0 开始的非负整数，进程使用文件描述符来标识一个打开的文件。Linux 中一切皆文件。系统为每个进程维护了一个文件描述符表，表示该进程打开文件的记录表，文件描述符实际就是这张表中的索引。 **文件描述符集 fd_set：**select 函数参数中的 fd_set 类型表示文件描述符的集合，fd_set 的每一位来表示一个文件描述符。比如，当 select 返回 fd_set = 00010011 时，表示文件描述符 1、2、5 已经就绪。 Socket：用于不同进程间的通信。操作系统将 Socket 映射到进程的一个文件描述符上，进程就可以通过读写这个文件描述符来进行通信。通过 Socket 通信，实际上就是通过文件描述符 fd 读写文件。 IO 多路复用：利用单个进程来同时监听多个 fd，并在某个 fd 可读、可写时得到通知，从而避免无效的等待。 select select 实现多路复用的方式：将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写，接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 看个例子： 服务器进程 A 启动的时候，要监听的连接的 socket 文件描述符是 3、4、5； 如果这三个连接均没有数据到达网卡，则进程 A 会让出 CPU，进入阻塞状态；同时会将进程 A 的进程描述符和被唤醒时用到的回调函数组成等待队列项加入到 socket 对象 3、4、5 的进程等待队列中。注意，select 调用时，fdsr 文件描述符集会从用户空间拷贝到内核空间； 当网卡接收到数据，然后网卡通过中断信号通知 CPU 有数据到达，执行中断程序，中断程序主要做了两件事： 将网络数据写入到对应 socket 的数据接收队列里面； 唤醒队列中的等待进程 A，重新将进程 A 放入 CPU 的运行队列中； 假设连接 3、5 有数据到达网卡，注意，这时 select 调用结束时，fdsr 文件描述符集会从内核空间拷贝到用户空间： 进程 A 需要遍历 fd_set，获取就绪的文件描述符。 select 的缺点： 性能开销大 调用 select 时会陷入内核，这时需要将参数中的 fd_set 从用户空间拷贝到内核空间；select 执行完后，还需要将 fd_set 从内核空间拷贝回用户空间，高并发场景下这样的拷贝会消耗极大资源；（epoll 优化为不拷贝） 进程被唤醒后，不知道哪些连接已就绪，需要遍历拷贝过来的 fd_set 的每一位；（epoll 优化为异步事件通知） 同时能监听的文件描述符太少 受限于 sizeof(fd_set) 的大小，在编译内核时就确定了且无法更改。一般是 32 位操作系统是 1024，64 位是 2048。（poll、epoll 优化为适应链表方式） poll 和 select 类似，只是描述 fd 集合的方式不同：poll 使用 pollfd 结构而非 select 的 fd_set 结构。 基于链表存储，无最大数量限制，因此解决了 select 的第二个缺点。 epoll epoll 是对 select 和 poll 的巨大改进： 解决了 select 中 fd_set 不断重复拷贝到内核的问题：使用红黑树在内核中存储一份文件描述符集合，每个文件描述符只需在添加时传入内核一次，无需每次都重新传入； 通过事件的发生触发回调函数，存储就绪的文件描述符列表，而不是通过轮询的方式； 使用队列存储就绪的文件描述符，且会按需返回就绪的文件描述符，无须再次遍历。 主要涉及3个函数： // 创建一个 eventpoll 内核对象 int epoll_create(int size); // 将连接的socket对象添加到 eventpoll 对象中，epoll_event是要监听的事件 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 等待连接 socket 的数据是否到达 int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); epoll_create epoll_create 函数会创建一个内核对象 eventpoll，把它关联到当前进程的已打开文件列表中。主要包含3个成员： struct eventpoll { struct rb_root rbr; // 红黑树，管理用户进程下添加进来的所有 socket 连接 struct list_head rdllist; // 数据就绪的文件描述符都会放到这里 wait_queue_head_t wq; // 等待队列链表，存放阻塞的进程 ...... } rbr：一棵红黑树，管理所有要监听的 socket 连接，增删改的时间复杂度是 O(logn)； rdllist：就绪的描述符的链表。当某个 socket 注册事件触发时，通过注册的回调函数将就绪的 socket 放到 rdllist 链表里； wq：等待队列，如当前进程要等待数据，就会把当前进程描述符和回调函数构造成一个等待队列项，放入当前 wq 等待队列。 epoll_ctl epoll_ctl 函数有三个功能：增、删、改。主要负责把 socket 连接注册到 eventpoll 对象里，会做三件事： 创建一个 epitem 对象，主要包含两个字段：socket 的文件描述符、所属的 eventpoll 对象的指针； 将一个数据到达时用到的回调函数添加到 socket 的进程等待队列中； 将第 1 步创建的 epitem 对象插入红黑树。 epoll_wait 当 eventpoll 监控的 socket 对象有数据到达时，会通过 socket 进程等待队列中的回调函数唤醒红黑树中的节点 epitem，并将其添加到就绪队列 rdllist 中； 检查 eventpoll 对象的进程等待队列上是否有等待项，通过回调函数唤醒这个进程，进行数据的处理； 进程唤醒后，把 rdllist 中就绪的事件列表拷贝到用户空间。 问：I/O 多路复用是啥？有啥用？实现原理？⭐ IO多路复用是一种同步的IO模型。这里的I/O通常指网络I/O，也指Socket通信。 可以实现多个请求复用一个进程。利用IO多路复用模型，可以实现一个线程监视多个文件句柄；一旦某个文件句柄就绪，就能够通知到对应应用程序进行相应的读写操作；没有文件句柄就绪时就会阻塞应用程序，从而释放出CPU资源。 有三种实现方式： select：首先将所有的socket都放到一组文件描述符中，然后调入内核，内核通过轮询检查是否有网络事件发生。 若检查到事件发生，就将整组文件描述符调入用户态，然后用户程序再次轮询，对有事件发生的进行处理。 这种方式，一共轮询两次，并且需要两次拷贝文件描述符。并且有数量限制，1024个； poll：和select没啥区别，只不过没有数量限制，因为改成了用链表存储。 ==epoll：== epoll 在内核里使用**「红黑树」来关注进程所有待检测的事件**。红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。epoll 因为在内核维护了红黑树，可以保存所有待检测的事件，不需要像 select/poll 在每次操作时都传入整个事件集合，只需要传入一个待检测的事件，减少了内核和用户空间大量的数据拷贝和内存分配。 epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符，m不需要像 select/poll 那样轮询扫描整个事件集合，大大提高了检测的效率。 epoll 最大的优点是： 避免了轮询所有的文件描述符，采用回调函数定向通知程序要处理的事件，大大提高了CPU执行效率。 在内核中维护红黑树，避免文件描述符集的拷贝过程。 事件通知机制 问：epoll 支持哪几种事件通知机制？ epoll 支持两种事件触发模式，分别是边缘触发(ET)和水平触发(LT)。 LT：当被监控的 FD 有数据可读时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，直至数据处理完成。Epoll 的默认模式。 ET：当被监控的 FD 有数据可读时，服务器端只会从 epoll_wait 中苏醒一次，不管数据是否处理完成，因此要保证一次性将内核缓冲区的数据读取完； ET 的效率要比 LT 高，但是实现起来比较复杂，因为要保证一次读完所有的数据，要注意采用非阻塞的读取，也就是读不到数据了也返回，不然会一直阻塞在这里等待数据。 LT 可能会有惊群现象。 基于 epoll 的服务端模型 Redis 就跟这个类似。 ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:5:2","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"六、Linux 查看进程 ps aux | grep 进程名 ps -ef | grep 进程名 ps aux 和 ps -ef 命令都可以用于显示当前系统中运行的进程列表，但它们的输出格式略有不同。 ps aux 命令的输出格式是以用户为主导的，它显示了所有进程的详细信息，包括进程的用户、进程 ID、CPU 占用率、内存占用率等。其中，a 选项表示显示所有进程，u 选项表示显示详细信息，x 选项表示同时显示没有控制终端的进程。 ps -ef 命令的输出格式是以进程为主导的，它显示了所有进程的简要信息，包括进程的用户、进程 ID、父进程 ID、启动时间、命令等。其中，e 选项表示显示所有进程，f 选项表示显示进程的详细信息，包括父进程 ID、进程状态等。 因此，ps aux 输出的信息比 ps -ef 更详细，但也更复杂，而 ps -ef 输出的信息则更为简洁。在实际使用中，可以根据自己的需要选择使用哪个命令。 查看 socket $ netstat $ ss # 推荐 输出的内容都差不多，都包含了 socket 的状态（State）、接收队列（Recv-Q）、发送队列（Send-Q）、本地地址（Local Address）、远端地址（Foreign Address）、进程 PID 和进程名称（PID/Program name）等。 **接收队列（Recv-Q）和发送队列（Send-Q）**比较特殊，在不同的 socket 状态。它们表示的含义是不同的。 当 socket 状态处于 Established时： Recv-Q 表示 socket 接收缓冲区中还没有被应用程序读取的字节数； Send-Q 表示 socket 发送缓冲区中还没有被远端主机确认的字节数； 而当 socket 状态处于 Listen 时： Recv-Q 表示全连接队列的长度； Send-Q 表示全连接队列的最大长度； 日志分析 用一个大概几万条记录的 nginx 日志文件 access.log 作为案例，看看如何分析出「用户信息」。 准备工作 查看日志文件的大小： $ ls -lh 日志名 如果日志文件大小非常大，最好不要在线上环境做，下面的 access.log就只有 6.5 MB： 如果日志量太大，cat命令会非常影响性能，导致性能抖动；最好先用scp命令将日志文件传输到闲置的服务器再分析。 慎用cat cat读取文件时，文件中有多少数据，它就读多少，不适用于大文件。应使用less命令读取大文件的内容，因为 less 并不会加载整个文件，而是按需加载：先是输出一小页的内容，当要往下看的时候，才会继续加载。 若要看日志最新的内容，应使用tail命令： $ tail -n 5 access.log # 查看 access.log 最新的 5 条数据 $ tail -f # 实时查看日志 PV 分析 PV(Page View)：指页面的访问量(点击次数)。比如大多数博客平台，点击一次页面，阅读量就加 1，所以说 PV 的数量并不代表真实的用户数量，只是点击量。 分析 PV 比较容易，因为有多少行日志记录就有多少 PV，可以使用： $ wc -l access.log # 输出 access.log 有多少行 49903 access.log PV 分组 根据访问时间进行分组，比如按天分组，得到每天的访问量。根据日志记录的格式，时间在第 4 列，可以利用awk构造过滤语句： $ awk '{print $4}' access.log 但包含了时分秒，进一步过滤出年月日，使用awk的substr，从第 2 个字符开始，截取 11 个字符： $ awk '{print substr($4, 2, 11)}' access.log 但没排序，进一步排序，使用sort，然后使用uniq -c进行统计： $ awk '{print substr($4, 2, 11)}' access.log | sort | uniq -c 注意，使用 uniq -c 命令前，先要进行 sort 排序，因为 uniq 去重的原理是比较相邻的行，然后除去第二行和该行的后续副本。 UV 分析 UV(Uniq Visitor)：指访问人数。比如公众号的阅读量就是以 UV 统计的，不管单个用户点击了多少次，最终只算 1 次阅读量。 access.log中没有用户信息，可以用 IP地址 近似统计： $ awk '{print $1}' access.log | sort | uniq | wc -l 该命令的输出结果是 2589，也就说明 UV 的量为 2589。 awk '{print $1}' access.log，取日志的第 1 列内容，客户端的 IP 地址正是第 1 列； sort，对信息排序； uniq，去除重复的记录； wc -l，查看记录条数； UV 分组 按天分组分析每天的 UV 数量。命令较多，分开来看： 过滤出 「日期 + IP地址」 $ awk '{print substr($4, 2, 11) \" \" $1}' access.log | sort | uniq awk 将第 4 列的日期和第 1 列的客户端 IP 地址过滤出来，并用空格拼接起来； sort 对 awk 输出的内容进行排序； 接着用 uniq 去除重复的记录，也就说 日期 IP 相同的行就只保留一个； 统计次数，在上述命令后拼接：awk '{uv[$1]++;next}END{for (day in uv) print day, uv[day]}' $ awk '{print substr($4, 2, 11) \" \" $1}' access.log | sort | uniq | awk '{uv[$1]++;next}END{for (day in uv) print day, uv[day]}' awk 本身是「逐行」进行处理的，当执行完一行后，我们可以用 next 关键字来告诉 awk 跳转到下一行，把下一行作为输入； 对每一行输入，awk 会根据第 1 列的字符串(也就是日期)进行累加，这样相同日期的 ip 地址，就会累加起来，作为当天的 uv 数量； 之后的 END 关键字代表一个触发器，就是当前面的输入全部完成后，才会执行 END {} 中的语句，通过 for 遍历 uv 中所有的 key，打印出按天分组的 uv 数量。 终端类型分析 access.log 日志最末尾关于 User Agent 的信息，主要是客户端访问服务器使用的工具：手机、浏览器等。 可利用这些信息，分析不同终端类型分别有多少。 User Agent 的信息在日志里的第 12 列 $ awk '{print $12}' access.log | sort | uniq -c | sort -rn awk 过滤出第 12 列的内容； sort 排序； uniq -c 去重并统计； sort -rn(r 表示逆向排序， n 表示按数值排序)，对统计的结果排序 分析 TOP3 请求 获取到访问路径最频繁的 TOP3。 $ awk '{print $7}' access.log | sort | uniq -c | sort -rn | head -n 3 ","date":"0001-01-01","objectID":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:6:0","tags":null,"title":"","uri":"/05-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:0","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"常见面试题 用于自测，点击 G 即可跳转到相应答案~~ MySQL 索引(⭐⭐必问) 索引的类型有哪些？G 索引的数据结构有哪些？G B+树和B-树的区别？G B+树和Hash的区别？G 索引创建原则？G 什么情况下索引失效？G 聚集索引是什么？选取规则是什么？G 前缀索引？G uuid 和 自增id，做索引有啥区别？G 什么是回表查询？什么时候会触发回表查询？G⭐🚩 联合索引应用场景？为什么要建联合索引？G⭐🚩 MySQL 事务(⭐⭐必问) 事务隔离级别？G 可重复读下，如何避免幻读？G MVCC 的实现原理？G 各事务隔离级别是如何实现的？可重复读：G；读已提交：G 事务实现原理？ACID 是怎么保证的？未 MySQL 锁(⭐⭐必问) 行级锁，表级锁；排它锁，共享锁；记录锁、间隙锁，临键锁；两阶段锁； 死锁的原因？G 如何避免死锁？G MySQL 日志(⭐⭐常问) undo log 是啥？有啥用？G redo log 是啥？有啥用？G undo log 和 redo log 有啥区别？G 为什么有 bin log 了还要 redo log，两者有什么区别以及两者生成的时机？G 执行 update 的过程？⭐G 事务提交过程：什么是两阶段提交？G 为啥要两阶段提交？G MySQL 架构(⭐常问) 主从复制是咋实现的？G 从库是越多越好吗？G 主从复制有哪些模型？/如何保持主从间的数据一致性？G 分库、分表的方式有哪些？G 水平分片有哪些规则？G MySQL 数据类型 MySQL有哪些数据类型？ varchar 与 char 的区别？int 和 int (11) 区别？tinyint 与 int 区别？ MySQL 的 NULL 值是怎么存放的？会占用空间吗？ MySQL 怎么知道 varchar(n) 实际占用数据的大小？ varchar(n) 中 n 最大取值为多少？ 行溢出后，MySQL 是怎么处理的？ 面试问的 执行MySQL语句特别慢，可能的原因？G drop 和 delete 有啥区别？G count(1)、count(*)、count(字段)，哪个效率最高？G⭐🚩 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:1","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"一、事务 1.1 概念及原理 问：什么是事务？ 事务是一组操作的集合，是一个不可分割的单位，事务中包含若干操作，这些操作要么都成功，要么都失败。 # 开启一个事务 START TRANSACTION; # 多条 SQL 语句 SQL1,SQL2... # 提交事务 COMMIT; 问：事务的四大特性？ACID 是什么？ 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性⭐（Consistency）：执行事务前后，数据保持一致。例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后，它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 注：只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！ 问：MySQL中，各有什么机制保证以上四个属性？ **原子性、一致性、持久性：**redo log、undo log； **隔离性：**锁、MVCC。 问：持久性是怎么保证的？ redo log。 1.2 并发事务 A、B同时对数据库进行事务操作时，会发生的问题。 问：并发事务会带来哪些问题？ 脏读 不可重复读 幻读 丢失修改 … **脏读：**一个事务读到了另一个事务还未commit的数据； **不可重复读：**一个事务中先后读取同一条数据，期间另一个事务修改了该数据，造成第一个事务先后读取到的数据不一致。即，一个事务中前后两次读到的数据不一致； **幻读：**一个事务查询某条数据时，发现没有对应行，但之后另一个事务插入了该条数据，当第一个事务准备插入该条数据时，又发现这行数据已存在。即，前后读取的记录数量不一致，就像出现了幻觉一样； **丢失修改：**第一个事务修改了某条数据，第二个事务随后又修改了某条数据，造成第一个事务的修改结果丢失。 问：不可重复读和幻读的区别？ 不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把区分幻读的原因主要是解决幻读和不可重复读的方案不一样。 **举个例子：**执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。 问：并发事务的控制方式有哪些？ MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。锁可以看作是悲观控制的模式，多版本并发控制（MVCC，Multiversion concurrency control）可以看作是乐观控制的模式。 锁 控制方式下会通过锁来显示控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。 共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。 读写锁可以做到读读并行，但是无法做到写读、写写并行。另外，根据根据锁粒度的不同，又被分为 表级锁（table-level locking） 和 行级锁（row-level locking） 。InnoDB 不光支持表级锁，还支持行级锁，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说，InnoDB 的性能更高。不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。 MVCC 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。 MVCC 在 MySQL 中实现所依赖的手段主要是：隐藏字段、read view、undo log。 undo log：undo log 用于记录某行数据的多个版本的数据。 read view 和 隐藏字段：用来判断当前版本数据的可见性。 1.3 事务隔离级别 问：都有哪些事务隔离级别？ SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)：最低的隔离级别，允许读取尚未提交的数据变更。可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)：允许读取并发事务已经提交的数据。可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。可以阻止脏读和不可重复读，但幻读仍有可能发生。MySQL InnoDB 引擎的==默认隔离级别==； SERIALIZABLE(可串行化)：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰。也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × 问：可重复读下，如何避免幻读？ 首先要明确，使用「串行化」隔离级别才能彻底解决幻读现象，**==可重复读==只能在==很大程度上==**避免幻读(并不是完全解决了，详见这篇文章)。 可重复读的解决方案分为两方面： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读。因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 以下说明：为啥可重复读没完全解决幻读？ 示例场景1： 事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。注意，此时并未提交事务！ # 事务 A mysql\u003e begin; Query OK, 0 rows affected (0.00 sec) mysql\u003e select * from t_stu where id = 5; Empty set (0.01 sec) 然后事务 B 插入一条 id = 5 的记录，并且提交了事务。 # 事务 B mysql\u003e begin; Query OK, 0 rows affected (0.00 sec) mysql\u003e insert into t_stu values(5, '小美', 18); Query OK, 1 row affected (0.00 sec) mysql\u003e commit; Query OK, 0 rows affected (0.00 sec) 此时，事务 A 更新 id = 5 这条记录； # 事务 A mysql\u003e update t_stu set name = '小林coding' where id = 5; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u003e select * from t_stu where id = 5; +----+--------------+------+ | id | name | age | +----+--------------+------+ | 5 | 小林coding | 18 | +----+--------------+------+ 1 row in set (0.00 sec) 然后再次查询 id = 5 的记录，事务 A 就能看到事务 B 插入的纪录了，且被自己更新过。这就产生了幻读。 整个过程的时序图： 事务 A 开始时，会创建一个 Read View； 然后，事务 B 新插入了一条记录； 接着，事务 A 通过 update 操作对该记录进行更新，此时这条新记录的**trx_id就变成了事务 A 的事务 id**； 之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。 示例场景2： T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id \u003e 100 得到了 3 条记录。 T2 时刻","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:2","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"二、存储引擎 5.5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎，且所有的存储引擎中只有 InnoDB 是事务性存储引擎，也就是说只有 InnoDB 支持事务。 -- 查询当前数据库支持的数据库引擎 show engines; 问：MySQL存储引擎架构？ MySQL 存储引擎采用的是 插件式架构 ，支持多种存储引擎，我们甚至可以为不同的数据库表设置不同的存储引擎以适应不同场景的需要。存储引擎是基于表的，而不是数据库。 还可以根据 MySQL 定义的存储引擎实现标准接口来编写一个属于自己的存储引擎。(像目前最常用的 InnoDB 其实刚开始就是一个第三方存储引擎，后面由于过于优秀，其被 Oracle 直接收购了。) 问：MyISAM 和 InnoDB 有何区别？ 是否支持行级锁 MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。也就是说，MyISAM 一锁就是锁住了整张表，并发时性能远不如 InnoDB。 是否支持事务 MyISAM 不提供事务支持。 InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重复读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。 是否支持外键 MyISAM 不支持，而 InnoDB 支持。 外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗。因此，通常情况下，我们是不建议在实际生产项目中使用外键的，在业务代码中进行约束即可！ 是否支持数据库异常崩溃后的安全恢复 MyISAM 不支持，而 InnoDB 支持。 使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。 是否支持 MVCC MyISAM 不支持，而 InnoDB 支持。 MyISAM 连行级锁都不支持，而 MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。 索引的实现不同 二者均采用B+Tree作为索引结构，但是两者的实现方式不太一样。 InnoDB 引擎中，其数据文件本身就是索引文件，支持聚簇索引。 而 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录，在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引（非聚集索引）”。 详细需要看索引。 性能差别 InnoDB 的性能比 MyISAM 更强大，不管是在读写混合模式下还是只读模式下，随着 CPU 核数的增加，InnoDB 的读写能力呈线性增长。MyISAM 因为读写不能并发，它的处理能力跟核数没关系。 问：如何选择 MyISAM 和 InnoDB、MEMORY？ **InnoDB⭐：**如果应用对事务的完整性有较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询外，还包含很多更新、删除的操作，那么选择 InnoDB。 **MyISAM：**如果应用以插入和查询操作为主，很少更新和删除，并且对事务的完整性、并发性要求不高，也不需要崩溃后安全恢复的话，那么也凑合能用。(现在被 MongoDB 替代了) **MEMORY：**通常用于临时表及缓存，将所有数据保存在内存，访问速度快。缺点就是对表的大小有限制，且安全性无法保障。(现在被 Redis 替代了) 绝大部分情况下选择 InnoDB 都是没有问题的。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:3","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"三、索引⭐ 3.1 索引结构 索引是帮助 MySQL 高效获取数据(快速查询和检索数据)的数据结构(有序)。 常见的索引结构有: B 树(也称 B- 树)，B+ 树 和 Hash、红黑树。在 MySQL 中，无论是 Innodb 还是 MyIsam，都使用了 B+ 树 作为索引结构。大部分都支持 B+ 树 索引。 InnoDB 的数据是按==「数据页」(16KB)==为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。 问：B-树 和 B+树 有何异同？ B-树 的所有节点既存放键(key) 也存放 数据(data)，而 B+树 只有叶子节点存放 key 和 data，其他节点只存放 key； B-树 的叶子节点都是独立的；B+树 的叶子节点之间构成一个有序链表； B+树 的非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小），这样虽然有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点。 B-树 的检索可能还没有到达叶子节点，检索就结束了，查询波动比较大；而 B+树 的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程。 问：B+ Tree 相比于 B- Tree 的优点？ **范围查询效率更高。**因为 B+ 树所有叶子节点间有一个链表进行连接，只需要查到头节点，然后往后遍历即可。但 B- 树就只能通过一个一个查找完成。 **插入和删除效率更高。**因为 B+ 树有冗余节点，插入和删除时，树的结构不用怎么变化。 查询效率也更高一点。因为I/O操作会少一点嘛。 问：Hash 索引相比于 B+ 树的优缺点？ Hash索引自身只需要存储对应的哈希值，所以索引内存结构非常紧凑，查询效率很高； 但由于是通过哈希映射进行索引，因此无法排序或进行范围查询。 问：B+ Tree 的特点？ 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。 非叶子节点分为不同层次，通过分层来降低每一层的搜索量； 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询； 问：B+ Tree 索引一个元素的过程？ B+ 树如何实现快速查找主键为 6 的记录： 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项； 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录； 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。 问：为什么 InnoDB 存储引擎选用 B+Tree 索引结构？ 相比于红黑树等二叉树结构，B+Tree 层级更少，因此搜索效率更高(因为磁盘I/O操作更少)； 相比于 B-Tree ，因为 B-Tree 无论叶子节点还是非叶子节点，都会保存数据，这样会导致一页中存储的键值减少，指针也跟着减少，要保存同样的数据，只能增加树的高度，导致性能下降；其实我觉得，主要是**==减少了调页的I/O操作次数==**。 相比于 Hash索引 ，B+Tree 支持范围匹配及排序操作，比如SELECT * FROM tb1 WHERE id \u003c 500;，如果用 Hash索引，难道要把1-499都挨个hash定位吗？ 注： 其实一开始我很不理解为啥 ==“1. 层级减少，搜索效率会变高”==，因为你就算层级变少了，但是节点内的键值对变多了啊，搜索的时候还是用二分，效率并没有减少啊！ 后来，我知道了每次访问一个节点，其实就是需要一次调页操作的，也就是一次磁盘I/O，而单个节点内的键值对变多，显然会减少调页次数，也就提高了效率。 问：B+ 树不同高度的数据存储？ 假设 B+ 树的高度为 2 的话，即有一个根结点和若干个叶子结点。这棵 B+ 树的存放总记录数为 = 根结点指针数 * 单个叶子节点记录行数。 如果一行记录的数据大小为 1k，那么单个叶子节点可以存的记录数 = 16k/1k = 16. 非叶子节点内存放多少指针呢？我们假设主键ID为 bigint 类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6 = 14 字节，16KB/14B = 16*1024B/14B = 1170 因此，一棵高度为2的B+树，能存放1170 * 16=18720条这样的数据记录。同理一棵高度为 3 的 B+ 树，能存放 1170 *1170 * 16 = 21902400，大概可以存放两千万左右的记录。B+ 树高度一般为 1-3 层，如果 B+ 到了 4 层，查询的时候会多查磁盘的次数，SQL 就会变慢。 3.2 索引类型 分类 含义 特点 关键字 主键索引 针对表中主键创建的索引 默认自动创建，只能有一个 PRIMARY 唯一索引 避免同一个表中某数据列中的值重复 可以有多个 UNIQUE 常规索引 快速定位特定数据 可以有多个 全文索引 全文索引查找的是文本中的关键词，而不是比较索引中的值 可以有多个 FULLTEXT 在 InnoDB 存储引擎中，根据索引的存储形式，又可以分为以下两种： 分类 含义 特点 聚集索引(Clustered Index) 将索引与数据存储放到一起，索引结构的叶子节点中保存了行数据 有且只有一个 二级索引(Secondary Index) 将数据与索引分开存储，索引结构的叶子节点中保存了对应的主键 可以有多个 比如：select * from user where name='Tom'，会先去查找二级索引name，找到对应的主键id值，然后回表查询通过聚集索引拿到对应的行数据。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:4","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"思考：以下 SQL语句，哪个执行效率高？为什么？ select * from user where id = 10; select * from user where name = 'Arm'; -- 备注：id为主键，name字段创建的有索引。 1显然效率更高。 问：索引类型？ 索引从数据结构进行划分的分为：B+树索引、B-树索引、Hash索引、二叉树索引。 索引从物理存储的角度划分为：聚族索引和非聚族索引。 从逻辑的角度分为：主键索引、普通索引、唯一索引、联合索引。 问：InnoDB 主键索引的 B+Tree 高度有多高？ 黑马视频。 问：聚集索引选取规则？ 聚集索引有且仅有一个，它将索引与数据存储放到一起，索引结构的叶子节点中保存了行数据。 如果存在主键，主键索引就是聚集索引； 如果不存在主键，第一个唯一索引就是聚集索引； 如果二者都无，则 InnoDB 会自动生成一个 隐式自增的id 作为隐藏的聚集索引。 问：SQL性能分析方法？ SQL 执行频次 慢查询日志 profiles详情 explain性能分析，可以查看执行计划 3.3 索引使用 索引法则 **单列索引：**一个索引值包含单个列 **联合索引：**一个索引包含了多个列 问：索引失效的情况？即，使用索引时需要的注意事项？⭐⭐🚩 最左前缀法则 如果索引了多列(联合索引)，要遵守最左前缀法则。最左前缀法则指的是查询条件从索引的最左列开始，并且不跳过索引中的列。如果跳过某一列，索引将部分失效(后面的字段索引失效)。 如果创建了一个 (a, b, c) 联合索引： # 不会失效 where a=1； where a=1 and b=2 and c=3； where b=2 and a=1 and c=3; # 查询优化器会自动进行排序 where a=1 and b=2； # 部分生效 where a=1 and c=3 # 会失效 where b=2； where c=3； where b=2 and c=3； 其实联合索引(a, b, c)，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的。 有一个比较特殊的查询条件：where a = 1 and c = 3 ，符合最左匹配吗？ 严格意义上来说是属于索引截断，不同版本处理方式也不一样： MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值； 从 MySQL 5.6 之后，有一个索引下推功能，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。 索引下推的基本原理：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 (a, b, c) 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。 因此，where a = 1 and c = 3 会部分用到索引，并且在 MySQL 5.6 后，还会用到索引下推。 详细 范围查询 联合索引中，出现范围查询(\u003e, \u003c)，范围查询右侧的列索引失效。注意：若使用 (\u003e=, \u003c=)，则不会失效，因此建议使用 (\u003e=, \u003c=)。 **字符串不加引号：**字符串类型字段使用时，若索引值不加引号，索引将失效。 explain select * from user where phone = '17799990015'; -- 不失效 explain select * from user where phone = 17799990015; -- 失效 模糊查询：如果仅仅是尾部模糊匹配，索引不会失效；如果是头部模糊匹配，索引失效。因为排序时是按字典序。 explain select * from user where prefession like '软件%' -- 不失效 explain select * from user where prefession like '%工程' -- 失效 **or连接的条件：**用or分割开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。即，只有or两边的条件均有索引，整体才会生效，否则，均不生效。 **数据分布影响：**如果 MySQL 评估使用索引比全表查询更慢，则不使用索引。 -- 数据范围：00-20 explain select * from user where phone = '17799990005'; -- 全表查询 explain select * from user where phone = '17799990015'; -- 索引查询 对索引进行表达式计算：因为索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值，所以无法走索引，只能通过把索引字段的取值都取出来，然后依次进行表达式的计算来进行条件判断，因此采用的就是全表扫描的方式。 explain select * from t_user where id + 1 = 10; # 索引失效 where id = 10 - 1; # 索引不失效 建议参考：索引失效有哪些？ 问：如何查看 MySQL 是否用到了索引？🚩 在查询语句前加上 explain 关键字。 问：优化数据库查询操作的做法？即 优化索引的方法？ 前缀索引优化； 覆盖索引优化； 主键索引最好是自增的； 防止索引失效 使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值数目； 尽量使用覆盖索引，避免使用select *，会大量造成回表查询，原因见下。 主键索引最好是自增的，这样的话，每次插入一条新记录，都是追加操作，不需要重新移动数据； 索引时，要避免索引失效。 覆盖索引、回表查询⭐🚩 如果一个索引覆盖所有需要查询的字段的值，就称之为**覆盖索引**。我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次，这样就会比较慢。 **覆盖索引，即需要查询的字段正好是索引中的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询。**因此，尽量避免使用select *，除非你联合索引的条件很多很多。 问：什么是回表查询？什么时候会触发回表查询？ 回表查询是指在查询过程中，如果需要获取的数据不在查询语句的索引列中，那么就需要通过回表操作来获取额外的数据。回表操作会根据查询语句中的主键或唯一索引定位行数据，然后再根据行数据中的其他列获取需要的数据。 例：《黑马》P84 讲的很好！ 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。 问：联合索引应用场景？为什么要建联合索引？⭐🚩 多条件联合查询：当查询语句中需要同时使用多个列进行查询时，可以使用联合索引来提高查询效率。 减少开销：建一个联合索引(a, b, c)，实际相当于建了(a)，(a, b)，(a, b, c)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引：当查询语句只需要查询索引列和联合索引中的列时，可以使用联合索引来避免回表操作，从而提高查询效率。 排序操作：当查询语句需要对多个列进行频繁排序时，可以使用联合索引来提高排序效率。例如，一个学生表包含了学生ID、姓名、年龄、成绩等列，如果需要按照成绩和年龄进行排序，可以使用联合索引（成绩，年龄）来提高排序效率。 问：一张表，有四个字段(id, username, password, status)，由于数据量大，需要对以下 SQL 语句进行优化，该如何进行才是最优方案？ select id, username, password from user where username='itcast'; **需要建立索引：**针对 username 和 password 建立联合索引，这样的话，查到username=‘itcast’时，val值为id，username和password也知道，直接返回即可，无需回表查询。 前缀索引 问：前缀索引是什么？ 字段类型为字符串时，索引很长的字符串，会让索引变得很大，导致一个索引页中的索引数量变少，层级就会变高，导致查询时，浪费大量的磁盘IO，影响查询效率。 前缀索引就是只对字符串的一部分前缀，建立索引，可以减小索引字段大小，增加一个索引页中存储的索引数量，有效提高索引的查询速度。 create index idx_xxx on table_name(column(n)) # column(n)表示列column只取前n个字符构建索引 不过，前缀索引有一定的局限性，例如： order by、group by 无法使用前缀索引； 由于只存储了部分前缀，所以也无法把前缀索引用作覆盖索引(覆盖索引需要全部的数据)。 索引下推 问：什么是索引下推？ 索引下推（Index Condition Pushdown） 是 MySQL 5.6 版本中提供的一项索引优化功能，可以","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:5","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"四、SQL优化 其实2-7都是跟索引相关。 4.1 插入数据 insert优化： 批量插入，若特别大量(百万级)，建议使用load指令而非insert； 手动提交事务； 主键顺序插入，因为乱序插入可能会发生页分裂和页合并。 4.2 主键优化 尽量降低主键的长度； 插入数据时，尽量选择顺序插入，选择使用auto_increment自增主键； 尽量不要使用UUID做主键或是其他自然主键，如身份证号，因为这些主键不是顺序的，插入时相当于乱序，且这些主键较长； 尽量避免对主键的修改。 4.3 order by 优化 using index：直接通过索引返回数据，性能高； using filesort：需要将返回的结果在排序缓冲区重新排序。 对order by字段建立索引，默认是升序排列，查询时需要按照建立索引时指定的排列顺序，否则还是会额外的排序(filesort)； 也要遵循最左前缀法则，尽量使用覆盖索引； 不可避免出现filesort时，大数据排序时，可以适当增大排序缓冲区大小。 4.4 group by 优化 对group by字段建立索引，避免using temporary； 也要遵循最左前缀法则。 4.5 limit 优化 覆盖索引+子查询 4.6 count 优化 MyISAM 是把count结果记录在磁盘上，需要的时候直接读取。 InnoDB 需要一条一条读取数据，再累计计数，没有什么好的优化方法。 用法： count(主键)：遍历整张表，把每一行的主键id(不可能为null)的值都取出，然后进行累加； count(字段)： 没有not null约束：遍历整张表，取出每行的值，服务层判断是否为null，不为null的累加； 有not null约束：遍历整张表，取出每行的值，直接累加。 **count(1)：**InnoDB 遍历整张表，不取值，对每一行放一个1，直接按行累加。 **count(*)：**等价于 count(0)，InnoDB 并不把所有字段取出，专门做了优化，不取值，直接按行累加。(使用 count(*) 时，MySQL 会将 * 参数转化为参数 0 来处理)。 问：count() 是什么？ count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。 假设 count() 函数的参数是字段名，如下： select count(name) from t_order; 这条语句是统计「t_order 表中，name 字段不为 NULL 的记录」有多少个。也就是说，如果某一条记录中的 name 字段的值为 NULL，则就不会被统计进去。 再来假设 count() 函数的参数是数字 1 这个表达式，如下： select count(1) from t_order; 这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。 1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句，其实是在统计 t_order 表中有多少个记录。 问：count(1)、count(*)、count(字段)，哪个效率最高？⭐🚩 **==效率排序：==**count(字段) \u003c counts(索引字段) \u003c count(1) ≈ count(*)，所以尽量选择count(*)。 其实，尽量不要使用count来统计，可以使用： show table status 估算； 单独建个表，用来计数 4.7 update 优化 update 更新时，更新条件要按照索引，这样加的才是行锁，否则是表锁，会降低数据库的并行性能。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:6","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"五、视图 \u0026 存储过程 \u0026 触发器（未） 5.1 视图 视图是一种虚拟存在的表。视图只保存了查询的 SQL 逻辑，不保存查询结果。所以在创建视图的时候，主要工作就落在创建这条 SQL 查询语句上。 # 创建视图 create or replace view stu_v_1 as select id, name from student where id \u003c= 10; # 查询视图，此时就会输出id, name 两列的数据，即简化了SQL查询语句 select * from stu_v_1; # 带检查选项的创建，此时向视图插入 id\u003e10的就会报错 create or replace view stu_v_1 as select id, name from student where id \u003c= 10 with local check option; 视图的作用 **简化操作。**无需每次都指定全部条件。 **安全。**通过视图，用户只能查询和修改他们所见到的数据。 **数据独立。**屏蔽基表变化对业务的影响。 5.2 存储过程 语法 # 创建 无返回值 create procedure 过程名 begin sql语句; end; # 调用 call 过程名; # 查看 select * from information_schema.ROUTINES where ROUTINE_SCHEMA = 'itcast'; show create procedure 过程名; # 删除 drop procedure if exists 过程名; 5.3 存储函数 就是有返回值的存储过程。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:7","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"六、锁 锁是协调多个进程或线程并发访问某一资源的机制。 **全局锁：**锁定数据库中的所有表；（粒度最大的锁） **表级锁：**每次操作锁住整张表；针对非索引字段； **行级锁：**每次操作锁住对应的行数据；针对索引字段；（粒度最小的锁） 6.1 全局锁 问：全局锁的应用场景？ 全局锁是对整个数据库实例加锁，加锁后数据库变成只读状态(DQL可执行)，DML、DDL语句都会被阻塞。典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获得一致性视图，保证数据的完整性。 flush tables with read lock; unlock tables; 但是加全局锁是个非常重的操作： 若在主库上备份，那么业务就得停摆； 若在从库上备份，那么备份期间从库不能执行主库同步，会导致主从延迟。 在 InnoDB 上备份时，加上参数–single-transaction参数可以完成不加锁的一致性数据备份。这种方式实际上是通过快照实现的。 6.2 表级锁 **表共享锁(read lock)：**大家(包括自己)都可以读，但都不可以写 **表排他锁(write lock)：**自己可以读写，别人不可以读写 # 加锁 lock tables 表名... read/write # 释放锁 unlock tables /客户端断开连接 元数据锁(meta data lock，MDL)：MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的数据一致性，在表上有活动事务时，不可以对元数据进行写入操作。 对表进行增删改查时，加MDL读锁(共享锁)；对表结构进行变更操作时，加MDL写锁(排他锁)。 意向锁⭐：为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使表锁不用检查每行数据是否已被加锁，==使用意向锁来减少表锁对行锁的检查==。 **意向共享锁(IS)：**与表共享锁(read)兼容，与表排他锁(write)互斥； **意向排他锁(IX)：**与表共享锁(read)及表排他锁(write)都互斥。 意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InnoDB 会先获取该数据行所在在数据表的对应意向锁。 ==意向锁之间不会互斥。== IS 锁 IX 锁 IS 锁 兼容 兼容 IX 锁 兼容 兼容 意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。 IS 锁 IX 锁 S 锁 兼容 互斥 X 锁 互斥 互斥 问：意向锁有什么作用？ 使用表锁之前，如果已经有行锁存在，就会冲突，因此需要先检查是否有行锁，但是一行一行扫描的效率太低，此时就会用到意向锁。 在加行锁之后，会对表加一个意向锁，之后再加表锁时，只需检查是否有意向锁即可。当检查意向锁和要加的表锁是兼容的，那直接加，如果冲突，就会阻塞，直到意向锁释放。 例：事务A对表中某行进行修改，此时会自动加上行锁，同时还会对表加上意向排他锁，此时若事务B向表加锁(共享锁/排他锁)，都不能成功，因为有意向排他锁。 问：共享锁和排他锁？ 共享锁（S 锁）：事务在读取时获得；允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：事务在修改的时获得；不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。只允许获得该锁的事务读写，不允许其他事务操作。 6.3 行级锁 分类： **记录锁：**锁定单行记录的锁，防止其他事务对该行进行update和delete。在RC、RR隔离级别下都支持。 **间隙锁：**锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下支持。 **临键锁⭐：**行锁和间隙锁的组合，锁住该行数据，及该行前的间隙。在RR隔离级别下支持。 插入意向锁⭐：如果某个间隙被间隙锁锁定，其他事务进行插入时就会阻塞，直到间隙锁释放，在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。插入意向锁是特殊的间隙锁，不互斥。 间隙锁的唯一目的是：防止其他事务插入该间隙，解决幻读。间隙锁是共享锁，即允许多个事务在同一间隙上采用间隙锁。 问：临键锁的范围？ 唯一索引的等值查询，数据存在时，会加行锁； 唯一索引的等值查询，数据不存在，会对查询条件主键所在的间隙加间隙锁； 普通索引的等值查询，数据存在时，会对该数据前后第一个不满足条件的两端之间的所有间隙加间隙锁，相同数据的行都加行锁，这是因为普通索引可能会插入相同的数据，所以这些间隙都得加锁；如果是范围查询，那么该范围内存在的数据的行都加行锁，其余区间都加间隙锁。 问：为什么会产生死锁？ 关键点： Innodb 引擎为了解决**「可重复读」隔离级别下的幻读问题，引出了next-key 锁**，它是记录锁和间隙锁的组合。 行锁的释放时机是在事务提交（commit）后，锁才会被释放，并不是一条语句执行完就释放行锁。 例，表中数据范围[1001-1006]，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，要先查询该订单是否存在，不存在才插入记录： 为了防止幻读嘛，查询时(注意这不是普通的快照读！)，select ... for update 语句会加临键锁，此时退化成间隙锁，间隙锁与间隙锁之间是兼容的，因此此时A、B都获得了间隙锁； 插入时，insert语句会在插入间隙上获取插入意向锁，而==插入意向锁与间隙锁是冲突的==，获得插入意向锁后，需要等待间隙锁释放，此时A、B都获得了插入意向锁，但都等待彼此的间隙锁释放，造成死锁。 满足了死锁的四个条件：互斥、保持与请求、不可被抢占、循环等待，因此发生了死锁。 **注：**为什么间隙锁与间隙锁是兼容的？ 间隙锁的意义只在于阻止区间被插入，因此是可以共存的。共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同，即两个事务可以同时持有包含共同间隙的间隙锁。 ==另外，==虽然相同范围的间隙锁是多个事务相互兼容的，但对于==记录锁==，还是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的！！！ 问：如何避免死锁？ 死锁的四个必要条件：互斥、保持与请求、不可被抢占、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 在数据库层面，有两种策略通过**「打破循环等待条件」**来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超时，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:8","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"七、MVCC 7.1 概念 问：当前读和快照读有什么区别？ **快照读：**一致性非锁定读，就是普通的select语句； **当前读：**一致性锁定读，会给行加X锁或S锁。 # 对读的记录加一个X锁 SELECT...FOR UPDATE # 对读的记录加一个S锁 SELECT...LOCK IN SHARE MODE # 对修改的记录加一个X锁 INSERT... UPDATE... DELETE... 快照读时，若读取的记录正在进行update/delete操作，快照读不会等待其X锁的释放，而是会去读取快照。只有在事务隔离级别 RC(读取已提交) 和 RR（可重读）下，InnoDB 才会使用快照读： 在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。 在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。 当前读时，读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前事务，所以会加锁。 问：什么是MVCC？ **多版本并发控制。**指维护一个数据的多个版本，使得读写操作没有冲突，快照读为实现MVCC提供了一个非阻塞读功能。 7.2 MVCC实现 MVCC的实现依赖于数据库中：三个隐藏字段、undo log日志、readView。 7.2.1 隐藏字段 DB_TRX_ID：最后一次插入或更新改行的事务ID。 DR_ROLL_PTR：回滚指针，指向上个版本，即undo log。 DB_ROW_ID：隐藏主键。如果没有设置主键且没有唯一非空索引时，会使用该ID生成聚集索引。 7.2.2 undo log 回滚日志。在 insert、update、delete的时候产生的便于数据回滚的日志。 insert undo log：insert时产生的undo log。只在回滚时需要，事务提交后，可立即被删除。 update undo log：update/delete时产生的undo log。不仅在回滚时需要，在快照读时也需要，因此不会被立即删除。 7.2.3 readview ReadView(读视图)是快照读 SQL 执行时 MVCC 提取数据的依据，记录并维护系统当前活跃的事务(未提交的)ID。 包含以下字段： **m_low_limit_id：**目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见 **m_up_limit_id：**活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的数据版本均可见 m_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View 时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中） **m_creator_trx_id：**创建该 Read View 的事务 ID 问：MVCC的实现原理？⭐⭐ MVCC 的实现主要依赖： Read View； 聚簇索引中的跟事务相关的两个隐藏列[trx_id, undo_log]。 ==Read View 的结构：== creator_trx_id：指的是创建该 Read View 的事务的事务 id； m_ids：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表。注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务； **min_trx_id：**指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值； max_trx_id：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1。 ==聚簇索引的两个隐藏列：== trx_id：当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后roll_pointer 指向旧版本记录，通过它找到修改前的记录。 可以看到，聚簇索引中每行记录都会有个trx_id，可以将**所有记录的trx_id**划分为三种情况： 一个事务去访问记录时，自己的更新总是可见的，除此之外： 若当前记录的trx_id \u003c Read View 中的min_trx_id，说明是创建Read View之前已经提交的事务生成的，所以该记录对当前事务可见； 若当前记录的trx_id \u003e= Read View 中的max_trx_id，说明是创建Read View之后才启动的事务生成的，所以该记录对当前事务不可见； 若当前记录的trx_id 在min_trx_id和max_trx_id之间，需要判断trx_id是否存在m_ids列表中： 若存在，表示该事务依然活跃(也就是还没提交呢)，所以该记录对当前事务不可见，就会顺着 undo log 链寻找旧版本数据； 若不存在，表示该事务在当前事务创建Read View之前已经提交了，所以该记录对当前事务可见。 这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。 问：RC和RR隔离级别下MVCC的差异？ 在 RC 隔离级别下的 每次select 查询前都生成一个Read View (m_ids 列表) 在 RR 隔离级别下只在事务开始后 第一次select 数据前生成一个Read View（m_ids 列表） 问：MVCC+临键锁 防止幻读？ 1、执行普通 select，此时会以 MVCC 快照读的方式读取数据 在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读” 2、执行 select…for update/lock in share mode、insert、update、delete 等当前读 在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lockopen in new window 来防止这种情况。**当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。**只要我不让你插入，就不会发生幻读。 其实就是： 快照读时，通过只在第一次查询时生成Read View，来防止幻读； 当前读时，通过加临键锁，拒绝数据插入，来防止幻读。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:9","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"八、数据类型 这点之前没记，现在补充一下~ 8.1 表空间的文件结构 行 数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 页 InnoDB 的数据是按**「页」为单位来读写**，一次I/O操作读取一页，默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。 区 数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用**顺序 I/O **了。 段 表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。 8.2 行格式 现在用的都是 Compact 行格式，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:10","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"九、日志 更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、bin log（归档日志）这三种日志。 undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC； redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； bin log（归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制。 undo log 和 redo log 问：undo log 是啥？有啥用？ undo log 是一种用于回退撤销的日志。在事务没提交之前，MySQL 会先把更新前的数据记录到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。 每当 InnoDB 引擎对一条记录进行更新(修改、删除、新增)时，要把回滚时需要的信息都记录到 undo log 里。 另外，undo log 还可以串成链表，称为版本链，用来实现 MVCC。 因此，undo log 共两大作用： 实现事务回滚，保障事务的原子性。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）的关键因素之一。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。 问：WAL 技术？ 说明 redo log 有啥用之前，需要先介绍 Buffer pool 和 WAL 技术。 Buffer pool 相当于数据库中的缓存，以页为单位，读取数据时也先从这里读，更新数据时，也先尝试更新 Buffer pool 中的数据页。若 Buffer pool 中的页相比原数据库中的页做了修改，就称为脏页。 内存中的数据若不刷盘，断电了就消失了，所以为了防止断电导致数据丢失，在修改 Buffer pool 中的页之后，会将本次对这个页的修改以 redo log 的形式记录下来，然后定时由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这称为 WAL(Write-Ahead Logging)技术。 WAL 技术指的是，MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。 问：redo log是啥？有啥用？ redo log 是重做日志，记录事务提交时数据页的物理修改。记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。 在事务提交时，只要先将 redo log 持久化到磁盘即可，不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。 问：undo log 和 redo log 有啥区别？⭐⭐ redo log 记录了此次事务「提交后」的数据状态，记录的是更新之后的值； undo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值； 事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务； 事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。 所以，undo log 保证了原子性，redo log 保证了持久性。 问：redo log 会满吗？ 会。redo log 类似 Redis 的 repl_backlog，也是个环形缓冲区，当写满了之后，就会触发 buffer pool 的刷盘操作，然后擦除旧的 redo log，就可以继续写入了~ bin log 问：什么是 bin log？ bin log 是由 MySQL 的 Server 层生成的。 bin log 文件记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，以二进制形式保存在磁盘上。 问：为什么有了 bin log 还要有 redo log？这俩有啥区别？ 这跟 MySQL 的时间线有关系。 最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，bin log 日志只能用于归档。 而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 bin log 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。 区别： 适用对象不同 bin log 是 MySQL 的 Server 层实现的，所有的存储引擎都可以使用； redo log 是 Innodb 存储引擎实现的，也就是独有的。 文件格式不同 bin log 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED。区别如下： STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致； ROW：记录每行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已； MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式； redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新； 写入方式不同 bin log 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。 redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。 用途不同 bin log 用于备份恢复、主从复制； redo log 用于掉电等故障恢复。 问：如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？ 不可以使用 redo log 文件恢复，只能使用 bin log 文件恢复。 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。 bin log 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 bin log 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 bin log 文件恢复数据。 问：执行 update 的过程？ 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录： 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新； 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样： 如果一样的话就不进行后续更新流程； 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作； 开启事务，InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来。 InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术。 至此，一条记录更新完了。 在一条更新语句执行完成后，然后开始记录该语句对应的 bin log，此时记录的 bin log 会被保存到 bin log cache，并没有刷新到硬盘上的 bin log 文件，在事务提交时才会统一将该事务运行过程中的所有 bin log 刷新到硬盘。 事务进行两阶段提交。 问：什么是两阶段提交？ 两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是**「准备（Prepare）阶段」和「提交（Commit）阶段」**。 MySQL 使用了内部 XA 事务，由 bin log 作为协调者，存储引擎是参与者。 prepare 阶段：将 XID(内部 XA 事务的 ID) 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘； commit 阶段","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:11","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"十、内存 基础 问：为啥要有 Buffer Pool？ MySQL 的数据存储在磁盘中，若每次操作都直接操作磁盘，效率就会很低。 因此，加一层缓存，将读出的数据页缓存到内存中，下次用到的话直接访问内存即可。Innodb 通过**缓冲池(Buffer Pool)**机制实现： 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取； 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。 问：Buffer Pool 缓存了什么？ Innodb 按页存储数据，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。 InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页，Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 Buffer Pool 除了缓存**「索引页」和「数据页」**，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。 问：查询一条数据，只需要缓存一条数据吗？ No！查询记录时，通过索引找到磁盘上的页，然后会把整页加载，并存入 Buffer Pool。 一方面是因为，索引只能定位到页；另一方面，若每次IO读入了整页，却只保留一条数据，也挺浪费的。。 管理 问：如何管理空闲页？ 因为有的页面被使用，有的页面没被使用，总不能每次要找到个空闲页就遍历一遍吧？ 解决方案类似Go的内存管理。 通过一个带头双向链表 Free，将空闲缓存页的控制块存起来： Free 链表的头节点：包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息； Free 链表的节点：一个个控制块。 问：如何管理脏页？ 类似 Free 链表，设计了 Flush 链表存储脏页，后台线程可以遍历 Flush 链表，将脏页写入到磁盘。 问：缓存更新策略？ 类似 LRU。 问：脏页什么时候会被刷盘？⭐⭐ InnoDB 的更新操作采用的是 WAL(Write Ahead Log) 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。 下面几种情况会触发脏页的刷新： 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘； Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘； MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘； MySQL 正常关闭之前，会把所有的脏页刷入到磁盘。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:12","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"十一、集群架构 主从复制 问：为什么要集群？ 数据备份； 故障转移； 读写分离，减轻主库读写压力。 问：主从复制是如何实现的？ MySQL 的主从复制依赖于 bin log，复制过程： 写入 bin log：主库在事务提交时，会把**数据变更(增删改)**记录在 bin log 中； 同步 bin log：从库创建 I/O 线程，请求获取主库 bin log； 发送 bin log：主库创建一个 log dump 线程，将 bin log 发送给从库； 重放 bin log：从库将获取的 bin log 写入从库的中继日志(relay log)，同时创建线程，读取并重放 relay log，更新从库中的数据。 问：从库是越多越好吗？ 当然不是。 因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽。 所以在实际使用中，1 个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。 问：主从复制有哪些模型？/如何保持主从间的数据一致性？ 同步复制：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。实际没法用； **异步复制(默认)：**主库不用等 bin log 同步到从库就返回结果。缺点就是，主库宕机可能会丢失部分数据； **半同步复制：**主库等 bin log 复制到一部分从库再返回结果。兼顾上述方案，就算主库宕机了，也不会丢失数据。 分库分表 问：为什么要分库？为什么要分表？ 为什么要分库？ 如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。从这两方面来看： 磁盘存储 业务量剧增，MySQL单机磁盘容量会撑爆，因此可以拆成多个数据库； 并发连接支撑 数据库连接数是有限的。在高并发的场景下，大量请求访问数据库，MySQL单机是扛不住的！高并发场景下，会出现too many connections报错。 为什么要分表？ 假如你的单表数据量非常大，存储和查询的性能就会遇到瓶颈了(由于B+树)，如果你做了很多优化之后还是无法提升效率的时候，就需要考虑做分表了。一般千万级别数据量，就需要分表。 问：什么时候就要进行分库分表了？ 对于MySQL，InnoDB存储引擎的话，单表最多可以存储10亿级数据。 但是的话，如果真的存储这么多，性能就会非常差。一般数据量千万级别，B+树索引高度就会到3层以上了，查询的时候会多查磁盘的次数，SQL就会变慢。 阿里巴巴的《Java开发手册》提出： 单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表。 那我们是不是等到数据量到达五百万，才开始分库分表呢？ 不是这样的，我们应该提前规划分库分表，如果估算3年后，你的表都不会到达这个五百万，则不需要分库分表。 MySQL服务器如果配置更好，是不是可以超过这个500万这个量级，才考虑分库分表？ 虽然配置更好，可能数据量大之后，性能还是不错，但是如果持续发展的话，还是要考虑分库分表 一般什么类型业务表需要才分库分表？ 通用是一些流水表、用户表等才考虑分库分表，如果是一些配置类的表，则完全不用考虑，因为不太可能到达这个量级。 问：有哪些分库、分表方式？ 垂直分库：以表为依据，根据业务，将不同的表拆分到不同的库中。 每个库的表结构都不一样； 每个库的数据也不一样； 所有库的并集是全量数据。 垂直分表：以字段为依据，根据字段属性，将不同字段拆分到不同表中。 每个表的结构都不一样； 每个表的数据也不一样，一般通过一列(主键/外键)关联； 所有表的并集是全量数据。 水平分库⭐：以字段为依据，按照一定策略，将一个库的数据拆分到多个库中。 每个库的表结构都一样； 每个库的数据都不一样； 所有库的并集是全量数据。 水平分表⭐：以字段为依据，按照一定策略，将一个表的数据拆分到多个表中。 每个表的表结构都一样； 每个表的数据都不一样； 所有表的并集是全量数据。 总结： 垂直拆分的关注点在于 业务相关性； 水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在 数据的特点。 问：水平分片的规则有哪些？ 范围分片：划分多个范围区间，落在相应区间的数据存入相应的库或表； 取模分片：指定的字段值 % 节点数量，落到哪个节点就存到哪个； 一致性hash：增加节点或删除节点时，取模分片会导致大量数据迁移；一致性hash中，只会影响一小部分数据的迁移。 读写分离 就是，只有主节点负责写请求，其他节点负责读请求，可以降低单台服务器的压力。 一主一从：一主负责写，一从负责读； 双主双从：一主负责写，一主两从负责读。并且，每组主从间互为主备，一组挂了，另一组就会顶上，实现高可用。 分布式 ID 当分库分表之后，同一个逻辑表的数据被分布到多个库中，这时如果使用数据库自增字段作为主键，那么只能保证在这个库中是唯一的，无法保证全局的唯一性。那么假如设计用户系统的时候，使用自增 ID 作为用户 ID，就可能出现两个用户有两个相同的 ID，这是不可接受的，那么就需要生成全局唯一的 ID。 UUID 不建议使用 UUID 作为数据库主键，因为： ID 有序更利于索引数据的插入，而 UUID 是无序的，造成了多余的数据移动的开销； UUID 不具备业务含义； UUID 是由 32 个 16 进制数字组成的字符串(128位)，如果作为数据库主键使用比较耗费空间。 ==雪花算法(Snowflake)== Snowflake 的核心思想是将 64 位的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。可以自定义各字段代表的含义和位数。 原理知道了，那工程上是怎么实现呢？ 一种是嵌入到业务代码里，也就是分布在业务服务器中。 一种是作为独立的服务部署，这也就是我们常说的发号器服务。 Snowflake 算法设计的非常简单且巧妙，性能上也足够高效，同时也能够生成具有全局唯一性、单调递增性和有业务含义的 ID，但是它也有一些缺点： 其中最大的缺点就是它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止； 另外，如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。 这一点，也是我在实际项目中踩过的坑，而解决办法主要有两个： 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均； 生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量的均衡了。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:13","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"十二、面试题 问：执行一条MySQL语句，非常慢，可能的原因？ 分两种情况： 大多数情况正常，偶尔很慢 数据库在刷盘，例如将 redo log、buffer 刷新到磁盘。因为采用了 WAL 技术：也就是更新数据时先写入 redo log，等空闲时再将 redo log 写入磁盘。刷脏页有以下场景： redo log 写满了，需要刷盘； buffer 不够了，需要淘汰一些页，而如果要淘汰的页刚好是脏页，就会刷盘； 空闲时； 遇到锁，拿不到锁，得阻塞等待。可以用 show processlist 这个命令来查看当前的状态。 一直执行得很慢 没用上索引，导致全表查询，还得回表，就很慢； 表中数据太多了，索引层数过高，建议分表； 分析慢查询日志； 数据库走错索引了，此时可以强制数据库走某个索引。 问：通过 select from limit 查询数据时，查询 0-10 和 990-1000 的效率一样吗？ limit 查询方式对应 limit offset, size，即从 offset 处开始查找 size 条数据。例如，当执行以下两条语句时： select * from page order by id limit 0, 10; select * from page order by id limit 6000000, 10; 第一条会获取到第0到10条完整行数据； 第二条则要先获得第0到(6000000 + 10)条完整行数据，返回给server层之后根据offset的值挨个抛弃，最后只留下最后面的size条，也就是10条数据。 由于获取到很多无用的数据，效率是不一样的。 如何优化呢？ 优化查询语句 优化查询语句：当select后面是*号时，需要拷贝完整的行信息，拷贝完整数据跟只拷贝行数据里的其中一两个列字段耗时是不同的，所以可以优化查询语句为： select * from page where id \u003e=(select id from page order by id limit 6000000, 1) order by id limit 10; 但这种方法也只是缓解，当 Offset 增长到百万千万级别，就也不太行了，这就涉及到了深度分页问题。 深度分页 这需要从背后的需求出发，不同的需求有不同的解决方案。 取出全表数据 select * from page; 因为数据量较大，mysql根本没办法一次性获取到全部数据，肯定超时报错。 解决方法：可以将所有的数据根据id主键进行排序，然后分批次取，将当前批次的最大 id 作为下次筛选的条件进行查询。如下伪代码： 这个操作，可以通过主键索引，每次定位到id在哪，然后往后遍历100个数据，这样不管是多少万的数据，查询性能都很稳定。 做分页展示 啥样的分页展示能到百万千万展示量啊？想想谷歌才提供多少页？去跟产品经理battle吧还是。。 问：执行一条MySQL语句，过程？ 连接器：建立连接，管理连接、校验用户身份； 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块； 解析 SQL：通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型； 执行 SQL：执行 SQL 共有三个阶段： 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。 优化阶段：基于查询成本的考虑，选择查询成本最小的执行计划(选择索引等)； 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端。 ","date":"0001-01-01","objectID":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/:0:14","tags":null,"title":"","uri":"/06-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/07-redis/:0:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"常见面试题 记录一下常见的面试题，用于自测~~ 🚩：代表被问过 Redis 数据类型和结构（必问⭐⭐） Redis常见的数据类型，使用场景？G 各数据类型的底层数据结构是什么？G 各数据结构的底层实现，做了哪些优化？🚩G Zset底层用的跳表，为啥跳表这么快？G 为什么用跳表，而不用平衡树？G Redis 架构（必问⭐⭐⭐） Redis 为啥这么快？🚩🚩G Redis 是单线程还是多线程？哪部分是单线程？哪部分是多线程？G Redis 的线程模型？G Redis 为啥选择单线程呢？G Redis 集群（必问⭐⭐⭐） Redis 是怎么实现高可用的？G 多个节点间的一致性是咋实现的？主从复制是怎么实现的？🚩G 主节点如何判断一个从节点是不是第一次来同步数据？G 全量同步和增量同步的区别？什么时候执行全量同步？什么时候执行增量同步？G 哨兵模式是怎么实现的？🚩G 分片集群是怎么实现的？G Redis 持久化（⭐⭐） Redis 如何实现数据持久化存储？🚩G 持久化机制、持久化方式是什么，各有什么优缺点？G 混合持久化是什么？G AOF 日志重写机制？G 后台重写？G 写时复制是什么？有啥用？G RDB 创建快照时会阻塞主进程吗？若不会阻塞，那数据能被修改吗？G BigKey 有啥影响？G Redis 缓存（⭐⭐） 缓存穿透及解决方案？G 布隆过滤器原理？G 缓存击穿及解决方案？G 缓存雪崩及解决方案？G 如何保证缓存与数据库的一致性？🚩G Redis 内存淘汰策略有哪些？G Redis 怎么判断一个键值对是否过期？G 对于过期 Key 的策略？G LRU 和 LFU 有啥区别？Redis 是咋实现的？G ","date":"0001-01-01","objectID":"/07-redis/:1:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"一、Redis 概念 问：什么是 Redis？有啥用？/为什么要用缓存？ Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。 **高性能：**若从数据库读取数据，就是从磁盘读取，速度很慢；而从缓存中读取数据是从内存读取的。若把需要频繁读取的数据放入缓存，那么效率就会大大提高； **高并发：**直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以会提高系统整体的并发。 问：Redis 为啥快？ Redis 基于内存，内存的访问速度是磁盘的上千倍； Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用； Redis 内置了多种优化过后的数据结构实现，性能非常高。 问：Redis 和 Memcached 的区别？ 共同点： 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。 区别： Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。 Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。 **Redis 有灾难恢复机制。**因为可以把缓存中的数据持久化到磁盘上。 Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。 Redis 使用单线程的多路 IO 复用模型；Memcached 是多线程，非阻塞 IO 复用的网络模型。 Redis 支持发布-订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。 Redis 同时使用了惰性删除与定期删除；Memcached 过期数据的删除策略只用了惰性删除。 ","date":"0001-01-01","objectID":"/07-redis/:2:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"二、Redis 数据结构 数据类型 问：Redis 常用的数据类型有哪些？使用场景？ 5 种基础数据类型：String(字符串)、List(列表，类似双向链表)、Set(集合)、Hash(散列)、Zset(有序集合)。 3 种特殊数据类型：HyperLogLogs(基数统计)、Bitmap(位存储)、Geospatial(地理位置)。 String 类型的应用场景：缓存session、token、常规计数、分布式锁、共享 session 信息等。 List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。 Hash 类型：缓存对象、购物车等。 Set 类型：聚合计算场景，比如点赞、共同关注(交集)、抽奖活动(去重)等。 Zset 类型：排序场景，比如排行榜、电话和姓名排序等。 问：String 还是 Hash 存储对象数据更好？ 依据使用场景： String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。比如购物车。 String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。 问：常见的数据类型是怎么实现的？ Redis 基本数据类型的底层数据结构实现如下： String List Hash Set Zset SDS LinkedList/ZipList/QuickList Hash Table、ZipList ZipList、Intset ZipList、SkipList 数据结构 SDS⭐ 问：SDS 的底层实现？⭐ Redis没有直接用C中的char*实现字符串，主要是因为char*有如下缺陷： 获取字符串长度的时间复杂度为 O(N)； 字符串的结尾是以 \\0 字符标识，字符串里面不能包含有 \\0 字符，因此不能保存二进制数据； 字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止； 而Redis中，String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）(类似Go的)： SDS 获取字符串长度的时间复杂度是 O(1)，因为 SDS 使用 len 属性的值 而不是\\0字符来判断字符串是否结束； SDS 不仅可以保存文本数据，还可以保存二进制数据； 当判断出缓冲区大小不够用时，SDS 支持动态扩容，避免缓冲区溢出。扩容规则： 如果新的 sds 长度(newlen) 小于 1 MB，那么最后的扩容是按照翻倍扩容来执行的，即 2 * newlen + 1；(+1 是因为结束标识符\\0) 如果新的 sds 长度(newlen) 超过 1 MB，那么最后的扩容长度应该是 newlen + 1MB + 1。 分配多余的空间，可以有效的减少内存分配次数。 这是SDS的数据结构，是不是贼像Go的： len，记录了字符串长度。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O(1)。 alloc，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。 flags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，代表了SDS的最大长度，比如2^8^-1、2^16^-1。 buf[]，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。 String 类型的应用场景：缓存session、token、常规计数、分布式锁、共享 session 信息等。 intset 问：整数集合(intset) 的底层实现？ 整数集合本质上是一块连续内存空间： typedef struct intset { //编码方式：int16_t、int32_t、int64_t uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[]; } intset; 其中，contents[] 的真正类型取决于 encoding 属性的值。 插入元素会按序排列，且占用空间相同，方便用下标寻址。 ==升级机制：== 主要针对：插入新元素时，若新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级。也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里。 例，向set[1, 2, 3]插入65535： 好处就是节省内存。 只有升级操作，没有降级操作。 哈希表⭐ 问：哈希表(dict) 的底层实现？ 哈希表的实现方式之一就是 dict (元素数量 \u003e 500时)。可以以 O(1) 的复杂度快速查询数据。 typedef struct dictht { //哈希表数组，桶数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 unsigned long sizemask; //该哈希表已有的节点数量 unsigned long used; } dictht; 哈希表比较熟悉(因为跟Go的好像hhh)，这里只记几个关键词： 与运算； 拉链法； 渐进式扩容； 负载因子： 当负载因子 \u003e= 1 ，并且Redis没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作； 当负载因子 \u003e 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。 当负载因子 \u003c 0.1 时，会做哈希表收缩。 将首个 2^n^ \u003e 新的所需容量，作为扩容/收缩后的容量。 list 问：list 的底层实现？ list的底层实现方式之一就是用List。 其实就是个双向链表。 // 链表 typedef struct list { //链表头节点 listNode *head; //链表尾节点 listNode *tail; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值比较函数 int (*match)(void *ptr, void *key); //链表节点数量 unsigned long len; } list; // 链表节点 typedef struct listNode { //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value; } listNode; 一个3节点链表的示意图： 优点： 获取链表的表头节点和表尾节点的时间复杂度只需O(1)； 获取链表中的节点数量的时间复杂度只需O(1)； 获取某个节点的前置节点或后置节点的时间复杂度只需O(1)。 缺点： 保存一个链表节点的值都需要一个链表节点结构头的分配，内存开销较大。 ziplist⭐ 问：压缩列表(ziplist) 的底层实现？ Redis 对象(List 对象、Hash 对象、Zset 对象)包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。 压缩列表是由连续内存组成的顺序型数据结构，类似数组。 压缩列表表头： zlbytes，记录整个压缩列表占用字节数； zltail，记录压缩列表「尾部」节点距离起始地址有多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。 ==节点 entry==： ==prevlen==，记录了「前一个节点」的长度，目的是为了实现从后向前遍历。(当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，导致连续更新)； encoding，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。 data，记录了当前节点的实际数据，类型和长度都由 encoding 决定； 优点： 压缩列表插入数据时，会根据数据大小和类型进行不同的空间大小分配，节省内存； 缺点： 不能保存过多的元素，否则查询效率就会降低； 新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发**==连锁更新==**的问题。 因此，压缩列表只会用于保存的节点数量不多的场景。 ==连锁更新：== 问题根源是，新插入元素时，后一元素的prevlen占用空间可能会变大，导致自身占用空间变大，然后可能导致后续元素的 prevlen 占用空间都发生变化，发生连锁更新。 quicklist 问：quicklist 的底层实现？ List 的底层对象就是 quicklist。 其实 quick","date":"0001-01-01","objectID":"/07-redis/:3:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"三、Redis 线程模型 问：Redis 到底是单线程还是多线程？ 核心业务部分由单个线程(主线程)来完成：「接收客户端请求-\u003e解析请求 -\u003e进行数据读写等操作-\u003e发送数据给客户端」 但整个 Redis 是多线程的是会启动后台线程(BIO)的： 关闭文件； AOF 刷盘； 释放内存。 一共三个后台线程，用于处理这些比较耗时的任务。 后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。 问：Redis 的单线程模型是什么样的？⭐ 首先创建一个epoll对象，然后创建一个server socket并开始监听它的 FD，初始化完后，主线程就进入到一个监听事件循环函数，主要会做以下事情： 首先，先调用处理发送队列函数，检查发送队列里是否有任务，如果有发送任务，就会注册写事件(到这里就形成闭环了：连接-\u003e读-\u003e写-\u003e返回)，等待 epoll_wait 处理。 接着，才会调用 epoll_wait 函数等待事件就绪： 如果是连接事件到来，则会调用连接事件处理函数，该函数会做这些事情：调用 accpet 获取已连接的 socket -\u003e 调用 epoll_ctl 将已连接的 socket 加入到 epoll -\u003e 注册**「读事件」**处理函数； 如果是读事件就绪，则会调用读事件处理函数，该函数会做这些事情：调用 read 获取客户端发送的数据并写到客户端对象的接收缓冲区 -\u003e 解析命令 -\u003e 处理命令 -\u003e 将执行结果写到客户端对象的发送缓存区等待发送 -\u003e 将客户端对象添加到发送队列； 如果是写事件就绪，则会调用写事件处理函数，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理。 多线程的部分主要是在 网络I/O 部分： 读事件到来，要读取请求数据，可以在这里开启多线程； 写事件，要把数据写到网络，在这里可以开启多线程。 其余执行操作时，均为单线程。 可以看到 socket对象的发送缓冲区和接收缓冲区： 当 socket 状态处于 Established时： Recv-Q 表示 socket 缓冲区中还没有被应用程序读取的字节数； Send-Q 表示 socket 缓冲区中还没有被远端主机确认的字节数； 而当 socket 状态处于 Listen 时： Recv-Q 表示全连接队列的长度； Send-Q 表示全连接队列的最大长度； 黑马Redis的视频：P171 原理篇-27 问：为啥 Redis 的单线程还这么快？ 大部分操作在内存中完成，并且采用高效的数据结构； 单线程可以避免多线程切换的开销； 采用了I/O多路复用处理客户端请求。 注：I/O 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。 问：Redis 6.0 之前为啥单线程，6.0 之后为啥多线程？⭐ ==为啥要选择单线程？== Redis 是在内存操作(最主要原因⭐)，执行速度非常快，它的性能瓶颈是 网络I/O，而不是执行速度，因此多线程并不会带来巨大的性能提升； 引入多线程的话，会面临线程安全问题，增加了系统复杂性，同时可能引发线程切换、加锁解锁等带来的性能损耗。 ==为啥又选择多线程？== 6.0 之后采用多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。所以为了提高网络 I/O 的并行度，Redis 6.0 **==仅对于网络 I/O 采用多线程==**来处理。但是对于命令的执行，Redis 仍然使用单线程来处理。 ","date":"0001-01-01","objectID":"/07-redis/:4:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"四、Redis 持久化 问：Redis 如何实现数据不丢失？ 为了保证内存中的数据不丢失，Redis 实现了数据持久化的机制，会把数据存储到磁盘。 共有三种数据持久化的方式： AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点。 问：什么是 AOF 日志？ Redis 在执行完一条写操作命令后，会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。 问：AOF 中，为什么先执行写操作命令，再写入日志？ **避免额外的检查开销：**先执行可以检查命令是否正确，要是先写入日志又发现命令有错误，就不好办了。 不会阻塞当前写操作。 也会带来风险： **数据丢失：**刚执行完，还没来得及写入日志，Redis 就寄了。 **可能阻塞后一个指令：**AOF 操作也是由主线程完成，所以有可能会阻塞下一个操作无法执行。 问：AOF 写回策略有哪几种？ 由主进程执行写入，写入 AOF 日志的过程： 3 种写回策略的优缺点： 问：AOF 日志过大，会触发什么机制？ AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。 所以，Redis 为了避免 AOF 文件越写越大，提供了 ==AOF 重写机制==。当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。 问：AOF 重写机制的过程？ 当 AOF 变得太大时，Redis 能够在后台自动重写 AOF 产生一个新的 AOF 文件(相当于压缩版 AOF)，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。 在 AOF 重写期间，Redis 服务器会维护一个 AOF 重写缓冲区，并创建一个子进程执行重写操作； 子进程会将生成的新 AOF 文件保存在一个临时文件中，同时主进程会继续将新的写命令追加到旧的 AOF 文件和一个重写缓冲区中(此处为什么还要追加到旧的 AOF？是因为怕宕机导致丢失数据，如果不追加到旧的 AOF，可能会发生宕机导致重写缓冲区没了，然后这部分写操作也没加到旧的 AOF，就造成丢失了。)； 当子进程完成重写操作后，它会向主进程发送一个信号，主进程会将重写缓冲区的内容追加到新 AOF 文件中，然后用新 AOF 文件替换旧 AOF 文件。 也就是说，主进程主要完成三个工作： 执行客户端发来的命令； 将执行后的写命令追加到「AOF 缓冲区」； 将执行后的写命令追加到「AOF 重写缓冲区」。 注意： 重写操作：扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志。 **为啥能减少命令数目呢？**就比如： 问：AOF 后台重写？ 普通的写入 AOF 日志的操作是在主进程完成的，因为它写入的内容不多，所以一般不太影响命令的操作。但 AOF 重写时，一般 AOF 文件都很大，所以不应该放到主进程里完成。 Redis 的重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的，优点：子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程。 思考：为什么是子进程而不是子线程？ 因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生**「写时复制」**，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。 问：写时复制是什么？有啥用？ 在子进程执行 AOF 重写 或 执行 RDB 的过程中，如果主进程又修改了数据，会导致数据不一致，这怎么办？ 实际上，当主进程修改了数据，就会发生写时复制，子进程就会拥有原始未更改的数据副本了。 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存。也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。这样可以共享物理内存资源，节省内存。同时，页表对应的页表项的属性会标记该物理内存的权限为只读。 当父进程或者子进程在修改共享内存中的某条数据时，CPU 就会触发写保护中断，执行写时复制。也就是说，在发生写操作时，操作系统才去复制物理内存。这个过程还会阻塞主进程。之后，主进程就可以对数据副本进行操作，子进程就可以对原数据进行 AOF 重写。 综上，共有两处阻塞主进程的地方： 创建子进程时，需要复制页表等，会阻塞主进程； 发生写时复制时，需要复制数据副本，会阻塞主进程。 问：什么是 RDB 快照？ RDB 是 Redis 默认采用的持久化方式，它会将某一时刻的内存数据以文件的形式保存到磁盘中，记录的是实际的数据。 作用： 可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能）; 还可以将快照留在原地以便重启服务器的时候使用。 Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。显然，这是一个比较重的操作。 问：RDB 创建快照时会阻塞主进程吗？若不会阻塞，那数据能被修改吗？ 提供两种方式： save : 主进程执行，会阻塞主进程； bgsave : 子进程执行，不会阻塞主进程，默认选项 若通过bgsave的方式，执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的。 主要是通过 写时复制 来实现的。详细见 AOF 。 问：如何选择 RDB 还是 AOF？ RDB 更好的地方： RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。 AOF 更好的地方： AOF 可以近实时的持久化数据，保证数据不丢失； AOF 记录了所有的命令操作，可以用于审计和故障排查，安全性更好。 综合来说： 如果需要高性能和快速恢复，并且可以容忍一定程度的数据丢失，可以选择 RDB； 如果需要高可靠性和完整性，并且可以容忍一定程度的性能损耗和恢复延迟，可以选择 AOF； 如果需要同时满足两者的需求，并且有足够的磁盘空间和内存资源，可以选择混合持久化（RDB + AOF）。 问：AOF 会丢失数据吗？ 如果命令执行成功，写入日志的时候宕机了，命令没有写入到日志中，这时候就有丢失数据的风险了。 如果 AOF 文件损坏了，可能会导致数据恢复失败或者部分丢失。 问：为啥要混合持久化？ RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。 AOF 优点是丢失数据少，但是数据恢复不快。 Redis 4.0 提出了混合使用 AOF 日志和 RDB 内存快照，也叫混合持久化。既保证了 Redis 重启速度，又降低数据丢失风险。 ==什么是混合持久化：== 混合持久化工作在 AOF 日志重写过程，重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程用新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的 AOF 文件。 混合持久化的原理是，在 AOF 重写的过程中，把 RDB 格式的全量数据写到 AOF 文件的开头，然后再追加 AOF 格式的增量数据。这样，当 Redis 启动时，只需要加载一个文件就可以恢复所有数据，而不需要先加载 RDB 文件再加载 AOF 文件。也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。 ==混合持久化优点：== 开头为 RDB 的格式，使得 Redis 可以更快的启动； 同时结合 AOF 的优点，有减低数据丢失的风险。 ==混合持久化缺点：== AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差； 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。 ","date":"0001-01-01","objectID":"/07-redis/:5:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"五、Redis 事务 问：如何使用事务？ Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务(transaction)功能。 MULTI 命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 EXEC 命令后，再执行所有的命令。 通过 DISCARD 命令取消一个事务，它会清空事务队列中保存的所有命令。 通过 WATCH 命令监听指定的 Key，当调用 EXEC 命令执行事务时，如果一个被 WATCH 命令监视的 Key 被 其他客户端/Session 修改的话，整个事务都不会被执行。 问：Redis 支持原子性吗？ Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）。 **原因：**Redis 开发者们觉得没必要支持回滚，命令执行错误应该在开发过程中就被发现而不是生产过程中。 可以将 Redis 中的事务就理解为：Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。 实际中，不建议使用 Redis 的事务。 ","date":"0001-01-01","objectID":"/07-redis/:6:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"六、Redis 性能优化 ","date":"0001-01-01","objectID":"/07-redis/:7:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"6.1 键值设计 Key 的最佳实践： 固定格式：[业务名]:[数据名]:[id] 足够简短，不超过44字节； 不包含特殊字符。 Value的最佳实践： 合理拆分数据，拒绝bigkey； 选择合适的数据结构； Hash 结构的 entry 数量不超过 1000； 设置合理的超时时间。 ","date":"0001-01-01","objectID":"/07-redis/:7:1","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"6.2 bigkey 6.2.1 bigkey 发现与删除 问：什么是 bigkey？ 简单来说，如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。 一般有以下两种情况： String 类型的值大于 10 KB； Hash、List、Set、ZSet 类型的元素的个数超过 5000 个； 问：bigkey 会造成什么影响？ 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时(慢查询)，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应； 引发网络阻塞。每次获取大 key 产生的网络流量较大； 持久化时，若对 bigkey 进行修改，会触发写时复制，由于是 bigkey，可能会阻塞主进程较长的时间； 内存分布不均。有大 key 的 Redis 节点占用内存多，出现数据和查询倾斜情况。 问：如何发现 bigkey？ redis-cli --bigkeys 使用 Redis 自带的 --bigkeys 参数来查找，可以遍历分析所有的 key，并返回 key 的整体统计信息与每个数据的 Top1 的 bigkey。 分析 RDB 文件 网上有现成的代码/工具RDB-Tools，可以进行离线的分析 RDB 文件。 网络监控 自定义工具，监控进出 Redis 的网络数据，超出预警值时主动告警。 问：如何删除 bigkey？ bigkey 内存占用较多，导致即使是删除 bigkey，也贼慢。。 unlink -keyname。redis 4.0 后提供的异步删除方式。 若是集合类型，可以遍历bigkey的元素，先逐个删除子元素，再删除该 bigkey。 6.2.2 bigkey 避免 问：假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？ 方案一 方案二 每个 key 存储的时候，还会存储它的元信息，应尽量减少 key 的数量。 方案三⭐ ","date":"0001-01-01","objectID":"/07-redis/:7:2","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"6.3 批处理优化 6.3.1 什么是批处理 普通执行 N 条命令：将 N 条命令依次发送和执行。 $$ N 次命令的响应时间 = N 次往返的网络传输耗时 + N 次Redis执行命令耗时 $$ 其中，命令耗时 是非常短的也就是大部分时间都浪费在了 网络传输。 批量执行：将 N 条命令批量发送和执行。 $$ N 次命令的响应时间 = 1 次往返的网络传输耗时 + N 次Redis执行命令耗时 $$ 那么如何实现上述的批量操作呢？ 6.3.2 批处理方案 6.3.2.1 Mset Redis 提供了很多 Mxxx 这样的命令，可以实现批量插入数据，例如： mset hmset 但 mset 只能操作 string 类型，因此具有局限性。 6.3.2.2 Pipeline⭐ mset 虽然能批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用 Pipeline。 注意事项： 批处理时要避免一次性发送过多命令，导致管道内的命令太多，进而发生网络阻塞； Pipeline 的多个命令之间不具备原子性，而 mset 具备原子性。即 Pipeline 多个命令间可能有别的命令插队。 6.3.2.3 并行slot 集群中，批处理操作通常不会成功，因为不同的 key-val 分布在不同的 slot 中。这时，可以采用并行 slot 操作(spring 已经实现了)。 实现思路：在客户端计算每个 key 的 slot，将 slot 一致的分成一组，每组都利用 Pipeline 批处理，并行执行各组命令。 $$ N 次命令的响应时间 = 1 次往返的网络传输耗时 + N 次Redis执行命令耗时 $$ ","date":"0001-01-01","objectID":"/07-redis/:7:3","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"6.4 服务端优化 6.4.1 慢查询 慢查询：在 Redis 执行时耗时超过某个阈值的命令，称为慢查询。 通常，bigkey 会导致慢查询，可以通过慢查询日志发现哪些命令触发了慢查询，进而优化。 通常，慢查询的原因主要有： 使用复杂度过高的命令 bigkey问题 集中过期 6.4.2 内存配置 当 Redis 内存不足时，可能导致 Key 频繁被删除、响应时间变长、QPS 不稳定等问题。当内存使用率达到 90% 以上时就需要警惕，并快速定位到内存占用的原因。 ","date":"0001-01-01","objectID":"/07-redis/:7:4","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"6.5 集群优化 6.5.1 可用性 在 Redis 的默认配置中，如果发现任意一个 slot 不可用，则整个集群都会停止对外服务。 为了保证高可用性，可以将 cluster-require-full-coverage = false。这样，只有 down 的 slot 不可用。 6.5.2 集群带宽问题 集群节点间会不断的互相 ping 来确定集群中其他节点状态。每次 ping 携带的信息至少包括： slot 信息； 集群状态信息。 集群中节点越多，集群状态信息量也越大，此时每次集群互通所需带宽就会非常高。 解决途径： 避免大集群，集群节点数不要太多，最好 \u003c 1000，如果业务庞大，则建立多个集群； 避免在单个物理机上运行太多 Redis 实例； 配置合适的 cluster-node-timeout 值。 ","date":"0001-01-01","objectID":"/07-redis/:7:5","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"七、Redis 缓存设计 7.1 缓存穿透 Cache Penetration 问：什么是缓存穿透？ 简单来说就是，大量请求的 key 是不合理的，根本不存在于缓存中，也不存在于数据库中。导致这些请求直接砸到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 问：有哪些解决方法？ 缓存无效 key。就是把缓存找不到的、数据库也查不到的 key，写入到缓存中，并设置过期时间。但无法根本上解决，缓存一堆没用的数据照样能给你干宕机。 布隆过滤器。可以帮助快速判断一个给定数据是否存在于海量数据中。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走之后的流程(缓存、数据库)。 问：布隆过滤器原理？缺陷及解决？ 元素加入布隆过滤器的过程： 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在多个位数组中把对应下标的值置为 1。 判断一个元素是否存在于布隆过滤器的过程： 对给定元素再次进行相同的哈希计算； 得到值之后判断位数组中对应下标元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 布隆过滤器的缺点： 还是有几率缓存穿透，布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。解决方法：可以增多哈希函数，计算出多个哈希值，只有所有哈希值对应的数组中的值都为 1 时，才会认为这个元素在集合中。 不支持删除元素，这也和哈希冲突有关。解决方法：让数组中不再只有 0 和 1 两个值，而是存储一个计数。比如如果 A 和 B 同时命中了一个数组的索引，那么这个位置的值就是 2，如果 A 被删除了就把这个值从 2 改为 1。但这会增加空间的消耗。所以，要依据业务场景来选择使用布隆过滤器。 7.2 缓存击穿 Hotspot Invalid 问：什么是缓存击穿？ 缓存击穿中，请求的 key 对应的是热点数据，该数据存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。 **比如：**秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。 问：有啥解决方法？ 设置热点数据永不过期或者过期时间比较长。 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 分布式锁。控制在某一个热点缓存项失效之后启动一个后台线程获得锁，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都阻塞或直接返回； 逻辑过期，当发现数据过期，并且尝试获取互斥锁失败时，会返回旧数据，因为此时已经有其他线程去更新数据了。这主要保证数据可用性。 问：缓存穿透和缓存击穿的区别？ 缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。 缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。 7.3 缓存雪崩 问：什么是缓存雪崩？ 缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。 **比如：**数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。 问：有啥解决方法？ ==针对 Redis 宕机的情况：== 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 服务降级限流 因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动服务降级限流机制，暂停业务应用对缓存服务的访问，返回默认值或友好提示，不用再继续访问数据库，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。 服务降级限流机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作。 请求限流 为了减少对业务的影响，我们可以启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。 ==大量数据同时过期的情况：== **均匀(随机)**设置过期时间； 互斥锁。如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存。 问：缓存雪崩和缓存击穿有啥区别？ 缓存雪崩是缓存中的大量或所有数据失效； 缓存击穿是某个热点数据不存在与缓存中（通常是因为缓存中的那份数据已经过期）。 7.4 缓存一致性⭐ 缓存一致性的核心问题是：在更新数据库数据时，如何保证缓存数据也同步更新或失效，避免读取到过期或错误的数据。 常见的缓存更新策略有以下几种： Cache Aside⭐：旁路缓存策略； Read/Write Through：读穿/写穿策略； Write Back：写回策略。 以上策略都不能完全保证强一致性（即任何时刻都能读取到最新的数据），只能保证最终一致性（即经过一段时间后能够达到一致状态）。要实现强一致性，则需要牺牲系统的可用性或分区容忍性（根据CAP理论）。 这里主要介绍了旁路缓存策略，有空再看其他两种策略。 问：如何保证缓存与数据库的一致性？⭐⭐ 实际开发中，Redis 和 MySQL 的更新策略用的是旁路缓存策略(Cache Aside)。策略可以细分为「读策略」和「写策略」。 写策略： 采用先更新数据库再删除缓存⭐，主要是为了解决线程安全问题； 确保数据库与缓存操作的原子性。单体系统天生就能原子性，分布式系统的话就用分布式事务。 读策略： 缓存命中则直接返回； 缓存未命中则查询数据库，并写入缓存，设定超时时间(相当于兜底方案，避免写方案更新缓存失效)。 问：写策略中，能否先删除缓存，后更新数据库呢？⭐ 不能滴~~ 先删除缓存再更新数据库：这种方式可以保证不会读取到过期的缓存数据，但是存在并发问题。如果在删除缓存后、更新数据库前，有其他线程读取了该数据，并将旧数据写入了缓存，那么就会导致缓存和数据库不一致。 先更新数据库再删除缓存⭐：这种方式其实理论上也有问题： 存在延迟问题(会读到旧数据)。如果在更新数据库后、删除缓存前，有其他线程读取了该数据，就会读取到过期的旧数据； 理论上也可能出现缓存和数据库的不一致，不过出现的机率远小于第一种。原因是缓存的写入通常远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据，所以不会出现这种不一致的情况。 简单总结，足以适应绝大部分的互联网开发场景的决策： 针对大部分读多写少场景，建议选择更新数据库后删除缓存的策略。 针对读写相当或者写多读少的场景，建议选择更新数据库后更新缓存的策略。 问：Cache Aside 有啥问题吗？ Cache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案： 一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响； 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受。 参考文章： 万字图文讲透数据库缓存一致性问题 7.5 过期、淘汰 问：Redis 怎么判断一个键值对是否过期？ 可以通过expire设置过期时间ttl。利用两个 Dict 分别记录key-value和key-ttl。 typedef struct redisDb { dict *dict; /* 数据库键空间，存放着所有的键值对 */ dict *expires; /* 键的过期时间 */ .... } redisDb; 问：Redis 对于过期 Key 的策略？ 对于过期 key，Redis 采用的是 定期删除+惰性删除 策略。 惰性删除：在访问一个key时，先检查它是否过期，如果过期就删除它。 优点：在访问时才会检查，只会使用很少的系统资源，对 CPU 友好； 缺点：若 key 过期，之后一直没被访问到，就会一直占用内存。 定期删除：周期性的取出部分 key 进行检查，然后删除其中过期的。 优点：通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能规避惰性删除的问题； 缺点：执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。 问：大量 key 集中过期的情况怎么办？ 常采用以下两种解决方法： 给 key 设置随机过期时间； 开启惰性删除，让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 问：Redis 都有啥内存淘汰策略？ Redis 内存淘汰策略共有 8 种，这 8","date":"0001-01-01","objectID":"/07-redis/:8:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"八、Redis 集群 ","date":"0001-01-01","objectID":"/07-redis/:9:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"8.1 主从复制 问：Redis 如何实现服务高可用？ **数据持久化：**这是基础，保证系统在发生宕机或者重启之后数据不会丢失。 ==三种模式：== **主从复制：**将数据存储至多台服务器，当主节点挂了，保证能够很快的切换； 哨兵：监控主节点的状态，若主节点挂了，自动选举新的主节点，并完成故障转移； 集群：提供了多主多从的 Redis 分布式集群环境，实现分布式存储，每个节点存储不同的内容，节省了内存也提高了可用性。 问：如何保证多个 Redis 节点间的数据一致性呢？ 通过主从复制和读写分离。 问：主从复制是如何实现的？⭐🚩 主从复制是 Redis 高可用服务的最基础的保证。实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是**「读写分离」**的方式。 ==读写分离：== 读写分离指主服务器可以进行读和写操作，当发生写操作时自动将写操作同步给从服务器；而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。 该方式，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。 ==主从复制：== 全量同步(从节点是新加入集群的)： 从节点向主节点发送 slaveof 命令，包括(replid=?, offset=-1)，建立复制关系，并发送请求同步命令。 主节点收到命令后，判断要进行哪种同步，若是全量同步，会创建一个后台子线程，负责将自己的数据**快照（RDB文件）**发送给从节点。 从节点收到数据快照后，会先保存在本地，然后清空自己的数据，并载入收到的数据快照。 主节点在等待从节点同步数据的同时，还会将自己新执行的所有写命令缓存在 replication buffer 中。 当从节点完成数据快照的载入后，会向主节点发送一个消息，请求接收写命令。 主节点收到消息后，会将 replication buffer 中的写命令依次发送给从节点，从而使得从节点与主节点保持一致。 此后，主节点和从节点保持一个长连接。每执行一个写命令，就会将该命令同步给所有的从节点。 增量同步(从节点重启后同步)： 若网络不好，长连接断了。恢复后，主从服务器会采用增量同步的方式继续同步。 从节点向主节点发送同步命令(replid, offset)； 主节点判断 replid 是否一致，若一致且从节点的 offset 跟主节点的 offset 差距没有过大(未同步的数据没被覆盖)，就会增量备份，主节点会从repl_baklog获取从节点offset之后的增量数据，将增量数据写入到 replication buffer 缓冲区，然后发送给从节点。 问：主节点如何判断从节点是不是第一次来同步数据？⭐ 两个很重要的概念： **Replication Id：**简称replid，是数据集的标记，id一致说明是同一数据集。每一个主节点都有唯一的replid，从节点会继承主节点的replid。 Offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。从节点完成同步时也会记录当前同步的offset。如果从节点的offset小于主节点的offset，说明从节点数据落后于主节点，需要更新。 从节点同步数据时，必须向主节点声明自己的replid和offset，然后由主节点判断需要同步哪些数据： 若replid为 “?” 或 不一样，就是第一次，将进行全量同步； 若replid一样，就通过offset进行增量同步。 ==注意：==难道从节点断联特别久，再连接上也是增量同步吗？ 当然不是！这就跟repl_baklog有关了~ repl_baklog相当于一个环形缓冲区，写满之后就会覆盖最早的数据。如果从节点断开过久，导致尚未备份的数据已经被覆盖了，就无法基于repl_baklog做增量同步了，只能触发全量同步！ 问：全量同步和增量同步的区别？什么时候执行全量同步？什么时候执行增量同步？ 区别： **全量同步：**主节点将内存数据生成RDB，发送RDB文件给从节点。后续命令记录在baklog中，逐个发送给从节点； **增量同步：**从节点提交自己的offset到主节点，主节点获取baklog中的offset之后的命令给从节点。 什么时候全量同步： 从节点第一次连接到主节点时； 从节点离开太久，未同步的baklog已经被覆盖； 什么时候增量同步： 从节点断开又恢复，并且在baklog中能找到offset时。 问：如何优化主从数据同步？ 优化全量同步： 在网络条件很好的时候，在 master 启用无磁盘复制，也就是不把 RDB 文件写入到磁盘，而是直接写入网络IO，减少磁盘的复制； 减少全量同步次数： 适当提高repl_backlog； 发现从节点宕机时，尽快实现故障恢复，尽可能避免全量同步； 限制一个主节点上的从节点数量，如果实在太多从节点，则可以采用 主-从-从 的结构，减少主节点压力。 问：Redis主从节点时长连接还是短连接？ 长连接。 问：怎么判断 Redis 某个节点是否正常工作？ Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong 心跳检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。 Redis 主从节点发送的心跳间隔是不一样的，而且作用也有一点区别： Redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。 Redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了： 实时监测主从节点网络状态； 上报自身复制偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点的复制缓冲区中拉取丢失数据。 问：主从复制架构中，过期key如何处理？ 主节点处理了一个key或者通过淘汰算法淘汰了一个key时，主节点需要模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。 问：Redis 是同步复制还是异步复制？ Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。 问：主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？ replication buffer 、repl backlog buffer 区别如下： 出现的阶段不一样： repl backlog buffer 是在增量复制阶段出现，一个主节点只分配一个 repl backlog buffer； replication buffer 是在全量复制阶段和增量复制阶段都会出现，主节点会给每个新连接的从节点，分配一个 replication buffer； 这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样： 当 repl backlog buffer 满了，因为是环形结构，会直接覆盖起始位置数据; 当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，重新开始全量复制。 问：如何应对主从数据不一致？ 之所以会出现主从数据不一致的现象，是因为主从节点间的命令复制是异步进行的，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。 有两种方法： 第一种方法，尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。 第二种方法，可以开发一个外部程序来监控主从节点间的复制进度。具体做法： Redis 的 INFO replication 命令可以查看主节点接收写命令的进度信息（master_repl_offset）和从节点复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从节点的进度，然后，我们用 master_repl_offset 减去 slave_repl_offset，这样就能得到从节点和主节点间的复制进度差值了。 如果某个从节点的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从节点连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从节点都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。 问：主从切换如何减少数据丢失？ 主从切换过程中，产生数据丢失的情况有两种： 异步复制同步丢失 集群产生脑裂数据丢失 不可能保证数据完全不丢失，只能做到使得尽量少的数据丢失。 异步复制同步丢失： 对于 Redis 主节点与从节点之间的数据复制，是异步复制的，当客户端发送写请求给主节点的时候，会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。 减少异步复制的数据丢失的方案： Redis 配置里有一个参数 min-slaves-max-lag，表示一旦所有的从节点数据复制和同步的延迟都超过了 min-slaves-max-lag 定义的值，那么主节点就会拒绝接收任何请求。 假设将 min-slaves-max-lag 配置为 10s 后，根据目前 master-\u003eslave 的复制速度，如果数据同步完成所需要时间超过10s，就会认为 ","date":"0001-01-01","objectID":"/07-redis/:9:1","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"8.2 哨兵机制 哨兵模式是在主从复制的基础上增加了一组哨兵（sentinel）节点来监控主从节点的状态，实现主从节点自动故障转移。哨兵的结构和作用如下： 监控：Sentinel 会不断检查 Master 和 Slave 的状态； 自动故障恢复：如果 Master 故障，Sentinel 会自动将一个 Slave 提升为 Master。当故障节点恢复后也会以新的 Master 为主节点； 通知：Sentinel 充当 Redis 客户端的服务发现源，当集群发生故障转移时，会将最新信息自动推送到 Redis 客户端。 问：哨兵机制是如何实现的？⭐ 如果发现主节点失效，哨兵会自动选举出一个领导者(leader)，然后由领导者从剩余的从节点中选出一个新的主节点，并通知其他哨兵和客户端。 ==具体工作过程：== 哨兵会定期(每隔1s)向所有的主节点和从节点发送心跳包，检测它们的运行情况； 如果一个哨兵发现某个主节点没有响应心跳包，就会将其标记为主观下线，然后请求其他哨兵节点进行投票； 如果有超过指定值的哨兵(配置文件中指定的 quorum 值)都将某个主节点标记为主观下线(也就是赞成)，那么该主节点就被认为是客观下线，并开始进行故障转移； 故障转移过程前，哨兵会从该主节点的所有候选者中选出一个合适的候选者，将其升级为哨兵中的 Leader，负责进行故障转移； ​ 候选者：哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点以及投赞成票的哨兵节点就都是候选者； Leader 会从所有的从节点中选择一个合适的从节点作为新的主节点； 故障转移完成后，原来的主节点如果恢复了正常，就会变成新主节点的从节点。 问：哨兵 如何成为 哨兵Leader？ 候选者：哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点以及投赞成票的哨兵节点就都是候选者。 候选者会向其他哨兵发送投票请求； 每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己； 要成为哨兵 Leader，需满足以下条件： 第一，拿到半数以上的赞成票； 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。 问：哨兵Leader如何选择新的主节点？⭐ 哨兵 Leader 通过如下规则选择新的主节点： 选择 Slave 中优先级最高的。优先级是在 Slave 配置中设置的； ⭐哨兵 Leader 会优先选择 offset 最大的 Slave，因为它表示数据最完整。 如果有多个从节点复制偏移量相同，ID 号小的从节点胜出。 问：哨兵Leader节点进行 主从故障转移操作 的过程？⭐ 挑选出 Master； **广播通知所有 Slave **与新的 Master 进行同步； 将新的 Master 通过「发布者/订阅者机制」通知给客户端； 继续监视旧的 Master ，当它重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新的 Master 的 Slave。 问：哨兵集群是怎么组成的？ 哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。 在主从集群中，主节点上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到__sentinel__:hello 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。 问：集群脑裂？ 什么是脑裂？ 由于网络问题，哨兵和从节点都与主节点失联了，但主节点依然正常运行，此时由于哨兵以为主节点挂了，所以就会从从节点选出新的主节点，此时就有两个主节点 - ==脑裂现象==。 由于此时旧主节点依然和客户端能正常通信，客户端向旧主节点写入数据，然后网络又好了！此时旧主节点发现已经有新的主节点，就会变为从节点，清楚自身所有数据，然后进行全量同步，显然这样会导致丢失部分数据。 **总结一句话就是：**由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。 咋解决呢？ 当主节点发现 $从节点总数量 - 从节点下线或者通信超时的数量 \u003c 阈值$ 时，那么禁止主节点进行写数据操作，直接把错误返回给客户端。 等到新主节点上线时，就只有新主节点能接收和处理客户端请求，此时，新写的数据会被直接写到新主节点中。而原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有新数据丢失。 ","date":"0001-01-01","objectID":"/07-redis/:9:2","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"8.3 分片集群 问：分片集群是如何实现的？ 集群模式是将多个 Redis 节点组成一个分布式系统，每个节点负责一部分数据，并通过**槽（slot）**来映射数据分片。集群模式支持多个主节点和多个从节点，每个主节点可以有多个从节点作为备份。集群模式可以实现数据的分布式存储、读写分离、负载均衡、故障转移等功能，提高了服务可扩展性和稳定性，但是也增加了系统复杂度和维护成本。 ==散列插槽== Redis 共有 16384 个哈希槽(hash slot)，将每个 key 通过哈希函数 crc16() 将 key 转化成一个长整型数字，再对 16384 取余，最终决定这个 key 存储的哈希槽。也就是会把每个 key 映射到0-16383个插槽上，每个主节点负责一部分插槽(即一部分键值对)。 ==实现方式== 客户端分片 客户端自己计算key需要映射到哪一个主节点。 优点：降低了集群的复杂度 缺点：当新增Redis实例时需要支持动态分片 服务端分片⭐ 客户端访问某个key时，服务器计算key应该映射到哪个节点，若不是当前节点，就会重定向到指定节点。 代理分片 客户端将请求发送到代理，代理计算得到需要映射的节点信息，然后将客户端的请求转发到对应节点上，然后返回响应给客户端。 ==分片机制的缺点== 分片是由多台Redis实例共同运转，所以如果其中一个Redis实例宕机，则整个分片都将无法使用，所以分片机制无法实现高可用。 如果有不同的key映射到不同的Redis实例，这时候不能对这两个key做交集或者使用事务。 使用分片机制因为涉及多实例，数据处理比较复杂。 分片中对于实例的添加或删除会很复杂，不过可以使用预分片技术进行改善。 问：自动故障转移和手动故障转移？ 自动故障转移： 首先是 Master 与其他节点失去连接； 其他节点标记 Master 为疑似宕机； Master 确定宕机，自动提升一个 Slave 为 Master。 手动故障转移：利用 cluster failover 命令可以手动让集群中某个 Master 宕机，切换到执行 cluster failover 命令的这个 Slave 节点，实现无感知的数据迁移。 ","date":"0001-01-01","objectID":"/07-redis/:9:3","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"九、多级缓存(未) 多级缓存就是利用请求处理的每个环节，分别添加缓存，减轻 TomCat 的压力。 ","date":"0001-01-01","objectID":"/07-redis/:10:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"十、Redis 实战(未) ","date":"0001-01-01","objectID":"/07-redis/:11:0","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"10.1 如何为秒杀系统设计缓存体系 ","date":"0001-01-01","objectID":"/07-redis/:11:1","tags":null,"title":"","uri":"/07-redis/"},{"categories":null,"content":"[toc] 参考文章： 开源消息引擎系统 Kafka 3 新特性 https://juejin.cn/post/7176576097205616700 https://mp.weixin.qq.com/s/vzvmOXGcsX7rwY4J_--onw 20道经典的Kafka面试题详解 《深入理解Kafka：核心设计与实践原理》 ","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:0:0","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"一、消息队列 这里的消息队列指的是各个服务以及系统内部各个组件/模块之前的通信，属于一种中间件。使用消息队列可以降低系统耦合性、实现任务异步、有效地进行流量削峰，是分布式和微服务系统中重要的组件之一。 问：为啥要使用消息队列？消息队列有啥用？ 六个字总结：解耦、异步、削峰 解耦 传统模式下系统间的耦合性太强。举个例子：系统 A 通过接口调用发送数据到 B、C、D 三个系统，如果将来 E 系统接入或者 B 系统不需要接入了，那么系统 A 还需要修改代码，非常麻烦。 如果系统 A 产生了一条比较关键的数据，那么它就要时时刻刻考虑 B、C、D、E 四个系统如果挂了该咋办？这条数据它们是否都收到了？显然，系统 A 跟其它系统严重耦合。 **而如果我们将数据（消息）写入消息队列，需要消息的系统直接自己从消息队列中消费。**这样下来，系统 A 就不需要去考虑要给谁发送数据，不需要去维护这个代码，也不需要考虑其他系统是否调用成功、失败超时等情况，反正我只负责生产，别的我不管。 异步 将用户的请求数据存储到消息队列之后就立即返回结果，消息发送者不需要等待消息接收者的响应，可以继续执行其他任务。随后，系统再对消息进行消费。 因为用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此，使用消息队列进行异步处理之后，需要适当修改业务流程进行配合，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。这就类似我们平时手机订火车票和电影票。 削峰 先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务(mysql)再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。 问：引入消息队列会带来哪些问题？ 系统可用性降低：在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况； 系统复杂性提高：加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！ 一致性问题：消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了! 问：队列模型是啥？存在啥问题？ 使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。 存在的问题： 假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容。队列模型就不好解决了。 问：发布-订阅模型是啥？ 发布-订阅模型主要是为了解决队列模型存在的问题。 发布-订阅模型(Pub-Sub)使用主题(Topic)作为消息通信载体，类似于广播模式：发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。 在发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布-订阅模型在功能层面上是可以兼容队列模型的。 ","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:1:0","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"二、Kafka Kafka 是一个分布式流处理平台。 ","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:0","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"2.1 Kafka 应用生态 ==Kafka 应用架构：== 这张图中居于核心地位的是 Kafka Core 的集群，也就是常用的消息引擎的这部分功能，是本篇的重点； 核心的左右两端分两层，下层分别是 Producer 和 Consumer 的基础 API，提供基础事件流消息的推送和消费；上层提供了更加高级的 Connect API，能够实现 Kafka 和其他数据系统的连接，比如消息数据自动推送到 MySQL 数据库或者将 RPC 请求转换为事件流消息进行推送； 最上面的是，Kafka 基于消息引擎打造了一个流式计算平台 Streams，提供流式的计算和存储一体化的服务。 ==具有三个关键功能：== 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。 存储事件流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。 处理事件流：在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。 ==Kafka 主要有两大应用场景：== 数据收集：可以将不同来源的数据流通过Kafka进行集中收集和处理； 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。 流式处理：构建实时的流数据处理程序来转换或处理数据流。 ","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:1","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"2.2 Kafka Core 架构 2.2.1 消息模型 问：Kafka 使用啥消息模型？ Kafka 使用发布-订阅模型。 消费端：消费者通过消费者组进行划分，一条消息只能由消费者组中的一个消费者消费，消费从队列的头部开始，在 HW 前结束； 消息队列：消息存储是队列的数据结构，只允许消息追加写入，此外，Kafka 的队列还设计了高水位机制，避免未被从副本完成同步的消息被消费者感知并消费； 生产端：生产端的 Producer 持续发送消息到队列中，消息追加到队列尾部，通过指定分区算法可以决定消息发往 Topic 下的哪个分区。 Kafka 将生产者发布的消息发送到 **Topic **中，需要这些消息的消费者可以订阅这些 **Topic **，如下图所示： 问：Kafka消息模型中有哪些角色和实体？ 消息模型的图中也为我们引出了，Kafka 比较重要的几个概念： Producer(生产者)：将消息发送到指定 Topic 的 Partition 中，写入到 LEO 的位置； Consumer(消费者)：从指定的 Topic 和 Partition 中拉取或推送消息，并且可以指定消费组(Consumer Group)和消费位移(Consumer Offset)等参数； Consumer Group(消费者组)：消费者组由一个或者多个消费者组成，同一个组中的消费者对于同一条消息只消费一次。每个分区只能由同一个消费者组内的一个消费者(consumer)来消费(避免竞争)，可以由不同的消费者组来消费； Controller(管理者)：整个 Kafka 集群的管理者角色，任何集群范围内的状态变更都需要通过 Controller 进行，在整个集群中是个单点的服务，可以通过选举协议进行故障转移； Topic的新建和删除； Partition的新建、重新分配； Broker 的加入、退出； 触发分区 Leader 选举。 Broker(代理)：Broker是Kafka中负责存储和转发消息的服务器节点，它可以组成一个集群，并且通过Zookeeper进行协调和管理。 Topic(主题)：一个Topic代表一类消息，是消息的逻辑分类。每个Topic可以被分为多个分区(Partition)，每个分区可以存储一定数量的消息，并且有一个唯一的ID。Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题)来消费消息； Partition(分区)：一个Partition是Topic的物理划分，是消息的存储单位。每个Partition中的消息是有序的，并且按照先进先出（FIFO）的顺序消费； Replica(副本)：每个Partition可以有多个副本，其中一个副本是Leader，负责处理读写请求，其他副本是Follower，负责同步Leader的数据。 ​ 主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份。 问：Kafka 是通过 Push 还是 Pull？ Kafka中，消费端是通过主动 pull 消息的方式来消费的。直觉上会觉得本来就应该这样，但其实不是。Kafka 的文档里有讨论这点，主要围绕：消息消费的流控策略应该放在 Broker 端还是 Consumer 端。 2.2.2 集群架构 一个具有代表性的 Kafka 集群通常具备： 1 个独立的 ZK 集群； 3 个部署在不同节点的 Broker 实例。 就以一个这样的典型集群的为例来介绍 Kafka 的整体架构： 2.2.3 Zookeeper 的作用 参考文章： 深入解读基于 Kafka 和 ZooKeeper 的分布式消息队列原理 ","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:2","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"2.3 核心机制 2.3.1 水位机制 问：水位机制的作用？ 水位机制共有两个作用： 辅助从副本完成异步同步； 定义消息可见性，即标识哪些消息可消费。 问：Partition 中的水位机制？⭐ 每个 Partition 是一个独立的消息队列： LSO(Log Stable Offset) 是起点，此偏移会随着消息过期时间等的影响，逐渐向右移动； HW 是已提交消息的可见性的边界，仅在此偏移之下的消息对外是可见的(注意，不含 HW 本身): Leader HW = min(LEO)； Follower HW = min(Follower本地 LEO, Leader HW)。 LEO(Log End Offset) 是消息队列的终点，下一条消息将在这个地方写入。 其中，[LSO, HW) 就是消息的可见范围(已提交)。 问：水位更新？⭐ (这个感觉有点问题。) 主要是高水位是如何更新的，这里用一个 3 副本的场景描述高水位是如何更新到 5 的： 阶段1：此时 ISR 中最小 LEO 为 4。副本 1 发出同步请求，获取 Offset = 4 的数据； 阶段2：同时，HW 更新为 4； 阶段3：当副本 1 收到 Offset = 4 的数据，更新本地 LEO 为 5。此时 ISR 中最小 LEO 更新为 5，于是 HW 更新到 5。 参考文章： https://juejin.cn/post/7070319066325450765 2.3.2 Partition 和 Replica Kafka 中通过分区的多副本策略解决消息备份问题，有如下概念： AR: **所有副本(replicas)**统称为assigned replicas，即 AR； ISR: leader 副本 以及与 leader 副本保持一定同步的 follower 副本，叫 In Sync Replica； OSR: 与 leader 副本同步数据有一些延迟的 follower 节点。 问：Kafka 的多分区(Partition)以及多副本(Replica)机制有什么好处呢？⭐ 多分区(Partition)的好处： 解决伸缩性问题，实现负载均衡，提高并发性能：每个Topic可以被划分为多个Partition，各个Partition可以分布在不同的Broker上，每个Partition可以被不同的Producer和Consumer并行读写，从而实现负载均衡。 多副本(Replica)的好处： 提高容错能力：每个Partition可以有多个Replica，其中一个Replica是Leader，负责处理读写请求，其他Replica是Follower，负责同步Leader的数据。当Leader出现故障时，Zookeeper会自动选举一个Follower作为新的Leader，从而保证服务可用。 问：Kafka 分区的分配策略有哪些？⭐ 消费者与主题之间的分区分配策略：用来解决到底由哪个consumer来消费哪个partition的数据。Kafka 提供了默认的分区策略，同时支持自定义分区策略。 Range(平均)：将每个主题的分区平均分配给消费者。这种策略适合每个主题的分区数相同，且消费者数量稳定的场景。 Round Robin(轮询)⭐：轮流将每个分区分配给消费者。这种策略适合每个主题的分区数不同，且需要实现负载均衡的场景。 Sticky(粘性)：在保持之前分配结果不变的前提下，尽量减少再平衡时重新分配的分区数量。这种策略适合需要避免频繁再平衡导致性能下降的场景。 问：Leader Replica 和 Follower Replica 的同步机制？⭐ ==// TODO== 问：Partition 的并发性？ 一句话总结：同一个 Topic 不同 Partition 之间是支持并发写入消息的，同一个 Partition 不支持并发写入消息。 这很好理解，单个 Partition 是临界资源，需要用锁来进行冲突检测保证同一时间只有一批消息在写入避免出现消息乱序或者写入被覆盖的情况。 问：Kafka 如何保证消息的消费顺序？⭐ Kafka 是不能保证全局消息顺序的，只能保证单个 Partition 下的顺序 Kafka 中 Partition(分区) 是真正保存消息的地方，每次添加消息到 Partition(分区) 的时候都会采用尾加法，即 Kafka 只能为我们保证 单个Partition(分区) 中的消息有序。因此，有如下两种做法： 一个 Topic 只拥有一个 Partition； 在需要保证顺序的场景可以使用 Key-Ordering 策略将同一个用户的消息发送到同一分区，即可保证顺序。例如订单ID或用户ID等，这样同一业务字段的消息会发送到同一分区，并且消费者也按照业务字段进行消费。 2.3.3 持久化 Kafka 通过： 使用**日志(Log)**来保存数据，一个日志就是磁盘上一个只能追加写(Append-only)消息的物理文件； 日志越来越大，必然要定期地删除日志以回收磁盘，这是通过日志段(Log Segment)机制。 Kafka 的日志架构： 一般情况下，一个 Topic 有很多 Partition，每个 Partition 就对应一个 Log 对象，在物理磁盘上则对应于一个子目录。比如创建了一个双 Partition 的 Topic:test-topic，那么，Kafka 在磁盘上会创建两个子目录：test-topic-0 和 test-topic-1。而在服务器端，这就是两个 Log 对象，每个子目录下存在多组日志段，也就是多组.log、.index、.timeindex文件组合，只不过文件名不同，因为每个日志段的起始位移不同。 2.3.4 消息丢失与重复消费 消息丢失 一句话概括，Kafka 只对“已提交”的消息(committed message)做有限度的持久化保证。 第一个核心要素是已提交的消息。 什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。 那为什么是若干个 Broker 呢？这取决于你对“已提交”的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，Kafka 只对已提交的消息做持久化保证这件事情是不变的。 ==总结：==当达到设定数量的Broker成功接收消息并写入保存之后，该消息就认为是已提交的。 第二个核心要素就是有限度的持久化保证。 也就是说 Kafka 不可能保证在任何情况下都做到不丢失消息。 有限度其实就是说 Kafka 不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。 问：Kafka 如何避免消息丢失？ 在使用 MQ 的时候最大的问题就是消息丢失，常见的丢失情况如下： 1）Producer 端丢失 2）Broker 端丢失 3）Consumer 端丢失 一条消息从生产到消费一共要经过以下 3 个流程： 1）Producer 发送到 Broker 2）Broker 保存消息(持久化) 3）Consumer 消费消息 3 个步骤分别对应了上述的 3 种消息丢失场景： ==实际情况分析：== Producer 端丢失 **原因：**由于网络或者Broker异常造成的。 解决方案：消息重传。 具体实现：Producer 不使用fire and forget的发送方式，永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。通过回调，如果Producer发送消息后没有收到Broker的确认回复，就会认为发送失败，进而重传。如果重试，可能会导致消息重复；如果放弃，可能会导致消息丢失。 Broker 端丢失 原因：Kafka 为了减少磁盘 I/O，采用异步批量的刷盘策略，也就是按照一定的消息量和间隔时间进行刷盘。Kafka 收到消息后会先存储在也缓存中(Page Cache)中，之后由操作系统根据自己的策略进行刷盘或者通过 fsync 命令强制刷盘。如果系统挂掉，在 PageCache 中的数据就会丢失。 解决方案：考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。 具体实现：Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份。Follower 中有一个特殊的集合叫做 ISR，当 Leader 故障时，会从 ISR 中新选举出来 Leader。Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。 由于消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个选项叫做 acks，当这个选项被设置为 all 时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 IS","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:2:3","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"三、常见面试题 什么是 Kafka，它有哪些特点和优势？ Kafka 的架构是怎样的，它包含哪些组件和角色？ Kafka 是如何实现高吞吐量和高可用性的？ Kafka 是如何保证消息的顺序性和一致性的？ Kafka 是如何实现分区和副本的，它们有什么作用？ Kafka 是如何实现生产者和消费者之间的通信的，它们有哪些参数和策略可以配置？ Kafka 是如何维护消费者的消费状态和偏移量的，它们存储在哪里？ Kafka使用消费者组来维护消费者的消费状态和偏移量。消费者组中的每个消费者都会读取一个或多个分区中的数据，并将其偏移量存储在内存中。Kafka使用一个名为__consumer_offsets的内部主题来存储消费者组的偏移量信息。每个消费者组都有一个对应的__consumer_offsets主题，其中包含每个分区的偏移量信息。消费者组中的每个消费者都会定期将其偏移量提交到__consumer_offsets主题中，以便其他消费者可以知道哪些数据已经被消费，哪些数据还没有被消费。 Kafka 有哪些常见的使用场景，它与其他消息系统有什么区别和联系？ Zookeeper 对于 Kafka 的作用是什么，如果 Zookeeper 宕机了会怎样？ 如何监控和度量 Kafka 的运行状态和性能指标？ 如何优化 Kafka 的生产者和消费者的性能，提高吞吐量和降低延迟？ 如何保证 Kafka 的数据安全性，避免数据丢失或重复消费？ 如何处理 Kafka 的异常情况，比如分区不平衡、主从切换、消息堆积等？ 问：Kafka是什么？ Kafka 是一款分布式流处理框架，用于实时构建流处理应用。它有一个核心的功能广为人知，即作为企业级的消息引擎被广泛使用。 问：什么是消费者组？⭐ 标准答案：关于它的定义，官网上的介绍言简意赅，**即消费者组是 Kafka 提供的可扩展且具有容错性的消费者机制。**切记，一定要加上前面那句，以显示你对官网很熟悉。 另外，最好再介绍下消费者组的原理：在 Kafka 中，消费者组是一个由多个消费者实例构成的组。多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有相同的组ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。 此时，又有一个小技巧给到你：消费者组的题目，能够帮你在某种程度上掌控下面的面试方向。 如果你擅长位移值原理，就不妨再提一下消费者组的位移提交机制； 如果你擅长Kafka Broker，可以提一下消费者组与Broker之间的交互； 如果你擅长与消费者组完全不相关的Producer，那么就可以这么说：“消费者组要消费的数据完全来自于Producer端生产的消息，我对Producer还是比较熟悉的。” 使用这个策略的话，面试官可能会被你的话术所影响，偏离他之前想问的知识路径。当然了，如果你什么都不擅长，那就继续往下看题目吧。 问：在 Kafka 中，ZooKeeper 的作用是什么？🚩⭐ 这是一道能够帮助你脱颖而出的题目。碰到这个题目，请在心中暗笑三声。 标准答案：目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。KIP-500 提案之后，Kafka 就不再依赖于 ZooKeeper。 存放元数据：是指主题分区的所有数据都保存在ZooKeeper中，且以它保存的数据为权威，其他“人”都要与它保持对齐； 成员管理：是指Broker节点的注册、注销以及属性变更； Controller选举：是指选举集群Controller，而其他管理类任务包括但不限于主题删除、参数配置等。 KIP-500：是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举。 问：解释下 Kafka 中位移(offset)的作用？ 在 Kafka 中，每个 Partition 下的每条消息都被赋予了一个唯一的 ID 数值，用于标识它在分区中的位置。这个ID数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能被修改。 主要是用来： 记录当前消费到哪里了？ 记录当前日志提交到哪里了？引出水位机制。 问：阐述下 Kafka 中的主副本(Leader Replica)和从副本(Follower Replica)的区别？ 可以这么回答：Kafka 副本分为 Leader 副本和 Replica 副本。只有 Leader 副本才能对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉(PULL)的方式，被动地同步Leader副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时准备选举成 Leader 副本，实现高可用性。 通常来说，回答到这个程度，其实才只说了60%，因此，我建议你再回答两个额外的加分项。 强调 Follower 副本也能对外提供读服务。自 Kafka 2.4 版本开始，社区通过引入新的 Broker 端参数，允许 Follower 副本有限度地提供读服务； 强调 Leader 和 Follower 的消息序列在实际场景中不一致。很多原因都可能造成Leader和Follower保存的消息序列不一致，比如程序Bug、网络问题等。这是很严重的错误，必须要完全规避。你可以补充下，之前确保一致性的主要手段是高水位机制，但高水位值无法保证Leader连续变更场景下的数据一致性，因此，社区引入了Leader Epoch机制，来修复高水位值的弊端。关于“Leader Epoch机制”，国内的资料不是很多，它的普及度远不如高水位，不妨大胆地把这个概念秀出来，力求惊艳一把。上一季专栏的[第27节课]讲的就是Leader Epoch机制的原理，推荐你赶紧去学习下。 问：LEO、LSO、AR、ISR、HW 都表示什么含义？ LEO：Log End Offset。日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。举个例子，如果日志有10条消息，位移值从0开始，那么，第10条消息的位移值就是9。此时，LEO = 10； LSO：Log Stable Offset。这是Kafka事务的概念。如果你没有使用到事务，那么这个值不存在（其实也不是不存在，只是设置成一个无意义的值）。该值控制了事务型消费者能够看到的消息范围。它经常与Log Start Offset，即日志起始位移值相混淆，因为有些人将后者缩写成LSO，这是不对的。在Kafka中，LSO就是指代Log Stable Offset； HW：高水位值（High watermark）。这是控制消费者可读取消息范围的重要字段。一个普通消费者只能“看到”Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。水位以上的消息是对消费者不可见的； AR：Assigned Replicas。AR是主题被创建后，所有副本统称为assigned replicas，即 AR； ISR：In-Sync Replicas。指代的是AR中那些与Leader保持同步的副本集合。在AR中的副本可能不在ISR中，但Leader副本天然就包含在ISR中。关于ISR，还有一个常见的面试题目是如何判断副本是否应该属于ISR。目前的判断依据是：Follower LEO落后Leader LEO的时间，是否超过了Broker端参数replica.lag.time.max.ms值。如果超过了，副本就会被从ISR中移除。 问：Leader Partition 的选举策略有几种？/在哪些场景下需要执行 Leader 选举？ Partition 的 Leader 选举由 Controller 负责。当前，Kafka有 4 种 Leader Partition 选举策略： OfflinePartition Leader选举：每当有分区上线时，就需要执行 Leader 选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区 Leader 选举场景。 ReassignPartition Leader选举：当你手动运行kafka-reassign-partitions命令，或者是调用Admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举。假设原来的AR是[1，2，3]，Leader是1，当执行副本重分配后，副本集合AR被设置成[4，5，6]，显然，Leader必须要变更，此时会发生Reassign Partition Leader选举。 PreferredReplicaPartition Leader选举：当你手动运行kafka-preferred-replica-election命令，或自动触发了Preferred Leader选举时，该类策略被激活。所谓的Preferred Leader，指的是AR中的第一个副本。比如AR是[3，2，1]，那么，Preferred Leader就是3。 ControlledShutdownPartition Leader选举：当Broker正常关闭时，该Broker上的所有Leader副本都会下线，因此，需要为受影响的分区执行相应的Leader选举。 这 4 类选举策略的大致思想是类似的，即从 AR 中挑选首个在 ISR 中的副本，作为新 Leader。 问：Kafka 的哪些场景中使用了零拷贝(Zero Copy)？⭐ Zero Copy是特别容易被问到的高阶题目。Kafka的数据是持久","date":"0001-01-01","objectID":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/:3:0","tags":null,"title":"","uri":"/08-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"categories":null,"content":"[toc] 一些比较好的文档： https://tanxinyu.work/raft/ https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md https://tanxinyu.work/consistency-and-consensus/ https://tanxinyu.work/zookeeper-thesis/ Zookeeper Etcd https://mp.weixin.qq.com/s/x-AdmN0UN5KT58XWO1BCOA(未) ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:0:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"常见面试题 RAFT 算法 主节点选举过程？ 怎么保证个节点的一致性？G ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:1:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"一、分布式理论和一致性模型 ==CAP== Consistency（一致性）：所有节点访问同一份最新的数据副本； Availability（可用性）：非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）； Partition Tolerance（分区容错性）：分布式系统出现网络分区的时候，仍然能够对外提供服务。 **注：**什么是网络分区？ 分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 网络分区。 问：所谓的 “3选2” ？ 其实不是任意的 “3选2”。 当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。 ==简而言之就是：==CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。 因此，分布式系统理论上不可能选择 CA 架构，==只能选择 CP 或者 AP 架构==。 问：为啥不可能同时满足 CAP 呢？ 首先，分布式系统要保障整体的服务，就必须拥有分区容错性 P。 然后，可以举个例子。若系统发生“分区”，分为A、B： 有写请求进来，修改了 A 中某数据，正常情况下要同步给 B，但分区状态，发生同步失败； 此时，B 来了读请求，要么保证一致性，阻塞请求，等待分区状态结束再继续服务；要么保证可用性，返回给旧的数据。 ==BASE== BASE：Basically Available（基本可用）、**Soft-state（软状态）**和 Eventually Consistent（最终一致性）。 **基本可用：**指分布式系统在出现不可预知故障的时候，允许损失部分可用性。损失部分可用性，例如响应时间变长，系统提供的功能变少等； **软状态：**允许系统存在短暂的数据不一致； 最终一致性：系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。 ==一致性模型== 分布式系统按照对一致性要求的不同，主要分为强一致性，弱一致性这两大类，前者是基于 safety 的概念，后者是基于 liveness 的概念。 强一致性 顺序一致性：如果一个并发执行过程所包含的所有读写操作能够重排成一个全局线性有序的序列，并且这个序列满足以下两个条件，那么这个并发执行过程就是满足顺序一致性的： 重排后的序列中每一个读操作返回的值，必须等于前面对同一个数据对象的最近一次写操作所写入的值； 原来每个进程中各个操作的执行先后顺序，在这个重排后的序列中必须保持一致。 **线性一致性：**和顺序一致性很相似，除了满足上面两个条件外，还需要满足： 不同进程的操作，如果在时间上不重叠，那么它们的执行先后顺序，在这个重排后的序列中必须保持一致。 区别： 线性一致性考虑了时间先后顺序，而顺序一致性没有。 满足线性一致性的执行过程，肯定都满足顺序一致性；反之不一定。 线性一致性总是能读到最新的数据，顺序一致性有可能读到旧版本的数据。 弱一致性 弱一致性是指系统在数据成功写入之后，不承诺立即可以读到最新写入的值，也不会具体承诺多久读到，但是会尽可能保证在某个时间级别之后，可以让数据达到一致性状态。其中包括了最终一致性。 问：那共识和一致性有什么区别？ 一致性指的是分布式系统中多个副本对外呈现的数据状态，比如顺序一致性、线性一致性等。 共识则指的是分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程，比如Paxos、Raft等算法。 因此，一致性描述的是结果状态，共识则是达成一致性的一种手段。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:2:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"错误类型与错误容忍(Fault Tolerance) 在分布式系统当中可能出现的错误主要有两种： CF (Crash Fault)：宕机故障，系统中的某些节点可能出现宕机故障，不会响应请求，但是不会恶意响应； BF (Byzantine Fault): 拜占庭故障，系统中的某些节点可能出现拜占庭故障，可能会不响应请求，也可能错误响应请求。 出现拜占庭故障的节点我们称为拜占庭节点。 能够容忍宕机故障的系统我们称为 CFT（Crash Fault Tolerance）系统； 能够容忍拜占庭故障的系统我们称为 BFT（Byzantine Fault Tolerance）系统。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:2:1","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"二、Paxos 算法 概述 主要包括两部分： Basic Paxos 算法：描述的是多节点之间如何就某个值(提案 Value)达成共识。 Multi-Paxos 思想：描述的是执行多个 Basic Paxos 实例，就一系列值达成共识。Multi-Paxos 说白了就是执行多次 Basic Paxos ，核心还是 Basic Paxos 。 Basic Paxos 中存在 3 个重要的角色： 提议者（Proposer）：也可以叫做协调者（coordinator），提议者负责接受客户端的请求并发起提案。提案信息通常包括提案编号 (Proposal ID) 和提议的值 (Value)。 接受者（Acceptor）：也可以叫做投票员（voter），负责对提议者的提案进行投票，同时需要记住自己的投票历史； 学习者（Learner）：如果有超过半数接受者就某个提议达成了共识，那么学习者就需要接受这个提议，并就该提议作出运算，然后将运算结果返回给客户端。 Multi-Paxos 思想： 思想的核心就是通过多个 Basic Paxos 实例就一系列值达成共识。 也就是说：Basic Paxos 是 Multi-Paxos 思想的核心，Multi-Paxos 就是多执行几次 Basic Paxos。 两阶段 prepare 阶段 Proposer提案者：负责提出 proposal。在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号 N，然后将该编号关联其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者； Acceptor表决者：每个表决者在 accept 某提案编号后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer 。 accept 阶段 当Proposer收到超过半数的Accepter的响应后，就会发送提案的内容与编号； 当Accepter收到提案内容与编号后，若提案编号是自己批准过的最大编号，那就Accept该提案。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:3:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"三、RAFT 算法 动态演示 RAFT 只有三种类型的节点： **Leader：**负责发起心跳，响应客户端，创建日志，同步日志。 Candidate：Leader 选举过程中的临时角色，由Follower转化而来，发起投票参与竞选。 **Follower：**接受Leader的心跳和日志同步数据，投票给 Candidate。 任期(Term) RAFT 算法划分任意时间长度的任期(Term)，任期用连续的数字表示，看作当前 term 号。 问：Term 号的作用？ 每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号。 如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值； 如果一个**Candidate或者Leader**发现自己的 term 过期了，他会立即退回成 Follower； 如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求。 日志(Log) entry：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为\u003cterm, index, cmd\u003e，其中 cmd 是可以应用到状态机的操作。 log：由 entry 构成的数组，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。 RAFT 强化了 Leader 的地位，日志算法只能由 Leader 复制给其他成员，这意味着日志复制是单向的，Leader 从不会覆盖本地日志，即所有的日志均以 Leader 为基准。 ==Leader 选举== RAFT 使用心跳机制来触发Leader的选举。 如果一台服务器能够收到来自Leader或者Candidate的有效信息，那么它会一直保持为Follower状态，并且刷新自己的 election计时器，重新计时。 问：选主过程？ 每个Follower节点都保持一个election计时器，如果一个Follower在一个周期内没有收到心跳信息，就叫做选举超时，然后它就会认为此时没有可用的 Leader，并且开始进行一次选举以选出一个新的 Leader： Follower 会自增自己的term号并且转换状态为 Candidate(候选者)； 然后他会向所有节点发起**RequestVoteRPC(投票请求)：自身的任期 term、memberId、最新日志(即最后一个Entry)的任期 term 和 index。每个节点只有一票(保证每个Term至多只有一个Leader，避免split brain)，如果发现 候选者的任期 \u003e= 自身任期 并且 候选者的最新日志 \u003e= 自身的最新日志，则回复同意；这样可以保证新 leader 节点一定包含最新提交的日志**。 Candidate的状态会持续到以下情况发生： 赢得选举：收到了来自集群内的多数选票(N/2+1)； 其他节点赢得选举； 一轮选举结束，无人胜出。 在Candidate等待选票的时候，它可能收到其他节点声明自己是Leader的心跳，此时有两种情况： 该Leader的term号\u003e=自己的term号，说明对方已经成为 Leader，则自己回退为 Follower。 该Leader的term号\u003c自己的term号，那么会拒绝该请求并让该节点更新 term。 问：会出现选不出主的情况吗？如何解决？ 会。同一时刻出现多个 Candidate，导致没有Candidate获得大多数选票，如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。 RAFT 通过随机的election时间来缓解这一问题：每一个Candidate在发起选举后，都会随机化一个新的选举超时时间，一旦超时后还没完成选举，则自增自己的Term，然后发起新一轮的选举(Term 较大的有更大的概率压倒其他节点)。这种机制使得各个服务器能够分散开来，在大多数情况下只有一个服务器会率先超时；它会在其他服务器超时之前赢得选举。 ==日志复制== 问：日志复制的过程是什么样的？ 一旦选出Leader，它就负责所有的客户端请求。每一个客户端请求都包含一条需要被复制状态机（Replicated State Mechine）执行的命令； Leader 收到客户端请求后，会生成一个 entry，包含\u003cindex, term, cmd\u003e，再将这个entry添加到自己的日志末尾后( Append Entries)； 然后 Leader 会生成日志复制请求，包含本次待复制的日志列表(新的entry)、上一条日志(已提交的最后一个entry)等信息，并行地向所有从节点广播该请求； Follower收到日志复制请求后： 如果发现 leader 的任期 \u003e= 自身任期 并且 日志一致性检查 通过，就接受待复制的日志列表，同时返回给Leader同意； 否则，返回拒绝。 如果Leader收到了多数的成功响应，Leader 会将这个entry应用到自己的状态机中，之后可以认为这个entry是 committed 的，并且向客户端返回执行结果。 ==RAFT 保证以下两个性质：== 在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd。 在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同 第一条通过**只有Leader才能生成entry来保证；第二条通过一致性检查**来保证。 问：一致性检查的过程是怎样的？/如何保证节点一致性？⭐⭐ leader 在通过AppendEntriesRPC和follower通讯时，会携带**上一个entry **的信息； follower在收到后会对比自己的日志：如果发现这个entry的信息(index、term)和自己日志内的不匹配，则会拒绝该请求； 一旦leader发现有follower拒绝了请求，则会与该follower不断进行一致性检查，直到找到双方最大的共识点，然后用leader的entries记录覆盖follower在最大共识点之后的所有数据。 这样，主从节点就一致了。 问：一致性检查失效的情况？如何解决呢？ 在出现网络分区时，不同分区A、B就会出现不同的Leader，然后两个分区就有可能出现日志不一致(因为没办法同步了呀)，例如： 如果分区状态结束，重新合并为一个区，Term号小的节点就会找到和**Term大的节点**的日志中最后一个相同的entry，并回滚该位置之后的所有entry，然后复制Term大的节点的日志Append到后面，此时所有节点的日志就一致了。 问：参加选举的节点有没有什么限制？ **Leader 需要保证自己存储全部已经提交的日志条目。**这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。 **每个 Candidate 发送 RequestVoteRPC 时，都会带上最后一个 entry 的信息。**所有节点收到投票信息时，会对该 entry 进行比较，如果发现自己的更新，则拒绝投票给该 Candidate。 **判断日志新旧的方式：**如果两个日志的 term 不同，term 大的最新；如果 term 相同，index 大的最新。 问：节点崩溃会发生什么？ Leader节点崩溃：集群中的节点在electionTimeout时间内没有收到Leader的心跳信息就会触发新一轮的选主，在选主期间整个集群对外是不可用的； Follower、Candidate节点崩溃：那么发送给它的 RequestVoteRPC 和 AppendEntriesRPC 会失败，但由于 raft 的所有请求都是幂等的，所以失败的话会无限的重试。如果崩溃恢复后，就可以收到新的请求，然后选择追加或者拒绝 entry。 问：RAFT 中的各种时间设置？ broadcastTime \u003c\u003c electionTimeout \u003c\u003c MTBF broadcastTime：向其他节点并发发送消息的平均响应时间； electionTimeout：选举超时时间； MTBF(mean time between failures)：单台机器的平均健康时间； broadcastTime应该比electionTimeout小一个数量级，为的是使Leader能够持续发送心跳信息（heartbeat）来阻止Follower开始选举； electionTimeout也要比MTBF小几个数量级，为的是使得系统稳定运行。当Leader崩溃时，大约会在整个electionTimeout的时间内不可用。我们希望这种情况仅占全部时间的很小一部分。 由于broadcastTime和MTBF是由系统决定的属性，因此需要决定electionTimeout的时间。 一般来说，broadcastTime 一般为 0.5～20ms，electionTimeout 可以设置为 150～300ms，MTBF 一般为一两个月。 日志压缩 同其他系统一样，日志总不能无限制的增长，这样不仅会导致日志文件很大，还会导致恢复数据时执行日志的时间很长。因此，需要定时的快照(snapshot)。snapsh","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:4:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"四、PBFT 算法 参考文章： https://chenquan.me/posts/pbft-key-points/ https://learnblockchain.cn/2019/08/29/pbft https://sammyne.github.io/pbft/ ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"简介 PBFT 是 Practical Byzantine Fault Tolerance 的缩写，意为实用拜占庭容错算法。 该算法首次将拜占庭容错算法复杂度从指数级降低到了多项式级，其可以在恶意节点不高于总数 1/3 的情况下同时保证安全性（Safety）和活性（Liveness）。 约定变量 集群数量定义为 N，其数量定义为 ∣N∣=n 拜占庭或者是宕机节点集合为定义为 F，其数量定义为 ∣F∣=f quorum 法定成员集合Q，即每次访问的节点数量∣Q∣ 术语 Primary: 主节点 Replica: 副本节点 Client: 客户端，用于向共识集群发送消息，请求共识 View: 视图，Primary 和 Replica 共同达成的一个状态视图，所有节点都基于某个视图进行共识 Sequence Number：序列号，由主节点生成的序列号，用于标识共识轮次 Check Point: 检查点，如果某个序列号被确认，则成为检查点 Stable checkpoint: 稳定检查点，该检查点通常会被持久化 N \u003e 3f + 1 这里先提出一个问题：在分布式系统中需要读写多少台节点才可以满足正确性要求，即 quorum 的值为多少比较合适？ 先给出结论： 在 CFT 系统中，只需要达到2f + 1就可以了； 在 BFT 系统中，就需要达到3f + 1才行，因为是允许同时存在故障节点和拜占庭节点的。 给出分析： 节点总数是n，其中作恶节点有f，那么剩下的正确节点为n - f，意味着只要收到n - f个消息就能做出决定，但是这n - f个消息有可能有f个是由作恶节点冒充的，那么正确的消息就是n - f - f个，为了多数一致，正确消息必须占多数，也就是 n - f - f \u003e f，但是节点必须是整数个，所以 n 最少是 3f + 1 个。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:1","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"算法流程 约定符号 i：节点ID(replica id)，应该是在 [0, N−1] 范围内的值； v#：视图编号(view number)，初始为零，用 v# 表示； Primary：主节点，通常采用模运算取得: Primary = v# mod N； m：即本轮共识的具体操作，可以是数据库操作，也可以是区块写入操作； d(m)：是m的摘要信息(digest)； seq# 为 sequence number； log：操作日志，通常记录了当前收到的消息，形式为 \u003cv#, seq#, status, d\u003e status 为 pre-prepared 、prepared或者是committed； 消息结构 这里列出了三阶段协议相关的消息结构，其中只有 PRE-PREPARE 消息包含新生成的区块，其他消息则主要包含一些 id、sequence number、区块摘要和签名等信息。 核心过程 STEP 1: 客户端发送请求给主节点(或者发给所有节点)，之后主节点将会触发三阶段协议。这里可以有一个优化，节点可以先把请求缓存起来，等到攒够一堆请求之后再一起发送，这样可以降低网络开销和系统负载。 STEP 2: 主节点收到客户端发送来的消息后，构造pre-prepare消息结构体 \u003c\u003cPRE-PREPARE, v#, seq#, d, sig\u003e, m\u003e (p)，其中 (p) 表示由主节点发出，d是当前消息摘要，m为原始消息，sig 为d的数字签名 PRE-PREPARE标识当前消息所处的协议阶段； v#标识当前视图编号； seq#为主节点广播消息的一个唯一递增序号； d为m的消息摘要； sig 为d的数字签名； m为客户端发来的消息。 STEP 3: 从节点检查主节点发送的 pre-prepare 消息，检查通过会存储在本节点日志。检查通过会进入PREPARE状态，广播消息\u003cPREPARE, v#, seq#, d, i,\u003e (i)，其中 (i) 标识从i节点发出。消息的有效性检查过程如下： 检查收到的消息体中摘要d，是否和自己对m生成的摘要一致，确保消息的完整性。 检查v#是否和当前视图v#一致。 检查序号seq#是否在水线h和H之间，避免快速消耗可用序号。 检查之前是否接收过相同序号seq#和v#，但是摘要d不同的消息。 STEP 4: 所有节点收到PREPARE消息后，同样也会对消息进行有效性检查，检查的内容也是 STEP3 中的1, 2, 3, 4。 当收到2f(包括自己)个检查通过且一致的PREPARE消息后，会进入COMMIT阶段，并且广播消息\u003cCOMMIT, v#, seq#, d, i\u003e (i) 2f-1 个从其他节点收到的prepare消息(不包括自己的)。这里是因为主节点不会再发送prepare消息，因此收到2f-1个prepare，加上主节点的pre-prepare，以及自己的prepare，就是2f+1个了； STEP 5: 所有节点收到COMMIT消息后，同样也会对消息进行有效性检查，检查的内容也是 STEP3 中的1, 2, 3, 4。 当收到2f+1(包括自己)个检查通过且一致的COMMIT消息后，进入committed-local状态，按照m中的请求顺序执行操作。 执行完成之后，所有节点将发送结果给到客户端。 STEP 6: 客户端收到超过2f+1的一致消息则确认当前结果成功 整个过程不需要要求所有的消息是有序到达的，因为seq#会保证顺序，只需要对应的pre-prepare，prepare和commit消息都是完整的即可。 一种优化流程 以下是基于公开资料收集的 Hyperchain 优化之后的 RBFT 算法 主要优化点： 客户端可以发送请求到任意节点，如果这个节点不是主节点的话，将会进行一次广播；(类似读写分离) 主节点收到交易之后会先进行验证，并把验证结果放在pre-prepare中，并且pre-prepare是以区块为单位处理的，这样的 pre-prepare 消息中既包含了排好序的交易信息也包含了区块验证结果； 从节点收到pre-prepare后，也是先验证消息的合法性，然后广播prepare。不同的是，在收到2f个prepare后会对区块内容进行验证，并与pre-prepare中的验证结果对比，若一致，则广播 commit 表明本节点同意主节点的验证结果；若不一致，直接发起 view-change 表明本节点认为主节点存在异常行为，需要切换主节点。 RBFT 具体流程： **交易转发阶段：**客户端将交易发送到区块链中的任意节点（包括共识节点与记账节点），其中记账节点在收到交易后会主动转发给与其相连的共识节点；而共识节点在收到客户端的交易后将其广播给其他共识节点，这样所有共识节点的交易池中都会维护一份完整的交易列表； 共识节点就是参与RBFT共识过程的节点，记账节点是不参与共识，只接受结果并写入区块的节点 PrePrepare 阶段：主节点按照如下策略进行打包：用户可以根据需求自定义打包的超时时间（batch timeout）与打包的最大区块大小（batch size），主节点在超时时间内收集到了足够多（超过最大区块大小个数）的交易或者超时时间到达后仍未收集到足够多的交易都会触发主节点的打包事件。主节点将交易按照接收的时间顺序打包成块，并进行验证，计算执行结果，最后将定好序的交易信息连同验证结果等写入 pre-prepare 消息中，广播给所有共识节点，开始三阶段处理流程； Prepare 阶段： 从节点在收到主节点的 pre-prepare 消息后，首先进行消息合法性检查，检查当前的视图与序列号号等信息，检查通过后向共识节点广播 prepare 消息； **Commit 阶段：**从节点在收到quorum-1 即(2f) 个prepare 消息以及相应的 pre-prepare 消息后进行验证，并将验证结果与主节点写入pre-prepare 消息中的验证结果进行比对，比对结果一致则广播 commit 表明本节点同意主节点的验证结果，否则直接发起 view-change 表明本节点认为主节点存在异常行为，需要切换主节点； **写入账本：**所有共识节点在收到 quorum 个 commit 消息后将执行结果写入本地账本。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:2","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"日志压缩 PBFT的每个阶段都写入了日志，长时间运行内存总会不够用，需要一种日志压缩机制。PBFT通过检查点实现日志压缩，其本质和RAFT算法采用快照的形式清理日志是一样的，只是实现的方式不同。 为每一次操作创建一个集群中稳定检查点，代价是非常昂贵的。因此，PBFT为常数k个操作创建一次稳定检查点，比如每100个操作创建一次检查点checkpoint，当这个checkpoint得到集群中多数节点认可以后，就变成了稳定检查点stable checkpoint。 总之，稳定检查点是一个确定性的系统状态快照，可以用来恢复系统状态，类比于**RDB快照**；而水位线[h, H]间的消息就相当于**AOF文件**。 稳定检查点 生成过程： 当 replica i 生成了一个 checkpoint，将广播消息 \u003cCHECKPOINT, seq#, d(state), i\u003e，其中，seq#是最后一次执行的消息序号，d是seq执行后的状态机状态的摘要； 当所有节点收到了2f+1个拥有相同的 seq# 和 d(state) 的检查点消息(包括自己)后，将会生成stable checkpoint。 作用： 当stable checkpoint生成之后，将会删除stable checkpoint之前(seq#之前)的 pre-prepare、prepare、commit消息，日志就被压缩了，并且稳定检查点是一个确定性的系统状态快照，可以用来恢复系统状态。 同时checkpoint还有一个**提高水线(water mark)**的作用，当一个stable checkpoint被创建的时候，水线h被修改为stable checkpoint的seq#，水线H为h + k而k就是之前用到创建checkpoint的那个常数。 水位线 水位线机制用于限制消息序号的有效范围，包括： 低水位线(low-water mark) h； 高水位线(high water mark) H = h + k。 设置规则： 通常来讲，低水位线是最近的一个稳定检查点的seq#，而高水位线需要在低水位线上加上一个常量k。 k要足够大，避免需要频繁创建稳定检查点； 但**k又不能太大**，避免出现故障或错误，进行状态恢复时需要重放大量的请求数量。 作用： 在共识进行的过程中，由于节点之间的性能差距，可能会出现节点间运行速率差异过大的情况。部分节点执行的序号可能会领先于其他节点，导致于领先节点的共识数据长时间得不到清理，造成内存占用过大的问题，而高低水位的作用就是对集群整体的运行速率进行限制，从而限制了节点的共识数据大小。在执行到最高水位 H 时，如果低水位 h 没有被更新，节点会暂停执行序号更大的请求，等待其他节点的执行，待低水位 h 更新后重新开始执行更大序号的请求。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:3","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"视图切换 视图切换(view-change)是为了保证系统的高可用性，主要发生在： 主节点超时； 从节点认为主节点是拜占庭节点。 view-change通过定时器来进行切换，避免从节点长时间等待请求。 原文中是这样做的：在通常情况下，主节点将会发送 pre-prepare 来正常进行共识，从节点也可以通过该消息确认主节点是否存活，因此如果超过一段时间没有收到 pre-prepare 的话就会认为该主节点有问题； 工程上：在实际运行当中，长时间没有pre-prepare是常见的，因此一般会通过心跳+定时器来进行探测保活。 View-Change 过程 当从节点收到请求时，如果有定时器在运行就重置(reset)定时器，否则开启一个定时器。但是主节点宕机的时候，从节点i就会在当前视图v#中超时，这个时候该从节点i就会触发view-change： 从节点i会将视图切换为v#+1，停止接收除了checkpoint，view-change和new view-change以外的请求，同时广播消息\u003cVIEW-CHANGE, v#+1, seq#(stable_checkpoint), C-set, P-set, i\u003e (i)到集群： seq#是节点i知道的最后一个stable checkpoint的消息序号； C-set是节点i保存的 2f+1 个能够证明seq#(stable_checkpoint)是正确检查点的的消息集合； P-set是一个保存了seq#之后所有已经达到prepared状态消息的集合，通过P-set可以把原来的在稳定检查点之后确定的交易进行重新共识。 当视图(v#+1)中的**新主节点p1**接收到2f个有效的视图切换消息以后，p1就会广播消息\u003cNEW-VIEW, v#+1, V-set, Q-set\u003e (p)： V-set是p1收到的，包括自己发送的view-change的消息集合； Q-set是PRE-PREPARE状态的消息集合，是从P-set转换过来的： 主节点根据最新stable_checkpoint的seq# s 和P-set的最大seq# t，将[s, t]间的所有seq#创建pre-prepare消息成为Q-set； 从节点接收到NEW-VIEW消息后，校验签名，V和Q中的消息是否合法，如验证通过，将执行Q-set中的请求，然后主节点和从节点都进入视图v#+1。 C、P、Q 当p1接收到2f个VIEW-CHANGE消息以后，可以确定**stable checkpoint之前的消息在视图切换的过程中不会丢**。 但是**[当前检查点，下一个检查点]间已经通过PREPARE阶段的消息**可能会被丢弃，所以在视图切换到v+1后，PBFT会把旧视图中已经PREPARE的消息变为PRE-PREPARE，组成Q然后广播。 如果集合P为空，创建\u003cPRE-PREPARE, v#+1, seq#, null\u003e，接收节点就什么也不做； 如果集合P不为空，创建\u003cPRE-PREPARE, v#+1, seq#, d\u003e。 总结一下，在view-change中最重要的就是C，P，Q三个消息的集合： C确保了视图变更的时候，stable checkpoint之前的状态安全； P确保了视图变更前，已经PREPARE的消息的安全； Q确保了视图变更后，P-set中的消息安全。 回想一下pre-prepare和prepare阶段最重要的任务是保证同一个主节点发出的请求在同一个视图(view)中的顺序是一致的，而在视图切换过程中的C，P，Q三个集合就是解决这个问题的。 Leader 选举 在介绍 view-change 时，并没有说明在新的视图中，新主节点是如何选出来的，其实不同的系统做法不同： FISCO BCOS系统中，leader索引的计算公式如下： leader_idx = (view + block_number) % node_num ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:4","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"主动恢复 区块链网络在运行过程中由于网络抖动、突然断电、磁盘故障等原因，可能会导致部分节点的执行速度落后于大多数节点。在这种场景下，节点需要能够做到自动恢复才能继续参与后续的共识流程。 传统的PBFT并没有实现主动恢复的功能，但**RBFT提供了一种动态数据自动恢复的机制(recovery)，recovery 通过主动索取现有共识网络中所有节点的视图、最新区块高度等信息，更新自身的存储状态，最终同步至整个系统的最新状态**。 在节点启动、节点重启或者节点落后的时候，节点将会自动进入 recovery，同步至整个系统的最新状态。 比如，一个节点落后太多，这个时候它收到主节点发来的消息时，对消息进行水位检查会失败，当计时器超时，就会发送view-change的消息，但是由于只有自己发起view-change达不到2f+1个节点的数量，本来正常运行的节点就退化为一个拜占庭节点。 视图协商 新增/落后节点Replica 4发起NegotiateView消息给其他节点； 其余节点收到消息以后，返回NegotiateViewResponse消息，包含自己的视图信息，节点ID，节点总数N； Replica 4收到2f+1个NegotiateViewResponse消息后，则更新本节点的视图信息； Replica 4同步完视图后，广播RecoveryInit消息到其余节点，通知其他节点本节点需要进行自动恢复，请求其余节点的检查点信息和最新区块信息； 其余节点收到RecoveryInit后将自身最新的检查点信息和区块信息返回给Replica 4; Replica 4收到quorum个RecoveryResponse消息后，更新自己的检查点到最新； 更新完成后，还要向正常节点索要P-set、Q-set和C-set的信息，同步至全网最新状态。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:5","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"增删节点(随便看看而已) 传统的PBFT算法不支持节点的动态增删，RBFT 为了能够更加方便地控制联盟成员的准入和准出，添加了保持集群非停机的情况下动态增删节点的功能。 增加节点 Replica 5新节点加入的流程： 新增节点Replica 5主动向现有的所有节点发起连接，确认所有节点连接成功后更新自身的路由表，并发起recovery； 现有节点接收到Replica 5的连接请求后向全网广播AddNode消息，表明自己同意该新节点加入整个共识网络； 当现有节点收到N条（N为现有区块链共识网络中节点总数）AddNode消息后，更新自身的路由表，随后开始回应新增节点的共识消息请求（在此之前，新增节点的所有共识消息是不予处理的）； Replica 5完成recovery之后，向全网现有节点广播ReadyForN请求； 现有节点在收到ReadyForN请求后，重新计算新增节点加入之后的N，view等信息，随后将其与PQC消息封装到AgreeUpdateN消息中，进行全网广播； Replica 5加入后的共识网络会产生一个新的主节点，该主节点在收到N-f个AgreeUpdateN消息后，以新的主节点的身份发送UpdateN消息； 全网所有节点在收到UpdateN消息之后确认消息的正确性，进行VCReset； 每个节点完成VCReset后，全网广播FinishUpdate消息； 节点在收到N-f个FinishUpdate消息后，处理后续请求，完成新增节点流程。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:5:6","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"五、分布式ID⭐ 参考文章 问：什么是分布式ID？ 例如，多机 MySQL 中，也就是分库了，数据库的自增主键已经没办法满足生成的主键是唯一的了。如何在不同节点生成全局唯一的主键？ 这个时候就需要 分布式ID 。 问：分布式ID 需要满足啥条件？ 其实最主要的就是 全局唯一。 ==全局唯一==：ID 的全局唯一性肯定是首先要满足的！ 高性能：分布式 ID 的生成速度要快，对本地资源消耗要小。 高可用：生成分布式 ID 的服务要保证可用性无限接近于 100%。 除了这些之外，一个比较好的分布式 ID 还应保证： 安全：ID 中不暴露系统和业务的信息。 有序递增：如果要把 ID 存放在数据库的话，ID 的有序性可以提升数据库写入速度。并且，很多时候，我们还很有可能会直接通过 ID 来进行排序。 有具体的业务含义：生成的 ID 如果能有具体的业务含义，可以让定位问题以及开发更透明化（通过 ID 就能确定是哪个业务）。 独立部署：也就是分布式系统单独有一个发号器服务，专门用来生成分布式 ID。这样就生成 ID 的服务可以和业务相关的服务解耦。不过，这样同样带来了网络调用消耗增加的问题。总的来说，如果需要用到分布式 ID 的场景比较多的话，独立部署的发号器服务还是很有必要的。 ⭐问：分布式ID 常见的解决方案？ **==数据库主键自增==**⭐ 数据库自增 ID 是最常见的一种生成 ID 方式。优势是使用简单，满足基本业务需求，天然有序；缺点是强依赖 DB，会由于数据库部署的一些特性而存在单点故障、数据一致性等问题。 以 MySQL 举例，我们通过下面的方式即可。 创建一个数据库表。 CREATE TABLE `sequence_id` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `stub` char(10) NOT NULL DEFAULT '', PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; stub 字段无意义，只是为了占位，便于我们插入或者修改数据。并且给 stub 字段创建了唯一索引，保证其唯一性。 通过 replace into 来插入数据。 BEGIN; REPLACE INTO sequence_id (stub) VALUES ('stub'); SELECT LAST_INSERT_ID(); COMMIT; 插入数据这里，我们没有使用 insert into 而是使用 replace into 来插入数据，具体步骤是这样的： 第一步：尝试把数据插入到表中。 第二步：如果主键或唯一索引字段出现重复数据错误而插入失败时，先从表中删除含有重复关键字值的冲突行，然后再次尝试把数据插入到表中。 **优点：**实现起来比较简单、ID 有序递增、存储消耗空间小 **缺点：**支持的并发量不大、每次获取 ID 都要访问一次数据库 **==数据库号段模式==**⭐⭐ 数据库主键自增模式的话，某个节点每次获取 ID 都要访问一次数据库，这肯定不太好。因此，数据库号段模式就批量获取一批 ID，存在该节点的内存中，这样就可以每次用的时候就从内存中慢慢获取了，不够用了就再申请一批，美滋滋~~ 以 MySQL 举例，我们通过下面的方式即可。 创建一个数据库表。 CREATE TABLE `sequence_id_generator` ( `id` int(10) NOT NULL, `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id', `step` int(10) NOT NULL COMMENT '号段的长度', `version` int(20) NOT NULL COMMENT '版本号', `biz_type` int(20) NOT NULL COMMENT '业务类型', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; current_max_id 字段和step字段主要用于获取批量 ID，获取的批量 ID 为： current_max_id ~ current_max_id+step。 ==Redis 自增== 优势是不依赖于数据库，使用灵活，性能也优于数据库；而缺点则是可能要引入新的组件 Redis，如果 Redis 出现单点故障问题，则会影响序号服务的可用性。 通过 Redis 的 incr 命令即可实现对 id 原子顺序递增。 127.0.0.1:6379\u003e set sequence_id_biz_type 1 OK 127.0.0.1:6379\u003e incr sequence_id_biz_type (integer) 2 127.0.0.1:6379\u003e get sequence_id_biz_type \"2\" **==UUID==**⭐ UUID 由32位的16进制数组成，可以保证唯一性，有如下生成规则： 基于时间的 UUID：主要依赖当前的时间戳和机器 mac 地址。优势是能基本保证全球唯一性，缺点是由于使用了 mac 地址，会暴露 mac 地址和生成时间； 基于随机数的 UUID：基于随机数或伪随机数生成。优势是实现简单，缺点是重复几率可计算； 基于名字空间的 UUID(MD5 版)：基于指定的名字空间/名字生成 MD5 散列值得到，优势是不同名字空间/名字下的 UUID 是唯一的，缺点是 MD5 碰撞问题； 因为其生成规则包括 MAC 地址、时间戳、名字空间、随机或伪随机数、时序等元素，计算机基于这些规则生成的 UUID 是肯定不会重复的。 很少使用 UUID。 **优点：**生成速度快，简单易用； **缺点：**存储消耗空间太大(128位)、无序(非常影响MySQL的性能)、没有具体业务含义、有可能出现重复 ID、不安全(基于 MAC 地址生成的话，有可能会泄露 MAC地址) **==雪花算法(Snowflake)==**⭐⭐⭐ Snowflake 由 64 bit 的二进制数字组成，这 64bit 的二进制被分成了几部分，每一部分存储的数据都有特定的含义： 第 0 位：符号位(标识正负)，始终为 0，没有用，不用管。 第 1~41 位：一共 41 位，用来表示时间戳，单位是毫秒，可以支撑 2 ^41 毫秒(约 69 年) 第 42~51 位：一共 10 位，机器编码，一般来说，前 5 位表示机房 ID，后 5 位表示机器 ID(实际项目中可以根据实际情况调整)。这样就可以区分不同集群/机房的节点。 第 52~63 位：一共 12 位，用来表示序列号。序列号为自增值，代表单台机器每毫秒能够产生的最大 ID 数(2^12 = 4096)，也就是说单台机器每毫秒最多可以生成 4096 个 唯一 ID。 **优点：**单机生成的 ID 有序递增、生成速度比较快、比较灵活(可根据业务需求调整bit位)； 缺点：重复 ID 问题(强依赖时间，当机器时间回拨的情况下，可能导致会产生重复 ID)、ID 可能不是全局递增，虽然 ID 在单机上是递增的，但是由于涉及到分布式环境下的每个机器节点上的时钟，可能会出现不是全局递增的场景。 ==利用Zookeeper== zookeeper 是通过 树形结构 来存储数据节点的，那也就是说，对于每个节点的 全路径，它必定是唯一的，我们可以使用节点的全路径作为命名方式了。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:6:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"六、分布式锁⭐ 概述 分布式锁示意图： 一个最基本的分布式锁需要满足： 多进程可见⭐：你总得让人知道有锁的存在吧？ 互斥⭐：任意一个时刻，锁只能被一个线程持有； 高可用：锁服务是高可用的。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。 可重入：一个节点获取了锁之后，还可以再次获取锁。 分布式锁的实现，目前常用的方案有以下三类： 数据库乐观锁； 基于分布式缓存实现的锁服务，典型代表有 Redis 和基于 Redis 的 RedLock； 基于分布式一致性服务实现的锁服务，典型代表有 ZooKeeper 和 ETCD。 通常情况下，采用ZooKeeper或者Redis获得分布式锁，Redis用的多一些。 基于 Mysql 实现分布式锁 利用MySQL本身的互斥锁机制，主要是基于主键和唯一索引。比如说两个线程去同一个数据库表进行操作，利用主键冲突来保证。 基于 Redis 实现分布式锁 加解锁流程 加锁 SET lock_name my_random_value NX PX 30000 # SETNX 获得锁 lock_name：锁名(key)，在分布式环境中，对于某一确定的公共资源，所有争用方（客户端）都应该知道对应锁的名字，全局可知； my_random_value：随机字符串(value)，作为持有者的唯一标识，避免误删； NX：只有当lock_name不存在的时候才能 SET 成功，从而保证只有一个客户端能获得锁，而其它客户端在锁被释放之前都无法获得锁，保证互斥； PX 30000：表示这个锁节点有一个 30 秒的自动过期时间，避免死锁。 释放锁 首先，向 Redis 节点发送命令，获取锁对应的 Value GET lock_name 如果查询回来的 value 和客户端自身的 my_random_value 一致，则可确认自己是锁的持有者，可以发起解锁操作，即主动删除对应的 Key，发送命令： DEL lock_name 安全性分析 死锁避免 典型的死锁场景：获得锁的客户端，在释放锁之前崩溃了，导致锁一直无法被释放，进而导致死锁。 为了解决该问题，对锁设置了过期时间，当锁到期后，Redis 会自动删除该锁对应的 key-value，也就释放了锁。 但存在隐患，比如这个场景： 客户端 A 获取锁成功； 客户端 A 在某个操作上阻塞了很长时间； 过期时间到，锁自动释放； 客户端 B 获取到了对应同一个资源的锁； 客户端 A 从阻塞中恢复过来，认为自己依旧持有锁，继续操作同一个资源，导致互斥性失效。 为了解决该问题，有如下方案： 有隐患的方案，但网上很多都是这样做的。第 5 步中，客户端 A 恢复后，可以比较下目前已经持有锁的时间，如果发现已经过期，则放弃对共享资源的操作，即可避免互斥性失效的问题。但分布式中，各节点的时钟不一定是强一致的，导致了一定的隐患。其实，任何依赖两个节点时间比较结果的互斥性算法，都存在隐患； 可取的方案。可以比较 my_random_value，即客户端 A 恢复后，在操作共享资源前应比较目前自身所持有锁的 my_random_value 与 Redis 中存储的 my_random_value 是否一致，如果不相同，说明已经不再持有锁，则放弃对共享资源的操作以避免互斥性失效的问题。 解锁操作的原子性 为了保证解锁的正确性，引入了my_random_value。具体的解锁过程就分成了两步： 先查询(GET)锁对应的 Value，与自己加锁时设置的 my_random_value 进行对比； 如果相同，则可确认这把锁是自己加的，然后再发起解锁(DEL)。 但是，GET 和 DEL 是两个操作如果是非原子性的，那么解锁本身也会存在破坏互斥性的可能。 比如在查询完，释放前，又阻塞了很长时间。下面是典型场景： 客户端 A 获取锁成功； 客户端 A 访问共享资源； 客户端 A 为了释放锁，先执行 GET 操作获取锁对应的随机字符串的值； 客户端 A 判断随机字符串的值，与预期的值相等； 客户端 A 由于某个原因阻塞了很长时间； 过期时间到了，锁自动释放了； 客户端 B 获取到了对应同一个资源的锁； 客户端 A 从阻塞中恢复过来，执行 DEL 操纵，释放掉了客户端 B 持有的锁。 为了解决该问题，有如下方案： Redis 支持 Lua 脚本并保证其原子性，使用 Lua 脚本实现锁校验与释放，并使用 Redis 的 eval 函数执行 Lua 脚本。 // Lua脚本，用于校验并释放锁 String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; // 执行Lua脚本，校验并释放锁 jedis.eval(script, Collections.singletonList(\"lock_name\"), Collections.singletonList(\"my_random_value\")); 主备切换的一致性 当主从切换时，由于 Redis 的主从复制是异步的，就可能导致切换过程中丧失锁的安全性。 典型场景： 客户端 A 从 Master 获取了锁； Master 宕机了，存储锁的 Key 还没有来得及同步到 Slave 上； Slave 升级为 Master； 客户端 B 从新的 Master 获取到了对应同一个资源的锁； 客户端 A 和客户端 B 同时持有了同一个资源的锁，锁的安全性被打破。 可以通过 RedLock 来解决。 运行 Redlock 算法的客户端依次执行以下步骤，来进行加锁的操作： 获取当前系统时间（毫秒数）； 按顺序依次向 N 个 Redis 节点执行获取锁的操作。这个获取操作跟前面基于单 Redis 节点获取锁的过程相同，包含随机字符串 my_random_value，也包含过期时间（比如 PX 30000，即锁的有效时间）。为了保证在某个 Redis 节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间（Time Out），它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个 Redis 节点获取锁失败以后，应该立即尝试下一个 Redis 节点。这里的失败，应该包含任何类型的失败，比如该 Redis 节点不可用； 计算获取锁的整个过程总共消耗了多长时间，计算方法是用当前时间减去第 1 步记录的时间。如果客户端从大多数 Redis 节点（\u003e=N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间（Lock Validity Time），那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败； 如果最终获取锁成功了，就要重新计算这个锁的有效时间，等于最初的锁的有效时间减去第 3 步计算出来的获取锁消耗的时间； 如果最终获取锁失败了（可能由于获取到锁的 Redis 节点个数少于 N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有 Redis 节点发起释放锁的操作。 释放锁的过程比较简单：即客户端向所有 Redis 节点发起释放锁的操作，不管这些节点在获取锁的时候成功与否。 但 RedLock也有缺陷(如下场景)，一般不建议用这种方式，真要用的话，真不如用Zookeeper来做。 如下场景，假设一共有 5 个 Redis 节点：A、B、C、D、E。 客户端 1 成功锁住了 A、B、C，获取锁成功（但 D 和 E 没有锁住）。 节点 C 时间异常，导致 C 上的锁数据提前到期，而被释放。 客户端 2 此时尝试获取同一把锁：锁住了C、D、E，获取锁成功。 可重入 问：如何实现可重入锁？⭐ 可重入锁指的是在一个线程中可以多次获取同一把锁，比如一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法即可重入，而无需重新获得锁。 可重入分布式锁的实现核心思路是线程在获取锁的时候判断是否为自己的锁，如果是的话，就不用再重新获取了。 实现思路：可以为每个锁关联一个可重入计数器和一个占有它的线程。若可重入计数器大于 0，则表示锁被占有，需要判断占有该锁的线程和请求获取锁的线程是否为同一个。每次获取锁时，计数器+1，每次释放锁时，计数器-1。 问：如果对资源的操作还未结束，锁就到期了咋办？⭐ 这就涉及到如何给锁优雅的续期了。有非常成熟的解决方案：Java-Redisson、Go-Redsync等。。。 **原理简单来说就是：**提供了一个专门用来监控和续期锁的 Watch Dog（ 看门狗），如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。 基于 Zookeeper 实现分布式锁 主要是利用临时顺序节点。 问：怎么利用 Zookeeper 实现分布式锁呢？能实现共享锁和独占锁嘛？ 主要是利用创建节点的有序性。 可以让多个客户端在指定节点(通常是持久节点)下创建临时顺序节点，判断自己创建的是否是有序节点中序号最小的那个，若是就获得锁；若不是，就通过Watcher进行监听，若自己前边的序号都失效了，就说明锁释放了，就可以通过回调函数尝试得到该锁。 同时实现共享锁和独占锁： 读请求：如果 没有比自己更小的节点，或比自己小的节点都是读请求，则可以获取读锁； 写请求：如果 没有比自己更小的节点，则可以获得写锁。 为避免羊群效应，可以让","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:7:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"七、分布式事务 分布式事务指事务的参与者、支持事务的服务器、资源服务器、事务管理器分别位于不同的分布式系统的不同节点上，分布式事务要保证这些操作要么全部成功要么全部失败。**本质上：**就是为了保证不同数据库的一致性。 ","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:8:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"八、Zookeeper Zookeeper 基础理论 问：Zookeeper 是什么？ Zookeeper 是一个分布式一致性解决方案集，保证了 CP，可用来实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 ZooKeeper 将数据保存在内存中。 问：Zookeeper 具有哪些特性？⭐ 顺序一致性⭐：从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。实现原理：原子广播。 **原子性⭐：**所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。实现原理：事务。 单一视图⭐：无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 **高可用⭐：**基于副本机制实现，此外 ZooKeeper 支持故障恢复。实现原理：选举 Leader。 **高性能：**ZooKeeper 将数据全量存储在内存中，所以其性能很高。 问：Zookeeper 有哪些数据类型？⭐ zookeeper 数据模型采用树形结构，使用了 znode 作为数据节点。 znode 是 zookeeper 中的最小数据单元，每个 znode 上都可以保存数据，同时还可以挂载子节点，形成一个树形化命名空间。 持久节点：一旦创建就一直存在(即使 ZooKeeper 集群宕机)，直到主动将其删除； **临时节点：**临 客户端会话（session）结束则节点消失 。并且，临时节点只能做叶子节点，不能创建子节点； 持久顺序节点：除了具有持久节点的特性外，节点ID还具有顺序性，如/node1/app0000000001、/node1/app0000000002 **临时顺序节点：**除了具有临时节点特性外，节点ID还具有顺序性。 每个 znode 由 2 部分组成: stat：状态信息； data：节点存放的数据的具体内容。 问：Zookeeper 集群中有哪些角色？⭐ 共有 Leader、Follower 和 Observer 三种角色： Leader： 负责发起并维护与各 Follower 及 Observer 间的心跳； 所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器； 一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader。 Follower： 响应 Leader 的心跳； Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票； 一个 Zookeeper 集群可能同时存在多个 Follower。 Observer：角色与 Follower 类似，但是无投票权。 Zookeeper 工作原理 读操作 Leader/Follower/Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。 由于处理读请求不需要服务器之间的交互，Follower/Observer 越多，整体系统的读请求吞吐量越大，也即读性能越好。 写操作 所有的写请求实际上都要交给 Leader 处理。Leader 将写请求以事务形式发给所有 Follower 并等待 ACK，一旦收到半数以上 Follower 的 ACK，即认为写操作成功。Follower/Observer 均可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理。 问：Watcher(事件监听器) 有啥用？⭐ 客户端注册监听它关心的 znode，当 znode 状态发生变化(数据变化、子节点增减变化)时，ZooKeeper 服务会推送给客户端。 Watcher 可以实现分布式锁、发布订阅等功能。 问：会话机制？(Zookeeper 是咋推送给客户端的呢？) 客户端通过TCP 长连接与 ZooKeeper 服务集群建立会话(Session)，之后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也可以接收到 Watch 事件的通知。 每个会话都会有一个超时时间，客户端通过心跳方式(ping)来保持会话不过期，若服务器在超时时间内没有收到任何请求或心跳，则相应会话被视为过期。 ZAB 协议 ZAB 协议主要定义了两个可以无限循环的流程： 崩溃恢复：用于故障恢复。当主节点出现故障时，选举 Leader，从而保证高可用。 原子广播：用于主从同步，从而保证数据一致性。 在 ZAB 中很重要的字段： **zxid：**是一个 64 位长度的 Long 类型。其中高 32 位表示 epoch，低 32 表示 xid； $$ zxid = (epoch, xid) $$ epoch：每个 Leader 都会具有一个不同的 epoch，用于区分不同的时期（可以理解为朝代的年号）； xid：事务 id，是一个流水号。每次朝代更替，即 leader 更换时，会重新从 0 开始递增； 每当选举产生一个新的 Leader ，就会从这个 Leader 服务器上取出本地事务日志中最大编号 Proposal 的 zxid，并从 zxid 中解析得到对应的 epoch 编号，然后再对其加 1，之后该编号就作为新的 epoch 值，并将低 32 位数字归零，由 0 开始重新生成 zxid。 **myid：**节点id。 问：Zookeeper 如何实现高可用？崩溃恢复/选举过程是啥样的？⭐⭐ Zookeeper 通过副本机制，副本机制通过原子广播实现，当 Leader 出现故障时，会进行崩溃恢复来保证高可用。 关键点：保证选举出的新 Leader 拥有集群中所有节点中最大编号(zxid)的事务！！ 崩溃恢复的过程大致是这样的： **自增选举轮次：**每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作； 初始投票：每个服务器最开始都通过广播把票投给自己，投票内容为所投票服务器的 myid 和 zxid； 接收外部投票：每个服务器都会接收其它服务器的投票，并记入自己的投票箱内； **判断选举轮次：**收到外部投票后，首先会根据投票信息中的 logicClock 进行判断： 若外部投票的 logicClock 大于自己的，说明自己落后，会立即清空并更新自己的投票箱； 若外部投票的 logicClock 小于自己的，直接忽略该选票； 若等于，就将该选票存入投票箱，之后进行投票 PK； **投票 PK：**每个节点都只有一票，这步就是确定最终投给谁。**优先选择 zxid 大的，然后选择 myid 大的。**然后将最终投票广播出去； **统计选票：**若某个 Server 的投票数大于半数以上，则该 Server 就成为了 Leader； **同步状态：**利用 leader 前一阶段获得的最新提议，同步集群中所有的副本。同步完成之后，就可以对外提供服务了。 问：Zookeeper 如何实现分布式数据一致性？⭐⭐ Zookeeper 主要依赖 ZAB 协议来实现分布式数据一致性，ZAB协议是顺序一致性的。主要是通过原子广播来保证。 详细过程： ZooKeeper 中所有的写请求都由 Leader 节点来处理： 客户端的写请求进来之后，Leader 会将写请求包装成 Proposal 事务，并添加一个递增事务 ID，也就是 Zxid。Zxid 是单调递增的，以保证每个消息的先后顺序； 广播这个 Proposal 事务。Leader 会为每一个 Follower 服务器分配一个单独的 FIFO 队列，然后把 Proposal 放到队列中； Follower 节点收到对应的 Proposal 之后会把它持久到磁盘上，当完全写入之后，发一个 ACK 给 Leader； 当 Leader 收到超过半数 Follower 的 ACK 之后，会提交本地机器上的事务，同时开始广播 commit； Follower 收到 commit 之后，完成各自的事务提交。 问：Zookeeper 如何保证事务(Proposal)发送的顺序性？⭐⭐ 如果Follower收到事务的顺序不同，那么会造成数据不一致的。 主要是靠**Zxid和队列**： Leader会为每个事务分配一个全局递增的事务ID(Zxid)，生成事务后，按照该 ID 进行排序，以保证顺序； Leader会为每一个Follower分配一个单独的队列，然后将事务 Proposal 依次放入队列中，并根据 FIFO(先进先出) 的策略进行消息发送。 问：为啥集群中的机器最好是奇数台？ Zookeeper集群中，存活主机数目 \u003e 宕机数目 时，才能继续提供服务。 也就是说，2n 和 2n-1 的容忍度是一样的，都是 n-1。既然多出一台也一样，那何必呢？ 问：Zookeeper 集群如何防止脑裂现象？⭐ ==采用过半机制。==在收到大于一半的选票才能成为 Leader。 ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。 Zookeeper 应用 参考链接 因为Zookeeper的强一致性，可以保证在高并发情况下创建全局唯一的节点。 分布式ID 在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，ZooKeeper 可以通过顺序节点的特性来生成全局唯一 ID，从而可以对分布式系统提供命名服","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:9:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"九、Etcd 主要参考： 深入解读RAFT算法与ETCD工程实现 ETCD原理与实现 Etcd 是一个基于 Raft 共识算法实现的分布式键值存储服务，是 K8s 的核心存储。在项目结构上采用了模块化设计，其中最主要的三个部分是实现分布式共识的 Raft 模块、实现数据持久化的 WAL 模块和实现状态机存储的 MVCC 模块。 更详细的架构图如下： api 接口支持 http 协议和 grpc 协议； node 主要负责 raft 算法的实现； storage 主要负责 raft 日志以及 snap 快照文件的存储； transport 主要负责集群节点间的通信； kvstore 分为 v2 和 v3 两个版本数据库，主要负责业务数据的存储，其中 v3 版本数据库的实现采用 lboltdb 和 keyIndex，支持 mvcc 机制。 RAFT 模块 ==日志复制== 在分布式环境中，如果我们要让一个服务具有容错能力，最常用的方法就是让一个服务的多个副本同时运行在多个节点上。为了保证多个副本在运行时的状态都是同步的，即客户端无论将请求发送到哪一个节点中，最后都能得到相同的结果，通常采用状态机复制（State Machine Replication）方法。 Etcd使用日志复制实现。Etcd 将日志实例化为 Entry 日志，每个节点会存储一系列 Entry 日志，每个节点的 Entry 日志都相同并且顺序也一致，状态机按顺序执行 Entry 中的命令，因此每个状态机处理相同的命令序列，这样就能得到相同的数据状态和输出序列。 RAFT 就是用来保证复制日志的一致性。服务器节点上的Consensus模块接收来自客户端的写请求，将它们添加到 WAL (Write Ahead Log，预写日志）中。随后该服务器与其他服务器上的Consensus模块通信，以确保每个服务器上具有相同的日志序列。每个服务器上的状态机按顺序执行命令，并将执行结果返回给客户端，这样就形成了高可用的复制状态机。 数据通道 为了网络层能够高效地处理不同数据量的消息，etcd 采取分类处理的方式，它抽象出 2 种类型的消息传输通道： **Stream 通道：**用于处理数据量较少、发送比较频繁的消息，例如心跳消息、追加日志消息等，节点与节点之间只维护 1 个 HTTP 长连接，交替向连接中写入数据； **Pipeline 通道：**用于处理数据量大的消息，比如传输快照消息。这种类型的消息需要与心跳消息等分开处理，否则会阻塞心跳包的传输，进而影响集群的稳定性。Pipeline 通道只通过短连接传输数据，用完即关闭。 这两种消息传输通道都使用 gRPC 传输数据。 ==Leader 选举== Raft 通过『leader 选举机制』选举出一个 Leader，由它全权管理日志复制来实现一致性。 Raft 算法论文规定了三种节点身份：Leader、Follower 和 Candidate，Etcd 的实现中又添加了 PreCandidate 和 Learner 这两种身份。 集群启动时所有节点初始状态均为 Follower，随后会有一个节点选举成功成为 Leader，在绝大多数时间里集群内的节点会处于这两种身份之一； 当一个 Follower 节点的选举计时器超时后，会切换为 PreCandidate 身份，进行**preVote**，不自增任期号仅发起预投票，也就是询问集群中其他节点是否愿意参与选举： 如果集群中的其它节点能够正常收到 Leader 的心跳消息，那么会拒绝参与选举； 如果有超过法定人数的节点响应并表示参与新一轮选举，该节点会从 PreCandidate 身份切换到 Candidate，自增任期号并投票给自己，并向其他节点广播竞选投票信息； 当节点收到其他节点的竞选消息后，首先判断竞选节点的任期号大于本节点，则可以投票给竞选节点，否则拒绝投票。 当一个节点成为 Leader 后会立即提交一条空日志，将自身携带的所有日志都设置为提交状态，包括由其它 Leader 创建但还没有提交的日志条目，然后向集群内的其它节点同步。这样就可以保证集群数据的一致性，防止 Leader 节点切换过程中发生数据丢失。 当一个新节点刚进入集群，此时就是 Learner 身份，主要是因为需要花费很长时间来同步日志，这可能导致集群无法处理新的请求，为了避免这种间隔，所以 Learner 不具有投票权，接收 Leader 发来的快照以快速赶上日志，当和Leader日志一致后会转变身份为 Follower。 Entry Raft 模块维护的**所有数据（键值对）**都被实例化为 Entry 日志表示。 Raft 算法中所有写请求都是由 Leader 节点处理的，如果收到提案的节点是 Follower，它会转发给 Leader。 Leader 收到提案后，需要对客户端发送的数据封装为 Entry 日志： Data字段是客户端发送的键值对； Term字段是当前集群的任期； Index字段是该 Entry 日志的索引，相当于全局唯一标识 ID。 封装完数据后会将这些 Entry 日志追加到 Raft Log 中。 写请求流程 client 通过负载均衡算法选择一个 Etcd 节点，发起 gRPC 调用，发送 K-V 请求； 经过检验之后，传递提案给上层，RAFT 模块收到提案后，若当前节点是 Follower，就会转发给 Leader，只有 Leader 才能处理写请求； Leader 收到提案后，通过 RAFT 模块生成 Entry，并保存到 unstable中； Leader 获得 Entry 后，会将其写入 WAL 文件，同时将其广播给集群中的其他节点； 然后 Leader 的 RAFT 模块会把该 Entry 移到 MemoryStorage； 待该 Entry 日志被复制到集群半数以上的节点时，该 Entry 日志会被 Leader 节点确认为己提交，Leader 会回复客户端写请求操作成功； 然后 Leader 将该 Entry 应用到状态机。 线性一致读 ETCD 中，所有的写请求都只由Leader处理，再通过日志复制的方法同步给其他Follower。 但所有的节点(Leader+Follower)都可以处理读请求。由于以下原因，从不同的节点读数据可能会出现不一致: Etcd 应用日志的过程是异步的，Follower的状态总的落后于Leader，且Follower之间的状态也可能存在差异； 若出现网络分区，进而出现脑裂，新旧Leader的状态也会不一致。 也就是说，各个节点并非是 实时 一致，所以读取数据很有可能读取到不一致的旧数据。 问：怎么解决线性一致读问题？⭐ Etcd 采用 ReadIndex 机制实现线性一致读，基本原理： Leader首先通过某种机制确认自己依然是Leader； Leader需要给客户端返回最近已应用的数据：即最新被应用到状态机的数据。 流程如下： 当 Follower 节点收到一个线性读请求时，它首先会向 Leader 请求获取集群最新的、已提交的日志索引，记为ReadIndex； Leader 收到 ReadIndex 请求时，会向 Follower 发送心跳消息，如果超过法定人数的节点响应了心跳消息，就说明自己是合法的 Leader，然后才能将读时已提交的索引返回给请求节点； Follower 拿到后，等待状态机『至少』应用到ReadIndex，即 AppliedIndex \u003e= ReadIndex，然后执行读请求，将结果返回给 Client。 日志存储 RAFT 共有两类数据需要持久化存储： **RAFT 日志：**已提交的日志是不能丢失的； 节点的状态：包括当前的任期 term、当前的投票目标 vote、已提交的最后一条日志索引。前两个字段是 leader 选举流程中的承诺，第三个字段是节点在重启恢复时用来控制日志回放到哪一条日志。 WAL 问：什么是 WAL ？ ETCD 使用 WAL(Write Ahead Log，预写日志) 保存上面两种数据。 所有数据在提交之前都要先写入 WAL 中； 然后定期对数据进行快照备份，快照文件存储了某一时刻 ETCD 的所有数据，数据已经存储在快照中的 WAL 文件就可以删除。 问：WAL 如何工作？ WAL 的工作过程非常像区块链： 首个 WAL 文件的文件开头 crc32 初始值为 0，之后每个记录(raft 日志或者节点状态)的 crc32值 = calc(pre_crc32, 本记录的二进制值)； 对于第二个及以后的 WAL 文件，文件开头的初始 crc32 值 = 上一个 wal 文件最后一条记录的 crc32 值。 这样的话，所有 WAL 文件，其所有记录的 crc32 值可以形成一个可进行强校验的链表。这样在重启恢复的时候，ETCD 就可以对 WAL 文件的内容进行精细化的校验。 日志压缩 WAL 是一种 Append Only 的日志文件，只会在文件结尾不断地添加新日志。当数据量越来越大，WAL 文件就会越来越大，会占用大量空间，并且，通过这么大的 WAL 文件进行数据恢复时，也会耗费很长时间。因此，同 Redis 一样，会定期创建快照，将整个节点的状态进行序列化，然后写入稳定的快照文件中，在该快照文件之前的日志记录就可以全部丢弃掉。 在 RATF 日志中，首先定义几个概念： **log_index：**最新的日志位置索引。 **commit_index：**已达成多数派一致，可提交的最大日志位置索引。 appl","date":"0001-01-01","objectID":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/:10:0","tags":null,"title":"","uri":"/09-%E5%88%86%E5%B8%83%E5%BC%8F/"},{"categories":null,"content":"前言：**用来记录Go的语言特性，主要参考为B站《幼麟实验室》及《深度探索Go语言》。 一、基础知识 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:0:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.1 数据结构 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.1.1 String 编码：定长编码非常浪费内存，所以采用变长编码。**那么怎么划分边界呢？**最高几位空出来作为标识位，标记该字符占用几个字节。 这是 Go 默认的编码方式：UTF-8 编码： ==string的结构：== 一个起始地址：用来标记字符串起始位置；但是怎么找到结尾呢？C 是在字符串结尾处放个\\0，但这限制了内容不能出现这个字符，所以 Go 并不这样做； 一个字符串长度：用来标记该字符有多长(字节个数，而不是字符个数！)，这样就能够找到字符串在哪结束了。 Go 的字符串内容不能修改，所以 Go 的编译器会把定义好的字符串内容分配到只读内存段。可以通过[]byte()将字符串转换为字节slice，这样会为slice变量重新分配一段内存，并拷贝之前字符串的内容，可脱离只读内存的限制。 问：rune 和 byte 的区别？ 本质区别就是： type byte = uint8 type rune = int32 rune 等同于 int32，即4个字节长度，常用来处理 unicode 或 utf-8 字符。比如用来处理中文字符。 byte 等同于 uint8，即一个字节长度，常用来处理 ascii 字符(共128个)。 在go中修改字符串，需要先将字符串转化成数组，[]byte 或 []rune，然后再转换成 string 型。 str := \"你好 world\" // str[i] 其实是 byte for i := 0; i \u003c len(str); i++ { fmt.Printf(\"%c\", str[i]) // ä½\u0026nbsp;å¥½ world } // 使用range，其实是使用rune类型来编码的，rune类型用来表示utf8字符，一个rune字符由一个或多个byte组成。 for _, value := range str { fmt.Printf(\"%c\", value) // 你好 world } ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:1","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.1.2 Slice 1.1.2.1 数据结构 Slice 有三个部分： 元素存哪里(data) 存了多少个元素(len) 可以存多少个元素(cap) 例如： 若通过var ints []int或new创建数组，data是该数组的起始地址，但初始化为nil，len=0，cap=0，因为不会开辟底层内存给它； 若通过make([]int, 2, 5)创建数组，不仅会分配上述三部分，还会开辟一段内存作为它的底层数组； 1.1.2.2 append append可以为没有底层内存空间的Slice开辟一段内存，并赋值。 可以把不同的Slice关联到同一个数组，它们会共用底层数组，例如： 这三个Slice访问和修改的都是同一个底层数组，s1和s2若访问超过其len的元素，会产生访问越界。 上图中，若再给s2添加元素会怎样？这个底层数组是不能用了，得开辟新数组，原来的元素要拷贝过去，还要添加新元素，此时s2就不指向原底层数组了： 1.1.2.3 ==扩容规则== 当使用append添加元素，容量不够时，该怎么重新分配容量呢？ 预估扩容后的容量： 预估规则： oldLen*2 \u003c cap：旧容量*2 还是小于最少要分配的容量，那么就分配最少要分配的容量，此处为5； 否则：oldLen \u003c 1024时，直接 *2，oldLen \u003e= 1024时，就先扩 1/4。 **预估元素需要占用多大内存：**直接分配 预估容量 * 元素类型大小 内存可以嘛？不可以的！因为不一定有刚好一样大的预置规格的内存块。这就是第三步要做的事。 匹配到合适的内存规格：之前例子中，预估容量为 5，64位下就需要申请 40 字节内存，而最接近的内存规格为 48 字节。也就是能装 6 个该元素，所以 扩容后容量为 6。 分配完新的底层 Array 空间后，就把原 Array 中的数据拷贝到新的上面。 问：Slice 和 Array 有啥区别？ arr := [2]int{1, 2} // 声明了一个数组 sli := []int{1, 2} // 声明了一个Slice Array 长度是固定的；Slice 是动态数组，长度可变； Slice 是在 Array 基础上实现的，Slice有仨字段，首个就是对底层 Array 的引用，所以 Slice 是引用型。 在 C 语言中，数组变量是指向第一个元素的指针，但是 Go 语言中并不是。 由于值传递，数组进行赋值、传递时，实际上会复制整个数组： a := [...]int{1, 2, 3} // ... 会自动计算数组长度 b := a // 值拷贝，复制整个数组 a[0] = 100 fmt.Println(a, b) // [100 2 3] [1 2 3] // 为了避免复制数组，一般会传递指向数组的指针。 a := [...]int{1, 2, 3} b := \u0026a (*b)[0] = 100 fmt.Println(a, *b) // [100 2 3] [100 2 3] 问：Slice 的性能陷阱？ 大量内存得不到释放 在已有切片的基础上进行切片，不会创建新的底层数组。因为原来的底层数组没有发生变化，内存会一直占用，直到没有变量引用该数组。因此很可能出现这么一种情况，原切片由大量的元素构成，但是我们在原切片的基础上切片，虽然只使用了很小一段，但底层数组在内存中仍然占据了大量空间，得不到释放。比较推荐的做法，使用 copy 替代 re-slice。 // 1. 无法释放 origin，造成内存浪费 func lastNumsBySlice(origin []int) []int { return origin[len(origin)-2:] } // 2. 自动回收 origin，节省内存 func lastNumsByCopy(origin []int) []int { result := make([]int, 2) copy(result, origin[len(origin)-2:]) return result } ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:2","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.1.3 结构体与内存对齐 太强了，看视频吧去。拨云见日，茅塞顿开！ 1.1.3.1 访问内存 CPU是将内存地址通过地址总线传输给内存，内存准备好数据后通过数据总线传给CPU： 若想一次读取 8字节 的数据，就需要64位数据总线，这里的数据总线位数就是机器字长。如何能只传输一个地址，读取 8字节 数据呢？ 为了更高的访问效率，内存布局如下：就是8个chip排列在一起(每个chip由8个bank组成，即 1字节 内存)，共用同一个内存地址，各自寻找 1字节，然后组合起来成为 8字节： 所以每次访问内存都只能从起始地址%8==0处开始访问。 1.1.3.2 内存对齐 为了提高访问效率(保证一次读取)，编译器会把各种类型的数据安排到合适的地址，并占用合适的长度。 内存对齐要求数据存储起始地址，及占用的字节数都要是它对齐边界的倍数： 1.1.3.3 结构体对齐 共两个条件： 各成员要对齐边界； 结构体总内存大小 % 对齐边界 == 0。 可以看出，结构体各字段的顺序会影响结构体占用内存的大小。 ==为什么要有结构体总内存大小 % 对齐边界 == 0？== 如下情况，若不是整数倍的话，只有第一个T的内存是对齐的，第2个T就没有对齐。 问：什么是内存对齐？ 答：为了提高访问效率，编译器会把各种类型的数据安排到合适的地址，并占用合适的长度。内存对齐要求数据存储起始地址，及占用的字节数都要是它**==对其边界==的倍数**。 问：如何确定数据类型的对齐边界？ 机器字长是最大对齐边界，而数据类型的对齐边界是：min(类型大小, 最大对齐边界)。 ==为什么不统一按照最大对齐边界或类型大小分配呢？== 为了减少浪费，提高性能。 如果是int8类型，只占 1字节，若对齐到最大边界，就会浪费 7字节，所以对齐到 1字节 最合适； 如果是int64类型，占用 8字节，若对齐到 8字节，如下情况中就会浪费前面的 6字节，所以对齐到最大对齐边界最合适。 如果是结构体类型，对齐边界就是包含类型中最大的对齐边界。 问：为什么要内存对齐？ 有些CPU能访问任意地址，是因为做了处理：比如读1-8的内存：会先读0-7，只取1-7，再读8-15，只取8，组合起来就是1-8，但是这样会降低访问效率。为了避免这样读取，因此要内存对齐。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:3","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.1.4 Map 1.1.4.1 概述 Map主要由哈希函数和桶组成。 哈希函数用来实现key-value的映射，是决定哈希表的读写性能的关键，哈希函数映射的结果一定要尽可能均匀。如果使用结果分布较为均匀的哈希函数，那么哈希的增删改查的时间复杂度为 O(1)；但是如果哈希函数的结果分布不均匀，那么所有操作的时间复杂度可能会达到 O(n)。 桶用来解决哈希映射的冲突问题，常见方法有：开放寻址法和拉链法。 ==Point 1：== 因为哈希之后的地址空间通常远大于实际地址空间，因此需要对哈希值进行处理，常用有两种方法： 取模法：hash % m； 与运算(Go采用)：hash \u0026 (m-1)。这里m必须是2的整数次幂，这样可以确保不会出现空桶。 ==Point 2：== 上述对哈希值的操作会造成哈希冲突，因此需要对哈希冲突进行处理，常用有两种方法，如图所示： 开放寻址法： 写入：对当前元素进行哈希映射得到地址，若该地址空闲，可以直接填入；若已被占用，则需要将当前元素分配在该地址后的空闲地址； **读取：**若映射地址中存储元素的Key与当前元素的Key不同，则需要遍历该地址之后的地址空间，直到地址为空或找到目标Key。 拉链法（最常用）： 写入：对当前元素进行哈希映射得到地址，若该地址空闲，可以直接填入；若已被占用，则需要在链表的末尾追加新的键值对； **读取：**遍历映射地址的键值对链表，直到搜索到相同的Key(存在)或链表末尾(不存在)。 1.1.4.2 数据结构 runtime.hmap 是最核心的结构体： type hmap struct { count int // 记录 已存储键值对的数目 flags uint8 B uint8 // 记录 桶(buckets)的数目是2的多少次幂 noverflow uint16 // 记录 使用的溢出桶的数目 hash0 uint32 // 哈希的种子，为哈希函数的结果引入随机性 buckets unsafe.Pointer // 记录 桶的位置 oldbuckets unsafe.Pointer // 记录 扩容阶段旧桶的位置，大小是当前 buckets 的一半 nevacuate uintptr // 记录 扩容阶段旧桶迁移进度：下一个要进行迁移的旧桶编号 extra *mapextra // 记录 溢出桶相关信息 } // 记录溢出桶相关信息 type mapextra struct { overflow *[]*bmap // 记录 目前已被使用的溢出桶的地址 oldoverflow *[]*bmap // 记录 扩容阶段旧桶使用到的溢出桶的地址 nextOverflow *bmap // 下一个空闲溢出桶 } type bmap struct { topbits [8]uint8 // 每个topbit都是对应hash值的高8位，索引 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr // 溢出桶，布局与常规bmap相同，是为了减少扩容次数 } Go语言中，Map类型的变量本质上是一个指向hmap结构体的指针。 使用的桶的数据结构为bmap结构，每一个bmap都能存储8个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 extra.nextOverflow 中的桶存储溢出的数据。随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用更多溢出桶存储溢出的数据。 1.1.4.3 初始化 ==字面量：== Go语言中通过key: value的方法表示键值对，可以通过如下方式初始化： hash := map[string]int{ \"1\": 2, \"3\": 4, \"5\": 6, } 当**哈希表中的元素数量 \u003c= 25 **时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： hash := make(map[string]int, 3) hash[\"1\"] = 2 hash[\"3\"] = 4 hash[\"5\"] = 6 当**哈希表中的元素数量 \u003e 25 **时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： hash := make(map[string]int, 26) vstatk := []string{\"1\", \"2\", \"3\", ... ， \"26\"} vstatv := []int{1, 2, 3, ... , 26} for i := 0; i \u003c len(vstak); i++ { hash[vstatk[i]] = vstatv[i] } ==运行时：== 根据传入的B来确定需要创建的桶的数量： 若桶的数量 \u003c 2^4，此时认为数据量较小，使用溢出桶的概率较低，因此不创建溢出桶； 若桶的数量 \u003e 2^4，会额外创建2^(B-4)个溢出桶。 **注意：**正常桶和溢出桶在内存中的存储空间是连续的。 1.1.4.4 读写操作 ==访问：== 共有两种访问方式： v := hash[key] // =\u003e v := *mapaccess1(maptype, hash, \u0026key) v, ok := hash[key] // =\u003e v, ok := mapaccess2(maptype, hash, \u0026key) 赋值语句左侧接受参数的个数会决定使用的运行时方法： 当接受一个参数时，会使用 runtime.mapaccess1，该函数仅会返回一个指向目标值的指针（感觉这里的指针并不是一个地址，感觉还是目标值）； 当接受两个参数时，会使用 runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 bool 值。 查找过程⭐：哈希会依次遍历正常桶和溢出桶中的数据，它会先比较哈希的高 8 位和桶中存储的 tophash(==减少key的对比次数，缩小查找成本==)，后比较传入的和桶中的key(==因此key需要是可比较类型==)以加速数据的读写。 每一个桶都是一整片的内存空间，当发现桶中的 tophash 与传入键的 tophash 匹配之后，我们会通过指针和偏移量获取哈希中存储的键 keys[x] 并与 key 比较，如果两者相同就会获取目标值的指针 values[x] 并返回。 ==写入：== 首先会根据传入的key拿到对应的哈希和桶，然后通过遍历比较桶中存储的 tophash 和key的哈希， 如果当前键值对在哈希中存在，那么就会直接返回目标区域的内存地址； 如果当前键值对在哈希中不存在，哈希会为新键值对规划存储的内存地址并存入。 1.1.4.5 ⭐扩容 除了用散列均匀的哈希函数来提高读写性能，还可以通过对地址空间适时扩容减少哈希冲突以提高性能。 负载因子：count/(2^B)，即存储键值对的数目/桶的数目，用来判断是否需要进行扩容。不难理解，装载因子越大，哈希的读写性能就越差。 扩容规则： count/(2^B) \u003e 6.5 –\u003e 翻倍扩容(hamp.B++)； 使用了\"过多\"的溢出桶 -\u003e 等量扩容。 注：“过多” 指： 1. `B \u003c= 15`时，`noverflow \u003e= 2^B`； 1. `B \u003e 15`时，`noverflow \u003e= 2^15`。 **翻倍扩容：**会创建旧桶数目2倍的新桶，然后将旧桶中的键值对分流到对应的两个新桶中，b = hash(key) \u0026 (2^B-1)，(这个地方很有意思)。 等量扩容：所谓等量扩容就是创建和旧桶数目一样多的新桶，然后把原来的键值对迁移到新桶中。**这里有一个问题：**既然是等量的，那何必扩容呢？ **答：**当发生大规模删除操作时，旧桶中存放的键值对可能非常稀疏，因此为了紧凑内存，需要将这些键值对重新排列到新桶中。 ==Point 3== 扩容时，需要把旧桶中的数据迁移到新桶，但并不需要一次性迁移完。 渐进式扩容：把键值对迁移的时间分摊到多次哈希表操作中，可以避免瞬时的性能抖动。在哈希表每次进行读写操作时，如果检测到当前处于扩容阶段，就完成一部分键值对迁移任务，直到所有的旧桶迁移完毕。 **具体过程：**扩容时，字段oldbuckets指向旧桶，nevacuate记录下一个待迁移的旧桶。 个人觉得，Go本质上还是拉链法，但是它做了一些内存上的优化，以空间换时间，给每个桶预先分配可以放8个数据的空间，和传统的拉链法相比，好处就是不需要频繁的分配内存，同时在某些极限情况下，也可以节省一些空间，传统的拉链法还需要存放前后数据的指针，在64位机器上又是16个字节的开销，但是用数组的方式组织的话，就不需要存储前后的指针。如果一个桶里面存放了超过8个数据，还是需要另一个bmap来放多余的数，然后把两个bmap连接起来。我觉得对比一下，传统的拉链法就是一个节点只能放一个数据，而go是一个节点可以放8个数据，这8个数据是按照数组来组织的。 1.1.4.5 小结 Go 语言使用拉链法来解决哈希碰撞的问题实现了哈希表，它的访问、写入和删除等操作都在编译期间转换成了运行时的函数或者方法。哈希在每一个桶中存储键对应哈希的前 8 位，当对哈希进行操作时，这些 tophash 就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:4","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.1.5 sync.map 问：sync.map 和 mutex+map 有啥区别？sync.map 为啥要有俩 map(read+dirty)？一个不行吗？ 一个是不行的，你总不能读不加锁，写加锁吧？这样照样会有并发访问的问题(是会报错的)。但是如果是 read+dirty，就可以对 read 的所有操作都不加锁，对 dirty 的所有操作都要加锁，就可以避免并发问题。我觉得最关键的差别就是这个地方！也是很精妙的地方！ 参考文章： https://eddycjy.com/posts/go/sync-map/ https://mp.weixin.qq.com/s/vtvlye801ePWRY7RvtkDmA ⭐ 先来看看 sync.map 的底层数据结构： type Map struct { mu Mutex // 保护 dirty 和 read read atomic.Value // readOnly，只读类型，所以是并发安全的 dirty map[interface{}]*entry // 一个非线程安全的原始 map misses int // 计数作用。当读数据时，该字段不在 read 中，尝试从 dirty 中读取，不管是否在 dirty 中读取到数据，misses+1。当 misses 累计到 len(dirty) 时，会将 dirty 拷贝到 read 中，并将 dirty 清空，以此提升读性能。 } // read 的类型为 atomic.Value，它会通过 atomic.Value 的 Load 方法将其断言为 readOnly 对象 read, _ := m.read.Load().(readOnly) // m 为 sync.Map // read 的真实类型即是 readOnly type readOnly struct { m map[interface{}]*entry // read 中的 go 内置 map 类型，但是它不需要锁。 amended bool // 当 sync.Map.diry 中的包含了某些不在 m 中的 key 时，amended 的值为 true. } // map 存储的值类型是 *entry，它包含一个指针 p，指向用户存储的 value 值。 type entry struct { p unsafe.Pointer // *interface{} } mu：保护 dirty； read：存只读数据。读是并发安全的，但如果要更新 read，则需要加锁保护； dirty：包含最新写入的数据。当 misses 计数达到一定值，将其赋值给 read； misses：计数作用。当读数据时，该字段不在 read 中，尝试从 dirty 中读取，不管是否在 dirty 中读取到数据，misses+1。当 misses 累计到 len(dirty) 时，会将 dirty 拷贝到 read 中，并将 dirty 清空，以此提升读性能。 1.1.5.1 查询数据 Load(): 首先，从只读数据read中读取(因为不用加锁)，若有就直接返回，若无再继续往下； 若read没有，且dirty中有新数据，就会去dirty查找； 先加锁，然后再次检查read，若还没有，才真正去dirty查找，并且对miss计数器+1(无论是否找到)； 若miss的值 \u003e= dirty中的元素数量，就把dirty赋给read，因为穿透次数太多了，然后就可以把dirty置为空了。 func (m *Map) Load(key interface{}) (value interface{}, ok bool) { // 首先从 m.read 中通过 Load 方法得到 readOnly read, _ := m.read.Load().(readOnly) // 从 read 中的 map 中查找 key e, ok := read.m[key] // 如果 read 没有，并且 dirty 有新数据，那么去 dirty 中查找 if !ok \u0026\u0026 read.amended { m.mu.Lock() // 双重检查：避免在本次加锁的时候，有其他 goroutine 正好将 Map 中的 dirty 数据复制到了 read 中。 read, _ = m.read.Load().(readOnly) e, ok = read.m[key] // 如果 read 中还是不存在，并且 dirty 中有新数据 if !ok \u0026\u0026 read.amended { e, ok = m.dirty[key] // m 计数 +1 m.missLocked() } m.mu.Unlock() } if !ok { return nil, false } return e.load() // 返回指针指向的值 } func (m *Map) missLocked() { m.misses++ if m.misses \u003c len(m.dirty) { return } // 将dirty置给read，因为穿透概率太大了(原子操作，耗时很小) m.read.Store(readOnly{m: m.dirty}) m.dirty = nil // 清空 dirty m.misses = 0 // 重置 misses } 1.1.5.2 删除数据 Delete()： 首先，从只读数据read中读取，若有的话，就直接从read中\"删除\"(并非真的删除，只是标记一下)； 若read中没有，就获得锁，然后再检查一遍read，然后就从dirty中删除； func (m *Map) Delete(key interface{}) { // 读出 read，断言为readOnly 类型 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 如果 read 中没有，并且 dirty 中有新元素，那么就去 dirty 中去找。这里用到了 amended，当 read 与 dirty 不同时为 true，说明 dirty 中有 read 没有的数据。 if !ok \u0026\u0026 read.amended { m.mu.Lock() // 再检查一次，因为前文的判断和锁不是原子操作，防止期间发生了变化。 read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026\u0026 read.amended { // 直接删除 delete(m.dirty, key) } m.mu.Unlock() } if ok { // 如果 read 中存在该 key，则将该 value 赋值 nil(采用标记的方式删除！) e.delete() } } // 如果 read 中有该键，则从 read 中删除，其删除方式是通过原子操作 func (e *entry) delete() (hadValue bool) { for { p := atomic.LoadPointer(\u0026e.p) // 如果 p 指针为空，或者被标记清除 if p == nil || p == expunged { return false } // 通过原子操作，将 e.p 标记为 nil if atomic.CompareAndSwapPointer(\u0026e.p, p, nil) { return true } } } 1.1.5.3 增改数据 Store()： 首先，从只读数据read中获取该key，若存在，并且没有被标记删除，就尝试更新； 如果在read中不存在或已被标记删除，就在dirty中判断是否存在，若已存在，就尝试更新； 若在dirty中不存在，就加入dirty； func (m *Map) Store(key, value interface{}) { // 如果 m.read 中存在该键，且该键没有被标记删除(expunged) // 则尝试直接存储(见 entry 的 tryStore 方法) // 注意：如果 m.dirty 中也有该键(key 对应的 entry)，由于都是通过指针指向，所有 m.dirty 中也会保持最新 entry 值。 read, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) { return } // 如果不满足上述条件，即 read 不存在或者已经被标记删除 m.mu.Lock() read, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok { // read 存在该 key // 如果 entry 被标记 expunge，则表明 dirty 没有 key，可添加入 dirty，并更新 entry。 if e.unexpungeLocked() { // 加入 dirty 中，这儿是指针 m.dirty[key] = e } // 更新 entry 指向新的 value 地址 e.storeLocked(\u0026value) } else if e, ok := m.dirty[key]; ok { // read 不存在该 key，但 dirty 存在该 key，更新 e.storeLocked(\u0026value) } else { // read 和 dirty 都没有 // 如果 re","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:1:5","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2 语言基础 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.1 函数调用 1.2.1.1 栈帧布局 按照编程语言定义的函数，会被编译器编译为一堆机器指令，写入可执行文件，在运行时被加载到内存，位于虚拟地址空间的代码段。 当出现函数调用时，编译器就会对应生成一条call指令，程序执行到这条指令时，就会跳转到对应函数入口处执行，而每个函数最后都有一个ret指令，负责在函数调用结束后，跳转回调用处继续执行。 函数执行时需要足够的内存空间来存放局部变量、参数、返回值等数据，这些数据对应到虚拟地址空间的栈。 栈的执行顺序是从低地址到高地址，所有函数的栈帧格式都是统一的。执行到call指令会做两件事情： 首先是将下一条指令入栈，也即返回地址，当执行完调用函数就会跳转回这里； 然后会跳转到被调用函数入口处开始执行，这个过程是通过偏移量+栈指针sp完成的。 指令运行时，CPU用特定寄存器来存储运行时的栈基和栈指针，同时也有指令指针寄存器用来存放下一条要运行的指令。 Go语言中不是逐步扩张栈帧的，而是一次性分配。然后通过栈指针+偏移值使用栈帧。 ==Point：== 一次性分配栈帧主要是为了避免栈访问越界。 而Go语言编译器会在函数头部插入检测代码，当发现需要进行**“栈增长”**，就会另外分配一段足够大的栈空间，并把原来栈上的数据拷贝过来，同时释放原来那段栈空间。 **==call和ret指令==：**此处最好是看视频理解。 需要注意的是，可执行文件存放在代码段，所用的参数、变量等存放在栈空间，寄存器是指向栈空间的！ 1.2.1.2 传参与返回值 ==传值与传引用：== **传值：**函数调用时会对参数进行拷贝，被调用方和调用方两者持有不相关的两份数据； **传引用：**函数调用时会传递参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 不同语言会选择不同的方式传递参数，Go 语言选择了传值的方式，无论是传递基本类型、结构体还是指针，都会对传递的参数进行拷贝。 ==传参：== **过程：**下图swap函数并不能实现交换a, b的作用。 首先需要分配main的栈帧空间，即BP of main 和 SP of main中间的空间； 将main中的局部变量入栈； 从右至左依次将参数入栈(值拷贝)； call会将返回地址入栈，即return addr； 然后就是swap的栈帧了； 可以发现，执行交换操作只是对参数(同时也是swap的内部变量)进行操作，对main中原本的数据并不能造成影响，因此交换失败。 下图swap函数能实现交换a, b的作用。 前两步同上； 从右至左依次将参数入栈，这里同样是值拷贝，只不过值为a、b的地址； 交换时，是直接将addrA和addrB指向的数据进行交换，因此可以交换成功。 ==Point：== Go 语言中传指针也是传值。将指针作为参数传入某个函数时，函数内部会复制指针，也就是会同时出现两个指针指向原有的内存空间。因此，在传递数组或者内存占用非常大的结构体时，我们应该尽量使用指针作为参数类型来避免发生数据拷贝进而影响性能。 ==返回值：== 通常返回值是通过寄存器返回，但是Go支持返回多个返回值，也就是有可能返回值的数目大于寄存器个数，因此Go选择在栈上存储返回值。 **匿名返回值：**下图返回结果为1。 被调用函数执行完毕，ret会给返回值赋值，并执行defer函数，这里有一个问题：是先给返回值赋值还是先执行defer函数呢？ **答：**先给返回值赋值，再执行defer函数。 命名返回值： 和上边那个完全相同，只改动一个地方，返回结果为2。==这是因为被调用函数的返回值b一直在调用者栈帧中。== 参数空间分配： 若调用多个函数，将以最大的参数+返回值空间为标准来分配。如下图，将会按照B的参数+返回值空间进行分配，B执行完后，C的参数+返回值会从低地址到高地址进行分配，不满的空间就空着。 1.2.1.3 小结 Go 通过栈传递函数的参数和返回值，==参数和返回值居然是在调用者的栈帧中！！！==在调用函数之前会在栈上为返回值分配合适的内存空间，随后将入参从右到左按顺序压栈并拷贝参数，返回值会被存储到调用方预留好的栈空间上，我们可以简单总结出以下几条规则： 通过堆栈传递参数，入栈的顺序是从右到左，而参数的计算是从左到右； 函数返回值通过堆栈传递并由调用者预先分配内存空间； 调用函数时都是传值，接收方会对入参进行复制再计算； ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:1","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.2 闭包 函数，可以作为参数传递，可以做函数返回值，也可以绑定到变量。称这样的参数、返回值或变量为**function value**。 function value本质上是一个指针，但是并不直接指向函数指令入口，而是指向一个runtime.funcval的结构体，这个结构体里只有一个地址，就是这个二函数指令的入口地址。 将一个函数赋值给多个变量，这些变量会共用同一个funcval。 那么既然funcval中只有一个地址，为啥不直接使用这个地址呢？ 这是为了处理闭包。 闭包的一个示例： Go 语言中，闭包就是有捕获列表的Function Value。捕获列表中存储的值，通过funcval的地址+偏移量来获取。 ==闭包需要维持捕获变量在外层函数和内层函数中的一致性。== ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:2","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.3 方法 1.2.3.1 方法的本质 如果定义一个类型A，并给他关联一个方法，然后就可以通过类型A的变量来调用这个方法，这种调用方式其实是\"语法糖\"，实际上和下边那个调用方式一样。 Go语言中，函数类型只和参数与返回值相关，所以下边输出为True，可以说明==方法本质上就是普通函数，接收者就是隐含的第一个参数==。 1.2.3.2 方法调用 其实和函数调用一样。 举例说明过程： Go语言中传参值拷贝，此处为值接收者，所以参数首先为：data=addr1 4； 执行Name()中第一行时，data指向新的string，更新为：data=addr2 8； 返回值就是值拷贝的参数，因此main中的局部变量并未受到影响。 再举个例子对比： Go语言中传参值拷贝，此处为指针接收者，所以参数首先为：pa=\u0026a； 执行Name()中第一行时，修改pa地址处的变量，也就是a，a指向新的string，更新为：data=addr2 8； 返回值就是值拷贝的参数，即a指向的变量。此处main中的局部变量a也会被修改。 上述例子中，通过值调用值接收者的方法，通过指针调用指针接收者的方法，那么如果用值调用指针接收者的方法或用指针调用值接收者的方法，是否可行呢？ 答：可行，这些也是\"语法糖\"，在编译阶段，编译器会进行转换。 1.2.3.3 方法表达式和方法变量 来看看将一个方法赋给一个变量是怎么一回事？ Go语言中，函数作为变量、参数和返回值时都是以Function Value形式存在的，闭包也只是有捕获列表的Function Value而已。 先来看看什么是方法表达式和方法变量： 从本质上讲，方法表达式和方法变量都是Function Value。 看这段代码： ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:3","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.4 接口 1.2.4.1 概述 计算机科学中，接口是计算机系统中多个组件共享的边界，不同的组件能够在边界上交换信息。如下图所示，接口的本质是引入一个新的中间层，调用方可以通过接口与具体实现分离，解除上下游的耦合，上层的模块不再需要依赖下层的具体模块，只需要依赖一个约定好的接口。 Go 语言中的接口是一种内置的类型，它定义了一组方法的签名。Go 语言中接口的实现都是隐式的，类型实现接口时只需要实现接口中的全部方法。 在 Java 中：实现接口需要显式地声明接口并实现所有方法； 在 Go 中：实现接口的所有方法就隐式地实现了接口； 1.2.4.2 数据结构 Go 语言根据接口类型是否包含一组方法将接口类型分成了两类： 使用 runtime.iface 结构体表示包含方法的接口，又称非空接口类型； 使用 runtime.eface 结构体表示不包含任何方法的 interface{} 类型，又称空接口类型，可以接收任意类型的数据； runtime.eface 结构体： type eface struct { // 16 字节 _type *_type // 动态类型：表示类型元数据 data unsafe.Pointer // 动态值：记录在哪 } 举例说明：赋值前_type和data字段都为nil，赋值后： runtime.iface 结构体： type iface struct { // 16 字节 tab *itab // 记录动态类型和方法列表 data unsafe.Pointer // 动态值 } type itab struct { // 32 字节 inter *interfacetype // 接口的类型元数据，包含接口的方法列表：需要实现的方法 _type *_type // 接口的动态类型元数据 hash uint32 // 类型哈希值：用于快速判断类型是否相等，类型断言时会用到 _ [4]byte fun [1]uintptr // 方法地址数组：用于快速调用方法，无需再去接口的类型元数据寻找方法地址 } hash 是对 _type.hash 的拷贝，当我们想将 interface 类型转换成具体类型时，可以使用该字段快速判断目标类型和具体类型 runtime._type 是否一致； fun 是一个动态大小的数组，它是一个用于动态派发的虚函数表，存储了一组函数指针。虽然该变量被声明成大小固定的数组，但是在使用时会通过原始指针获取其中的数据，所以 fun 数组中保存的元素数量是不确定的。 举例说明：赋值前tab和data字段都为nil，赋值后： ==Point：== itab结构体内容一旦确定(接口类型和动态类型)，实际上是不会改变的，因此是可复用的。Go语言会将itab缓存起来，并且以接口类型和动态类型的组合为key(接口类型的hash ^ 动态类型的hash)，以\u0026itab为value构造一个哈希表。需要一个itab时，会先在这里边寻找，如果已经有对应的itab，就直接拿来用，如果没有，就新创建并添加。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:4","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.5 类型断言 类型断言作用在抽象类型上，包括：空接口和非空接口。而断言的目标类型可以是具体类型或非空接口类型。这样就组合出来了四种类型断言： 空接口.(具体类型) 非空接口.(具体类型) 空接口.(非空接口) 非空接口.(非空接口) 1.2.5.1 空接口.(具体类型) 1.2.5.2 非空接口.(具体类型) 1.2.5.3 空接口.(非空接口) 1.2.5.4 非空接口.(非空接口) 1.2.5.5 小结 类型断言的关键是：明确接口的**==动态类型==及对应的动态类型实现了哪些方法**，而明确这些的关键又在于动态类型的类型元数据，以及空接口与非空接口的**“数据结构”**。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:5","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.6 反射 反射的作用就是把类型元数据暴露给用户使用。 反射包中有两对非常重要的函数和类型，两个函数分别是： reflect.TypeOf 能获取类型信息； reflect.ValueOf 能获取数据的运行时表示。 两个类型是 reflect.Type 和 reflect.Value，它们与函数是一一对应的关系： 1.2.6.1 三大法则 Go 语言反射的三大法则： 从 interface{} 变量可以反射出反射对象； 从反射对象可以获取 interface{} 变量； 要修改反射对象，其值必须可设置； 法则1 为什么是从 interface{} 变量到反射对象？我们也可以执行reflect.ValueOf(1)呀，1是int类型呀，并不是interface{}？ 由于 reflect.TypeOf、reflect.ValueOf 两个方法的入参都是 interface{} 类型，所以在方法执行的过程中发生了类型转换。因为 Go 语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型 int 会转换成 interface{} 类型，这也就是为什么第一条法则是从接口到反射对象。 通过TypeOf获得变量类型； 通过ValueOf获得变量值； 然后就可以通过Method获得类型实现的方法； 通过Field获得类型包含的全部字段。 法则2 从反射对象可以获取 interface{} 变量。reflect 中的 reflect.Value.Interface 就能完成这项工作。 不过调用 reflect.Value.Interface 方法只能获得 interface{} 类型的变量，还需要进行类型断言才能变成原类型。 从反射对象到接口值的过程是从接口值到反射对象的镜面过程，两个过程都需要经历两次转换： 从接口值到反射对象： 从基本类型到接口类型的类型转换； 从接口类型到反射对象的转换； 从反射对象到接口值： 反射对象转换成接口类型； 通过显式类型转换变成原始类型(如果原来就是接口类型，那么不必这一步)。 法则3 假如想要更新原变量的值，如果这样写，是不行的： func main() { i := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) } 需要这样写： func main() { i := 1 v := reflect.ValueOf(\u0026i) v.Elem().SetInt(10) fmt.Println(i) } 调用 reflect.ValueOf 获取变量指针； 调用 reflect.Value.Elem 获取指针指向的变量； 调用 reflect.Value.SetInt 更新变量的值： 1.2.6.2 类型和值 TypeOf 如何传递参数 可以思考一下此处栈上参数列表应该是怎样的？ 由于TypeOf的参数是空接口类型，空接口是动态类型，实际大小不知道，因此需要传递地址，但是如果传递a的地址进去，就会违背Go语言值拷贝的特性，可能会修改原a的值，那么应该怎么做呢？ 实际上在编译阶段，会对a进行copy，实际传的是copy of a的地址，所有参数为空接口类型的情况，都是这样。 返回值是什么？ 通过TypeOf返回的，其实是一个非空接口变量： ValueOf 参数传递 同TypeOf，同时，ValueOf会将这个临时变量地址显式的逃逸到堆上。 例： a的地址被显式的逃逸到堆，注意此处的返回值ptr=\u0026a： 接下来调用v.Elem()，会拿到v.ptr指向的变量a，并把它包装成reflect.Value类型的返回值(ptr又变为\u0026a)，赋值给v： 然后在调用v.SetString()，此时通过参数v拿到a的地址，修改的就是原来的a： ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:6","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.7 方法集 问题：T和*T的方法集是啥关系？ T和*T是两种类型，分别有着自己的类型元数据，而根据自定义类型的类型元数据，可以找到该类型关联的方法列表，既然T和*T各有各的方法集，那为什么还要限制T和*T不能定义同名方法？又怎么会有\"*T的方法集包含T的方法集\"这种说法？ **答：**首先，可以确定的是，T的方法集里，全部都是有明确定义的接收者为T类型的方法；而*T的方法集里，除了有明确定义的接收者为*T的方法以外，**还会有编译器生成的一些\"包装方法\"：**这些包装方法是对接收者为T类型的同名方法的\"包装\"，为什么编译器要为接收者为T的方法包装一个接收者为*T的同名方法呢？ 你可能会想到 Go 支持通过指针变量访问方法。但这里首先要明确一点：通过*T类型的变量直接调用T类型接收者的方法只是一种语法糖，经验证，这种调用方式，编译器会再调用端进行指针解引用，并不会用到这里的包装方法。 ==实际上，编译器生成包装方法主要是为了支持接口。== 非空接口的数据结构只包含两个指针，一个和类型元数据相关，一个和接口装载的数据相关，虽然有数据指针，但却不能像上述语法糖那样，通过指针解引用来调用值接收者的方法。**原因：**方法的接收者是方法调用时隐含的第一个参数，Go 中的函数参数是通过栈来传递的，如果参数指针类型，那就很好实现：平台确定了，指针大小就确定了。但如果要解引用为值类型，就要有明确的类型信息，编译器才能确定这个参数要在栈上占用多大的内存空间。而对于接口，编译阶段并不能确定它会装载哪一类的数据，所以编译器并不能生成对应的指令来解引用。 总而言之，==接口不能直接使用接收者为值类型的方法==。 针对这个问题，编译器选择为值类型接收者的方法，生成指针接收者\"同名\"包装方法这一解决方案。 因此，回到最初的问题：“为什么还要限制T和*T不能定义同名方法？”，如果给T和*T定义了同名方法，就有可能和编译器生成的包装方法发生冲突，所以 Go 干脆不允许为T和*T定义同名方法。 至于，\"*T的方法集包含T的方法集的所有方法\"，这种说法可以这样理解。虽然编译器会为所有接收者为T的方法生成接收者为*T的包装方法，但是链接器会把程序中确定用不到的方法都裁剪掉，所以如果去分析可执行文件的话，就会发现不止是这些包装方法，就连我们明确定义的方法，也不一定会存在于可执行文件中。不过，一定要从可执行文件中去分析，不能通过反射去验证，因为反射的实现也是基于接口。若通过反射来验证，会被链接器认为用到了这个方法，从而把它保留下来，这就\"测不准\"了。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:7","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.2.8 泛型 go 1.17 在代码中经常会用到一些本地缓存组件，它们是复用性极高的基础组件，在使用体验上和map差不多，都提供了Set和Get方法。为了支持任意类型，这些方法都使用了空接口类型的参数，内部实际存储数据的是个值类型为空接口的map。 使用Set方法时，一般不会觉得有什么不方便，因为从具体类型或接口类型，到空接口的赋值不需要额外处理。但是Get方法使用时，需要通过类型断言，把取出来的数据转换成预期的类型。比如想从本地缓存c里面取出来一个string，就需要这样写： if v, ok := c.Get(\"key\"); ok { if s, ok := v.(string); ok { // use s } } 如果是仅仅多这一步，那也无可厚非，可实际上并不这么简单。 **空接口本质上是一对指针，用来装载值类型时会发生装箱，造成变量逃逸。**例如用Cache来缓存int64类型，缓存对象c底层是个map，在map的buckets中存储着元素的哈希值、key和value，对于c而言，bucket这里存储的value是一个一个的空接口，而实际上的int64会在堆上单独分配，空接口的data指针指向堆上的int64，相较于直接把int64存储在map的bucket里，堆分配方式凭空多出来一次堆分配，而且还多占用了两倍的内存空间。 针对这个问题，改造上述缓存为泛型缓存。 将Cache改为cache，因为 Go 1.17 的泛型实现还不支持导出，泛型相关的类型和函数只能在当前包中使用； Go 1.17 的泛型支持默认是关闭的，构建可执行文件时应指定参数来显式的开启，而且，据观察build命令只有在编译main包时，才会透传这个参数，这就限制了只能在main包中使用泛型。 改造好后，同样用来存储int64类型的数值，然后，通过反射观察底层map存储的是什么样类型的元素，下边的代码会打印int64，也就是说，泛型缓存cache的底层map会直接在bucket中存储int64类型的数值，没有额外的堆分配。 可以看出，泛型能够解决这个问题。但是，这不是没有代价的。 泛型的实现： 使用泛型最直接的代价就是：编译器会为同一套模板的每个类型，都生成一套代码，可能会导致可执行文件大小有所增加；而且，即便使用泛型，要想在一个缓存对象里面存储多种不同类型的值，依然要使用空接口，否则，一个缓存对象就只能存储一种类型的值。 所以说，泛型本质上是编译阶段的代码生成，它并不会替代空接口，空接口主要用来实现语言的动态特性，它们的适用场景根本不同~ go 1.18 Go 从 1.18 正式开始支持泛型，这里的T就是类型参数，与java、c++对比，没有使用\u003c\u003e，而是使用[]： 同时，为了让编译器能够更高效的检查类型参数的合法性，还引入了类型参数的约束条件。这个约束条件在语法层面是通过接口来实现的，它明确描述了调用方传入的类型参数，需要符合什么样的要求。 这里的fmt.Stringer接口限制了调用ToString方法时，传入的参数必须实现了String()方法，如果传入的参数不符合要求，就无法通过编译。当然，此处的接口也并不是原来的接口。 若使用原来的接口，就只能通过接口的方法集来约束类型参数，但这有时是行不通的。因为，这些内置类型是没有实现任何方法的，比如int32、int64。 例如，写了一个Sum()函数，想让它支持所有整型类型，该如何实现呢？ Go 1.18 将接口扩展了一下。原来的接口只能定义方法集，扩展后的接口增加了类型集，通过类型集指明哪些类型是被支持的。 例如，Integer接口用作约束条件时，就可以支持所有的有符号整型。 但这依然不够，如果我们自定义了type MyInt int类型，同样也希望被支持，这个约束条件又该怎么写呢？总不能每次新增加自定义类型都去改一下接口的类型集吧？ 为了解决这个问题，Go 新增加了符号~，只要写~int，就可以支持**int类型以及基于int创建的所有自定义类型**， **注意：**这种扩展后的接口，目前只用于泛型的约束条件。 现在有了泛型，只需要实现一遍功能函数，就可以通过多种类型参数来调用。 **问题：**编译器会不会给每种支持的类型都生成一套代码呢？// ==TODO== 貌似不用。通过字典和gcshape实现。没听懂。先这样吧。。。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:2:8","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.3 常用关键字 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:3:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.3.1 defer 使用defer的最常见场景是在函数调用结束后完成一些收尾工作，通常用来： 关闭文件描述符； 关闭数据库连接； 解锁资源 通常使用defer会遇到两个常见的问题： defer 关键字的调用时机以及多次调用 defer 时执行顺序是如何确定的； defer 关键字使用传值的方式传递参数时会进行预计算，导致不符合预期的结果。 ==执行顺序== deferProc()负责把要执行的函数信息保存起来，称之为**defer注册**；defer注册完成后，会继续执行后面的逻辑，直到返回之前通过deferreturn执行注册的defer函数。即：先注册，再延迟调用。 defer会在函数返回之前，按照倒序执行。这是因为goroutine运行时会有一个对应的结构体g，其中有一个字段指向defer链表头，defer链表链起来的是一个个_defer结构体，新注册的defer会添加到链表头，执行时从头开始，因此执行顺序是注册顺序的倒序。 ==预计算参数== Go 语言中所有的函数调用都是传值的，虽然 defer 是关键字，但是也继承了这个特性。如下代码： func main() { startedAt := time.Now() defer fmt.Println(time.Since(startedAt)) time.Sleep(time.Second) } $ go run main.go 0s 为什么会输出0呢？这是因为：调用 defer 关键字会立刻拷贝函数中引用的外部参数，所以 time.Since(startedAt) 的结果不是在 main 函数退出之前计算的，而是在 defer 关键字调用时计算的，最终导致上述代码输出 0s。 想要解决这个问题的方法非常简单，我们只需要向 defer 关键字传入匿名函数： func main() { startedAt := time.Now() defer func() { fmt.Println(time.Since(startedAt)) }() time.Sleep(time.Second) } $ go run main.go 1s 1.3.1.1 数据结构 defer在Go语言中的结构： type _defer struct { siz int32 // 参数和返回值共占多少字节 started bool // 标记defer是否已经执行 openDefer bool // sp uintptr // 调用者栈指针 pc uintptr // 返回地址 fn *funcval // defer 关键字中传入的函数，即注册函数 _panic *_panic // 触发延迟调用的结构体，可能为空 link *_defer // 下一个_defer指针 } 可以看出runtime._defer 结构体其实是_defer调用链表上的一个元素，所有的结构体都会通过 link 字段串联成链表。 1.3.1.2 执行机制 堆分配、栈分配和开放编码是处理 defer 关键字的三种方法。 Go 1.12 引入：堆分配runtime._defer 结构体； Go 1.13 引入：栈分配的结构体； Go 1.14- 引入：基于开放编码的 defer。 1.3.1.3 堆分配 deferproc函数执行时，需要堆分配一段空间，存放_defer结构体及参数与返回值。实际上Go语言也会预分配不同规格的_defer池，执行时从空闲_defer池中取出一个，没有合适的或空闲的就会进行堆分配，用完之后再放入_defer池，以避免频繁的堆分配与回收。 Go 1.12 defer很慢！原因： _defer结构体堆分配：即使有预分配的deferpool，也需要去堆上获取和释放，而且，参数还要在堆栈间来回拷贝； _defer注册通过链表：链表本身的操作就慢！ 1.3.1.4 栈上分配 先来对比一下1.12版本和1.13版本中，defer指令编译后有什么不同？ 1.12 将_defer结构体分配在堆上。在1.13中，通过在编译阶段，增加局部变量，把defer信息保存到当前函数栈的局部变量区域，再通过deferprocStack把栈上这个_defer结构体注册到_defer链表中，执行依然是通过deferreturn实现。优化点：减少defer信息的堆分配。 1.13中的defer，官方提供的性能提升是30%。 1.3.1.5 开放编码 Go 1.14是通过在编译阶段插入代码，把defer函数的执行逻辑展开在所属函数内，从而免于创建_defer结构体，而且不需要注册到_defer链表。这种方式省去了构造_defer链表项，并注册到链表的过程。举例说明： A1可以简单的通过：定义局部变量，并在return前插入调用A1的指令 来实现延迟调用效果。但是对于A2呢？他在编译阶段是无法确定是否被调用的，因此需要一些处理。 Go语言通过一个**标识变量df**来解决这个问题。 df变量中的每一位对应一个defer函数是否要被执行。 这里先以A1举例： df变量首先需要通过异或运算|=将第1位置为1； return前插入的调用指令也应该进行修改，需要判断df变量第1位是否\u003e0，若\u003e0，在调用A1前，需要将df变量的第1位置为0，这是为了避免重复调用。 再以A2举例： 首先插入 判断是否需要将A2的标志位置为1 的代码； 然后在return前插入 检查df标志位 的代码。 这种方法将性能提高了一个数量级，但不是没有代价。 如果在code to do something，也就是还未执行到defer函数调用处，就发生了panic或runtime.Goexit函数，后面这些代码根本无法执行到，因此需要通过栈扫描的方式来发现。所以，defer变快了，但panic变得更慢了。 1.3.1.6 小结 需要注意的是，栈上分配和开放编码的方法均不适用于循环中的defer，因此也保留1.12中的堆分配方法。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:3:1","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"1.3.2 panic和recover panic 能够改变程序的控制流，调用 panic 后会立刻停止执行当前函数的剩余代码，并在当前 Goroutine 中递归执行调用方的 defer； recover 可以中止 panic 造成的程序崩溃。它是一个只能在 defer 中发挥作用的函数，在其他作用域中调用不会发挥作用。 1.3.2.1 现象 跨协程失效：panic 只会触发当前 Goroutine 的 defer； 失效的崩溃恢复：recover 只有在 defer 中调用才会生效； 嵌套崩溃：panic 允许在 defer 中嵌套多次调用。 跨协程失效 func main() { defer println(\"in main\") go func() { defer println(\"in goroutine\") panic(\"\") }() time.Sleep(1 * time.Second) } ❯ go run test_go.go in goroutine panic: ... 上述代码没有执行main中的defer，只执行了 goroutine 中的defer。 **总结：**当程序发生崩溃时只会调用当前 goroutine 的defer。 失效的崩溃恢复 func main() { defer println(\"in main\") if err := recover(); err != nil { fmt.Println(err) } panic(\"unknown err\") } ❯ go run test_go.go in main panic: unknown err ... 在主程序中调用 recover 试图中止程序的崩溃，但是从运行的结果中我们也能看出，程序没有正常退出。应该如下面这样写： func main() { defer println(\"in main\") defer func() { if err := recover(); err != nil { fmt.Println(\"错误发现:\", err) } }() panic(\"unknown err\") } ❯ go run test_go.go 错误发现: unknown err in main 可以发现程序正常执行。 总结：recover 只有在发生 panic 之后调用才会生效。然而在上面的控制流中，recover 是在 panic 之前调用的，并不满足生效的条件，所以需要在 defer 中使用 recover 关键字。 嵌套崩溃 func main() { defer println(\"in main\") defer func() { defer func() { panic(\"panic again and again\") }() panic(\"panic again\") }() panic(\"panic once\") } ❯ go run test_go.go in main panic: panic once panic: panic again panic: panic again and again ... 可以确定程序多次调用 panic 也不会影响 defer 函数的正常执行，所以使用 defer 进行收尾工作一般来说都是安全的。 1.3.2.2 数据结构 panic 关键字在 Go 语言的源代码是由数据结构 runtime._panic 表示的： type _panic struct { argp unsafe.Pointer // defer的参数空间 arg interface{} // panic的参数 link *_panic // link to earlier panic recovered bool // 是否被 recover 恢复 aborted bool // 是否被终止 pc uintptr sp unsafe.Pointer goexit bool } 和defer一样，panic也是一个链表，当有新的panic出现，也是在链表头插入新的_panic结构体。 panic执行defer时，是从头开始执行的。首先把_defer的started字段置为true，标记该defer已经开始执行，并且会把panic字段指向当前执行的panic，表示这个defer是由这个panic触发的。 如果函数A2能够正常执行，那么就会移除A2。 之所以这样设计，是为了应对defer函数没有正常结束的情况。假如此时A2顺利执行，那么执行A1： 因为A1也会触发panic，那么需要将panicA1链在panic头部，此时正在执行的panic就变成了panicA1，然后也会去执行defer链表，从标记字段会发现A1已经在执行了，且触发他的panic是panicA，所以会根据该指针找到panicA，把他**aborted标记为已终止**。 所以现在panicA已终止，A1也执行完毕，A1会被移除，当前defer链表为空。 接下来就该打印panic信息了，注意：**panic打印异常信息时，会从链表尾开始，即panic的发生顺序逐个输出。**所以此处会先panicA，再panic A1。 1.3.2.3 recover 上述过程没有添加recover，接下来看看添加recover之后的情况。 recover只做一件事，就是把当前panic的recovered字段变为true。 **以下为例。**当执行完A2时，会将当前panicA的recovered=true。每个defer执行完毕，panic都会检查当前recovered是否为true。此时会发现panicA已经被恢复了，就会把他从panic链表中移除，并且移除A2。不过A2被移除之前，要保存_defer.sp和_defer.pc，接下来就要利用这两个值跳出panicA的处理流程。 sp和pc是注册defer函数时保存的。这里sp就是函数A的栈指针，而pc就是调用deferproc函数的返回地址。 通过sp可以返回到函数A的栈帧，通过pc可以返回到调用deferproc处(即判定r\u003e0)处。若此时r=0，那么code to do something就会被重复执行，所以会将寄存器中的r=1，这样就可以跳转到deferreturn处，继续执行defer链表。**注意：deferreturn只负责执行当前函数A注册的defer函数，**他是通过栈指针来判断的。 所以，A2执行完毕，还会继续执行A1，执行完毕就结束了。 **这里要注意：**只有当defer函数执行完毕，panic才会去检查是否被恢复。但是如果defer先recover，然后又panic了呢？ 此时，由于发生了panic，所以会将panicA2注册到panic链表头，并成为当前的panic，他会去执行defer链表，当执行A2时，从标记字段发现A2已经开始执行，并且触发者是panicA，那么会将panicA终止(aborted=true)，并把A2从defer链表移除。继续执行下一个defer，A1就是由panicA2触发的了。 A1执行完毕后，会被移除，此时defer链表为空。 接下来就要输出panic信息了。 注意：在输出已经被recover的panic时，打印时会带上recovered标记。panic每一项被输出后，程序退出。 小结 用defer进行收尾工作通常是安全的，这是因为panic可以终止其他代码的执行，但不会影响到defer的执行。 在判断panic的执行过程时，只需要把握住两个链表defer和panic的执行顺序即可。 二、运行时 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:3:2","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1 并发编程 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1.1 GMP 2.1.1.1 概述 Go语言在并发编程方面有强大的能力，这离不开语言层面对并发编程的支持。谈到Go语言调度器，绕不开的是操作系统、进程与线程这些概念。 **多个线程可以属于同一个进程并共享内存空间。**因为多线程不需要创建新的虚拟内存空间，所以它们也不需要内存管理单元处理上下文的切换，线程之间的通信也正是基于共享的内存进行的，与重量级的进程相比，线程显得比较轻量。这不是挺好的嘛，为啥还要引入goroutine？ **引入goroutine的原因：**虽然线程比较轻量，但是在调度时也有比较大的额外开销。每个线程都会占用 1M 以上的内存空间，在切换线程时不止会消耗较多的内存，恢复寄存器中的内容还需要向操作系统申请或者销毁资源，每一次线程上下文的切换都需要消耗 ~1us 左右的时间，但是 Go 调度器对 Goroutine 的上下文切换约为 ~0.2us，减少了 80% 的额外开销。 ==Point：== Go语言中： 协程对应的数据结构是runtime.g； 工作线程对应的数据结构是runtime.m； 后来引入了runtine.p，**引入原因：**一开始所有的g都在一个全局队列中，多个m从全局队列中获取g时需要频繁的加解锁及等待；引入p后，m就可以直接从关联的p处获取待执行的g，不用每次都和众多m从一个全局队列中争抢任务，提高了并发性能。 其中，allgs、allm、allp分别记录所有的g、m和p。 首先看一个简单的场景 只有一个mian.main。 在main goroutine创建前，G、P、M的情况如上图。 main goroutine创建后，被加入当前P的本地队列中； 然后通过mstart开启调度循环。这个mstart是所有工作线程的入口，主要就是调用schedule函数，也就是执行调度循环。 当前队列中只有main goroutine等待执行，所以m0切换到main goroutine； 执行入口自然是runtime.main，它会做很多事情：创建监控线程、进行包初始化等，包括调用main.main，然后就可以执行main.main了！ 一个改进的场景 在main.main中又创建新的goroutine。 我们通过go关键字创建goroutine，会被编译器转换为newproc函数调用。(main goroutine也是由newproc创建的) 创建goroutine时，我们只负责指定入口、参数，而newproc会给goroutine构造一个栈帧，目的是让协程任务结束后，返回到go exit函数中，进行协程资源回收处理等工作。 新创建的goroutine，此处叫做hello goroutine，会被添加到当前P的本地runq中； 然后main.main就会返回了，然后exit()函数被调用，进程就结束了。所以此处hello goroutine并未能执行。 **问题：**问题在于，当main.main返回后，直接会调用exit()函数，会把进程都结束掉，没给hello goroutine调度执行的时间。所以应该在main.main返回前，拖延点时间给hello goroutine执行。 2.1.1.2 goroutine创建、让出与恢复 还通过一个例子来看一下。 通过函数栈帧看一下newproc的调用过程： main函数栈帧自然分配在main goroutine的协程栈中； newproc主要做的就是切换到g0栈去调用newproc1函数；为什么要切换到g0栈呢？简单来说，g0栈空间大。因为runtime中很多函数都有no-split标记，意味着这个函数不支持栈增长，而协程栈空间本来就小，容易栈溢出，而g0的栈直接分配在线程栈上，栈空间足够大。 newproc1(协程入口, 参数地址, 参数大小, 父协程, 返回地址)； newproc1首先通过acquirem()禁止当前m被抢占。**为什么不能被抢占？**因为接下来要执行的程序中，可能会把当前p保存到局部变量中，若此时m被抢占，p关联到别的m，等再次恢复时，继续使用这个局部变量里保存的p，就会造成问题。所以为了保持数据的一致性，会暂时禁止m被抢占。 接下来，会尝试获取一个空闲的g，如果当前p和调度器中都没有空闲的g，就创建一个并添加到全局变量allgs中。此处我们依然将此添加的g记为hello goroutine，此时它的状态是_Gdead，而且已然拥有自己的协程栈。 接下来，如果协程入口函数有参数，就把参数移动(拷贝)到协程栈上。 接下来，会把goexit()的地址+1，压入协程栈，即返回地址； 再把协程(hello goroutine)对应的g的startpc置为协程入口函数的起始地址，gopc置为父协程调用newproc后的返回地址，g.sched结构体用于保存现场：g.sched.sp置为协程栈指针，g.sched.pc置为协程入口函数的起始地址。 等到这个协程得到调度执行的时候，通过g.sched恢复现场，就会从协程入口函数处开始执行，而函数结束后便会返回到goexit()中，执行协程资源回收等收尾工作。到此，协程如何出场与收场就都有了着落。 接下来，newproc1还会给新建的goroutine赋予一个唯一id。给g.goid赋值前，会把协程的状态置为_Grunnable，这个状态意味着这个g可以进到run queue中了。 所以接下来会调用runqput把这个g放到当前p的本地队列中。 接下来判断，如果当前有空闲p，而且没有处于spinning状态的m，即所有m都忙，而且主协程已经开始执行了，那么就调用wakep()：启动一个m并把它置为spinning状态。 最后与一开始的acquirem()呼应，会调用releasem()允许当前m被抢占；而spinning状态的m启动后，会一直执行调度循环寻找任务，从本地runq到全局runq再到其他p的runq，只为找到个待执行的g。但此时，若main.main已经返回，那也不会执行剩余的g。 此处我们通过等待一个channel来实现调度执行g。 当前main goroutine会阻塞在\u003c-ch这里等待数据； 然后chanrecv()通过gopark()函数挂起当前goroutine，让出cpu； gopark()首先会调用acquirem()禁止当前m被抢占，然后把main goroutine的状态从_Grunning修改为_Gwaiting，main goroutine就不再是执行中状态了； 接下来调用releasem()解除m的抢占禁令； 最后调用mcall(park_m)：负责保存当前协程的执行现场； 然后切换到g0栈，调用由mcall的参数传入的这个函数，对应到这里就是park_m()函数； park_m()函数会根据g0找到当前m，把m.curg置为nil。此时当前m正在执行的g便不再是main goroutine了； 最后会调用schedule()寻找下一个待执行的g。 然后，hello goroutine要么被当前m0调度执行，要么被其他m调度执行，总归是能执行了。 等到hello goroutine执行完毕，关闭main gorutine等待的channel时，不止会修改channel的closed状态，还会处理等待队列中的g，最终调用goready()函数来结束这个g的等待状态； 而goready()函数会切换到g0栈，并执行runtime.ready()函数，目前待ready的协程自然是main goroutine，此时它的状态是_Gwaiting，接下来会被修改为_Grunnable，表示它又可以被调度执行了。 然后，它会被放入当前p的本地runq中，同协程创建时一样，接下来也会检查是否有空闲的p，并且没有spinning状态的m，是的话，也会调用weakp()函数启动新的m； 接下来hello goroutine结束，main goroutine得到调度执行，最终结束进程。 总结：底层通过newproc创建goroutine，通过gopark实现协程让出，使用goready把协程恢复到runnable状态放回到runq中 接下来，就需要了解调度循环schedule()是做啥的了，以及如何把一个可运行的协程真正的运行起来？ 2.1.1.3 goroutine让出、抢占、监控和调度 协程让出CPU分为两种：主动让出和被动让出(抢占)。其中，主动让出指协程自身要等待某种条件而主动让出，被动让出指调度器通过某种规则强制使协程让出。 主动让出 主动让出主要包括三种形式：time.Sleep()，\u003c-chan和I/O操作。 time.Sleep() 整体过程：协程执行time.Sleep()时，状态会从_Grunning变为_Gwaiting，并进入到对应的timer中等待，而timer中持有一个回调函数，在指定时间到达后调用这个回调函数，把等在这里的协程恢复到_Grunnable状态并放回到runq中。 **这里有一个问题？**谁负责触发timer注册的回调函数呢？ 答：其实每个p都有一个最小堆，存储在p.timers中，用于管理自己的timer，堆顶的timer就是接下来要触发的那一个。而每次调度时，都会调用checkTimers()函数，检查并执行那些已经到时间的timer。不过这不够稳妥，万一所有的m都在忙，那么就不能及时触发调度了，可能会导致timer执行时间发生较大偏差。所以还会通过监控线程来增加一层保障。 (接上)。监控线程是由main goroutine创建的，与GPM中的工作","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:1","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1.2 Mutex Mutex的由来，应该是mutual exclusion的前缀组合，称为\"互斥锁\"。 2.1.2.1 两种模式 Go语言sync包中Mutex的数据结构是这样的： type Mutex struct { state int32 // 存储互斥锁的状态 sema uint32 // 信号量, 用作等待队列 } state存储互斥锁的状态，加锁和解锁都是通过atomic包提供的函数原子性的操作该字段： sema用作一个信号量，主要用作等待队列。 Mutex有两种模式： **正常模式：在正常模式下，一个尝试加锁的goroutine会先自旋几次，尝试通过原子操作获得锁。若几次自旋(自旋阶段)**后仍不能获得锁，则通过信号量排队等待，所有等待者会按照先入先出(FIFO)的顺序排队。 但是当锁被释放，第一个等待者被唤醒后并不会直接拥有锁，而是需要和后来者竞争，也就是那些处于自旋阶段，尚未排队等待的goroutine，这种情况下后来者更有优势：一方面，它们正在CPU运行，自然比刚唤醒的goroutine更有优势，另一方面处于自旋状态的goroutine可以有很多，而被唤醒的goroutine每次只有一个，所以被唤醒的goroutine有很大概率拿不到锁。 这种情况下它会被重新插入到队列的头部，而不是尾部。而当一个goroutine本次加锁等待的时间超过1ms后，它会把当前Mutex从正常模式切换至饥饿模式。 **饥饿模式：**在饥饿模式下，Mutex的所有权从执行Unlock的goroutine，直接传递给等待队列头部的goroutine。后来者不会自旋，也不会尝试获得锁，即使Mutex处于Unlocked状态。它们会直接从队列的尾部排队等待。 当一个等待者获得锁后，它会在以下两种情况时将Mutex由饥饿模式切换回正常模式： 此轮获得锁的等待者的等待时间小于1ms，也就是它刚来不久； 它是最后一个等待者，等待队列已经空了，后面自然就没有饥饿的goroutine了。 综上所述：在正常模式下自旋和排队时同时存在的，执行Lock的goroutine会先一边自旋，尝试过几次后如果还没拿到锁，就需要去排队等待了。这种在排队之前先让大家来抢的模式，能够有更高的吞吐量，因为频繁的挂起、唤醒goroutine会带来较多的开销。但是又不能无限制的自旋，要把自旋的开销控制在较小的范围内。所以，在正常模式下，Mutex会有更好的性能，但是可能会出现队列尾端的goroutine迟迟抢不到锁的情况(尾端延迟)。 而饥饿模式下不再尝试自旋，所有goroutine都要排队，严格的先来后到，对于防止出现尾端延迟非常重要。 2.1.2.2 Lock和Unlock 首先看一下关于Mutex.state的几个常量定义：state的类型是int32。 第一位用作锁状态标识，置为1就表示已加锁，对应掩码常量为mutexLocked。 第二位用于记录是否已有goroutine被唤醒了，置为1表示已唤醒，对应掩码常量为mutexWoken。 第三位标识Mutex的工作模式，0代表正常模式，1代表饥饿模式，对应掩码常量为mutexStarving。 而常量mutexWaiterShift等于3，表示除了最低3位以外，state的其他位用来记录有多少个等待者在排队。 接下来看一下Lock和Unlock的代码，精简掉注释和部分race检测相关的代码。 两个方法中主要通过atomic函数实现了Fast path，相应的Slow path被单独放在了lockSlow和unlockSlow方法中，这样是为了便于编译器对Fast path进行内联优化。 Lock方法中的Fast path期望Mutex处于Unlocked状态，没有goroutine在排队，更不会饥饿。理想状况下，一个CAS操作就可以获得锁。但是如果CAS操作没能获得锁，就需要进入Slow path，也就是lockSlow方法。 Unlock方法同理，首先通过原子操作从state中减去mutexLocked，也就是释放锁。然后根据state的新值来判断是否需要执行Slow path。如果新值为0，也就意味着没有其他goroutine在排队，所以不需要执行额外操作；如果新值不为0，那就需要进入Slow path，看看是不是需要唤醒某个goroutine。 2.1.2.3 Slow path **问题：**当一个goroutine尝试给mutex加锁时，如果其他goroutine已经加了锁还没有释放，而且当前mutex工作在正常模式下，是不是就要开始自旋了呢？ 答：不一定。因为如果当前是单核场景，或者 GOMAXPROCS=1，或者当前没有其他P正在运行。这些情况下自旋是没有意义的： 自旋的goroutine在等待持有锁的goroutine释放锁，而持有锁的goroutine在等待自旋的goroutine让出CPU。 除此之外，如果当前P的本地runq不为空，相较于自旋来说，切换到本地goroutine更有效率，所以为保障吞吐量也不会自旋。 问：Goroutine 自旋的条件？ 最终，==只有在多核场景下，且GOMAXPROCS \u003e 1，且至少有一个其他的P正在running，且当前P的本地runq为空的情况下，才可以自旋。== 进入自旋的goroutine会先去争抢mutex的唤醒标识位，设置mutexWoken标识位的目的是在正常模式下，告知持有锁的goroutine在Unlock的时候不用再唤醒其他goroutine了，已经有goroutine在这里等待，以免唤醒太多的等待goroutine。 Mutex中的自旋，底层是通过procyield循环执行30次PAUSE，自旋次数上限为4，而且每自旋一次都要重新判断是否可以继续自旋。如果锁被释放了，或者锁进入了饥饿模式，亦或者已经自旋了4次，都会结束自旋。 结束自旋或者根本不用自旋的goroutine就该尝试原子操作修改mutex的状态了。把此时mutex.state保存到old中，把要修改为的新state记为new： 如果old处于饥饿模式或加锁状态，goroutine就得去排队，所以这些情况下排队规模要加1。 如果是正常模式，就要尝试设置lock位，所以new中这一位要置为1； 如果当前goroutine等待的时间已经超过1ms，而且锁还没被释放，就要将mutex的状态切换为饥饿模式。 把排队规模和几个标识位都设置好后，在执行原子操作修改state前，若是当前goroutine持有唤醒标识的话，还需要将唤醒标识位重置，因为，接下来无论是去抢锁还是单纯去排队： 如果原子操作成功了，要么成功抢到了锁，要么是成功进到了等待队列，当前goroutine都不再是被唤醒的goroutine了，所以要释放唤醒标识。 而如果原子操作失败，也就意味着其他goroutine在我们保存mutex.state到old后又修改了state的值，当前goroutine就要回过头去继续从自旋检查这里开始再次尝试，所以也需要释放自己之前抢到的唤醒标识位，从头再来。 Lock操作的Slow path 继续展开原子操作成功的分支： 如果是抢锁操作成功了，那么加锁的Slow path就可以宣告结束了； 如果是排队规模设置成功了，还要决定是排在等待队列头部还是尾部。如果当前goroutine已经排过队了，是在Unlock时从等待队列中唤醒的，那就要排到等待队列头部；如果是第一次排队，就得排到等待队列尾部，并且从第一次排队开始记录当前goroutine的等待时间。接下来就会让出，进到等待队列里，队列里的goroutine被唤醒时，要从上次让出的地方开始继续执行。接下来会判断，如果mutex处在正常模式，那就接着从自旋开始抢锁，如果唤醒后mutex处在饥饿模式，那就没有其他goroutine会和自己抢了，锁已经轮到自己这里，只需要把mutex.state中lock标识位设置为加锁，把等待队列规模减去1，再看看是不是要切换到正常模式，也就是自己的等待时间是不是小于1ms，或者等待队列已经空了，最后设置好mutex.state就一切ok了。 Unlock操作的Slow path 进到Unlock的Slow path说明除去lock标识位以外，剩下的位不全为0。 如果处在正常模式，若等待队列为空，或者已经有goroutine被唤醒或获得了锁，或者锁进入了饥饿模式，那就不需要唤醒某个goroutine，直接返回即可。否则就要尝试抢占mutexWoken标识位，获取唤醒一个goroutine的权利。抢占成功后，就会通过runtime_Semrelease函数唤醒一个goroutine；如果抢占不成功就进行循环尝试，直到等待队列为空，或者已经有一个goroutine被唤醒或获得了锁，或者锁进入了饥饿模式，则退出循环。 而在饥饿模式下，后来的goroutine不会争抢锁，而是直接排队，锁的所有权是直接从执行Unlock的goroutine传递给等待队列中首个等待者的，所以不用抢占mutexWoken标识位。第一个等待者唤醒后，会继承当前goroutine的时间片立刻开始运行，也就是继续lockSlow这里goroutine被唤醒以后的逻辑。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:2","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1.3 信号量 上节主要讲解 sync.Mutex 的第一个字段 state，本节主要讲解 sync.Mutex 的第二个字段 sema。 **问题：**协程等待一个锁时，要如何休眠、等待和唤醒呢？ **答：**这要靠runtime.semaphore来实现，这是可供协程使用的信号量。runtime内部会通过一个大小为251的sematable来管理所有semaphore，怎么通过这个大小固定的table来管理执行阶段数量不定的semaphore呢？大致思路如下： 这个sematable存储的是251课平衡树的根，平衡树中每个节点都是一个sudog类型的对象，要使用一个信号量时，需要提供一个记录信号量数值的变量，根据它的地址进行计算，映射到sematable中的一颗平衡树上，找到对应的节点就找到了该信号量的等待队列。 例如，我们常用的sync.Mutex中，有一个sema字段，用于记录信号量的数值，如果有协程想要等待这个Mutex，就会根据sema字段的地址计算映射到sematable中的某棵平衡树上，找到对应的节点，也就找到了这个Mutex的等待队列了。所以，syne.Mutex是通过信号量来实现排队的。 而channel需要有读(发送)等待队列以及写(接收)等待队列，还要支持缓冲区功能，所以并没有直接使用信号量来实现排队，而是自己实现了一套排队逻辑。 不过，无论是信号量还是channel，底层实现都离不开runtime.mutex，因为它们都需要保障在面临多线程并发时，不会出现同步问题。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:3","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1.4 抢占式调度 2.1.4.1 Go 1.13 Go 1.13 的抢占方式是依赖于栈增长检测代码的，并不算严格意义上的抢占式调度。 首先看一段代码： 按理来说，这段代码运行后应该会不断输出递增的数字，但是在 Go 1.14 之前，运行这段代码会发生阻塞。 运行环境是双核CPU，排查之后发现是在执行STW时发生的阻塞。 GC 开始前需要STW来进行开启写屏障等准备工作，所以STW就是要抢占所有的P，让GC得以正常工作。而示例程序中的main goroutine没能被抢占，它一直在执行，而STW一直在等待它让出，这样就陷入了僵局。 **问题：**为什么会陷入这样的局面？ 答：首先，梳理下STW的主要逻辑。GC需要抢占所有的P，但这不是说抢占就ok的，所以它会记录下自己要等待多少个P让出，当这个值减为0，目的就达到了。对于当前P、以及陷入系统调用的P(_Psyscall)、还有空闲状态的P，直接将其设置为_Pgcstop即可。对于还有G在运行的P，则会将对应的g.stackguard0设置为一个特殊标识(runtime.stackPreempt)，告诉它GC正在等待它让出。此外，还会设置一个gcwaiting标识(sched.gcwaiting=1)，接下来就通过这两个标识符的配合，来实现运行中的P的抢占。 这是怎么实现的呢？ goroutine创建之初，栈的大小时固定的，为了防止出现栈溢出的情况，编译器会在有明显栈消耗的函数头部插入一些检测代码。通过g.stackguard0来判断是否需要进行栈增长，但如果g.stackguard0被设置为特殊标识runtime.stackPreempt，便不会执行栈增长，而是去执行一次调度(schedule())，在schedule()调度执行时，会检测gcwaiting标识，若发现GC在等待执行，便会让出当前P，将其置为_Pgcstop状态。 这样看来，示例main goroutine之所以没能让出，是因为空的for循环并没有调用函数，也就没有机会执行栈增长检测代码，所以它并不知道GC在等待它让出。 2.1.4.2 Go 1.14 之后 依赖栈增长检测代码的抢占方式，遇到没有函数调用的情况就会出现问题。 在 Go 1.14 及之后，这一问题得到了解决。在Linux系统上，这种真正的抢占式调度是基于信号来实现的，所以也称为异步抢占。 函数preemptone用来抢占一个P，定位到该函数，对比 1.13 和 1.14 的实现有何不同。 信号发送 1.13 中，preemptone函数主要负责设置g.preempt=true，并将g.stackguard0设置为特殊标识(stackPreempt)。 而在 1.14 中，增加了最后这个if语句块： 第一个判断用于确认当前硬件环境是否支持这种异步抢占，这个常量值(preemptMSupported)是在编译期间就确定的； 第二个判断(debug.asyncpreemptoff)用于检测用户是否允许开启异步抢占，默认情况下是允许的，但是用户可以通过GODEBUG环境变量来禁用异步抢占。 如果这两条验证都通过了，就将p.preempt字段置为true，实际的抢占操作会交由preemptM函数来完成。 定位到preemptM函数，它的主要逻辑是通过runtime.signalM函数，向指定M发送sigPreempt信号，怎么发送的呢？ signalM函数会通过调用操作系统中信号相关的系统调用，将指定信号发送给目标线程。信号发出去了，异步抢占的前一半工作就算是完成了。 信号处理 后一半工作就要由接收到信号的工作线程来完成了。 线程接收到信号后，会调用对应的信号handler来处理，Go 语言中的信号交由runtime.sighandler来处理，sighandler在确定信号为sigPreempt以后，会调用doSigPreempt函数。它会首先判断runtime是否要对指定的G进行异步抢占，通过什么来判断呢？ 首先，指定的G与其对应P的preempt字段都要为true，而且指定的G还要处在_Grunning状态，还要确认在当前位置打断G并执行抢占是安全的，那么怎么确保安全性呢？ 指定的G可以挂起并安全的扫描它的栈和寄存器，并且当前被打断的位置并没有打断写屏障； 指定的G还有足够的栈空间来注入一个异步抢占函数调用(asyncPreempt)； 这里可以安全的和runtime进行交互，主要就是确定当前并没有持有runtime相关的锁，继而不会在后续尝试获得锁时发生死锁。 确认了要抢占这个G，并且此时抢占是安全的以后，就可以放心的通过pushCall向G的执行上下文中注入异步抢占函数调用了，被注入的异步抢占函数(asyncPreempt)是一个汇编函数，它会先把各个寄存器的值保存在栈上，也就是先保存现场到栈上，然后调用runtime.asyncPreempt2函数，这个函数最终会去执行schedule()，到这里，异步抢占就完成了。 再去执行上边的示例程序，发现可以正常运行。也就是说，即使空的for循环没有被插入栈增长检测代码，在 1.14 中，通过注入异步回调函数的方式，同样能实现抢占式调度。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:4","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1.5 Channel 2.1.5.1 数据结构 type hchan struct { qcount uint dataqsiz uint buf unsafe.Pointer elemsize uint16 closed uint32 elemtype *_type sendx uint recvx uint recvq waitq sendq waitq lock mutex } 问：channel底层数据结构是怎么设计的？ 通过make创建一个缓冲区大小为5，元素类型为int的channel，ch是存在于函数栈帧上的一个指针，指向堆上的hchan数据结构。 因为channel支持协程间并发访问，所以要有一把锁lock来保护整个数据结构。 对于有缓冲来讲，需要知道缓冲区在哪，已经存储了多少个元素，最多存储多少个元素，每个元素占多大空间，所以实际上，缓冲区就是个数组buf、elemsize。 因为 Go 运行中，内存复制、垃圾回收等机制依赖数据的类型信息，所以hchan还要有一个指针，指向元素类型的类型元数据elemtype。 此外，channel支持交替的读(接收)写(发送)，需要分别记录读、写下标的位置recvx、sendx。 当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读(接收)和写(发送)recvq、sendq。 此外，channel能够close，所以还要记录它的关闭状态closed。 综上所述，channel底层就长这个样子： 初始状态下，ch的缓冲区为空，读、写下标都指向下标0的位置，等待队列也都为空。然后，一个协程g1向ch发送数据[1,5]，此时缓冲区已满，若还要继续发送数字6，g1就会进到ch的发送等待队列中。这是一个sudog类型的链表，里面会记录哪个协程在等待，等待哪个channel，等待发送的数据在哪儿等信息。 接下来协程g2从ch接收一个元素，recvx指向下一个位置，第0个位置就空出来了，所以会唤醒sendq中的g1，将这里的数据发送给ch，然后缓冲区再次满了，sendq队列为空。 这个过程中，sendx和recvx都会从0到4再到0，循环移动，所以channel的缓冲区也被称为环形缓冲区。 2.1.5.2 发送数据 阻塞式发送 如果使用以下方式给channel发送数据： ch \u003c- 10 不阻塞的情况： 缓冲区还有空闲位置； 有协程在等着接收数据； 阻塞的情况： ch为nil； ch没有缓冲区，而且也没有协程等着接收数据； ch有缓冲区，但缓冲区已用尽。 非阻塞式发送 select { case ch \u003c- 10: ... default: ... } 若采用这种写法，如果检测到ch可以发送数据，就会执行case分支；如果会发生阻塞就执行default分支。 2.1.5.3 接收数据 阻塞式接收 以下是接收数据的三种写法，都允许发生阻塞： \u003c-ch // 1. 丢弃结果 v := \u003c-ch // 2. 将结果赋值给v v, ok := \u003c-ch // 3. comma ok风格的写法，ok为false表示ch已关闭，此时v是channel元素类型的零值 不阻塞的情况： 在缓冲区中有数据； 有协程等着发送数据； 阻塞的情况： ch为nil； ch无缓冲而且没有协程等着发送数据； ch有缓冲但缓冲区无数据； 非阻塞式接收 select { case \u003c-ch: ... default: ... } 若采用非阻塞式接收方式，如果检测到ch的recv操作不会阻塞时，就会执行case分支；如果会阻塞就会执行default分支。 2.1.5.4 多路select 上面的select只是针对单个channel的操作。多路select是指存在两个或更多的case分支，每个分支可以是一个channel的send或recv操作。 例如一个协程通过多路select等待ch1和ch2，这里default分支是可选的，暂且把这个协程记为g1。 多路select会被编译器转换为对runtime.selectgo函数调用，首先看参数： 第一个参数cas0指向一个数组，数组里装的是select中所有的case分支，顺序是send在前recv在后； 第二个参数order0指向一个uint16类型的数组，数组大小等于case分支的2倍，实际上被用作两个数组：第一个数组用来对所有channel的轮询进行乱序，第二个数组用来对所有的channel的加锁操作进行排序。轮询需要乱序才能保障公平性，而按照固定算法确定加锁顺序才能避免死锁； 第三个参数pc0和race检测相关； nsends和nrecvs分别表示所有case中，执行send和recv操作的分支分别有多少个。 block表示多路select是否要阻塞等待。对应到代码中，就是有default分支的不会被阻塞，没有的会阻塞。 再看返回值： 第一个返回值int类型，代表最终哪个case分支被执行了，对应到cas0指向的数组下标。但是如果进入到default分支，就会对应-1。 第二个返回值bool类型，用于在执行recv操作的case分支时，表明是实际接收到了一个值，还是因channel关闭而得到了零值。 多路select需要进行轮询来确定哪个case分支可操作了，但是轮询前需要先加锁，所以selectgo函数执行时，会先按照有序的加锁顺序，对所有的channel加锁； 然后按照乱序的轮询顺序检查所有channel的等待队列和缓冲区； 假如检查到ch1时，发现有数据可读，那就直接拷贝数据，进入对应分支； 假如所有的channel都不可操作，就把当前协程添加到所有channel的sendq或recvq中，对应这个例子，g1会被添加到ch1的recvq及ch2的sendq中，之后g1会被挂起，并解锁所有的channel； 假如接下来ch1有数据可读了，g1就会被唤醒，完成对应的分支操作后，会再次按照加锁顺序对所有channel加锁，然后从所有的sendq或recvq中将自己移除； 最后全部解锁后返回。 虽然，channel的读写操作写法众多，但事实上，channel阻塞式的send操作会被编译器转换为对runtime.chansend1()的调用，而它内部只是调用了runtime.chansend()；非阻塞式的send操作会被编译器转换为对runtime.selectnbsend()的调用，它也仅仅是调用了runtime.chansend()。所以，send操作主要是通过runtime.chansend()函数实现的。 同样的，channel阻塞式的recv操作会被编译器转换为对runtime.chanrecv1()的调用，而它内部只是调用了runtime.chanrecv()；comma ok风格的写法会被编译器转换为对runtime.chanrecv2()的调用，它的内部也是调用runtime.chanrecv()，只不过比chanrecv1()多了一个返回值；非阻塞式的recv操作会根据是否为comma ok风格，被编译器转换为对runtime.selectnbrecv()或selectnbrecv2()的调用，而它们两个也仅仅是调用了runtime.chanrecv()，所以，recv操作主要是通过runtime.chanrecv()函数实现的。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:5","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.1.6 协程 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:4:6","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.2 内存管理 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.2.1 内存分配器 程序中的数据和变量都会被分配到程序所在的虚拟内存中，内存空间包含两个重要区域：栈区（Stack）和堆区（Heap）。函数调用的参数、返回值以及局部变量大都会被分配到栈上，这部分内存会由编译器进行管理；不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，堆中的对象由内存分配器分配并由垃圾收集器回收。 从进程虚拟空间地址来看： 程序要执行的指令在代码段； 全局变量、静态数据等都会分配在数据段； 函数的局部变量、参数和返回值都会分配在函数栈帧； 2.2.1.1 设计原理 内存管理一般包含三个不同的组件，分别是用户程序（Mutator）、分配器（Allocator）和收集器（Collector），当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:1","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.2.2 GC 从进程虚拟空间地址来看： 程序要执行的指令在代码段； 已初始化的全局变量、静态常量等都会分配在**==数据段==**； 未初始化的全局变量、静态常量等都会分配在**==BSS段==**； 函数的局部变量、参数和返回值都会分配在**==函数栈帧==**； ==Point：== 由于函数调用栈会在函数返回后销毁，因此，如果不能在编译阶段确定数据对象的大小，或者对象生命周期会超过当前所在函数，那么就不适合分配在栈上，而应该分配到堆上。 问题：为什么需要垃圾回收？ 主要是为了释放==堆内存==。随着程序运行，有些数据不会再被用到了，直接分配在栈上的数据，会随着函数调用栈的销毁释放自身占用的内存；但是分配在堆上的数据，它们占用的内存需要程序主动释放才可以重新使用，否则就会成为垃圾，而越积越多的垃圾会不断的消耗系统内存。 垃圾回收有几种常见方式： 手动垃圾回收：C、C++、Rust。一旦释放早了，后续对该数据的访问便会出错，这就是所谓“悬挂指针”问题；而如果忘了释放，它又会一直占用内存，出现“内存泄露”； 自动垃圾回收：Python、Ruby、Java、Go。由运行时识别不再有用的数据并释放他们所占的内存，内存何时被释放，被释放的内存如何处理，都不需要我们关心。 跟踪式垃圾回收 引用计数式垃圾回收 2.2.2.1 设计原理 问题：自动垃圾回收怎么区分哪些数据是垃圾呢？ 可以确定，程序中用得到的数据，一定是从==栈、数据段==这些根节点追踪得到的数据。也就是说，从这些根节点追踪不到的数据一定是没用的数据，一定是垃圾。因此，目前主流的自动垃圾回收算法都是使用**“可达性”近似等价“存活性”**的。 标记-清扫算法 标记清除（Mark-Sweep）算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成**标记（Mark）和清除（Sweep）**两个阶段： 标记阶段 — 从根对象出发查找并标记堆中所有存活的对象； 清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表。 三色抽象 三色抽象可以清晰的展现追踪式回收中对象状态的变化过程。 垃圾回收开始时，所有数据均为白色； 然后把直接追踪到的root节点都标记为灰色：灰色代表基于当前节点展开的追踪还未完成； 当基于某个节点的追踪任务完成后，便会把该节点标记为黑色：表示它是存活数据，而且无需基于它再次进行追踪了。 基于黑色节点找到的所有节点都被标记为灰色，表示还要基于它们进一步开始追踪。 当没有灰色节点时，就意味着标记工作可以结束了。此时，有用数据都为黑色，垃圾都为白色。接下来回收这些白色数据即可。 标记-清扫算法的缺点： 标记-清扫算法容易造成很多小内存，这一问题可以： 基于**BiBOP(Big Bag of Pages)**的思想，把内存块划分为多种大小规格，对相同规格的内存块进行统一管理。 还可以通过紧凑的方法减少碎片化内存，但是会带来多次移动的开销。 复制回收算法 还有一种复制式回收算法，他会把堆划分为两个相等的空间From和To，程序执行时使用From空间，垃圾回收时会扫描From空间，把能追踪到的数据复制到To空间，当所有能追踪到的数据都复制到To空间后，把From和To空间角色对换，原来的To变为From，原来的From可以全部回收用作新的To。这种复制式不会产生碎片化问题，但是会浪费一半的堆内存。 为了提高堆内存利用率，通常会和其他垃圾回收算法搭配使用，只在一部分堆内存中使用复制式回收。比如分代回收。 分代回收 分代回收主要基于弱分代假说：大部分对象都会在年轻时死亡。 新生代对象：新创建的对象； 老年代对象：经受住特定次数GC而依然存活的对象； 基于弱分代假说，大部分对象会在最初经历的GC中死亡，也就是说新生代对象成为垃圾的概率高于老年代对象。因此，可以将数据划分为新生代和老年代，降低老年代执行垃圾回收的频率，不用每次都处理所有数据，将明显提高垃圾回收执行的效率。而且，新生代和老年代还可以分别采用不同的回收策略，进一步提升回收效益并减少开销。 以上均为跟踪式垃圾回收，而引用计数式垃圾回收有很大的不同。 引用计数式 **引用计数指的是一个数据对象被引用的次数。**程序执行过程中，会更新数据对象的引用计数，当对象的引用计数为0时，就表示这个对象不再被使用，可以回收它所占用的内存。因此，在引用计数法中垃圾识别的任务已经被分摊到每次对数据对象的操作中。虽然引用计数法可以及时回收无用内存，但是高频率的更新引用计数也会造成不小的开销，而且如果发生循环引用情况，那么将无法回收。 以上讨论均是在暂停用户程序，只专注于垃圾回收的前提下进行的，也即所谓**==STW==(Stop The World)**。但实际上用户程序无法接受长时间的暂停。 增量式垃圾回收 **增量式垃圾回收：**将长时间的垃圾回收，分成若干小段，和用户程序交替执行，即缩短每次暂停的时间，但增加暂停的次数。 **这会带来新的问题：**保不齐垃圾回收程序前脚刚标记一个黑色对象，用户程序后脚就修改了它(将它指向白色对象，此时原黑色对象应变为灰色，但并没有)，垃圾回收程序有可能误判将白色对象(应为灰色对象)回收。原因如下： 在三色抽象中，黑色对象处理完毕，不会被再次扫描，而灰色对象还会被回收器继续处理，所以若出现黑色对象到白色对象的引用，同时没有任何灰色对象可以抵达这个白色对象，它就会被判为垃圾，但实际上它仍是存活数据。 强三色不变式与弱三色不变式 如果能够做到不出现黑色对象到白色对象的引用，就必然不会出现这样的错误了。这被称为**“强三色不变式”**。 若把条件放宽一点，允许出现黑色对象到白色对象的引用，但是可以保证通过灰色对象可以抵达该白色对象，这样也可以避免这个错误，这被称为**“弱三色不变式”**。 读写屏障 实现**“强/弱三色不变式”通常的做法是建立“读/写屏障”**。 **写屏障：**会在写操作中插入指令，目的是把数据对象的修改通知到垃圾回收器，所以写屏障通常要有一个记录集，而记录集是采用顺序存储还是哈希表、记录精确到被修改的对象还是只记录其所在页等问题，就是写屏障具体实现要考虑的了。 “强三色不变式”提醒我们关注白色指针指向黑色对象的写入操作，无论如何都不允许出现黑色对象到白色对象的引用。可以把白色指针变为灰色，也可以把黑色对象变为灰色。这些都属于**==“插入\"写屏障==**。 “弱三色不变式”则提醒我们关注对那些到白色对象路径的破坏行为。例如要删除灰色对象到白色对象的引用时，可以把白色对象变为灰色。这种写屏障属于**==“删除\"写屏障==**。 **读屏障：**确保用户程序不会访问到已经存在副本的陈旧对象。（主要针对复制式回收） 多核 **并行垃圾回收：**多线程并行执行垃圾回收程序。 并发垃圾回收：用户程序与垃圾回收程序并发执行，这有可能导致错误(有些线程开启了写屏障，有些还没开启，所以通常采用下边那种) 主体并发式垃圾回收：在某些阶段采取STW(确保大伙儿都开启了写屏障)，在其他阶段支持并发。 主体并发增量式垃圾回收：在\"主体并发式垃圾回收\"基础上支持增量式回收， 2.2.2.2 Go Go语言的垃圾回收采用标记-清扫算法，支持**==主体并发增量式回收==，使用插入与删除两种写屏障结合的混合写屏障**。 Go语言的GC在准备阶段(Mark Setup)会为每个p创建一个mark worker协程，把对应的g指针存储到p中，这些后台mark worker创建后很快进入休眠，等到标记阶段得到调度执行。 接下来第一次STW，GC进入_GCMark阶段。全局变量gcphase记录GC阶段标识，全局变量writeBarrier记录是否开启写屏障，全局变量gcBlackenEnabled用于标识是否允许进行GC标记工作(此处置为1，标识允许)。 在STW的情况下开启写屏障。等所有准备工作做好以后，start the world，所有p都会知道写屏障已开启，然后这些后台mark worker可以得到调度执行，展开标记工作。 当没有标记任务时，第二次STW，GC进入_GCMarkTermination阶段，确认标记工作确实已经完成，然后停止标记工作，将gcBlackenEnabled置为0。 接下来，进入_GCOff阶段，关闭写屏障。**start the world，进入清扫阶段。**进入_GCOff阶段前，新分配的对象会直接标记为黑色，进入_GCOff阶段后，再新分配的对象就是白色的了。 执行清扫工作的协程由runtime.main在gcenable中创建，对应g指针存储在全局变量sweep中，到清扫阶段，这个后台的**sweeper会被加入到runq中，它得到调度执行时会执行清扫任务**，因为清扫工作也是增量进行的，所以每一轮GC开始前，还要先确保完成上一轮GC未完成的清扫工作。 这样看来似乎只需要两轮STW，标记与清扫工作并发增量执行的GC而已。 问题： **关于GC标记工作：**依照标记-清扫算法，标记工作要从扫描bss段、数据段、以及协程栈上的这些root结点开始，追踪到堆上的节点，那怎么确定这些数据对象是否是GC感兴趣的指针呢？ Go语言在编译阶段会生成bss段、数据段等对应的元数据，存储在可执行文件中，通过各模块对应的moduledata可以获得gcdatamask、gcbssmask等信息，它们会被用于判断特定root节点是否为指针。 协程栈也有对应的元数据，存储在stackmap中，扫描协程栈时，通过对应元数据，可以知道栈上的局部变量、参数、返回值等对象中那些","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:2","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.2.3 堆内存分配 Go语言的runtime将堆地址空间划分成一个一个的arena，arena区域的起始地址被定义为常量arenaBaseOffset，在amd64架构下的Linux环境下，每个arena的大小是64MB，起始地址也对齐到64MB。每个arena包含8192个page，所以每个page大小为8KB。 **问题：**因为程序运行起来所需分配的内存块有大有小，而分散的、大小不一的碎片化内存一方面可能降低内存利用率，另一方面可能会提高要找到大小合适的内存块的代价。 解决：为降低碎片化内存给程序性能造成的不良影响，Go语言的堆分配采用了与tcmalloc内存分配器类似的算法。**简单来讲就是：**按照一组预置的大小规格把内存页划分成块，然后把不同规格的内存块放入对应的空闲链表中。程序申请内存时，分配器会先根据要申请的内存大小，找到最匹配的规格，然后从对应空闲链表中分配一个内存块。 Go 1.16 runtime包给出了67种预置的大小规格，最小8B，最大32KB。 所以，在划分的整整齐齐的arena里，又会按需划分出不同的span，每个span包含一组连续的page，并且按照特定规格划分成等大的内存块。大小关系是：arena -\u003e span -\u003e page -\u003e 内存块。这些就组成了堆内存。 2.2.3.1 数据结构 在堆内存之外，有一大票用于管理堆内存的数据结构。 mheap用于管理整个堆内存； 一个arena对应一个heapArena结构； 一个span对应一个mspan结构； mheap中，有一个全局的mspan管理中心，它是一个长度为136的数组，数组元素是一个**mcentral结构**+一个padding。 问题：mcentral怎么管理span呢？ **解答：**实际上，一个mcentral对应一种mspan规格类型，记录在spanclass中，spanclass高七位标记内存块大小规格编号，runtime提供的预置规格对应编号1到67，编号0留出来用作标记大于32KB的大块内存，也即一共68种。然后每种规格会按照是否不需要GC扫描，进一步区分开，用最低位进行标识。包含指针的需要GC扫描，归为scannable这一类，不含指针的归为noscan这一类。所以共分为136种。 每种spanclass的mcentral中，会进一步将已用尽与未用尽的mspan分别管理，每一种又会放到两个并发安全的set中：一个是已清扫的，一个是未清扫的。 全局mspan管理中心mcentral方便取用各种类型的mspan，但是为了保障多个p之间并发安全，免不了频繁的加锁、解锁，为降低多个p之间的竞争性，Go语言的每个p都有一个本地小对象缓存p.mcache，从这里取用就不用再加锁了。mcache有一个长度为136的*mspan类型的数组，还有专门用于分配小于16字节的noscan类型的tiny内存，当前p需要用到特定规格类型的mspan时，先去本地缓存这里找对应的mspan，如果没有或者用完了，就去mcentral获取一个放到本地，把已用尽的归还到mcentral的full set中， 接下来看heapArena，这里存储着arena的元数据，里面有一群位图标记。 其中，bitmap位图，用一位标记这个arena中一个指针大小的内存单元到底是指针还是标量，再用一位来标记这块内存单元的后续单元是否包含指针，而且为了便于操作，bitmap中用一字节标记arena中4个指针大小的内存空间，低4位用于用于标记指针/标量，高4位用于标记扫描/终止。例如此处slice，bitmap第一字节的0-3位分别标记三个对应字段是指针还是标量，第4-6位分别标记三个对应字段是否需要继续扫描。 pageInUse是个uint8类型的数组，长度为1024，所以一共8192位。这个位图只标记**处于使用状态(mSpanInUse)**的span的第一个page。例如，arena中第一个使用状态的span包括两个page，对应pageInUse中第0位标为1，第二个span也在使用中，它包括三个page，但只有第一个page对应的第2位会被标记为1。 pageMarks的用法和pageInUse一样，只标记每个span的第一个page，在GC标记阶段会修改这个位图，标记哪些span中存在被标记的对象，在GC清扫阶段会根据这个位图，来释放不含标记对象的span， spans是个*mspan类型的数组，大小为8192，正好对应arena中的8192个page，所以用于定位一个page对应的mspan在哪儿。mspan管理着span中一组连续的page，同mcentral一样，将划分的内存块规格类型记录在spanclass中。 nelem记录着当前span共划分成多少个内存块，freeIndex记录着下个空闲内存块的索引。 与heapArena不同，mspan这里的位图标记，面向的是划分好的内存块单元。 allocBits位图用来标记哪些内存块已经被分配了。 gcmarkBits是当前span的标记位图，在GC标记阶段会对这个位图进行标记，一个二进制位对应span中的一个内存块，到GC清扫阶段会释放掉旧的allocBits，然后把标记好的gcmarkBits用作新的allocBits，这样未被GC标记的内存块就能回收利用了。当然，还会重新分配一段清零的内存给gcmarkBits位图。 2.2.3.2 分配策略 mallocgc是负责堆分配的关键函数，runtime中的new系列和make系列函数都依赖它。 它的主要逻辑可以分为四个部分： 第一部分：辅助GC。如果程序申请堆内存时，正处于GC标记阶段，当下已分配的堆内存还没标记完，你这边又要分配新的内存，万一内存申请的速度超过了GC标记的速度，就可能会出现内存不够的情况。所以，申请一字节内存需要做多少扫描工作？或者说，完成一字节扫描工作后可以分配多大的内存空间？这都是根据GC扫描的进度更新计算的。 每次执行辅助GC，最少要扫描64KB。这是因为协程每次执行辅助GC，多出来的部分会作为信用存储到当前g中，就像信用卡的额度一样，后续再执行mallocgc()时，只要信用额度用不完，就不用执行辅助GC了。 此外，还有一种方法可以逃避辅助GC：窃取信用。后台的GC mark worker执行扫描任务时，会在全局gcController这里(bgScanCredit)积累信用，如果能够窃取足够多的信用值来抵消当前协程背负的债务(说明此时空闲内存足够大)，那就不用执行辅助GC了。 **第二部分：空间分配。**这里需要根据要分配的空间大小，以及是否为noscan型空间来选择不同的分配策略。 如果是noscan类型且大小\u003cmaxTinySize，会使用tiny allocator； 大小\u003emaxSmallSize的内存分配，包括noscan和scanable类型，都会采用大块内存分配器； maxSmallSzie\u003e=大小\u003e=maxTinySize的noscan类型、以及maxSmallSize\u003e=大小的scanable类型，会使用直接匹配预置大小规格来分配。 大小\u003e32KB的大块内存额外处理，这是因为预置的内存规格最大才32KB，所以会直接根据所需页面数，分配一个新的span。 而对于\u003c16B的内存分配，也不直接匹配预置内存规格，主要是为了减少浪费：如果需要连续分配16次1B的内存，每次分配时匹配预置的内存规格为8B(这是最小的了)，那么每次就会浪费7B。而**tiny allocator能够将几个小块的内存分配请求合并**，所以例子中16次1B的内存分配请求可以合并到一个16B的内存块中。诸如此类，可以提高内存使用率。 **tiny allcoator分配内存的大致过程：**每个p的mcache有专门用于tiny allocator的内存(mcache.tiny)。这是一个16B的内存单元，mcache.tinyoffset记录这段内存已经用到哪里了，如果tiny allocator还够分配size大小的内存，就在tiny内存块中直接分配。 (接上)如果剩余的空间不够了，就从当前p的mcache中，找到对应的mspan，重新拿一个16B大小的内存块来用。如果本地缓存中相应规格的mspan也没有空间了，就会从mcentral中拿一个新的mspan过来，分配完以后，如果新拿来的内存块的剩余空间比旧内存的剩余空间还要大，那就用新的内存块把旧的tiny替换掉(旧的还在mcache，只不过不引用了)。 对于最后一种，直接通过本地mcache与全局mcentral配合工作，找到匹配规格的mspan即可。 空间分配好了还没完，还要记录下哪些内存已被分配，哪些数据需要GC扫描，才能继续内存管理工作。所以接下来需要进行一系列位图标记。 2.2.3.3 位图标记 **问题：**通过一个堆内存地址，如何找到对应的heapArena和mspan？ 已知：一个堆内存地址p，arena区域起始地址如图(arenaBaseOffset)，每个arena大小为heapArenaBytes。 求：p在第几个arena中？ 答：arena编号 = (p-arenaBaseOffset)/heapArenaBytes 已知：amd64架构的Linux环境下，一个arena大小和对齐边界都是64M(26位)，而虚拟地址空间中的线性地址有48位，那48位的线性地址可以寻址的虚拟空间就是2^48这么大。 求：这么大的空间可以划分成多少个arena？ 答：2^48/64M=4M Go开发者把h","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:3","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"2.2.4 栈内存分配 2.2.4.1 栈内存分配过程 堆内存分配中的arena中的span除了用作堆内存分配外，也用于栈内存分配，只是用途不同的span对应的mspan状态不同，用作堆内存的mspan是mSpanInUse状态，用作栈内存的是mSpanManual状态。 为提高栈内存分配效率，调度器初始化时，会初始化两个用于栈内存分配的全局对象： stackpool面向32KB以下的栈分配，栈大小必须是2的幂，最小为2KB； **大于等于32KB的栈，由stackLarge**来分配这也是个mspan链表的数组，长度为25，mspan规格从8KB开始，之后每个链表的mspan规格都是前一个的2倍，8KB和16KB这两个链表实际上一直是空的，留着他们是方便使用mspan包含页面数的(以2为底)对数作为数组下标。 初始化后，这些链表都还是空的，接下来它们会作为全局栈缓存来使用。 同堆内存分配一样，每个p也有用于栈分配的本地缓存，这相当于是stackpool的本地缓存。 要分配栈内存时： 小于32KB的栈空间，会优先使用当前p的本地缓存。如果本地缓存中对应规格的内存块链表为空，就从stackpool分配16KB的内存放到本地缓存(stackcache)中，然后继续从本地缓存分配；如果stackpool中对应的链表也为空，就从堆内存中直接分配一个32KB的span，划分成对应的内存块大小放到stackpool中；不过有些情况下，是无法使用本地缓存的，在不能使用本地缓存的情况下，就直接从stackpool分配； 本地无可用缓存，从stackpool分配： stackpool也为空： 无法使用本地缓存： 大于等于32KB的栈空间，就计算需要的page数目，并以2为底求对数(log2npage)，将得到的结果作为stackLarge数组的下标，找到对应的空闲span链表。若链表不为空，就拿一个过来用；若链表为空，就直接从堆内存分配一个拥有这么多个页面的span，并把它整个用于分配栈内存， 链表不为空： 链表为空： 2.2.4.2 栈增长 栈内存初始分配发生在goroutine创建时，由于初始栈大小都是2KB，在实际业务中可能会不够用，所以需要实现一种在运行阶段动态增长栈的机制。 goroutine的栈增长，是通过编译器和runtime合作实现的。编译器会在函数的头部安插检测代码，检查当前剩余的栈空间是否够用。若不够用，就调用runtime中的相关函数来增长栈空间(runtime.morestack_noctxt)，栈空间是成倍增长的，需要增长时，就先把当前的栈空间大小x2，并把协程状态置为_Gcopystack，接下来调用copystack函数分配新的栈空间并拷贝旧栈上的数据，释放旧栈的空间，最后恢复协程运行_Grunning。 2.2.4.3 栈收缩 栈收缩可以减少运行中的协程对栈空间的浪费。 栈收缩不会缩到比2KB还小。 唯一可以触发栈收缩的地方就是**GC**。 GC通过scanstack函数寻找标记root节点时，如果发现可以安全的收缩栈，就会执行栈收缩；不能马上执行时，就设置栈收缩标识(g.preemptShrink=true)，等到协程检测到抢占标识(stackPreempt)，在让出CPU前会检查这个栈收缩标识，为true时就会先进行栈收缩，再让出CPU。 2.2.4.4 栈释放 但是结束运行的协程的栈空间该怎么回收利用？ 常规gorontine结束时，会被放到调度器对象的空闲g队列(sched.gFree)中，这里的空闲协程分两种： 一种有协程栈(sched.gFree.stack)； 一种没有协程栈(sched.gFree.noStack)。 创建协程时，会先看看这里有没有空闲协程可以用，优先使用有栈的协程，其次使用无栈的协程。 不过，常规goroutine运行结束时，都有协程栈，应该进到哪个队列呢？ 如果协程栈没有增长过(还是2KB)，就把这个协程放到有栈的空闲g队列中。而这些空闲协程的栈，也会在GC执行markroot时被释放，到时候有栈的空闲g也会加入到无栈的空闲g队列中。 如果协程栈有增长过，就把协程栈释放掉，再把协程栈放入无栈的空闲g队列中。 **问题：**那么栈释放到哪里了呢？是放回到当前p的本地缓存？还是放回到全局栈缓存？抑或是直接还给堆内存？ **答：**其实都有可能，要视情况而定。 小于32KB的栈：在释放时会先放回本地缓存中，如果本地缓存对应链表中栈空间总和大于32KB，就把一部分放回stackpool中，本地这个链表只保留16KB；如果本地缓存不可用，也会直接放回stackpool中。而且，如果发现这个mspan中，所有内存块都被释放了就会把它归还给堆内存。 **大于等于32KB的栈：**如果当前处于GC清理阶段(gcphase == _GCoff)，就直接释放到堆内存；否则先把它放回到stackLarge。 三、面试题 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:5:4","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.1 Goroutine调度 题目：1 func main() { runtime.GOMAXPROCS(1) var wg sync.WaitGroup wg.Add(3) go func(n int) { println(n) wg.Done() }(1) go func(n int) { println(n) wg.Done() }(2) go func(n int) { println(n) wg.Done() }(3) wg.Wait() } 首先，第2行runtime.GOMAXPROCS(1)把GMP模型中**P的数量限制为1**，这也就限制了任一时刻只允许一个M执行Go代码。在这个前提下，再来分析这几个goroutine的执行顺序。 通过关键字go来创建新的goroutine，实际上会被编译器转化为对runtime.newproc的调用。该函数的主要逻辑就是先切换至系统栈，然后调用newproc1函数，分配并初始化一个新的g，再通过runqput把新的g添加到**当前P的本地runq**中。 听起来，最后的输出应该是1 2 3。但实际上最后的输出是3 1 2。 实际上，P不仅有本地runq，还有一个runnext字段，用来保存下次要运行的g，newproc1中调用runqput时会用到这个runnext。过程如下，我们将输出的数值作为对应goroutine的代号，： 首先，1号goroutine被记在runnext中，2号goroutine把1号goroutine挤走，1号goroutine进入到本地runq； 接下来，3号goroutine又会把2号goroutine挤走，2号goroutine会进入本地runq队列尾部； 调度goroutine执行时，通过runqget获取待执行的g。而runqget也会对runnext特殊处理，**优先调度runnext**这里记录的g，再按顺序调度本地runq中记录的g； 因此，3号goroutine优先执行，然后是本地runq队列，也就是3 1 2。 **本题只有 3 个goroutine，那如果是 4、5、6、… 个呢？**又是什么情况？请看下题！ 题目：2 func main() { runtime.GOMAXPROCS(1) var wg sync.WaitGroup N := 4 // 可以不断增大 N，临界点在 257 for i := 1; i \u003c= N; i++ { wg.Add(1) go func(n int) { println(n) wg.Done() }(i) } wg.Wait() } 其中，4个goroutine的输出是4 1 2 3，5个goroutine的输出是5 1 2 3 4，直到257个goroutine的输出是257 1 2 ... 256，可以看出N \u003c= 257时，都是这个规律。 但是N \u003e 257时又是什么情况呢？不要忘记全局runq！！！ 先解释一下N \u003c= 257是为啥？P的runnext可以记录1个g，本地runq可以记录256个g，一共就是257个。所以若N = 257，就会出现如下情况： 接下来若又到达258号g，会把257号g挤走，但本地runq已满，所以**257号g会和本地runq中的前一半g**一起进到全局runq中(之所以取前一半是为了防止饥饿，之所以随机放到全局runq是为了避免多核cpu修改同一个缓存)。 按照平时描述的调度逻辑：先从本地runq获取待执行的g，没有的话再从全局runq获取，还没有的话就去别的p那里steal一部分。所以： 这里最先执行的是runnext中的258号goroutine； 接下来是本地runq中的129号-256号； 最后全局队列中的g才会被拿回本地runq。 ==但实际上并非如此==。实际运行发现，在129号-256号之间，会发现1号和2号也穿插在这段区间内被执行了。这个问题与runq的排队逻辑无关，属于调度逻辑的范畴。 在介绍runtime.schedule时，介绍过每隔61个schedtick就会优先从全局runq中获取goroutine，这样是为了避免在每个p的本地runq都繁忙的时候，全局runq中的goroutine迟迟得不到调度的情况。 问答题集合 问：GPM模型中，P引入的原因？ 答： 一开始所有的g都在一个全局runq中，用一个全局的mutex保护全局runq，多个m从全局runq中获取g时需要频繁的加解锁及等待； g的每次执行会被随机的分到不同的m，造成在不同m的频繁切换，破坏程序的局部性；(这点有点怪，有待确定) 每个m都会关联一个内存分配缓存，造成大量的内存开销，但实际上只有执行g的m才需要，那些阻塞在调度的m根本不需要； 引入p后，m就可以直接从p处获取待执行的g，不用每次都和众多m从一个全局队列中争抢任务，提高了并发性能。 问：多个线程可以属于同一个进程并共享内存空间。 因为多线程不需要创建新的虚拟内存空间，所以它们也不需要内存管理单元处理上下文的切换，线程之间的通信也正是基于共享的内存进行的，与重量级的进程相比，线程显得比较轻量。这不是挺好的嘛，为啥还要引入goroutine？ 答： 虽然线程比较轻量，但是在调度时也有比较大的额外开销； 每个线程都需要一个用户栈和内核栈，当需要使用系统资源的时候，会通过系统调用进入内核态。(为什么要分开？为了防止用户态代码访问内核数据)。当系统的线程达到一定规模，内核栈和用户栈会占用大量内存；并且，操作系统基于时间片的策略调度所有线程，若线程规模过大，为了降低延迟，线程每次获得的时间片会被压缩，从而导致线程切换频率变大。线程的频繁切换也会占用大量CPU资源。而高并发的场景需求就是要频繁切换。 引入协程，可以节省内存空间，降低调度代价。协程的调度不需要操作系统参与，只需要用户态程序调度。 每个线程都会占用 1M 以上的内存空间，在切换线程时不止会消耗较多的内存，恢复寄存器中的内容还需要向操作系统申请或者销毁资源，每一次线程上下文的切换都需要消耗 ~1us 左右的时间，但是 Go 调度器对 Goroutine 的上下文切换约为 ~0.2us，减少了 80% 的额外开销。 **问：**谁负责触发timer注册的回调函数？ 答：timer的触发分为调度触发和监控线程触发，两者主要是通过调用函数checkTimers()来实现。 其实每个p都有一个最小堆p.timers，用于管理自己的timer，堆顶的timer就是接下来要触发的那一个(老版本这个堆是全局的，就很慢！)。而工作线程每次调度时(执行schedule()时)，都会调用checkTimers()函数，检查并执行那些已经到时间的timer。不过这不够稳妥，万一所有的m都在忙，那么就不能及时触发调度了，可能会导致timer执行时间发生较大偏差。所以还会通过监控线程来增加一层保障。 监控线程是由main goroutine创建的，与GPM中的工作线程不同，并不需要依赖p，也不由GPM调度。监控线程有多个任务，其中一项便是保障timer的正常执行。监控线程检测到接下来有timer要执行时(遍历所有的p，找出下次最先执行(时间值最小)的时间和其所在的p)，若此时无空闲m，便会创建新的工作线程以保障timer可以顺利执行。 问：如何抢占？具体说说？ 答：监控线程要本着公平调度的原则，对运行时间过长的p实行**“抢占”**操作。就是告诉那些运行时间超过特定阈值(10ms)的g，该让出了！ Go 1.14之前依赖于栈增长。**展开：**当runtime希望某个协程让出CPU时，就会把他的stackguard赋值为stackPreempt，这是一个非常大的值，真正的栈指针不会指向这个位置，因此用作特殊标识。进而会跳转到morestack处，而morestack会调用runtime.newstack()函数，负责栈增长工作。不过他在进行栈增长工作前会先判断stackguard0是否等于stackPreempt，等于的话就不进行栈增长了，而是执行一次协程调度。这种方式的缺点是过度依赖栈增长代码，如果来个空的for{}循环，因为与栈增长无关，程序就会卡死在这个地方。 其实，为了充分利用CPU，监控线程还会抢占处在系统调用中的p，因为一个协程要执行系统调用，就要切换到g0栈，在系统调用没执行完之前，这个m和g其实绑定了，不能被分开，也就用不到p，所以在陷入系统调用前，当前m会让出p，解除m.p与当前p的强关联，只在m.oldp中记录这个p。p的数目毕竟有限，如果有其他协程正在等待执行，那就会把他关联到其他m。 不过如果当前m从系统调用中恢复，会先检测之前的p是否被占用，没有的话就继续使用，否则再去申请一个，没申请到的话，就把当前g放入全局runq中，然后当前线程就睡眠了。 **问：**那抢占时，怎么知道某个g运行时间过长了呢？ 答：p里面有一个schedtick字段，每当调度执行一个新的g，并且不继承上个g的时间片时，就会把p.schedtick++，而sysmontick.schedwhen记录上一次调度的时间。监控线程如果监测到sysmontick.schedtick与p.schedtick不相等，说明这个p发生了新的调度，就会同步sysmontick.schedtick的值，并更新调度时间sysmontick.schedwhen；但若二者相等，说明没发生新的调度，或者即使发生了新的调度，也沿用了之前的时间片，所以可以通过当前时间与sysmontick.schedwhen的差值来判断当前p上的g是","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:6:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.2 组合式继承 问：如下代码输出什么？ 问：组合式继承中，编译器生成包装方法的规则？ ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:7:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.3 闭包 func main() { x()() } func x() (y func()) { y = func() { println(\"y\") } return func() { println(\"z\") y() } } 会输出什么呢？ 会不断的输出z。 先看main函数的栈帧： x函数只有返回值没有参数，而x的返回值是一个函数。函数作为参数、返回值或者被赋值给变量时，就被称为Function Value。所以这里的y是一个Function Value。Function Value本质上是一个指针，指向一个runtime.funcval结构体，这个结构体存储了对应函数的指令入口地址。x返回一个匿名函数，而这个函数中捕获了y，所以这个返回值是一个闭包对象。闭包对象就是一个有捕获列表的Function Value而已。 也就是说在这个函数入口地址后面，会有该闭包函数捕获的变量，**不过这里捕获的究竟是变量的值还是它的地址？**其实，如果被捕获的变量在其赋初值后没有在被修改过，就会捕获变量的值；反之，就捕获变量的地址。 在函数x中，先给y赋初值，return又将新的返回值写到了y，所以闭包对象这里捕获的是变量的地址。 但是当y的地址被捕获了，当x执行结束，main函数调用返回的y时，这里的栈帧就不再为调用x服务了，所以被捕获的变量需要逃逸到堆上，返回值这里就要存储y在堆上的地址，但是，这样就改变了返回值的类型，所以让y逃逸到堆上是行不通的。 那么，编译器会怎样处理返回值的地址被捕获的情况呢？ 实际上，编译器会在堆上分配一个y的副本，记为y'，同时为x生成一个局部变量，存储y'在堆上的地址，记为py'，然后在函数x和返回的闭包对象中都使用副本y'，这里捕获的是y'的地址，只在x返回前将y'的值拷贝到返回值空间，这样y和y'都指向堆上的同一个闭包对象。而在调用x的栈帧销毁后，这个闭包对象依然可以正常使用其捕获的变量。 当返回值y被调用，找到这里的闭包函数，输出第一个字母z，然后通过捕获列表找到y'，调用y'指向的函数-还是这个函数，因此会不停输出z。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:8:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.4 GC 问：自动垃圾回收怎么区分哪些数据是垃圾呢？ 可以确定，程序中用得到的数据，一定是从栈、数据段这些根节点追踪得到的数据。也就是说，从这些根节点追踪不到的数据一定是没用的数据，一定是垃圾。因此，目前主流的自动垃圾回收算法都是使用**“可达性”近似等价“存活性”**的。 ==标记-清扫算法== 标记清除（Mark-Sweep）算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成**标记（Mark）和清除（Sweep）**两个阶段： 标记阶段 — 从根对象出发查找并标记堆中所有存活的对象； 清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表。 ==三色抽象== 三色抽象可以清晰的展现追踪式回收中对象状态的变化过程。 垃圾回收开始时，所有数据均为白色； 然后把直接追踪到的root节点都标记为灰色：灰色代表基于当前节点展开的追踪还未完成； 当基于某个节点的追踪任务完成后，便会把该节点标记为黑色：表示它是存活数据，而且无需基于它再次进行追踪了。 基于黑色节点找到的所有节点都被标记为灰色，表示还要基于它们进一步开始追踪。 当没有灰色节点时，就意味着标记工作可以结束了。此时，有用数据都为黑色，垃圾都为白色。接下来回收这些白色数据即可。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:9:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.5 Mutex 问：RWMutex 是读优先还是写优先？读优先的话，如果一直有读请求，那么写请求会饥饿吗？⭐🚩 RWMutex 是一个读/写互斥锁，在某一时刻只能由任意数量的 reader 持有 或者 一个 writer 持有。也就是说，要么放行任意数量的 reader，多个 reader 可以并行读；要么放行一个 writer，多个 writer 需要串行写。 一旦涉及到多个 reader 和 writer ，就需要考虑优先级问题，是 reader 优先还是 writer 优先： 读者优先（readers-preference）：读者优先是读操作优先于写操作，即使写操作提出申请资源，但只要还有读者在读取操作，就还允许其他读者继续读取操作，直到所有读者结束读取，才开始写。读优先可以提供很高的并发处理性能，但是在频繁读取的系统中，会长时间写阻塞，导致写饥饿。 写者优先（writers-preference）：写者优先是写操作优先于读操作，如果有写者提出申请资源，在申请之前已经开始读取操作的可以继续执行读取，但是如果再有读者申请读取操作，则不能够读取，只有在所有的写者写完之后才可以读取。写者优先解决了读者优先造成写饥饿的问题。但是若在频繁写入的系统中，会长时间读阻塞，导致读饥饿。 RWMutex 的数据结构： type RWMutex struct { w Mutex // 用于控制多个写锁，获得写锁首先要获取该锁，如果有一个写锁在进行，那么再到来的写锁将会阻塞于此 writerSem uint32 // 写阻塞等待的信号量，最后一个读者释放锁时会释放信号量 readerSem uint32 // 读阻塞的协程等待的信号量，持有写锁的协程释放锁后会释放信号量 readerCount int32 // 记录读者个数 readerWait int32 // 记录写阻塞时读者个数 } RWMutex 设计采用写优先方法。 问题要点： 写操作是如何阻止写操作的？ RWMutex包含一个互斥锁(Mutex)，写锁定必须要先获取该互斥锁。 写操作是如何阻止读操作的？ RWMutex.readerCount是个整型值，用于表示读者数量，不考虑写操作的情况下，每次读锁定将该值+1，每次解除读锁定将该值-1，所以readerCount取值为[0, N]，N为读者个数，实际上最大可支持2^30^个并发读者。 当写锁定进行时，会先将readerCount减去2^30^，从而readerCount变成了负值，此时再有读锁定到来时检测到readerCount为负值，便知道有写操作在进行，只好阻塞等待，同时还会对readerCount+1，这样等待的读操作个数并不会丢失，只需要将readerCount加上2^30^即可获得。 所以，写操作将readerCount变成负值来阻止读操作。 读操作是如何阻止写操作的？ 写操作到来时，会把RWMutex.readerCount值拷贝到RWMutex.readerWait中，用于标记排在写操作前面的读者个数。前面的读操作结束后，除了会递减RWMutex.readerCount，还会递减RWMutex.readerWait值，当RWMutex.readerWait值变为0时唤醒写操作。 为什么写锁定不会被饿死？ 写操作要等待读操作结束后才可以获得锁，写操作等待期间可能还有新的读操作持续到来，如果写操作等待所有读操作结束，很可能被饿死。然而，通过RWMutex.readerWait可完美解决这个问题。 写操作到来时，会把RWMutex.readerCount值拷贝到RWMutex.readerWait中，用于标记排在写操作前面的读者个数。 前面的读操作结束后，除了会递减RWMutex.readerCount，还会递减RWMutex.readerWait值，当RWMutex.readerWait值变为0时唤醒写操作。 问：Mutex的工作模式？正常模式和饥饿模式？ Mutex 共有两种工作模式：正常模式和饥饿模式。 正常模式下，一个尝试加锁的goroutine会先自旋几次，尝试通过原子操作获得锁。若几次自旋之后不能获得锁，就会通过信号量进行排队等待。所有的等待者会按照先入先出的顺序排队，但是当锁被释放，被唤醒的等待者并不会直接获得锁，它需要和处于自旋阶段尚未排队的goroutine进行竞争。 这种情况后来者更有优势，首先是因为处于自旋状态的goroutine可能有多个，且后来者正在CPU上运行，显然比刚被唤醒的goroutine有优势。如果被唤醒的goroutine没有获得锁，它将再次进入排队队列，但是是直接在队头。 当一个goroutine本次等待加锁的时间超过1ms，它会把当前Mutex切换到饥饿模式，Mutex的所有权直接转让给队首goroutine，此时后来者也不再自旋，而是直接进入队列尾部开始排队。 当获得Mutex的goroutine是队列中最后一个时，或者它的等待时间小于1ms，它会把Mutex的状态改回正常模式。 正常模式需要大家争抢锁，从而获得更高的吞吐量；而饥饿模式对防止出现尾端延迟特别重要。 问：什么时候会发生自旋？ 加锁时，如果当前 Locked 位为1，则说明当前该锁由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续探测 Locked 位是否变为0，这个过程就是「自旋」。实际上就是执行了30次PAUSE。 多核场景。因为单核场景是没有意义的，一个占着CPU进行自旋等待锁，一个占着锁。这无意义。 gomaxprocs\u003e1。同上。 至少有一个其他的p正在running \u0026\u0026 当前p的本地runq队列为空。比起调度这个goroutine进行自旋，不如调度别的goroutine。 自旋上限为4，每执行一次自旋都会重新判断是否可以继续自旋。如果锁被释放了，或者锁进入了饥饿模式，或者已经自旋了4次，都会结束自旋。 问：为什么自旋次数有上限？ 自旋是为了避免频繁获得锁失败导致的协程切换，这样开销很大。若锁的持有时间很短，自旋几次就能获得，这样就能减少切换，但如果锁的持有时间很长，那就会无意义的自旋，反倒浪费了CPU资源，所以通常限制自旋次数，自旋次数内无法获得锁就让出CPU，以免长时间无意义的等待。 问：协程是如何进行排队的呢？ 通过sema字段。runtime内部会通过一个大小为251的sematable来管理所有semaphore，这个sematable存储的是251课平衡树的根，平衡树中每个节点都是一个sudog类型的对象，要使用一个信号量时，需要提供一个记录信号量数值的变量，根据它的地址进行计算，映射到sematable中的一颗平衡树上，找到对应的节点就找到了该信号量的等待队列，该信号量的协程就在这个队列中进行等待唤醒。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:10:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.6 方法集 问：为什么要限制 T 和 *T 不能声明同名方法？ 首先，T和*T是两种类型，分别有着自己的类型元数据，而根据自定义类型的类型元数据，可以找到该类型关联的方法列表。 可以确定的是，T的方法集里，全部都是有明确定义的接收者为T类型的方法；而*T的方法集里，除了有明确定义的接收者为*T的方法以外，**还会有编译器生成的一些\"包装方法”：**这些包装方法是对接收者为T类型的同名方法的\"包装”。 如果给T和*T定义了同名方法，就有可能和编译器生成的包装方法发生冲突，所以 Go 干脆不允许为T和*T定义同名方法。 问：为什么编译器要为 *T 生成 T 的同名方法？ 这里首先要明确一点：通过*T类型的变量直接调用T类型接收者的方法只是一种语法糖。经验证，这种调用方式，编译器会在调用端进行指针解引用，并不会用到这里的包装方法。 ==实际上，编译器生成包装方法主要是为了支持接口。== 问：为什么是为了支持接口？ 非空接口包含两个指针：一个和类型元数据相关，一个和接口装载的数据相关。虽然有数据指针，但是并不能像语法糖那样，对指针进行解引用来调用值接收者的方法。这是为啥呢？ 原因：方法的接收者是方法调用时隐含的第一个参数，Go 中的函数参数通过栈进行传递，如果参数是指针类型，平台确定了，指针大小也就确定了。但如果要解引用为值类型，就必须有明确的类型信息，编译器才能知道这个参数该在栈上分配多大的内存空间。对于接口来说，编译阶段并不能确定该接口会装载的数据类型，也就不能进行指针解引用。所以选择为*T生成一套T的包装方法。 在链接阶段，不会用到的方法会被忽略。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:11:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.7 抢占式调度 问：如何进行抢占式调度？ Go 1.14 之前，是借助于栈增长检测来实现抢占式调度的，若goroutine中没有导致栈增长的代码，就不会被抢占，所以这不算真正的抢占式调度。 以GC举例，STW阶段需要抢占所有的P，但不是说抢占就能抢占的，会先记录要等待多少个P，当这个值减为0，目的就达到了。 对于当前P、以及陷入系统调用的P(_Psyscall)、还有空闲状态的P，直接将其设置为_Pgcstop即可； 对于还有G在运行的P，则会将对应的g.stackguard0设置为一个特殊标识(runtime.stackPreempt)，告诉它GC正在等待它让出。此外，还会设置一个gcwaiting标识(设置gcwaiting=1)，接下来就通过这两个标识符的配合，来实现运行中的P的抢占。 goroutine创建之初，栈的大小是固定的，为了防止出现栈溢出的情况，编译器会在有明显栈消耗的函数头部插入一些检测代码，通过g.stackguard0来判断是否需要进行栈增长：如果g.stackguard0被设置为特殊标识runtime.stackPreempt，便不会执行栈增长，而是去执行一次调度(schedule())；在schedule()调度执行时，会检测gcwaiting标识，若发现GC在等待执行，便会让出当前P，将其置为_Pgcstop状态。 依赖栈增长检测代码的抢占方式，遇到没有函数调用的情况就会出现问题。 Go 1.14 之后，preemptone函数会判断当前硬件环境是否支持异步抢占，还会判断用户是否允许开启异步抢占，默认情况下是允许的。如果这两条验证都通过了，就将p.preempt字段置为true，实际的抢占操作会交由preemptM函数来完成。preemptM函数会调用signalM函数，通过调用操作系统中信号相关的系统调用，将指定信号发送给目标线程。 线程接收到信号后，会调用对应的信号处理函数sighandler来处理，sighandler在确定信号为sigPreempt(抢占信号)以后，它会首先判断runtime是否要对指定的G进行异步抢占，通过什么来判断呢？ 指定的G与其对应P的preempt字段都要为true，而且指定的G还要处在_Grunning状态； 还要确认在当前位置打断G并执行抢占是安全的 指定的G可以挂起并安全的扫描它的栈和寄存器，并且当前被打断的位置并没有打断写屏障； 指定的G还有足够的栈空间来注入一个异步抢占函数调用(asyncPreempt)； 这里可以安全的和runtime进行交互，主要就是确定当前并没有持有runtime相关的锁，继而不会在后续尝试获得锁时发生死锁。 确认了要抢占这个G，并且此时抢占是安全的以后，就可以放心的通过pushCall向G中注入异步抢占函数调用了，被注入的异步抢占函数(asyncPreempt)最终会去执行schedule()，到这里，异步抢占就完成了。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:12:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.8 Channel 问：channel 是否是并发安全的？ 是滴 问：怎么通过 channel 实现协程间的通信？ 问：向已关闭的 channel 写 会发生什么？从已关闭的 channel 读 会发生什么？⭐ func testClose() { intChan := make(chan int, 3) intChan \u003c- 2 // 1. 关闭一个channel close(intChan) // 2. 向关闭的channel中写入数据 //intChan \u003c- 3 // 会报错 panic: send on closed channel // 3. 从关闭的channel读取数据 num, ok := \u003c-intChan fmt.Println(num, ok) // 2 true num, ok = \u003c-intChan fmt.Println(num, ok) // 0 false } 问：如何优雅关闭一个 Channel？⭐⭐ 先说说为啥Channel关闭这么麻烦： 不能无脑关闭，如果一个channel已经关闭，重复关闭channel会导致panic 往一个关闭的channel写数据，也会导致panic **channel的关闭原则：**⭐ 不要在消费者端关闭channel 不要在有多个并行的生产者时关闭channel(应该只在唯一或者最后一个生产者协程中关闭channel) ==优雅的关闭，其实要分情况的：== 单个生产者，单个消费者 ​ 直接让生产者关闭。 单个生产者，多个消费者 这种情况很简单，直接让生产者关闭即可。 多个生产者，单个消费者 ​ 不能在消费端关闭，这违背了channel关闭原则。可以让消费者标记一个close信号，通知生产者不要继续写数据。 多个生产者，多个消费者 ​ 可以设置一个中间调解者角色。 首先设置一个通道toStop，当生产者或消费者达到条件，就向toStop发送关闭信号，中间角色收到后关闭stopCh(仅用作通知发送者不要再向数据通道dataCh写数据了)，生产者收到stopCh的关闭信号后，不再向dataCh写数据。 请注意，信号通道toStop的容量必须至少为1。如果它的容量为0，则在中间调解者还未准备好的情况下就已经有某个协程向toStop发送信号时，此信号有可能被抛弃。 参考文章： https://gfw.go101.org/article/channel-closing.html 问：channel 的发送、接收、关闭？ 发送： 发送操作会对 hchan 加锁； 当 recvq 中存在等待接收的 goroutine 时，若有 goroutine 要发送数据，就会调用 memmove 函数从发送 goroutine 的栈中，直接拷贝数据到接收 goroutine 的栈中，不经过 channel (无论 channel 是否有缓冲区)； 当 recvq 等待队列为空时，会判断 hchan.buf 是否可用。如果可用，则会将发送的数据拷贝至 hchan.buf 中； 如果 hchan.buf 已满，那么将当前发送 goroutine 置于 sendq 中排队，并在运行时中挂起； 向已经关闭的 channel 发送数据，会引发 panic； 对于无缓冲的 channel 来说，它天然就是 hchan.buf 已满的情况，因为它的 hchan.buf 的容量为 0。 接收： 接收操作会对 hchan 加锁。 当 sendq 中存在等待发送的 goroutine 时，意味着此时的 hchan.buf 已满（无缓存的天然已满），分两种情况： 如果是有缓存的 hchan，那么先将缓冲区的数据拷贝给接收 goroutine，再将 sendq 的队头 sudog 出队，将出队的 sudog 上的元素拷贝至 hchan 的缓存区。 如果是无缓存的 hchan，那么直接将出队的 sudog 上的元素拷贝给接收 goroutine。两种情况的最后都会唤醒出队的 sudog 上的发送 goroutine。 当 sendq 发送队列为空时，会判断 hchan.buf 是否可用。 如果可用，则会将 hchan.buf 的数据拷贝给接收 goroutine。 如果 hchan.buf 不可用，那么将当前接收 goroutine 置于 recvq 中排队，并在运行时中挂起。 与发送不同的是，当 channel 关闭时，goroutine 还能从 channel 中获取数据。如果 recvq 等待列表中有 goroutines，那么它们都会被唤醒接收数据。如果 hchan.buf 中还有未接收的数据，那么 goroutine 会接收缓冲区中的数据，否则 goroutine 会获取到元素的零值。 关闭： 如果关闭已关闭的 channel 会引发 painc。 关闭 channel 后，如果有阻塞的读取或发送 goroutines 将会被唤醒： 读取 goroutine 会获取到 hchan 的已接收元素，如果没有，则获取到元素零值； 发送 goroutine 的执行则会引发 painc。 问：channel 非得关闭吗？⭐🚩 不用，channel 没有被任何协程用到后最终会被 GC 回收。 但，需要分别考虑两种情况： channel 的发送次数 == 接收次数： 发送者 goroutine 和接收者 goroutine 分别都会在发送或接收结束时结束各自的 goroutine (也即是channel中没有阻塞的goroutine)，此时，channel由于没有被使用，就会被垃圾收集器自动回收。这种情况下，不关闭 channel，没有任何副作用。 channel 的发送次数 != 接收次数： channel 的发送次数不等于接收次数时，可能会导致发送者或接收者阻塞在channel。因此channel由于一直被使用，导致无法被垃圾回收。阻塞的 goroutine 和未被回收的 channel 都造成了内存泄漏的问题。 问：如何判断channel已关闭？🤔❓ 通过 v, ok := \u003c-chan，若已关闭，ok 就是 false； 似乎得分有缓冲和无缓冲： // 1. 有缓冲时，只要缓冲区有数据，ok就是true，因此不能用这种方法判断 func main() { ch := make(chan int, 2) ch \u003c- 1 close(ch) // 此处已关闭，但channel依然有数据未读完 v1, ok1 := \u003c-ch // 此时channel依然有数据未读完 fmt.Println(v1, ok1) // 1 true v2, ok2 := \u003c-ch // 此时channel没数据可读 fmt.Println(v2, ok2) // 0 false } // 2. 无缓冲时，可以酱紫判断。 func main() { ch := make(chan int) //ch \u003c- 1 close(ch) // 此处已关闭 v1, ok1 := \u003c-ch fmt.Println(v1, ok1) // 0 false v2, ok2 := \u003c-ch // 此时channel没数据可读 fmt.Println(v2, ok2) // 0 false } 通过 for range，会自动判断 channel 是否结束，如果结束则自动退出 for 循环。 同上，也得分有无缓冲。 似乎，没有什么好办法？ 问：Channel 有啥应用？ 终止信号通知。例如，main goroutine等待hello goroutine执行完毕； 任务定时。与timer结合，实现超时控制。Etcd中很常见 select { case \u003c-time.After(100 * time.Millisecond): case \u003c-s.stopc: return false } 生产者和消费者。生产者向Channel写数据，消费者从Channel读数据； 控制并发数； var limit = make(chan int, 3) func main() { // ………… for _, w := range work { go func() { limit \u003c- 1 w() \u003c-limit }() } // ………… } 问：Channel 啥时候会导致内存泄漏？ 泄漏的原因是 goroutine 操作 channel 后，处于发送或接收阻塞状态，而 channel 处于满或空的状态，一直得不到改变。 此时 goroutine 一直阻塞，得不到释放，就造成了内存泄露。其实并不是channel本身的内存泄漏？ 问：channel的底层是怎样的？ 用make创建chan时，函数栈帧上会存储chan的指针，指向堆上的hchan结构体。 因为channel支持协程间并发访问，所以要有一把**锁lock**来保护整个数据结构。 对于有缓冲来讲，需要知道缓冲区在哪，已经存储了多少个元素，最多存储多少个元素，每个元素占多大空间，所以实际上，缓冲区就是个数组buf、elemsize。 因为 Go 运行中，内存复制、垃圾回收等机制依赖数据的类型信息，所以hchan还要有一个指针，指向元素类型的类型元数据elemtype。 此外，channel支持交替的读(接收)写(发送)，需要分别记录读、写下标的位置recvx、sendx。 当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读(接收)和写(发送)rec","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:13:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.9 内存 问：内存逃逸？⭐🚩 编译器会根据变量是否被外部引用来决定是否逃逸： 如果函数外部没有引用，则优先放到栈中； 如果函数外部存在引用，则必定放到堆中； 如果栈上放不下，则必定放到堆上； 案例： **指针逃逸：**函数返回值为局部变量的指针，函数虽然退出了，但是因为指针的存在，指向的内存不能随着函数结束而回收，因此只能分配在堆上。 **栈空间不足：**当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量s占用内存过大，编译器会将其分配到堆上； **变量大小不确定：**编译期间无法确定slice的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存； **动态类型：**动态类型就是编译期间不确定参数的类型、参数的长度也不确定的情况下就会发生逃逸； **闭包引用对象：**闭包函数中局部变量i在后续函数是继续使用的，编译器将其分配到堆上； 反射：ValueOf。 问：make和new有啥区别？ **两者的作用类型不同：**new给int、string、数组分配内存，make给slice、map、channel分配内存； **两者的返回值不同：**new的返回值类型为一个指向新分配好的内存空间的一个指定类型指针。而make的返回值类型为它本身。 hash := make(map[int]bool, 10) // hash 是一个指向 runtime.hmap 结构体的指针 ch := make(chan int, 5) // ch 是一个指向 runtime.hchan 结构体的指针 new分配的内存空间会被清零，make分配空间之后会被初始化。 new分配的内存空间不一定会在堆上分配，比如说该指针就在本函数内使用。 若用ps := new([]string)初始化，new 是不负责底层数组的分配的，仅仅返回slice的起始地址，此时这个slice还没有底层数组，如果对其进行赋值，就会出错。 需要通过Append进行分配底层数组。 问：为什么要内存对齐？ 首先，CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。比如 32 位的 CPU ，字长为 4 字节，那么 CPU 访问内存的单位也是 4 字节。 有两个目的： 减少访存次数； 便于原子性操作。 减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如： 当内存对齐时，读取 b 只需要读取一次内存。 非内存对齐时，读取 b 需要两次访存([0, 3]，[4, 7]，然后拼接出 b)： 内存对齐对实现变量的原子性操作也是有好处的，每次内存访问是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，这个特性在并发场景下至关重要。 问：结构体是怎么进行内存对齐的？成员的顺序不同，结构体的大小会不同吗？ type demo1 struct { a int8 b int16 c int32 } type demo2 struct { a int8 c int32 b int16 } func main() { fmt.Println(unsafe.Sizeof(demo1{})) // 8 fmt.Println(unsafe.Sizeof(demo2{})) // 12 } ==结构体内存对齐规则==： 每个字段按照自身的对齐倍数来确定在内存中的偏移量，对齐倍数 = min(自身的长度，机器字长)； 排列完成后，需要对结构体整体再进行一次内存对齐。 成员的顺序不同，结构体的大小可能不同，因此结构体的内存对齐有技巧。 分析上面的代码示例(机器字长 32 位)，首先是 demo1： a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。 b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。 c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。 因此 demo1 的内存占用为 8 字节。 其次是 demo2： a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。 c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。 b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节。 demo2 的对齐倍数由 c 的对齐倍数决定，也是 4，因此，demo2 的内存占用为 12 字节。 ==额外的问题==：空 struct{} 的对齐 空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 struct{} 作为结构体最后一个字段时，需要内存对齐。因为如果有指针指向该字段，返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。 因此，当 struct{} 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全。我们做个试验，验证下这种情况。 type demo3 struct { c int32 a struct{} } type demo4 struct { a struct{} c int32 } func main() { fmt.Println(unsafe.Sizeof(demo3{})) // 8 fmt.Println(unsafe.Sizeof(demo4{})) // 4 } 可以看到，demo4{} 的大小为 4 字节，与字段 c 占据空间一致，而 demo3{} 的大小为 8 字节，即额外填充了 4 字节的空间。 另，没有任何字段的空 struct{} 和没有任何元素的 array 占据的内存空间大小为 0，不同的大小为 0 的变量可能指向同一块地址。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:14:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.10 数据结构 问：map 是并发安全的吗？那怎么让他并发安全？那加锁的 map 和 sync.map 有啥区别？sync.map 的适用场景？⭐🚩 普通的map不是并发安全的，sync.map是并发安全的。 如何让普通的map并发安全，一般的思路有两种： 加锁，操作前先获取锁，操作完释放。缺点是：粒度太大，效率不高； 划分成几个小的 map，只操作相应小的 map。缺点是：实现复杂，容易出错。 先看看sync.map： type Map struct { mu Mutex // 保护 dirty 和 read read atomic.Value // readOnly，只读，所以是并发安全的 dirty map[interface{}]*entry // 一个非线程安全的原始 map misses int // 计数作用。每次从read中读失败，则计数+1 } map+锁 和 sync.map 的对比： 自己实现的加锁的Map，每次操作都需要先获得锁，这就造成极大的性能浪费； sync.map中有只读数据read、锁mu、普通的Mapdirty、计数器misses。其中，执行增删查改前，都会先对read进行操作，因为这是只读的，支持原子操作，也就支持并发访问。这就会省去很大一部分加锁解锁带来的开销。 性能测试结论： 插入元素：SyncMapStore \u003c MapStore \u003c RwMapStore； 查找元素：MapLookup \u003c RwMapLookup \u003c SyncMapLookup； 删除元素：RwMapDelete \u003c MapDelete \u003c SyncMapDelete 测试如下： ❯ go test -bench=. goos: windows goarch: amd64 pkg: goLearn/sync/08-sync.map cpu: 12th Gen Intel(R) Core(TM) i7-12700K BenchmarkBuiltinMapStoreParalell-20 15114511 81.30 ns/op BenchmarkBuiltinRwMapStoreParalell-20 16176103 83.39 ns/op BenchmarkSyncMapStoreParalell-20 8515656 171.0 ns/op BenchmarkBuiltinMapLookupParalell-20 21025113 61.02 ns/op BenchmarkBuiltinRwMapLookupParalell-20 26539101 45.61 ns/op BenchmarkSyncMapLookupParalell-20 285766286 4.159 ns/op BenchmarkBuiltinMapDeleteParalell-20 20315636 60.36 ns/op BenchmarkBuiltinRwMapDeleteParalell-20 18308758 69.12 ns/op BenchmarkSyncMapDeleteParalell-20 296166151 4.112 ns/op PASS ok goLearn/sync/08-sync.map 13.145s 场景分析： sync.map的读和删，性能非常好，领先 map+锁； 写，性能非常差，落后于 map+锁。 sync.map的适用场景：大量读，少量写。这是因为，sync.map本质上是利用了**==读写分离==，如果是大量写的场景，会导致missess一直增加，也就会一直触发dirty晋升为read，导致性能反而不如普通的Map+锁**。 思维发散： 可以对大Map进一步划分，分成很多个小Map，单独对每部分加锁解锁，也就是细化锁的粒度。只是实现起来太麻烦了。 问：map中，key可以为nil吗？⭐🚩 需要分情况讨论。 nil是interface{}、chan、map等类型的零值。因此，如果map的key的类型是interface{}，那么key可以为nil，就跟空接口效果一样； 如果是其他类型，nil是肯定不行的，但是对应类型的零值是ok的。 问：map中，func 可以做key吗？什么类型能做？为什么？⭐🚩 **不可以。**必须是可比较类型才能做key。那为什么要可比较的类型才能做key呢？不是直接通过 top 8 位就能拿到吗？ 因为查找 key 的过程是这样的：当出现哈希冲突，就会到同一个桶中寻找，通过 top 8 位找到对应的 key’，用 key’ 和 key 进行对比，如果一样，就可以拿到对应的 value。 因为还需要一次 对比！所以当然要可比较。。。 问：[]byte{} 和 string 怎么转换？性能？原理？各自的适用场景？⭐🚩 共两种方法： 标准转换 s1 := \"hello\" b := []byte(s1) s2 := string(b) 强制转换 func String2Bytes(s string) []byte { sh := (*reflect.StringHeader)(unsafe.Pointer(\u0026s)) bh := reflect.SliceHeader{ Data: sh.Data, Len: sh.Len, Cap: sh.Len, } return *(*[]byte)(unsafe.Pointer(\u0026bh)) } func Bytes2String(b []byte) string { return *(*string)(unsafe.Pointer(\u0026b)) } 强转换方式的性能会明显优于标准转换。 ==可以延伸如下问题==： 为啥强转换性能会比标准转换好？ 对于标准转换，无论是从[]byte转string还是string转[]byte都会涉及底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。这样，当然后者的性能会更好。 为啥当x的数据较大时，标准转换方式会有一次分配内存的操作，从而导致其性能更差，而强转换方式却不受影响？ 标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针指向。所以，当转换数据较大时，两者性能差距会愈加明显。 既然强转换方式性能这么好，为啥go提供给我们使用的是标准转换方式？ 首先，我们需要知道Go是一门类型安全的语言，而安全的代价就是性能的妥协。但是，性能的对比是相对的，这点性能的妥协对于现在的机器而言微乎其微。另外强转换的方式，会给我们的程序带来极大的安全隐患。如下代码会直接报错： func main() { s := \"hello\" b := String2Bytes(s) fmt.Println(b) b[0] = 'l' fmt.Println(s) } unexpected fault address 0x6c47f8 fatal error: fault [signal 0xc0000005 code=0x1 addr=0x6c47f8 pc=0x6ab5aa] s是string类型，是不可修改的。通过强转换将s的底层数组赋给b，而b是一个[]byte类型，它的值是可以修改的，所以这时对底层数组的值进行修改，将会造成严重的错误（通过defer+recover也不能捕获）。 string为啥要设计成不可修改的？ string不可修改，意味它是只读属性，这样的好处就是：在并发场景下，我们可以在不加锁的控制下，多次使用同一字符串，在保证高效共享的情况下而不用担心安全问题。 因此，对于这两种方法的适用场景，有如下参考： 在你不确定安全隐患的条件下，尽量采用标准方式进行数据转换。 当程序对运行性能有高要求，同时满足对数据仅仅只有读操作的条件，且存在频繁转换（例如消息转发场景），可以使用强转换。 问：两种方法的转换原理？ // slice 的底层数据结构 type slice struct { array unsafe.Pointer // 指向的是某个数组的首地址 len int cap int } // string 的底层数据结构 type stringStruct struct { str unsafe.Pointer // 指向的是某个数组的首地址 len int } 标准转换 const tmpStringBufSize = 32 type tmpBuf [tmpStringBufSize]byte func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte if buf != nil \u0026\u0026 len(s) \u003c= len(buf) { *buf = tmpBuf{} b = buf[:len(s)] } else { b = rawbyteslice(len(s)) } copy(b, s) return b } // rawbyteslice allocates a new byte slice. The byte slice is not zeroed. func rawbyteslice(size int) (b []byte) { cap := roundupsize(uintptr(size)) p := mallocgc(cap, nil, false) if cap != uintptr(size) { memclrNoHeapPoint","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:15:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.11 结构体和接口 基础 问：Go 如何实现 多态？原理是什么？⭐🚩 如何实现： 多态使内部结构不同的对象可以共享相同的外部接口。 Go 通过接口实现多态： 某个类型若实现了接口的所有方法，就隐式的实现了该接口； 某个类型的对象可以赋给它所实现的任意接口类型的变量； (网上没找到啥好的讲解，自己尝试写个吧…) 原理： 首先要明确，每个类型在底层都会有一个类型元数据，存放着类型信息和方法元数据列表。 然后，定义一个非空接口，并让某类型实现该接口； 在多态的场景下，比如一个函数的入参是定义的非空接口类型，调用该函数时传参为具体类型的对象，其实就会把该具体类型的对象赋值给该非空接口。这里要了解，非空接口的底层结构体里共有两个字段，一个是itab，一个是data： itab中会记录接口的类型元数据(包含接口的方法列表)、动态类型元数据、动态类型实现的(接口所需要的)方法的地址列表fun； data为动态值，指向具体类型的对象。 因此，赋值过程就是把data指向具体类型的对象，修改itab中的动态类型元数据为具体类型的类型元数据，并从该类型元数据中的方法元数据列表拷贝方法地址到fun。 给出一段示例代码： type test interface { print() } type hello struct { } func (h hello) print() { fmt.Println(\"hello\") } // 多态场景 func hi(t test) { t.print() } func main() { h := hello{} // 第一种调用方式 var t test t = h t.print() // 第二种 hi(h) } 问：Go 如何实现 组合 和 继承？ Go 语言中没有继承的概念，更提倡的是组合。接口和结构体都可以组合。 接口的组合，如下代码所示： type Reader interface { Read(p []byte) (n int, err error) } type Writer interface { Write(p []byte) (n int, err error) } //ReadWriter是Reader和Writer的组合 type ReadWriter interface { Reader Writer } ReadWriter 接口就是 Reader 和 Writer 的组合，组合后的 ReadWriter 接口具有 Reader 和 Writer 中的所有方法，这样新接口 ReadWriter 就不用定义自己的方法了，组合 Reader 和 Writer 的就可以了。 结构体的组合，如下代码所示： type person struct { name string age uint address } 直接把结构体类型放进来，就是组合，不需要字段名。组合后，被组合的 address 称为内部类型，person 称为外部类型： 外部类型不仅可以使用内部类型的字段，也可以使用内部类型的方法，就像使用自己的方法一样； 如果外部类型定义了和内部类型同样的方法，那么外部类型的会覆盖内部类型，这就是方法的覆写。方法覆写不会影响内部类型的方法实现。 如下所示： p:=person{ age:30, name:\"飞雪无情\", address:address{ province: \"北京\", city: \"北京\", }, } //像使用自己的字段一样，直接使用 fmt.Println(p.province) 因为 person 组合了 address，所以 address 的字段就像 person 自己的一样，可以直接使用。 题目：1 type People struct{} func (p *People) ShowA() { fmt.Println(\"showA\") p.ShowB() } func (p *People) ShowB() { fmt.Println(\"showB\") } type Teacher struct { People } func (t *Teacher) ShowB() { fmt.Println(\"teacher showB\") } func main() { t := Teacher{} t.ShowA() } 这里定义了两个类型，类型Teacher中嵌入了类型People。**问题是：**通过Teacher类型的变量t调用方法showA()，输出结果是什么？ 答案： showA showB 解释： 首先要明确T和*T是两种类型，分别对应自己的类型元数据，有着各自的方法集，其中包含了自定义的方法以及编译器生成的方法。通过go tool compile -l -p main main.go可以生成main.go的obj文件，再通过go tool nm main.o就可以查看方法列表： ❯ go tool nm main.o | grep 'T' | grep People 301c T main.(*People).ShowA 308a T main.(*People).ShowB ❯ go tool nm main.o | grep 'T' | grep Teacher 36d9 T main.(*Teacher).ShowA 30e0 T main.(*Teacher).ShowB 可以发现，People和*People的方法集同代码中定义的一致，但Teacher和*Teacher相关的方法列表中多了一个ShowA()方法，这就是编译器自动生成的了，所以编译器为*Teacher生成了这样一个包装方法(红字部分)： 所以，调用过程为：t.ShowA()会在语法糖的作用下转换为对(*Teacher).ShowA()方法的调用，而它又会取出People成员的地址作为接收者去执行*People这里的ShowA()方法，所以会有如上输出。 题目：2 解释到这里，这道题已经解决了。但无法知道为什么编译器只给*Teacher生成了包装方法？为此探索一下编译器生成包装方法的规则。 type A int func (a A) Value() int { return int(a) } func (a *A) Set(n int) { *a = A(n) } type B struct { A b int } type C struct { *A c int } 分析以上B和C会分别继承哪些方法。 首先，值接收者A有Value()方法，前面已经讲过，为了支持接口，编译器会为值接收者方法生成指针接收者的包装方法，所以*A会有Value()和Set()方法；B和C拥有的方法如下： 其中，只有B只继承了Value()方法，这是因为以B为接收者调用方法时，方法操作的已经是B的副本，无法获取嵌入的A的原始地址；而*A的方法从语义上来讲需要操作原始变量，也就是说，对于B而言它继承*A的方法是没有意义的，所以编译器并没有给B生成Set()方法。 **结论就是：**无论是嵌入值还是嵌入指针，值接收者方法始终能够被继承；而只有在能够拿到嵌入对象的地址时，才能继承指针接收者方法。 ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:16:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"3.12 对比 Java 问：Go 和 Java 的区别？ 性能：无论在串行还是并发的的业务下，Java的性能都比Go差； goroutine 默认占用内存远比 Java 、C 的线程少(goroutine：2KB，线程：8MB)，占用资源更少； goroutine 可以避免内核态和用户态的切换导致的成本。 部署编译： Java通过虚拟机编译，使用JVM跨平台编译； Go语言针对不同的平台，编译对应的机器码。 访问权限： Java使用public、protected、private、默认等几种修饰符来控制访问权限； Go语言通过大小写控制包外可访问还是不可访问。Go语言中根据首字母的大小写来确定可以访问的权限。无论是方法名、常量、变量名还是结构体的名称，如果首字母大写，则可以被其他的包访问；如果首字母小写，则只能在本包中使用。可以简单的理解成，首字母大写是公有的，首字母小写是私有的。 接口 Java等面向对象编程的接口是侵入式接口，需要明确声明自己实现了某个接口； Go语言的非侵入式接口不需要通过任何关键字声明类型与接口之间的实现关系，只要一个类型实现了接口的所有方法，那么这个类型就是这个接口的实现类型。 异常处理 Java中错误（Error）和异常(Exception)被分类管理，二者的区别是： Error（错误）：程序在执行过程中所遇到的硬件或操作系统的错误。错误对程序而言是致命的，将导致程序无法运行。常见的错误有内存溢出，jvm虚拟机自身的非正常运行，calss文件没有主方法。程序本生是不能处理错误的，只能依靠外界干预。Error是系统内部的错误，由jvm抛出，交给系统来处理； EXCEPTION（异常）：是程序正常运行中，可以预料的意外情况。比如数据库连接中断，空指针，数组下标越界。异常出现可以导致程序非正常终止，也可以预先检测，被捕获处理掉，使程序继续运行。 Go语言中只有error，一旦发生错误逐层返回，直到被处理。Golang中引入两个内置函数panic和recover来触发和终止异常处理流程，同时引入关键字defer来延迟执行defer后面的函数。golang弱化了异常，只有错误，在意料之外的panic发生时，在defer中通过recover捕获这个恐慌，转化为错误以code,message的形式返回给方法调用者，调用者去处理，这也是go极简的精髓。 继承 Java的继承通过extends关键字完成，不支持多继承； Go语言的继承通过匿名组合完成：基类以Struct的方式定义，子类只需要把基类作为成员放在子类的定义中，支持多继承。 多态 Java的多态，必须满足继承，重写，向上转型；任何用户定义的类型都可以实现任何接口，所以通过不同实体类型对接口值方法的调用就是多态。 在Go语言中通过接口实现多态，对接口的实现只需要某个类型T实现了接口中的方法，就相当于实现了该接口。 指针 Java中不存在显式的指针，而Golang中存在显式的指针操作，使用 * 来定义和声明指针，通过\u0026来取得对象的指针。注意，Java和Golang都是只存在值传递。 并发 在Java中，通常借助于共享内存（全局变量）作为线程间通信的媒介，通常会有线程不安全问题，使用了加锁（同步化）、使用原子类、使用volatile提升可见性等解决； 但在Go语言中使用的是通道（Channel）作为协程间通信的媒介，这也是Go语言中强调的：不要通过共享内存通信，而通过通信来共享内存。 垃圾回收和内存管理机制 Java基于JVM虚拟机的分代收集算法完成GC，Go语言内存释放是语言层面，对不再使用的内存资源进行自动回收，使用三色标记算法； ","date":"0001-01-01","objectID":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/:17:0","tags":null,"title":"","uri":"/10-%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2go%E8%AF%AD%E8%A8%80/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:0:0","tags":null,"title":"","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":null,"content":"一、Gin 框架 问：为什么需要 Web框架？ net/http提供了基础的Web功能，即监听端口，映射静态路由，解析HTTP报文。一个实例： func main() { http.HandleFunc(\"/\", handler) http.HandleFunc(\"/count\", counter) log.Fatal(http.ListenAndServe(\"localhost:8000\", nil)) } func handler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"URL.Path = %q\\n\", r.URL.Path) } 但一些Web开发中简单的需求并不支持，需要手工实现： 动态路由：例如hello/:name，hello/*这类的规则。 鉴权：没有分组/统一鉴权的能力，需要在每个路由映射的handler中实现。 模板：没有统一简化的HTML机制。 统一入口 package http type Handler interface { ServeHTTP(w ResponseWriter, r *Request) } func ListenAndServe(address string, h Handler) error 其实就是，实现Handler接口，拦截所有的请求到咱们自己的处理逻辑。 解释一下：你可以看这点代码：http.ListenAndServe(\"localhost:8000\", nil)，后面是nil，其实http库会自动给个默认的DefaultServeMux，也就把所有的请求用这个处理了，所以第一件事就是拦截掉所有的请求！ ==路由映射==（动态路由有点问题吧，测试一下） func main() { r := gee.New() r.GET(\"/\", func(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \"URL.Path = %q\\n\", req.URL.Path) }) r.GET(\"/hello\", func(w http.ResponseWriter, req *http.Request) { for k, v := range req.Header { fmt.Fprintf(w, \"Header[%q] = %q\\n\", k, v) } }) r.Run(\":9999\") } 其实就是，把路由地址和对应的处理函数，存起来。 解释一下：这里最简单的办法是啥？不就是在r里边整个哈希表，把路由和处理函数分别当成key和val嘛？但是哈希表有一个弊端：只能支持静态路由。 支持动态路由，有很多方法： 正则表达式 前缀树、压缩前缀树(此处使用) 这里实现动态路由具备两个功能： 参数匹配:。例如 /p/:lang/doc，可以匹配 /p/c/doc 和 /p/go/doc； 通配*。例如 /static/*filepath，可以匹配/static/fav.ico，也可以匹配/static/js/jQuery.js，这种模式常用于静态服务器，能够递归地匹配子路径。 实现前缀树后，可以在router中对每一种类型的方法都维护一颗Trie。 对于动态路由传递的参数，可以放在Context中的Param里。 设计Context 设计上下文(Context)，封装 Request 和 Response，提供对 JSON、HTML 等返回类型的支持。 必要性： 对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter。但是这两个对象提供的接口粒度太细，比如我们要构造一个完整的响应，需要考虑消息头(Header)和消息体(Body)，而 Header 包含了状态码(StatusCode)，消息类型(ContentType)等几乎每次请求都需要设置的信息。因此，如果不进行有效的封装，那么框架的用户将需要写大量重复，繁杂的代码，而且容易出错。针对常用场景，能够高效地构造出 HTTP 响应是一个好的框架必须考虑的点。 示例： 封装前 obj = map[string]interface{}{ \"name\": \"geektutu\", \"password\": \"1234\", } w.Header().Set(\"Content-Type\", \"application/json\") w.WriteHeader(http.StatusOK) encoder := json.NewEncoder(w) if err := encoder.Encode(obj); err != nil { http.Error(w, err.Error(), 500) } VS 封装后： c.JSON(http.StatusOK, gee.H{ \"username\": c.PostForm(\"username\"), \"password\": c.PostForm(\"password\"), }) Context 还可以支撑其他功能。比如： **动态路由的参数：**将来解析动态路由/hello/:name，参数:name的值放在哪呢？ **中间件的参数与结果：**框架需要支持中间件，那中间件产生的信息放在哪呢？ Context 随着每一个请求的出现而产生，请求的结束而销毁，和当前请求强相关的信息都应由 Context 承载。 Context 就像一次会话的百宝箱，可以找到任何东西。 提供了访问Query和PostForm参数的方法； 提供了快速构造String/Data/JSON/HTML响应的方法。 package gee import ( \"encoding/json\" \"fmt\" \"net/http\" ) type H map[string]interface{} type Context struct { // origin objects W http.ResponseWriter Req *http.Request // req info Path string // 其实就是 pattern Method string // 请求方法 Params map[string]string // 存储Path传递的参数 // resp info StatusCode int // 响应码 // middleware handlers []HandlerFunc // 存储中间件 index int // 记录当前执行到第几个中间件 // engine pointer engine *Engine } func NewContext(w http.ResponseWriter, req *http.Request) *Context { return \u0026Context{ W: w, Req: req, Path: req.URL.Path, Method: req.Method, index: -1, } } // 获取传递的参数 func (c *Context) Param(key string) string { return c.Params[key] } // 获取Form的数据 func (c *Context) PostForm(key string) string { return c.Req.FormValue(key) } // 获取Query的数据 func (c *Context) Query(key string) string { return c.Req.URL.Query().Get(key) } func (c *Context) Status(code int) { c.StatusCode = code c.W.WriteHeader(code) } func (c *Context) SetHeader(key string, value string) { c.W.Header().Set(key, value) } func (c *Context) String(code int, format string, values ...interface{}) { c.SetHeader(\"Content-Type\", \"text/plain\") c.Status(code) c.W.Write([]byte(fmt.Sprintf(format, values...))) } func (c *Context) Data(code int, data []byte) { c.Status(code) c.W.Write(data) } func (c *Context) JSON(code int, obj interface{}) { c.SetHeader(\"Content-Type\", \"application/json\") c.Status(code) encoder := json.NewEncoder(c.W) if err := encoder.Encode(obj); err != nil { http.Error(c.W, err.Error(), 500) } } func (c *Context) HTML(code int, name string, data interface{}) { c.SetHeader(\"Content-Type\", \"text/html\") c.Status(code) i","date":"0001-01-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:1:0","tags":null,"title":"","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":null,"content":"二、分布式缓存框架 仿照 groupCache 实现，最大的特点是没有删除、更新接口，只有Get接口。 问：为什么要设计分布式缓存机制？ 最简单的缓存就是用哈希表。但是会有以下问题： 内存不够了咋办，需要实现一个合理的缓存淘汰策略； 全局哈希表存在访问冲突，需要加锁，降低效率； 单机性能可能不够，单点故障的成本太高，分布式缓存可以增强系统鲁棒性。 … 问：支持那些特性？ 单机缓存和基于 HTTP 的分布式缓存； 最近最少访问(Least Recently Used, LRU) 缓存策略； 使用 Go 锁机制防止缓存击穿； 使用一致性哈希选择节点，实现负载均衡； 使用 protobuf 优化节点间二进制通信； 。。。 缓存策略 缓存肯定不能无限大，超过设置容量时需要有合理的淘汰策略。 常见的缓存策略： FIFO：队列嘛，先进先出，显然很不合理； LFU：按照使用次数排序，淘汰最少使用的； LRU：最近最少使用； 问：缓存大小是如何表示的？ 使用[]byte存储数据，其长度len()就是占用多少Byte。 问：数据存放格式？⭐ 缓存Cache由以下字段组成： type Cache struct { MaxEntries int OnEvicted func(key Key, value interface{}) ll *list.List // 真正存储 entry 指针的地方 cache map[interface{}]*list.Element // 存储 key - entry，用于快速找到 entry } type Key interface{} type entry struct { key Key value interface{} } 当要存储一对 key-value时，首先转换成 entry 对象，理论上 key 和 value 都是 interface{}，也就是支持所有类型。 插入时，若key之前不存在，就是插入；若已存在，就是更新： // Add adds a value to the cache. func (c *Cache) Add(key Key, value interface{}) { if c.cache == nil { c.cache = make(map[interface{}]*list.Element) c.ll = list.New() } if ee, ok := c.cache[key]; ok { c.ll.MoveToFront(ee) ee.Value.(*entry).value = value return } ele := c.ll.PushFront(\u0026entry{key, value}) // ll 中存储的其实是 entry 对象的指针 c.cache[key] = ele if c.MaxEntries != 0 \u0026\u0026 c.ll.Len() \u003e c.MaxEntries { c.RemoveOldest() } } 问：数据支持哪些操作？ 只支持 Get。 用户使用时，需要实现以下： 初始化的时候，就需要明确当 key miss 的时候，怎么获取到内容的手段，把这个手段配置好是前提； get 调用的时候，当 key miss 的时候，就会调用初始化的获取手段来获取数据，如果 hit 的话，那么就直接返回了。 问：这种只能 get ，不能更新 key 的缓存有啥用？有什么适用场景？ 比如你缓存一些静态文件，用文件 md5 作为 key，value 就是文件。这种场景就很适合用 groupcache 这种缓存，因为 key 对应的 value 不需要变。 参考文章： https://liqingqiya.github.io/groupcache/golang/%E7%BC%93%E5%AD%98/2020/05/10/groupcache.html 单机并发缓存 并发设计多协程，所以肯定需要一把互斥锁。 问：单机并发缓存是如何实现的？ 在lru外再封装一层，主要数据结构： type cache struct { mu sync.Mutex // 支持并发, 必须有锁 lru *lru.Cache cacheBytes int64 // 缓存容量 Byte } 为了区分不同类型的缓存，设置Group，负责与用户交互，控制缓存值存储和获取的流程： /* 是 接收 key --\u003e 检查是否被缓存 -----\u003e 返回缓存值 ⑴ | 否 是 |-----\u003e 是否应当从远程节点获取 -----\u003e 与远程节点交互 --\u003e 返回缓存值 ⑵ | 否 |-----\u003e 调用`回调函数`，获取值并添加到缓存 --\u003e 返回缓存值 ⑶ */ 问：若缓存不存在，怎么获取呢？ 分为从远程节点获取和**调用用户逻辑(回调函数)**获取。 这部分是回调函数的实现逻辑： 因为数据怎么获得、获得的来源是哪，应该是框架的用户需要考虑的，所以只需要开放一个回调函数接口即可。 **用户需要自定义一个GetterFunc类型的函数。**当缓存未命中时，就会调用此函数获取数据，获取之后会调用cache.put()更新缓存。 // Getter 未命中时从数据源获取数据 type Getter interface { Get(key string) ([]byte, error) // 回调函数 } // 函数类型实现某一个接口，称之为接口型函数。 // 方便使用者在调用时既能够传入函数作为参数，也能够传入实现了该接口的结构体作为参数。 // 是一个将函数转换为接口的技巧 type GetterFunc func(key string) ([]byte, error) // Get 实现Getter接口 func (f GetterFunc) Get(key string) ([]byte, error) { return f(key) } 这部分是从远程节点获取的实现逻辑： 一致性哈希 问：一致性哈希原理？有啥用？ 一致性哈希算法将 key 映射到 2^32^ 的空间中，将这个数字首尾相连，形成一个环。 计算节点/机器(通常使用节点的名称、编号和 IP 地址)的哈希值，放置在环上。 计算 key 的哈希值，放置在环上，顺时针寻找到的第一个节点，就是应选取的节点/机器。 环上有 peer2，peer4，peer6 三个节点，key11，key2，key27 均映射到 peer2，key23 映射到 peer4。此时，如果新增节点/机器 peer8，假设它新增位置如图所示，那么只有 key27 从 peer2 调整到 peer8，其余的映射均没有发生改变。 也就是说，一致性哈希算法，在新增/删除节点时，只需要重新定位该节点附近的一小部分数据，而不需要重新定位所有的节点。 问：怎么解决数据倾斜问题？ ==数据倾斜是什么？== **如果服务器的节点过少，容易引起 key 的倾斜。**例如上面例子中的 peer2，peer4，peer6 分布在环的上半部分，下半部分是空的。那么映射到环下半部分的 key 都会被分配给 peer2，key 过度向 peer2 倾斜，缓存节点间负载不均。 ==怎么解决？== **引入了虚拟节点：**一个真实节点对应多个虚拟节点。 假设 1 个真实节点对应 3 个虚拟节点，那么 peer1 对应的虚拟节点是 peer1-1、 peer1-2、 peer1-3（通常以添加编号的方式实现），其余节点也以相同的方式操作。 第一步，计算虚拟节点的 Hash 值，放置在环上。 第二步，计算 key 的 Hash 值，在环上顺时针寻找到应选取的虚拟节点，例如是 peer2-1，那么就对应真实节点 peer2。 **虚拟节点扩充了节点的数量，解决了节点较少的情况下数据容易倾斜的问题。**而且代价非常小，只需要增加一个字典(map)维护真实节点与虚拟节点的映射关系即可。 问：具体是如何实现的呢？ Go实现部分：https://geektutu.com/post/geecache-day4.html 就是： 定义一致性哈希的数据结构： type Hash func(data []byte) uint32 type Map struct { hash Hash // 可更换用户自定义的哈希函数，默认为crc32.ChecksumIEE() replicas int // 虚拟节点倍数，即一个真实节点对应replicas个虚拟节点 keys []int // 哈希环，存储每个节点的hash值 hashMap map[int]string // 节点哈希值 - 真实节点名称 } 如何添加真实/虚拟节点： func (m *Map) Add(keys ...string) { // keys是节点名称 for _, key := range keys { for i := 0; i \u003c m.replicas; i++ { // 每个真实节点都创建replicas个虚拟节点 hash := int(m.hash([]byte(strconv.Itoa(i) + key))) // 求 虚拟节点(\"i+key\") 的哈希值 m.keys = append(m.keys, hash) // 加入哈希环 m.hashMap[hash] = key // 虚拟节点 - 真实节点 } } sort.Ints(m.keys) // 排序 } 如何选择节点： func (m *Map) Get(key string) string { // key是查找键值","date":"0001-01-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:2:0","tags":null,"title":"","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":null,"content":"三、Orm 框架 问：ORM 框架有什么用？ ORM 框架相当于对象和数据库中间的一个桥梁，借助 ORM 可以避免写繁琐的 SQL 语言，仅仅通过操作具体的对象，就能够完成对关系型数据库的操作。 问：设计 ORM 框架，需要关注哪些问题呢？ 如何屏蔽不同数据库之间的差异？ 如何从对象映射到数据库中的表结构/记录？ MySQL，PostgreSQL，SQLite 等数据库的 SQL 语句是有区别的，ORM 框架如何在开发者不感知的情况下适配多种数据库？ 如何实现：对象的字段发生改变，数据库表结构能够自动更新，即支持数据库自动迁移(migrate)？ 数据库支持的其他功能，如事务等，ORM 框架能实现哪些？ 简单的增删查改使用 ORM 替代 SQL 语句是没有问题的，但是也有很多特性难以用 ORM 替代，比如复杂的多表关联查询，ORM 也可能支持，但是基于性能的考虑，开发者自己写 SQL 语句很可能更高效。 问：你的 ORM 框架都实现了点啥？ 目前支持的特性有： 表的创建、删除、迁移。 记录的增删查改，查询条件的链式操作。 单一主键的设置(primary key)。 钩子(在创建/更新/删除/查找之前或之后)。 事务(transaction)。 数据库迁移。 为了轻量化，目前只支持轻量级数据库 SQLite。 问：项目结构是怎样的？各部分都实现了啥？ . |-- clause // 5. 生成sql语句 | |-- clause.go // 组合sql子句为完整句子 | `-- generator.go // 生成拼合用到的sql子句 |-- cmd | |-- gee.db | `-- main.go |-- dialect // 3. 抽象出各个数据库差异的部分 | |-- dialect.go // Go的数据类型 转换成 数据库的数据类型 | `-- sqlite3.go // 这是个示例：sqlite3的数据类型转换。要支持其他数据库，还需要添加对应数据库的 |-- geeorm.go // 2. 与用户交互的入口：交互前的准备工作（比如连接/测试），交互后的收尾工作（关闭连接） |-- schema // 4. 负责 对象 --\u003e 表 的转换 | `-- schema.go // schema就是存放 要转换成的表 的信息 `-- session // 1. 用来和数据库交互 |-- hooks.go // 钩子 |-- raw.go // 直接调用 SQL 语句进行原生交互的部分 |-- record.go // 用户直接调用的增删查改接口 |-- record_test.go |-- table.go // \"表\"的增删查 `-- transaction.go // 事务 表结构映射 问：怎么实现的从结构体对象到表的映射？ 在schema.go中。 在数据库中创建一张表需要哪些要素呢？ 表名(table name) —— 结构体名(struct name) 字段名和字段类型 —— 成员变量和类型。 额外的约束条件(例如非空、主键等) —— 成员变量的Tag（Go 语言通过 Tag 实现，Java、Python 等语言通过注解实现） 举一个实际的例子： type User struct { Name string `geeorm:\"PRIMARY KEY\"` Age int } 期望对应的 schema 语句： CREATE TABLE `User` (`Name` text PRIMARY KEY, `Age` integer); 主要问题是：如何通过任意类型的指针，得到其对应的结构体的信息。 所以 ORM 框架的实现需要依赖大量的 Reflect 操作： reflect.ValueOf() 获取接口对应的反射值。 reflect.Indirect() 获取指针指向的对象的反射值。 (reflect.Type).Name() 返回类名(字符串)。 (reflect.Type).Field(i) 获取第 i 个成员变量。 以上是一些基础知识。下面是映射流程： // 1. 要转换成的 // Schema 代表一张表 type Schema struct { Model interface{} // 被映射的对象 Name string // 表名 Fields []*Field // 所有的字段信息 FieldNames []string // 所有的字段名 fieldMap map[string]*Field // 映射 [字段名: *Field] } // Field 字段的信息 type Field struct { Name string // 字段名 Type string // 类型 Tag string // 约束条件 } // 2. 转换对象，示例 type User struct { name string `geeorm:\"primary\"` age int `geeorm:\"age\"` } 经过以下步骤，将User转换成数据库对象Schema： // 1. 得到该结构体的类型元数据 modelType := reflect.Indirect(reflect.ValueOf(dest)).Type() // 2. 建立Schema实例，也即映射到的表结构 schema := \u0026Schema{ Model: dest, Name: modelType.Name(), // 结构体的名称作为表名 fieldMap: make(map[string]*Field), } // 3. 得到该结构体所有的字段 for i := 0; i \u003c modelType.NumField(); i++ { p := modelType.Field(i) field := \u0026Field{ Name: p.Name, Type: d.DataTypeOf(reflect.Indirect(reflect.New(p.Type))), // 会通过reflect.Kind转换类型 } } // 4. 在tag中寻找约束条件，比如主键之类的 if v, ok := p.Tag.Lookup(\"geeorm\"); ok { field.Tag = v } // 5. 往Schema中添加结构体的字段 schema.Fields = append(schema.Fields, field) schema.FieldNames = append(schema.FieldNames, p.Name) schema.fieldMap[p.Name] = field 然后就可以用 schema 中的信息，在数据库中建表： // CreateTable 创建表 func (s *Session) CreateTable() error { table := s.RefTable() // table就是schema，也就是表的信息 var columns []string for _, field := range table.Fields { columns = append(columns, fmt.Sprintf(\"%s %s %s\", field.Name, field.Type, field.Tag)) } desc := strings.Join(columns, \",\") _, err := s.Raw(fmt.Sprintf(\"CREATE TABLE %s (%s);\", table.Name, desc)).Exec() return err } 插入、查询 问：如何实现带有条件的指令？ 通常select和insert等指令都会带有条件，以这俩为例。 带有条件的语句，**需要多个子句进行拼合！**毕竟你不能构造出所有组合出来的语句。 用户主要通过clause.go，构造最终的sql语句： // Type SQL 语句种类 type Type int const ( INSERT Type = iota VALUES SELECT LIMIT WHERE ORDERBY UPDATE DELETE COUNT ) // Clause 组合 SQL 独立语句为完整句子 type Clause struct { sql map[Type]string // SQL 语句 sqlVars map[Type][]interface{} // 参数 } // Set 按照SQL语句的Name和参数, 得到子句 func (c *Clause) Set(name Type, vars ...interface{}) { if c.sql == nil { c.sql = make(map[Type]string) c.sqlVars = make(map[Type][]interface{}) } sql, vars := generators[name](vars...) c.sql[name] = sql c.sqlVars[name] = vars } // Build 按照传入子句类型的顺序，构造最终的SQL语句 func (c *Clause) Build(orders ...Type) (string, []interface{}) { var sqls []string var vars []interface{} for _, order := range orders { if sql, ok := c.sql[order]; ok {","date":"0001-01-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:3:0","tags":null,"title":"","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":null,"content":"四、负载均衡器 ","date":"0001-01-01","objectID":"/11-%E9%A1%B9%E7%9B%AE/:4:0","tags":null,"title":"","uri":"/11-%E9%A1%B9%E7%9B%AE/"},{"categories":null,"content":" 问：什么是 JWT ？ JWT（JSON Web Token）是目前最流行的跨域认证解决方案，是一种基于 Token 的认证授权机制。从 JWT 的全称可以看出，JWT 本身也是 Token，一种规范化之后的 JSON 结构的 Token。 JWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息。这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。 JWT 本质上就是一组字符串，通过（.）切分成三个为 Base64 编码的部分： Header：描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型； Payload：用来存放实际需要传递的数据； Signature（签名）：服务器通过 Payload、Header 和私钥（Secret）使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。 JWT 通常是这样的：xxxxx.yyyyy.zzzzz。 示例： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9. eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ. SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c 你可以在 jwt.ioopen in new window 这个网站上对其 JWT 进行解码，解码之后得到的就是 Header、Payload、Signature 这三部分。 问：如何基于 JWT 进行身份验证？ 在基于 JWT 进行身份验证的的应用程序中，服务器通过 Payload、Header 和 Secret（密钥） 创建 JWT 并将 JWT 发送给客户端。客户端接收到 JWT 之后，会将其保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。 两点建议： 建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。 请求服务端并携带 JWT 的常见做法是将其放在 HTTP Header 的 Authorization 字段中（Authorization: Bearer Token）。 问：如何提高 JWT 的安全性？ JWT 存放在 localStorage 中而不是 Cookie 中，避免 CSRF 风险； 一定不要将隐私信息存放在 Payload 当中，因为它不加密； JWT 的过期时间不易过长。 问：JWT 为啥不会有 CSRF 攻击漏洞？ 一般情况下我们使用 JWT 的话，在我们登录成功获得 JWT 之后，一般会选择存放在 localStorage 中。前端的每一个请求后续都会附带上这个 JWT，整个过程压根不会涉及到 Cookie。因此，即使你点击了非法链接发送了请求到服务端，这个非法请求也是不会携带 JWT 的，所以这个请求将是非法的。 总结来说就一句话：使用 JWT 进行身份验证不需要依赖 Cookie ，因此可以避免 CSRF 攻击。 但是 XSS 依然会有。 问：JWT 重放攻击怎么防御？ JWT 过期时间设置的短点； 增加时间戳机制，但时间同步是个问题； 客户端每次需要携带服务端分发的随机数，随机数的维护是个问题； 客户端与服务端商量流水号，落后的序号将被认定为重放攻击，分布式场景下序号同步是个问题。 ","date":"0001-01-01","objectID":"/12-jwt%E8%AE%A4%E8%AF%81/:0:0","tags":null,"title":"","uri":"/12-jwt%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"Protobuf 的编码是基于变种的 Base 128。因此，按照 Base 64 --\u003e Base 128 --\u003e Protobuf 的顺序来学习比较好~ 原文链接 ","date":"0001-01-01","objectID":"/13-protobuf/:0:0","tags":null,"title":"","uri":"/13-protobuf/"},{"categories":null,"content":"一、Base 64 计算机之间传输数据时，数据本质上是一串字节流。由于不同机器采用的字符集不同等原因，我们并不能保证目标机器能够正确地“理解”字节流。 先看看 Base 64 如何工作，假设这里有 4 个字节，代表要传输的二进制数据： 首先将这个字节流按每 6 个 bit 为一组进行分组，剩下少于 6 bits 的低位补 0； 然后在每一组 6 bits 的高位补两个 0； 对照 Base 64 table，字节流可以用 ognC0w 来表示。另外，Base 64 编码是按照 6 bits 为一组进行编码，每 3 个字节的原始数据要用 4 个字节来储存，编码后的长度要为 4 的整数倍，不足 4 字节的部分要使用 pad 补齐，所以最终的编码结果为ognC0w==。 Base 64 编码之后所有字节均可以用数字、字母、+、/、= 进行表示，这些都是可以被正常显示的 ascii 字符，即**“安全”的字节**。绝大部分的计算机和操作系统都对 ascii 有着良好的支持，保证了编码之后的字节流能被正确地复制、传播、解析。 Base 64 存在的问题就是：编码后的每一个字节的最高两位总是 0，在不考虑 pad 的情况下，有效 bit 只占 bit 总数的 75%，造成大量的空间浪费。 ","date":"0001-01-01","objectID":"/13-protobuf/:1:0","tags":null,"title":"","uri":"/13-protobuf/"},{"categories":null,"content":"二、Base 128 因此，Base 128 的大致实现思路是：将字节流按 7 bits 进行分组，然后低位补 0。 但问题来了，Base 64 实际上用了 2^6^+1 个 ascii 字符，按照这个思路 Base 128 需要使用 2^7^+1 个 ascii 个字符，但是 ascii 字符一共只有 128 个。另外，即使不考虑 pad，ascii 中包含了一些不可以正常打印的控制字符，编码之后的字符还可能包含会被不同操作系统转换的换行符号(10 和 13)。因此，Base 64 至今依然没有被 Base 128 替代。 ","date":"0001-01-01","objectID":"/13-protobuf/:2:0","tags":null,"title":"","uri":"/13-protobuf/"},{"categories":null,"content":"三、Base 128 Varints Protocol Buffers 所用的编码方式就是 Base 128 Varints。(按照小端模式讨论) 编码/解码 对于编码后的每个字节，低 7 位用于储存数据，最高位用来标识当前字节是否是当前整数的最后一个字节，称为最高有效位（most significant bit, msb）。msb 为 1 时，代表着后面还有数据；msb 为 0 时代表着当前字节是当前整数的最后一个字节。 如何将使用 Base 128 Varints 对整数进行编码： 将数据按每 7 bits 一组拆分 逆序每一个组(因为小端) 添加 msb 如何将使用 Base 128 Varints 对整数进行解码： 去除 msb 将字节流逆序(msb 为 0 的字节储存原始数据的高位部分，小端模式) 最后拼接所有的 bits。 300 (0b 10 0101100)编码： 解码： protobuf 的 varints 最多可以编码 8 字节的数据，这是因为绝大部分的现代计算机最高支持处理 64 位的整型。 ","date":"0001-01-01","objectID":"/13-protobuf/:3:0","tags":null,"title":"","uri":"/13-protobuf/"},{"categories":null,"content":"四、Protobuf Protocol Buffers 所用的编码方式就是 Base 128 Varints。(按照小端模式讨论) 数据类型 protobuf 支持的数据类型(wire type)： 当实际使用 protobuf 进行编码时，经过了两步处理： 将 编程语言的数据结构 转化为 wire type。 根据不同的 wire type 使用对应的方法编码。前文所提到的 Base 128 Varints 用来编码 varint 类型的数据，其他 wire type 则使用其他编码方式。 部分数据类型到 wire type 的转换规则： 有符号整型 采用 ZigZag 编码来将 sint32 和 sint64 转换为 wire type 0。下面是 ZigZag 编码的规则（注意是算术位移）： n * 2 // when n \u003e= 0 -n * 2 - 1 // when n \u003c 0 一些例子： 定长数据(64-bit) 直接采用小端模式储存，不作转换。 字符串 以字符串\"testing\"为例： 编码后的 value 分为两部分： 蓝色，表示字符串采用 UTF-8 编码后字节流的长度(bytes)，采用 Base 128 Varints 进行编码。 白色，字符串用 UTF-8 编码后的字节流。 消息结构 Protobuf 采用 proto3 作为 DSL 来描述其支持的消息结构。 syntax = \"proto3\"; message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; } 设想一下这样一个场景：数据的发送方在业务迭代之后需要在消息内携带更多的字段，而有的接收方并没有更新自己的 proto 文件。要保持较好的兼容性，接收方需要分辨出哪些字段是自己可以识别的，哪些是不能识别的新增字段。要做到这一点，发送方在编码消息时还必须附带每个字段的 key，客户端读取到未知的 key 时，可以直接跳过对应的 value。 proto3 中每一个字段后面都有一个 = x，比如： string query = 1; 这里的等号并不是用于赋值，而是给每一个字段指定一个 ID，称为 field number。消息内同一层次字段的 field number 必须各不相同。 上面所说的 key，在 protobuf 源码中被称为 tag。tag 由 field number 和 type 两部分组成： field number 左移 3 bits 在最低 3 bits 写入 wire type 一个生成 tag 的例子： Go 版本 Protobuf 中生成 tag 的源码： func EncodeTag(num Number, typ Type) uint64 { return uint64(num)\u003c\u003c3 | uint64(typ\u00267) } 源码中生成的 tag 是 uint64，代表着 field number 可以使用 61 个 bit 吗？并非如此。事实上，==tag 的长度不能超过 32 bits==，意味着 field number 的最大取值为 2^29^-1 (536870911)。而且在这个范围内，有一些数是不能被使用的： 0：protobuf 规定 field number 必须为正整数。 19000 到 19999： protobuf 仅供内部使用的保留位。 理解了生成 tag 的规则之后，不难得出以下结论： field number 不必从 1 开始，可以从合法范围内的任意数字开始。 不同字段间的 field number 不必连续，只要合法且不同即可。 当修改 proto 文件时，需要注意⭐： field number 一旦被分配了就不应该被更改，除非你能保证所有的接收方都能更新到最新的 proto 文件； 由于 tag 中不携带 field name 信息，更改 field name 并不会改变消息的结构。发送方认为的 apple 到接受方可能会被识别成 pear。双方把字段读取成哪个名字完全由双方自己的 proto 文件决定，只要字段的 wire type 和 field number 相同即可。 最后再来个复杂例子(能看明白就算会了~)： 嵌套消息 wire type 2不仅支持 string，也支持 embedded messages。 对于嵌套消息： 首先要将被嵌套的消息进行编码成字节流； 然后就可以像处理 UTF-8 编码的字符串一样处理这些字节流：在字节流前面加入使用 Base 128 Varints 编码的长度即可。 能看明白就是胜利！😉 字段顺序 Proto 文件中定义字段的顺序与最终编码结果的字段顺序无关，两者有可能相同也可能不同。 任何 Protobuf 的实现都应该保证字段以任意顺序编码的结果都能被解码。 安全性 由于 Protobuf 序列化后就是一堆字节流，需要有原 Proto 声明文件才能反序列化，因此也具备一定的保密性。 对比JSON、XML XML、JSON 更注重数据结构化，关注人类可读性和语义表达能力； ProtoBuf 更注重数据序列化，关注效率、空间、速度，人类可读性差，语义表达能力不足（为保证极致的效率，会舍弃一部分元信息） ProtoBuf 的应用场景更为明确，XML、JSON 的应用场景更为丰富。 ","date":"0001-01-01","objectID":"/13-protobuf/:4:0","tags":null,"title":"","uri":"/13-protobuf/"},{"categories":null,"content":"一、微服务 ","date":"0001-01-01","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:0","tags":null,"title":"","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"1.1 微服务技术栈 先给出微服务的架构： 分类： ","date":"0001-01-01","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:1","tags":null,"title":"","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"1.2 认识微服务 单体架构：将业务的所有功能集中在一个项目中开发，打包成一个部署。 优点：架构简单，部署成本低； 缺点：耦合度太高，不适合大型项目。 微服务架构的特征： 单一职责：微服务拆分的粒度更小，每一个服务都对应唯一的业务能力，做到单一职责，避免重复业务开发； 面向服务：微服务对外暴露业务接口，允许远程调用； 隔离性强：各服务做好隔离、容错、降级等，避免服务挂了对其他服务产生影响。 ","date":"0001-01-01","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:1:2","tags":null,"title":"","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"二、gRPC ","date":"0001-01-01","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:0","tags":null,"title":"","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"概述 gRPC 是谷歌推出的一个开源、高性能的 RPC 框架。默认情况下使用 protoBuf 进行序列化和反序列化，并基于 HTTP/2 传输报文，带来诸如多请求复用一个 TCP 连接(所谓的多路复用)、双向流、流控、头部压缩等特性。 在 gRPC 中，开发者可以像调用本地方法一样，通过 gRPC 的客户端调用远程机器上 gRPC 服务的方法。gRPC 客户端封装了 HTTP/2 协议数据帧的打包、以及网络层的通信细节，把复杂留给框架自己，把便捷提供给用户。 gRPC 基于这样的一个设计理念： 定义一个服务，及其被远程调用的方法(方法名称、入参、出参)，在 gRPC 服务端实现这个方法的业务逻辑，并在 gRPC 服务端处理来自远程客户端对这个 RPC 方法的调用； 在 gRPC 客户端也拥有这个 RPC 方法的存根(stub)。gRPC 的客户端和服务端都可以用任何支持 gRPC 的语言来实现，例如一个 gRPC 服务端可以是 C++ 语言编写的，以供 Ruby 语言的 gRPC 客户端和 JAVA 语言的 gRPC 客户端调用，如下图所示： gRPC 默认使用 ProtoBuf 对请求/响应进行序列化和反序列化，这使得传输的请求体和响应体比 JSON 等序列化方式包体更小、更轻量。 gRPC 基于 HTTP/2 协议传输报文，HTTP/2 具有多路复用、头部压缩等特性，基于 HTTP/2 的帧设计，实现了多个请求复用一个 TCP 连接，基本解决了 HTTP/1.1 的队头阻塞问题，相对 HTTP/1.1 带来了巨大的性能提升。 ","date":"0001-01-01","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:1","tags":null,"title":"","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"协议格式 gRPC 基于 HTTP/2/协议进行通信，使用 ProtoBuf 序列化与反序列化，gRPC 的协议格式如下图： gRPC 协议在 HTTP 协议的基础上，对 HTTP/2 的帧的**有效包体(Frame Payload)**做了进一步编码：gRPC 包头(5 字节)+gRPC 变长包头，其中： 5 字节的 gRPC 包头：1 字节的压缩标志(compress flag) 和 4 字节的 gRPC 包头长度； gRPC 包体长度是变长的，是一串二进制流：使用指定序列化方式(通常是 ProtoBuf)序列化成字节流，再使用指定的压缩算法对序列化的字节流压缩而成的。如果对序列化字节流进行了压缩，gRPC 包头的压缩标志为 1。 ","date":"0001-01-01","objectID":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/:2:2","tags":null,"title":"","uri":"/14-%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/15-kubernetes/:0:0","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"一、简介 ","date":"0001-01-01","objectID":"/15-kubernetes/:1:0","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"1.1 部署方式的演变 传统部署时代：直接将应用程序部署在物理机上，不能为应用程序定义资源使用边界，很难合理地分配计算资源，所以程序之间容易产生影响； 虚拟化部署时代：可以在一台物理机上运行多个虚拟机(比如 VM)，每个虚拟机都是独立的一个环境。缺点是增加了操作系统，浪费了部分资源； 容器化部署时代：类似于虚拟化，被认为是轻量级的，具有自己的文件系统、CPU 、内存、进程空间等，运行应用程序所需要的资源都被容器包装，部署方便。 ","date":"0001-01-01","objectID":"/15-kubernetes/:1:1","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"容器化部署的优势： 敏捷性：敏捷应用程序的创建和部署。和使用 VM 镜像相比，提高了容器镜像创建的简便性和效率； 解耦性：关注开发和运维的分离。在构建、发布时创建应用程序的容器镜像，而不是在部署的时候，从而将应用程序和基础架构分离； 跨平台：跨开发、测试和生产的环境一致性。在便捷式的计算机上和在云上相同的运行； 大分布式：松散耦合、分布式、弹性、解放的微服务。应用程序被分解成较小的独立部分，并且可以动态的部署和管理。 容器化部署带来的问题： 故障转移：一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器； 负载均衡：当并发访问量变大的时候，怎么样做到横向扩展容器数量。 这些问题统称为容器编排问题，Kubernetes 是最主流的容器编排软件。 ","date":"0001-01-01","objectID":"/15-kubernetes/:2:0","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"1.2 为什么使用 Kubernetes (k8s) Kubernetes 的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能： 自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器； 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整； 服务发现：服务可以通过自动发现的形式找到它所依赖的服务； 负载均衡：如果一个服务启动了多个容器，能够自动实现请求的负载均衡； 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本； 存储编排：可以根据容器自身的需求自动创建存储卷。 ","date":"0001-01-01","objectID":"/15-kubernetes/:2:1","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"1.3 k8s 的组件 一个 k8s 集群主要是由控制节点(master)、**工作节点(node)**构成，每个节点上都会安装不同的组件： master：集群的控制平面，负责集群的决策 ( 管理 ) ApiServer: 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制； Scheduler: 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上； ControllerManager: 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等； Etcd：负责存储集群中各种资源对象的信息。 node：集群的数据平面，负责为容器提供运行环境 ( 干活 ) Kubelet: 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器； KubeProxy: 负责提供集群内部的服务发现和负载均衡； Docker: 负责节点上容器的各种操作。 ","date":"0001-01-01","objectID":"/15-kubernetes/:2:2","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"如何让 k8s 部署一个 nginx 服务？ kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中； 一个nginx服务的安装请求会首先被发送到master节点的apiServer组件； apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上； 在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer； apiServer调用controller-manager去调度Node节点安装nginx服务； kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod； pod是kubernetes的最小操作单元，容器必须跑在pod中； 至此，一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理； 外界用户就可以访问集群中的nginx服务了。 ","date":"0001-01-01","objectID":"/15-kubernetes/:3:0","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"1.4 k8s 概念 Master：集群控制节点，每个集群需要至少一个master节点负责集群的管控； Node：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行； Pod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器； Controller：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等； Service：pod对外服务的统一入口，下面可以维护者同一类的多个pod； Label：标签，用于对pod进行分类，同一类pod会拥有相同的标签； NameSpace：命名空间，用来隔离pod的运行环境。 ","date":"0001-01-01","objectID":"/15-kubernetes/:3:1","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"二、集群环境搭建 ","date":"0001-01-01","objectID":"/15-kubernetes/:4:0","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"2.1 集群分类 Kubernetes 集群大致分为两类： 一主多从：一个 Master 节点和多台 Node 节点，搭建简单，但是有单机故障风险，适合用于测试环境。 多主多从(高可用)：多台 Master 节点和多台 Node 节点，搭建麻烦，安全性高，适合用于生产环境。 ","date":"0001-01-01","objectID":"/15-kubernetes/:4:1","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"2.2 安装 2.2.1 安装方式 目前生产部署Kubernetes 集群主要有两种方式： Kubeadm：Kubeadm 是一个K8s 部署工具，提供kubeadm init 和 kubeadm join，用于快速部署Kubernetes 集群。 ​ 官方地址：https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/ 二进制包：从github 下载发行版的二进制包，手动部署每个组件，组成 Kubernetes 集群。 方便起见，还是用 Kubeadm 吧hhh，以后再说用二进制包的方式。 2.2.2 准备环境 在开始之前，部署 Kubernetes 集群机器需要满足以下几个条件： 一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB 或更多RAM，2 个CPU 或更多CPU，硬盘30GB 或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁止swap 分区 准备 3 个 CentOS7.x-86_x64 虚拟机： 在所有节点上安装Docker 和kubeadm 部署Kubernetes Master 部署容器网络插件 部署Kubernetes Node，将节点加入Kubernetes 集群中 部署Dashboard Web 页面，可视化查看Kubernetes 资源 角色 IP地址 组件 master01 192.168.5.3 docker，kubectl，kubeadm，kubelet node01 192.168.5.4 docker，kubectl，kubeadm，kubelet node02 192.168.5.5 docker，kubectl，kubeadm，kubelet 2.2.3 环境初始化 2.2.3.1 检查操作系统的版本 # 此方式下安装kubernetes集群要求Centos版本要在7.5或之上 [root@master ~]# cat /etc/redhat-release Centos Linux 7.5.1804 (Core) 2.2.3.2 主机名解析 为了方便集群节点间的直接调用，在这个配置一下主机名解析，企业中推荐使用内部DNS服务器 # 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容 192.168.90.100 master 192.168.90.106 node1 192.168.90.107 node2 2.2.3.3 时间同步 kubernetes要求集群中的节点时间必须精确一直，这里使用chronyd服务从网络同步时间 企业中建议配置内部的会见同步服务器 # 启动chronyd服务 [root@master ~]# systemctl start chronyd [root@master ~]# systemctl enable chronyd [root@master ~]# date 2.2.3.4 禁用iptable和firewalld服务 kubernetes和docker 在运行的中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则 # 1 关闭firewalld服务 [root@master ~]# systemctl stop firewalld [root@master ~]# systemctl disable firewalld # 2 关闭iptables服务 [root@master ~]# systemctl stop iptables [root@master ~]# systemctl disable iptables 2.2.3.5 禁用selinux selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题 # 编辑 /etc/selinux/config 文件，修改SELINUX的值为disable # 注意修改完毕之后需要重启linux服务 SELINUX=disabled 2.2.3.6 禁用swap分区 swap分区指的是虚拟内存分区，它的作用是物理内存使用完，之后将磁盘空间虚拟成内存来使用，启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备，但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明 # 编辑分区配置文件/etc/fstab，注释掉swap分区一行 # 注意修改完毕之后需要重启linux服务 vim /etc/fstab 注释掉 /dev/mapper/centos-swap swap # /dev/mapper/centos-swap swap 2.2.3.7 修改linux的内核参数 # 修改linux的内核采纳数，添加网桥过滤和地址转发功能 # 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置： net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 # 重新加载配置 [root@master ~]# sysctl -p # 加载网桥过滤模块 [root@master ~]# modprobe br_netfilter # 查看网桥过滤模块是否加载成功 [root@master ~]# lsmod | grep br_netfilter 2.2.3.8 配置ipvs功能 在Kubernetes中Service有两种带来模型，一种是基于iptables的，一种是基于ipvs的两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块 # 1.安装ipset和ipvsadm [root@master ~]# yum install ipset ipvsadm -y # 2.添加需要加载的模块写入脚本文件 [root@master ~]# cat \u003c\u003cEOF\u003e /etc/sysconfig/modules/ipvs.modules #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF # 3.为脚本添加执行权限 [root@master ~]# chmod +x /etc/sysconfig/modules/ipvs.modules # 4.执行脚本文件 [root@master ~]# /bin/bash /etc/sysconfig/modules/ipvs.modules # 5.查看对应的模块是否加载成功 [root@master ~]# lsmod | grep -e ip_vs -e nf_conntrack_ipv4 2.2.3.9 安装docker # 1、切换镜像源 [root@master ~]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo # 2、查看当前镜像源中支持的docker版本 [root@master ~]# yum list docker-ce --showduplicates # 3、安装特定版本的docker-ce # 必须制定--setopt=obsoletes=0，否则yum会自动安装更高版本 [root@master ~]# yum install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7 -y # 4、添加一个配置文件 #Docker 在默认情况下使用Vgroup Driver为cgroupfs，而Kubernetes推荐使用systemd来替代cgroupfs [root@master ~]# mkdir /etc/docker [root@master ~]# cat \u003c\u003cEOF\u003e /etc/docker/daemon.json { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"registry-mirrors\": [\"https://kn0t2bca.mirror.aliyuncs.com\"] } EOF # 5、启动dokcer [root@master ~]# systemctl restart docker [root@master ~]# systemctl enable docker 2.2.3.10 安装Kubernetes组件 # 1、由于kubernetes的镜像在国外，速度比较慢，这里切换成国内的镜像源 # 2、编辑/etc/yum.repos.d/kubernetes.repo,添加下面的配置 [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgchech=0 repo_gpgcheck=0 gpgkey=http://mirr","date":"0001-01-01","objectID":"/15-kubernetes/:4:2","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"三、资源管理 ","date":"0001-01-01","objectID":"/15-kubernetes/:5:0","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"3.1 简介 在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。 kubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的**容器**，并将指定的程序跑在容器中。 kubernetes的最小管理单元是pod而不是容器，所以只能将容器放在Pod中，而kubernetes一般也不会直接管理Pod，而是通过Pod控制器来管理Pod的。 Pod可以提供服务之后，就要考虑如何访问Pod中服务。kubernetes提供了**Service**实现这个功能。 当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种**存储**系统。 学习kubernetes的核心，就是学习如何对集群上的Pod、Pod控制器、Service、存储等各种资源进行操作。 ","date":"0001-01-01","objectID":"/15-kubernetes/:5:1","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"3.2 YAML YAML 常用来作为配置文件。 YAML的语法比较简单，主要有下面几个： 大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格( 低版本限制 ) 缩进的空格数不重要，只要相同层级的元素左对齐即可 ‘#‘表示注释 YAML支持以下几种数据类型： 纯量：单个的、不可再分的值 # 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期 # 1 布尔类型 c1: true (或者True) # 2 整型 c2: 234 # 3 浮点型 c3: 3.14 # 4 null类型 c4: ~ # 使用~表示null # 5 日期类型 c5: 2018-02-17 # 日期必须使用ISO 8601格式，即yyyy-MM-dd # 6 时间类型 c6: 2018-02-17T15:02:31+08:00 # 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区 # 7 字符串类型 c7: heima # 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 c8: line1 line2 # 字符串过多的情况可以拆成多行，每一行会被转化成一个空格 对象：键值对的集合 # 对象 # 形式一(推荐): heima: age: 15 address: Beijing # 形式二(了解): heima: {age: 15,address: Beijing} 数组：列表(list) # 数组 # 形式一(推荐): address: - 顺义 - 昌平 # 形式二(了解): address: [顺义,昌平] ","date":"0001-01-01","objectID":"/15-kubernetes/:5:2","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"小提示： 书写yaml切记在 : 后面要加一个空格 如果需要将多段yaml配置放在一个文件中，中间要使用 --- 分隔 一个yaml转json的网站，可以通过它验证yaml是否书写正确 ","date":"0001-01-01","objectID":"/15-kubernetes/:5:3","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"3.3 资源管理方式 命令式对象管理：直接使用命令去操作kubernetes资源 kubectl run nginx-pod --image=nginx:1.17.1 --port=80 # 很少直接用，顶多测试的时候用 命令式对象配置：通过命令配置和配置文件去操作kubernetes资源 kubectl create/patch -f nginx-pod.yaml # 开发环境用 声明式对象配置：通过apply命令和配置文件去操作kubernetes资源 kubectl apply -f nginx-pod.yaml # 支持目录操作，能直接应用整个目录下的YAML 类型 操作对象 适用环境 优点 缺点 命令式对象管理 对象 测试 简单 只能操作活动对象，无法审计、跟踪 命令式对象配置 文件 开发 可以审计、跟踪 项目大时，配置文件多，操作麻烦 声明式对象配置 目录 开发 支持目录操作 意外情况下难以调试 // TODO：https://gitee.com/yooome/golang/blob/main/k8s%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B-%E8%B0%83%E6%95%B4%E7%89%88/k8s%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B.md#3-%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86 ","date":"0001-01-01","objectID":"/15-kubernetes/:5:4","tags":null,"title":"","uri":"/15-kubernetes/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/16-docker/:0:0","tags":null,"title":"","uri":"/16-docker/"},{"categories":null,"content":"一、简介 ","date":"0001-01-01","objectID":"/16-docker/:1:0","tags":null,"title":"","uri":"/16-docker/"},{"categories":null,"content":"1.1 概念 一句话，Docker 是解决了运行环境和配置问题的软件容器，方便做持续集成并有助于整体发布的容器。 虚拟化技术演历路径可分为三个时代： 物理机时代，多个应用程序可能跑在一台物理机器上 虚拟机时代，一台物理机器启动多个虚拟机实例，一个虚拟机跑多个应用程序 容器化时代，一台物理机上启动多个容器实例，一个容器跑多个应用程序 Docker、虚拟机对比： 一次构建、随处运行，省去重复配置环境、设置的过程，就很方便； 仅包含业务运行所需的 runtime 环境，无需虚拟化整个操作系统； ","date":"0001-01-01","objectID":"/16-docker/:1:1","tags":null,"title":"","uri":"/16-docker/"},{"categories":null,"content":"1.2 安装 官方链接：https://docs.docker.com/get-docker/ ","date":"0001-01-01","objectID":"/16-docker/:1:2","tags":null,"title":"","uri":"/16-docker/"},{"categories":null,"content":"1.3 组成 docker 的基本组成： 镜像(image)：相当于一份模板，是跨平台、可移植的程序+环境包； 容器(container)：相当于镜像是实例，可以创建出很多个实例； 仓库(repository)：镜像的存储位置，有云端仓库和本地仓库之分，官方镜像仓库地址 ","date":"0001-01-01","objectID":"/16-docker/:1:3","tags":null,"title":"","uri":"/16-docker/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:0:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"一、概述 问：如何理解高并发系统？ 所谓设计高并发系统，就是设计一个系统，保证它整体可用的同时，能够处理很高的并发用户请求，能够承受很大的流量冲击。 我们要设计高并发的系统，那就需要处理好一些常见的系统瓶颈问题，如内存不足、磁盘空间不足，连接数不够，网络宽带不够等等，以应对突发的流量洪峰。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"分而治之，横向扩展 单个服务器的缺点： 抗住的流量请求是非常有限； 有单点的风险，挂了就寄了。 因此，可以分而治之，横向扩展。即，采用分布式部署的方式，部署多台服务器，把流量分流开，让每个服务器都承担一部分的并发和流量，提升整体系统的并发能力。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:1","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"微服务拆分（系统拆分） 所谓的微服务拆分，其实就是把一个单体的应用，按功能单一性，拆分为多个服务模块，这样就可以达到分摊请求流量的目的，提高了并发能力。比如一个电商系统，拆分为用户系统、订单系统、商品系统等等。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:2","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"分库分表 考虑将单机数据库，拆分为多个数据库或表。 详情参考： 分库分表经典15连问 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:3","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"池化技术 请求调用数据库时，都会先获取数据库的连接，然后依靠这个连接来查询数据，搞完收工，最后关闭连接，释放资源。如果我们不用数据库连接池的话，每次执行SQL，都要创建连接和销毁连接，这就会导致每个查询请求都变得更慢了，相应的，系统处理用户请求的能力就降低了。 因此，需要使用池化技术，即数据库连接池、HTTP 连接池、Redis 连接池等等。使用数据库连接池，可以避免每次查询都新建连接，减少不必要的资源开销，通过复用连接池，提高系统处理高并发请求的能力。 同理，我们使用线程池，也能让任务并行处理，更高效地完成任务。 面试必备：Java线程池解析 细数线程池的10个坑 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:4","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"读写分离 通常来说，一台单机的MySQL服务器，可以支持500左右的TPS和10000左右的QPS，即单机支撑的请求访问是有限的。 当请求量非常大的时候，对于实时性要求不高的读请求，都去读从库，写的请求或者实时性要求高的请求，才走主库。 面试必备：聊聊MySQL的主从 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:5","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"使用缓存 内存操作，显然更快，能支撑更高的并发量。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:6","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"CDN 什么是CDN？ Content Delivery Network/Content Distribution Network，翻译过来就是内容分发网络，它表示将静态资源分发到位于多个地理位置机房的服务器，可以做到数据就近访问，加速了静态资源的访问速度，因此让系统更好处理正常别的动态请求。 商品图片，icon等等静态资源，可以对页面做静态化处理，减少访问服务端的请求。如果用户分布在全国各地，有的在上海，有的在深圳，地域相差很远，网速也各不相同。为了让用户最快访问到页面，可以使用CDN。CDN可以让用户就近获取所需内容。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:7","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"消息队列 异步、削峰、解耦 搞一些双十一、双十二等运营活动时，需要避免流量暴涨，打垮应用系统的风险。因此一般会引入消息队列，来应对高并发的场景。 假设你的应用系统每秒最多可以处理2k个请求，每秒却有5k的请求过来，可以引入消息队列，应用系统每秒从消息队列拉2k请求处理得了。 有些伙伴担心这样可能会出现消息积压的问题： 首先，搞一些运营活动，不会每时每刻都那么多请求过来你的系统（除非有人恶意攻击），高峰期过去后，积压的请求可以慢慢处理； 其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面； ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:8","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"ElasticSearch 一般搜索功能都会用到它，它是一个分布式、高扩展、高实时的搜索与数据分析引擎，简称为ES。ES可以扩容方便，天然支撑高并发。当数据量大的时候，不用动不动就加机器扩容，分库等等，可以考虑用ES来支持简单的查询搜索、统计类的操作。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:9","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"降级熔断 熔断降级是保护系统的一种手段。当前互联网系统一般都是分布式部署的，而分布式系统中偶尔会出现某个基础服务不可用，最终导致整个系统不可用的情况, 这种现象被称为服务雪崩效应。 比如分布式调用链路A-\u003eB-\u003eC....，下图所示： 如果服务C出现问题，比如是因为慢SQL导致调用缓慢，那将导致B也会延迟，从而A也会延迟。堵住的A请求会消耗占用系统的线程、IO、CPU等资源。当请求A的服务越来越多，占用计算机的资源也越来越多，最终会导致系统瓶颈出现，造成其他的请求同样不可用，最后导致业务系统崩溃。 为了应对服务雪崩, 常见的做法是熔断和降级。最简单是加开关控制，当下游系统出问题时，开关打开降级，不再调用下游系统。还可以选用开源组件Hystrix来支持。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:10","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"限流 如果你的系统每秒扛住的请求是一千，如果一秒钟来了十万请求呢？换个角度就是说，高并发的时候，流量洪峰来了，超过系统的承载能力，怎么办呢？ 这时候，我们可以采取限流方案。就是为了保护系统，多余的请求，直接丢弃。 什么是限流：在计算机网络中，限流就是控制网络接口发送或接收请求的速率，它可防止DoS攻击和限制Web爬虫。限流，也称流量控制。是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定性。 可以使用Guava的RateLimiter单机版限流，也可以使用Redis分布式限流，还可以使用阿里开源组件sentinel限流。 面试的时候，你说到限流这块的话？面试官很大概率会问你限流的算法：面试必备：4种经典限流算法讲解 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:1:11","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"二、数据库 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"池化 原因：数据库的调用方式是先获取数据库的连接，然后依靠这条连接从数据库中查询数据，最后关闭连接释放数据库资源。这种调用方式下，每次执行 SQL 都需要重新建立连接，而建立连接的耗时可能要比执行sql的耗时还要高，因此采用池化技术。 做法：数据库连接池有两个最重要的配置：最小连接数和最大连接数，它们控制着从连接池中获取连接的流程： 如果当前连接池中的连接数小于最小连接数，则创建新的连接； 如果连接池中有空闲连接则复用空闲连接； 如果空闲池中没有空闲连接并且当前连接数小于最大连接数，则创建新的连接处理请求； 如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间等待旧的连接可用； 如果等待超过了这个设定时间则向用户抛出错误。 总结： 池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。 池子中的对象需要在使用之前预先初始化完成，叫做连接池预热，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。 池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:1","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"主从读写分离 原因：其实，大部分系统的访问模型是读多写少，读写请求量的差距可能达到几个数量级。读写分离主要用来解决查询请求增多的问题。 关键技术： 主从复制； 访问哪个数据库。可基于代理选择。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:2","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"分库分表 原因：读写分离主要解决读请求增多的问题，而分库分表解决写请求增多、存储变多的问题。 关键技术： 垂直分片：可以解决单库数据存储问题，同时，单库的数据量降低，也能提高数据查询的性能。 水平分片：解决单库或单表数据存储问题，同时，单库或单表的数据量降低，也能提高数据查询的性能。 当分库分表之后，同一个逻辑表的数据被分布到多个库中，这时如果使用数据库自增字段作为主键，那么只能保证在这个库中是唯一的，无法保证全局的唯一性。那么假如设计用户系统的时候，使用自增 ID 作为用户 ID，就可能出现两个用户有两个相同的 ID，这是不可接受的，那么就需要生成全局唯一的 ID。 UUID 不建议使用 UUID 作为数据库主键，因为： ID 有序更利于索引数据的插入，而 UUID 是无序的，造成了多余的数据移动的开销； UUID 不具备业务含义； UUID 是由 32 个 16 进制数字组成的字符串(128位)，如果作为数据库主键使用比较耗费空间。 ==雪花算法(Snowflake)== Snowflake 的核心思想是将 64 位的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。可以自定义各字段代表的含义和位数。 原理知道了，那工程上是怎么实现呢？ 一种是嵌入到业务代码里，也就是分布在业务服务器中。 一种是作为独立的服务部署，这也就是我们常说的发号器服务。 Snowflake 算法设计的非常简单且巧妙，性能上也足够高效，同时也能够生成具有全局唯一性、单调递增性和有业务含义的 ID，但是它也有一些缺点： 其中最大的缺点就是它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止； 另外，如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。 这一点，也是我在实际项目中踩过的坑，而解决办法主要有两个： 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均； 生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量的均衡了。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:3","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"NoSQL // TODO ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:2:4","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"三、缓存 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"概述 什么是缓存？ 凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。内存和缓存之间不能划等号。 常见硬件组件的延时情况： 可以看到，做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms，所以，使用内存作为缓存的存储介质相比于以磁盘作为主要存储介质的数据库来说，性能上会提高多个数量级，同时也能够支撑更高的并发量。 缓存分类 日常开发中，常见的缓存主要就是静态缓存、分布式缓存、热点本地缓存这三种。 静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。 例如，我们在做一些内容管理系统的时候，后台会录入很多的文章，前台在网站上展示文章内容，就像新浪，网易这种门户网站一样。解决思路是：每篇文章在录入的时候渲染成静态页面，放置在所有的前端 Nginx 或者 Squid 等 Web 服务器上，这样用户在访问的时候会优先访问 Web 服务器上的静态页面，在对旧的文章执行一定的清理策略后，依然可以保证 99% 以上的缓存命中率。 静态缓存只能针对静态数据来缓存，对于动态请求就无能为力了，针对动态请求做缓存就需要分布式缓存了。 分布式缓存最典型的就是 Redis 了。 当遇到极端的热点数据查询时，分布式缓存也扛不住了，就要考虑热点本地缓存了。 热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。 本地缓存方案，如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询。 比如，电商系统的首页有一些推荐的商品，请求量很大，可以使用 Guava Cache 来将所有的推荐商品的信息缓存起来，并且设置每隔 30 秒重新从数据库中加载最新的所有商品。这样，在获取所有商品信息的时候可以调用 Loading Cache 的 get 方法，就可以优先从本地缓存中获取商品信息，如果本地缓存不存在，会使用 CacheLoader 中的逻辑从数据库中加载所有的商品。 缺点就是有时效性，不能实时读到最新的数据。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:1","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"缓存一致性 旁路缓存策略。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:2","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"高可用 主要选择的方案有客户端方案、中间代理层方案和服务端方案三大类： 客户端方案：在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。 中间代理层方案：在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。 服务端方案：Redis 2.4 版本后提出的 Redis Sentinel 方案。 客户端方案⭐ 在客户端方案中，需要关注缓存的写和读两个方面： 写数据时，需要把被写入缓存的数据分散到多个节点中，即进行数据分片，通常采用一致性哈希； 读数据时，可以利用多组的缓存来做容错，提升缓存系统的可用性。关于读数据，这里可以使用主从和多副本两种策略，两种策略是为了解决不同的问题而提出的。 中间代理层方案 虽然客户端方案已经能解决大部分的问题，但是只能在单一语言系统之间复用。例如微博使用 Java 语言实现了这么一套逻辑，再使用 PHP 就难以复用，需要重新写一套，很麻烦。而中间代理层的方案就可以解决这个问题。 所有缓存的读写请求都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能。 服务端方案⭐ Redis 在 2.4 版本中提出了 Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题，它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性，整体的架构如下图所示： 缓存穿透及解决 回种空值； 布隆过滤器； 分布式锁。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:3","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"CDN 分布式缓存主要对动态请求数据做了加速，但是系统中还存在着大量的静态资源请求： 对于移动 APP 来说，静态资源主要是图片、视频和流媒体信息。 对于 Web 网站来说，则包括了 JavaScript 文件，CSS 文件，静态 HTML 文件等等。 问：是否也可以使用分布式缓存来解决这个问题呢？ 不能！ 一般来说，图片和视频的大小会在几兆到几百兆之间，如果我们的应用服务器和分布式缓存都部署在北京的机房里，这时一个杭州的用户要访问缓存中的一个视频，那这个视频文件就需要从北京传输到杭州，期间会经过多个公网骨干网络，延迟很高，会让用户感觉视频打开很慢，严重影响到用户的使用体验。 所以，静态资源访问的关键点是就近访问，即北京用户访问北京的数据，杭州用户访问杭州的数据，这样才可以达到性能的最优。 你可能会说：「那我们在杭州也自建一个机房，让用户访问杭州机房的数据就好了呀。」可用户遍布在全国各地，有些应用可能还有国外的用户，我们不可能在每个地域都自建机房，这样成本太高了。 另外，单个视频和图片等静态资源很大，并且访问量又极高，如果使用业务服务器和分布式缓存来承担这些流量，无论是对于内网还是外网的带宽都会是很大的考验。 所以考虑在业务服务器的上层，增加一层特殊的缓存，用来承担绝大部分对于静态资源的访问，这一层特殊缓存的节点需要遍布在全国各地，这样可以让用户选择最近的节点访问。缓存的命中率也需要一定的保证，尽量减少访问资源存储源站的请求数量（回源请求），也就是用 CDN。 关键技术 内容分发网络(CDN，Content Delivery Network/Content Distribution Network)：简单来说，CDN 就是将静态的资源分发到位于多个地理位置机房中的服务器上，因此它能很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。 要搭建一个 CDN 系统需要考虑哪两点： 如何将用户的请求映射到 CDN 节点上； 如何根据用户的地理位置信息选择到比较近的节点。 CNAME 首先，我们考虑一下如何让用户的请求到达 CDN 节点，你可能会觉得，这很简单啊，只需要告诉用户 CDN 节点的 IP 地址，然后请求这个 IP 地址上面部署的 CDN 服务就可以了啊。但是这样会有一个问题：就是我们使用的是第三方厂商的 CDN 服务，CDN 厂商会给我们一个 CDN 的节点 IP，比如说这个 IP 地址是「111.202.34.130」，那么我们的电商系统中的图片的地址很可能是这样的：「http://111.202.34.130/1.jpg」，这个地址是要存储在数据库中的。 那么如果这个节点 IP 发生了变更怎么办？或者我们如果更改了 CDN 厂商怎么办？是不是要修改所有的商品的 url 域名呢？这就是一个比较大的工作量了。所以，我们要做的事情是 将第三方厂商提供的 IP 隐藏起来，给到用户的最好是一个本公司域名的子域名。 问：那么如何做到这一点呢？这就需要依靠 DNS 来帮我们解决域名映射的问题了。 域名系统(DNS，Domain Name System)：实际上就是一个存储域名和 IP 地址对应关系的分布式数据库。而域名解析的结果一般有两种： 一种叫做 A 记录，返回的是域名对应的 IP 地址； 另一种是 CNAME 记录，返回的是另一个域名。 也就是说当前域名的解析要跳转到另一个域名的解析上，实际上 www.baidu.com 域名的解析结果就是一个 CNAME 记录，域名的解析被跳转到 www.a.shifen.com 上了，正是利用 CNAME 记录来解决域名映射问题的。 问：具体是怎么解决的呢？举个例子。 比如你的公司的一级域名叫做 example.com，那么你可以给你的图片服务的域名定义为 img.example.com，然后将这个域名的解析结果的 CNAME 配置到 CDN 提供的域名上。 比如 ucloud 可能会提供一个域名是 80f21f91.cdn.ucloud.com.cn 这个域名。这样你的电商系统使用的图片地址可以是 http://img.example.com/1.jpg。 用户在请求这个地址时，DNS 服务器会将域名解析到 80f21f91.cdn.ucloud.com.cn 域名上，然后再将这个域名解析为 CDN 的节点 IP，这样就可以得到 CDN 上面的资源数据了。 问：DNS 域名解析的时间可能会有点久，怎么办呢？ 一个解决的思路是：在 APP 启动时，对需要解析的域名做预先解析，然后把解析的结果缓存到本地的一个 LRU 缓存里面。这样当我们要使用这个域名的时候，只需要从缓存中直接拿到所需要的 IP 地址就好了，如果缓存中不存在才会走整个 DNS 查询的过程。同时，为了避免 DNS 解析结果的变更造成缓存内数据失效，我们可以启动一个定时器，定期地更新缓存中的数据。 GSLB 全局负载均衡(GSLB，Global Server Load Balance)：主要是对于部署在不同地域的服务器之间做负载均衡，底层可能管理了很多的本地负载均衡组件。它有两方面的作用： 一方面，它是一种负载均衡服务器。负载均衡，顾名思义嘛，指的是让流量平均分配使得下面管理的服务器的负载更平均； 另一方面，它还需要保证流量流经的服务器与流量源头在地缘上是比较接近的。 GSLB 可以通过多种策略，来保证返回的 CDN 节点和用户尽量保证在同一地缘区域： 比如说可以将用户的 IP 地址按照地理位置划分为若干的区域，然后将 CDN 节点对应到一个区域上，然后根据用户所在区域来返回合适的节点； 也可以通过发送数据包测量 RTT 的方式来决定返回哪一个节点。 有了 GSLB 之后，节点的解析过程变成了下图中的样子： 当然，是否能够从 CDN 节点上获取到资源还取决于 CDN 的同步延时。 一般，会通过 CDN 厂商的接口将静态的资源写入到某一个 CDN 节点上 ，再由 CDN 内部的同步机制将资源分散同步到每个 CDN 节点，即使 CDN 内部网络经过了优化，这个同步的过程是有延时的，一旦我们无法从选定的 CDN 节点上获取到数据，我们就不得不从源站获取数据，而用户网络到源站的网络可能会跨越多个主干网，这样不仅性能上有损耗，也会消耗源站的带宽，带来更高的研发成本。所以，我们在使用 CDN 的时候需要关注 CDN 的命中率和源站的带宽情况。 小结 DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上； DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间； GSLB 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:3:4","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"四、消息队列 上面一直关注的是如何提升读请求的性能，但随着业务发展，可能会遇到一些存在高并发写请求的场景，其中秒杀抢购就是最典型的场景。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"应用场景 高并发写请求-削峰 秒杀场景： 秒杀开始前，用户查询的是少量的商品数据，属于查询的热点数据，可以采用缓存策略，将请求尽量挡在上层的缓存中，能被静态化的数据，比如说商城里的图片和视频数据，尽量做到静态化，这样就可以命中 CDN 节点缓存，减少 Web 服务器的查询量和带宽负担。Web 服务器比如 Nginx 可以直接访问分布式缓存节点，这样可以避免请求到达 Tomcat 等业务服务器。 秒杀开始后，用户瞬间向电商系统请求生成订单，扣减库存，用户的这些写操作都是不经过缓存直达数据库的。1 秒钟之内，有 1 万个数据库连接同时达到，系统的数据库濒临崩溃，寻找能够应对如此高并发的写请求方案迫在眉睫。 在秒杀场景下，短时间之内数据库的写流量会很高，那么依照我们以前的思路应该对数据做分库分表。如果已经做了分库分表，那么就需要扩展更多的数据库来应对更高的写流量。但是无论是分库分表，还是扩充更多的数据库，都会比较复杂，原因是你需要将数据库中的数据做迁移，这个时间就要按天甚至按周来计算了。 而在秒杀场景下，高并发的写请求并不是持续的，也不是经常发生的，而只有在秒杀活动开始后的几秒或者十几秒时间内才会存在。为了应对这十几秒的瞬间写高峰，就要花费几天甚至几周的时间来扩容数据库，再在秒杀之后花费几天的时间来做缩容，这无疑是得不偿失的。 所以，解决思路是：将秒杀请求暂存在消息队列中，然后业务服务器会响应用户「秒杀结果正在计算中」，释放了系统资源之后再处理其它用户的请求。 我们会在后台启动若干个队列处理程序，消费消息队列中的消息，再执行校验库存、下单等逻辑。因为只有有限个队列处理线程在执行，所以落入后端数据库上的并发请求是有限的。而请求是可以在消息队列中被短暂地堆积，当库存被消耗完之后，消息队列中堆积的请求就可以被丢弃了。 这就是消息队列在秒杀系统中最主要的作用：削峰填谷。也就是说它可以削平短暂的流量高峰，虽说堆积会造成请求被短暂延迟处理，但是只要我们时刻监控消息队列中的堆积长度，在堆积量超过一定量时，增加队列处理机数量，来提升消息的处理能力就好了，而且秒杀的用户对于短暂延迟知晓秒杀的结果，也是有一定容忍度的。 比如秒杀商品有 1000 件，处理一次购买请求的时间是 500ms，那么总共就需要 500s 的时间。这时，你部署 10 个队列处理程序，那么秒杀请求的处理时间就是 50s，也就是说用户需要等待 50s 才可以看到秒杀的结果，这是可以接受的。这时会并发 10 个请求到达数据库，并不会对数据库造成很大的压力。 业务流程-异步 在刚才提到的秒杀场景下，我们在处理购买请求时，需要 500ms。这时，你分析了一下整个的购买流程，发现这里面会有主要的业务逻辑，也会有次要的业务逻辑：比如说，主要的流程是生成订单、扣减库存；次要的流程可能是我们在下单购买成功之后会给用户发放优惠券，会增加用户的积分。假如发放优惠券的耗时是 50ms，增加用户积分的耗时也是 50ms，那么如果我们将发放优惠券、增加积分的操作放在另外一个队列处理机中执行，那么整个流程就缩短到了 400ms，性能提升了 20%，处理这 1000 件商品的时间就变成了 400s。如果我们还是希望能在 50s 之内看到秒杀结果的话，只需要部署 8 个队列程序就好了。 经过将一些业务流程异步处理之后，我们的秒杀系统部署结构也会有所改变： 系统模块-解耦 比如数据团队对你说，在秒杀活动之后想要统计活动的数据，借此来分析活动商品的受欢迎程度、购买者人群的特点以及用户对于秒杀互动的满意程度等等指标。而我们需要将大量的数据发送给数据团队，那么要怎么做呢？ 一个思路是：可以使用 HTTP 或者 RPC 的方式来同步地调用，也就是数据团队这边提供一个接口，我们实时将秒杀的数据推送给它，但是这样调用会有两个问题： 整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。 当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。 这时，我们可以考虑使用消息队列降低业务系统和数据系统的直接耦合度。 秒杀系统产生一条购买数据后，我们可以先把全部数据发送给消息队列，然后数据团队再订阅这个消息队列的话题，这样它们就可以接收到数据，然后再做过滤和处理了。秒杀系统在这样解耦合之后，数据系统的故障就不会影响到秒杀系统了，同时，当数据系统需要新的字段时，只需要解析消息队列中的消息，拿到需要的数据就好了。 异步处理、解耦合和削峰填谷 是消息队列在秒杀系统设计中起到的主要作用，其中， 削峰填谷可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和，但会造成请求处理的延迟； 异步处理可以简化业务流程中的步骤，提升系统性能； 解耦合可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统，可以提升系统的鲁棒性。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:1","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"避免重复消费 避免消息丢失 如果要保证消息只被消费一次，首先就要保证消息不会丢失。 消息丢失主要存在三个场景： 消息从生产者写入到消息队列的过程。 消息在消息队列中的存储场景。 消息被消费者消费的过程。 消息生产的过程中丢失 主要原因：网络抖动，消息有可能因为网络的错误而丢失。 解决方案：消息重传。当你发现发送超时后你就将消息重新发一次，但是你也不能无限制地重传消息。一般来说，如果不是消息队列发生故障，或者是到消息队列的网络断开了，重试 2～3 次就可以了。 消息队列中丢失 主要原因：为了减少消息存储时对磁盘的随机 I/O，Kafka 可以配置当达到某一时间间隔，或者累积一定的消息数量的时候再刷盘，也就是所说的异步刷盘。 解决方案：考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。 具体实现：Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份。Follower 中有一个特殊的集合叫做 ISR，当 Leader 故障时，会从 ISR 中新选举出来 Leader。Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。 由于消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个选项叫做 acks，当这个选项被设置为 all 时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送成功。这样，只有 Leader 和所有的 ISR 都挂了，消息才会丢失。 建议是： 如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是需要使用集群的方式来解决，可以配置当所有 ISR Follower 都接收到消息才返回成功。 如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个 Follower 就可以返回成功了。 消费过程中消息丢失 主要原因：一个消费者消费消息的进度是记录在消息队列集群中的，而消费的过程分为三步：接收消息、处理消息、更新消费进度。接收消息和处理消息的过程都可能会发生异常或者失败，比如说，消息接收时网络发生抖动，导致消息并没有被正确的接收到；处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，那么这条失败的消息就永远不会被处理了，也可以认为是丢失了。 解决方案：一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，比方说某一条消息在处理之后，消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。 避免重复消费 为了避免消息丢失，需要付出两方面的代价：一方面是性能的损耗；一方面可能造成消息重复消费。性能损耗还能接受，但消息重复消费可能就会造成严重错误，那么如何避免呢？ Kafka 出现消息重复消费的原因： 根本原因：已经消费的数据没有成功提交 offset。 Kafka 侧由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。 想要完全的避免消息重复的发生是很难做到的，因为网络的抖动、机器的宕机和处理的异常都是比较难以避免的，在工业上并没有成熟的方法，因此我们会把要求放宽，只要保证即使消费到了重复的消息，从消费的最终结果来看和只消费一次是等同的就好了，也就是保证在消息的生产和消费的过程是幂等的。 注：**幂等**指只执行一次操作和多次执行同一个操作，最终得到的结果是相同的 问：Kafka 如何保证消息不被重复消费？/如何实现幂等性，设计去重机制？ 生产端： 思路：Kafka 支持将 Producer 升级为幂等性 Producer，保证消息虽然可能在生产端重复生产，但是最终在消息队列存储时只会存储一份。 具体做法：给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID，消息队列的服务端会存储 \u003c 生产者 ID，最后一条消息 ID\u003e 的映射。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致，如果一致，就认为是重复的消息，服务端会自动丢弃。 消费端： 思路：可分为通用层和业务层。 具体做法： 通用层：可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息 ID，消息被处理之后，把这个 ID 存储在数据库中，在处理下一条消息之前，先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费； 业务层：利用乐观锁的方式来实现。这个机制是在消息中添加一个版本号，在生产消息时先查询数据的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，执行时也带上版本号。比如在消费第一条消息时，version 值为 1，SQL 可以执行成功，并且同时把 version 值改为了 2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:2","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"消息延迟/堆积 如何监控消息延迟 监控消息的延迟有两种方式： 使用消息队列提供的工具，通过监控消息的堆积来完成； 通过生成监控消息的方式来监控消息的延迟情况。 监控消息的堆积 首先需要从原理上了解，在消息队列中消费者的消费进度是多少，因为这样才方便计算当前的消费延迟是多少。比方说，生产者向队列中一共生产了 1000 条消息，某一个消费者消费进度是 900 条，那么这个消费者的消费延迟就是 100 条消息。 在 Kafka 中，消费者的消费进度在不同的版本上是不同的。 在 Kafka0.9 之前的版本中，消费进度是存储在 ZooKeeper 中的，消费者在消费消息的时候，先要从 ZooKeeper 中获取最新的消费进度，再从这个进度的基础上消费后面的消息。 在 Kafka0.9 版本之后，消费进度被迁入到 Kakfa 的一个专门的 topic 叫 __consumer_offsets 里面。 Kafka 也提供了一些工具来获取这个消费进度的信息，帮助实现自己的监控，比较推荐 JMX。Kafka 通过 JMX 暴露了消息堆积的数据，我在本地启动了一个 console consumer，然后使用 jconsole 连接这个 consumer，你就可以看到这个 consumer 的堆积数据了。 生成监控消息 具体做法： 先定义一种特殊的消息； 然后启动一个监控程序，将这个消息定时地循环写入到消息队列中。消息的内容可以是生成消息的时间戳，并且也会作为队列的消费者消费数据； 业务处理程序消费到这个消息时直接丢弃掉，而监控程序在消费到这个消息时，就可以和这个消息的生成时间做比较，如果时间差达到某一个阈值就可以向我们报警。 减少消息延迟 减少消息的处理延迟，需要在消费端和消息队列两个层面来完成。 消费端： 增加消费者的数量 在 Kafka 中，Topic 的 Partition 数量决定了消费的并行度，增加多余的消费者也是没用的。这是因为 Kafka 约定一个 Partition 只能被一个消费者消费。 优化消费代码 可以在 consumer 中提升处理消息的并行度，所以可以考虑使用多线程的方式来增加处理能力：你可以预先创建一个或者多个线程池，在接收到消息之后，把消息丢到线程池中来异步地处理，这样，原本串行的消费消息的流程就变成了并行的消费，可以提高消息消费的吞吐量，在并行处理的前提下，我们就可以在一次和消息队列的交互中多拉取几条数据，然后分配给多个线程来处理。 消息队列： 零拷贝 传统数据文件拷贝 操作系统将数据从磁盘拷贝到内核缓冲区； 应用程序通过系统调用将内核缓存区的数据拷贝到用户缓冲区； 应用程序将用户缓冲区的数据拷贝到内核的 Socket 缓冲区中； 操作系统将 Socket 缓冲区的数据拷贝到网卡缓冲区中，通过网卡发送给数据接收方。 总结：涉及 1 次内核态到用户态的数据拷贝和 1 次 用户态到内核态的数据拷贝。 零拷贝 操作系统提供了 Sendfile 函数，可以减少数据被拷贝的次数。使用了 Sendfile 之后，在内核缓冲区的数据不会被拷贝到用户缓冲区，而是直接被拷贝到 Socket 缓冲区，节省了一次拷贝的过程，提升了消息发送的性能。 操作系统将数据从磁盘拷贝到内核缓冲区； 系统调用 Sendfile 将数据的文件描述符直接被拷贝到 Socket 缓冲区(仅仅会拷贝一个描述符过去，不会拷贝数据到 Socket 缓存)； 操作系统将 Socket 缓冲区的数据拷贝到网卡缓冲区中，通过网卡发送给数据接收方。 总结：省略了两次不必要的数据拷贝： 从内核空间拷贝到用户空间； 从用户空间再次拷贝到内核空间。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:4:3","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"五、微服务 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"概述 为什么要使用微服务架构？ 一体化架构增加了研发的成本，抑制了研发效率的提升。 《人月神话》中曾经提到：一个团队内部沟通成本，和人员数量 n 有关，约等于 n(n-1)/2，也就是说随着团队人员的增加，沟通的成本呈指数级增长，一个 100 人的团队，需要沟通的渠道大概是 100（100-1）/2 = 4950。那么为了减少沟通成本，我们一般会把团队拆分成若干个小团队，每个小团队 5～7 人，负责一部分功能模块的开发和维护。 按照亚马逊 CEO，贝佐斯的「两个披萨」的理论，如果两个披萨不够你的团队吃，那么你的团队就太大了，需要拆分，所以一个小团队包括开发、运维、测试以 6～8 个人为最佳； 有的研发同学会认为最快的方式，不是询问其他团队是否有现成的，而是自己写一套，但是这种想法是不合适的，这样一来就会造成功能服务的重复开发。 由于代码部署在一起，每个人都向同一个代码库提交代码，代码冲突无法避免；同时，功能之间耦合严重，可能你只是更改了很小的逻辑，却导致其它功能不可用，从而在测试时需要对整体功能回归，延长了交付时间。 模块之间互相依赖，一个小团队中的成员犯了一个错误，就可能会影响到，其它团队维护的服务，对于整体系统稳定性影响很大。 一体化架构对于系统的运维也会有很大的影响。 在项目初期，你的代码可能只有几千行，构建一次只需要一分钟，那么你可以很敏捷灵活地频繁上线变更修复问题。但是当你的系统扩充到几十万行，甚至上百万行代码的时候，一次构建的过程，包括编译、单元测试、打包和上传到正式环境，花费的时间可能达到十几分钟，并且，任何小的修改，都需要构建整个项目，上线变更的过程非常不灵活。 这些问题，都可以用微服务来解决。 微服务拆分原则 单一服务内部功能的高内聚、低耦合。即，每个服务只完成自己职责之内的任务，对于不是自己职责的功能，交给其它服务来完成。 关注服务拆分的粒度，先粗略拆分，再逐渐细化。因为服务多了也会带来问题，像是服务个数的增加会增加运维的成本。再比如，原本一次请求只需要调用进程内的多个方法，现在则需要跨网络调用多个 RPC 服务，在性能上肯定会有所下降。推荐的做法是：拆分初期可以把服务粒度拆的粗一些，后面随着团队对于业务和微服务理解的加深，再考虑把服务粒度细化。比如说，对于一个社区系统来说，你可以先把和用户关系相关的业务逻辑，都拆分到用户关系服务中，之后，再把其中比如黑名单的逻辑独立成黑名单服务。 拆分的过程，要尽量避免影响产品的日常功能迭代，也就是说，要一边做产品功能迭代，一边完成服务化拆分。总不能停掉所有业务开发，全盘推翻重构完再上线吧？参考如下剥离顺序： 优先剥离比较独立的边界服务。从非核心的服务出发，减少拆分对现有业务的影响，也给团队一个练习、试错的机会； 要理清服务之间的调用关系，当两个服务存在依赖关系时，优先拆分被依赖的服务。比如，内容服务会依赖用户服务获取用户信息，互动服务会依赖内容服务，所以要按照先用户服务，再内容服务，最后互动服务的顺序来进行拆分。 服务接口的定义要具备可扩展性。服务拆分之后，由于服务是以独立进程的方式部署，所以服务之间通信，就不再是进程内部的方法调用，而是跨进程的网络通信了。在这种通信模型下需要注意，服务接口的定义要具备可扩展性，否则在服务变更时，会造成意想不到的错误。比如，某一个微服务的接口有三个参数，在一次业务需求开发中，组内的一个同学将这个接口的参数调整为了四个，接口被调用的地方也做了修改，结果上线这个服务后，却不断报错，无奈只能回滚。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:1","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"远程调用 当采用微服务架构之后，原本的 1 次请求，可能需要调用 4、5 次服务，如图。 那如何避免其带来的性能损耗呢？ 选择合适的网络模型，有针对性地调整网络参数，以优化网络传输性能； 选择合适的序列化方式，以提升封包、解包的性能。 如何提升网络传输性能？ 有很多方面： I/O 多路复用； 禁用 Nagle 算法。 要讲讲 Nagle 算法： tcp 协议的包头有 20 字节，ip 协议的包头也有 20 字节，如果仅仅传输 1 字节的数据，在网络上传输的就有 20 + 20 + 1 = 41 字节，其中真正有用的数据只有 1 个字节，这对效率和带宽是极大的浪费。所以在 1984 年的时候，John Nagle 提出了以他的名字命名的 Nagle 算法： 如果是连续的小数据包，大小没有一个 MSS（Maximum Segment Size，最大分段大小），并且还没有收到之前发送的数据包的 Ack 信息，那么这些小数据包就会在发送端暂存起来，直到小数据包累积到一个 MSS，或者收到一个 Ack 为止。 原本是为了减少不必要的网络传输，但是如果接收端开启了 DelayedACK（延迟 ACK 的发送，这样可以合并多个 ACK，提升网络传输效率），那就会发生，发送端发送第一个数据包后，接收端没有返回 ACK，这时发送端发送了第二个数据包，因为 Nagle 算法的存在，并且第一个发送包的 ACK 还没有返回，所以第二个包会暂存起来。而 DelayedACK 的超时时间，默认是 40ms，所以一旦到了 40ms，接收端回给发送端 ACK，那么发送端才会发送第二个包，这样就增加了延迟。 解决的方式非常简单：只要在 socket 上开启 tcp_nodelay 就好了，这个参数关闭了 Nagle 算法，这样发送端就不需要等到上一个发送包的 ACK 返回，直接发送新的数据包就好了。这对于强网络交互的场景来说非常的适用，基本上，如果你要自己实现一套网络框架，tcp_nodelay 这个参数最好是要开启的。 选择合适的序列化方法 一次 RPC 调用需要经历两次序列化、两次反序列化的过程，因此需要选择高效的序列化方法。 没啥要求的可以用 JSON，不然还得是 Protobuf。(原因详见 Protobuf 的 md) ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:2","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"服务注册与发现 注册中心 注册中心提供的功能： 其一是提供了服务地址的存储； 其二是当存储内容发生变化时，可以将变更的内容推送给客户端。 有了注册中心之后，服务节点的增加和减少对于客户端就是透明的。这样，除了可以实现不重启客户端，就能动态地变更服务节点以外，还可以实现优雅关闭的功能。 问：什么是优雅的关闭？注册中心怎么做到？ 优雅关闭是必须要考虑的问题。因为如果直接暴力地停止服务，那么已经发送给服务端的请求，来不及被处理就会被丢弃了，就会造成这部分请求失败，服务就会有波动。 所以，服务在退出的时候，都需要先停掉流量，再停止服务，这样服务的关闭才会更平滑。 对于 RPC 服务来说，可以先将 RPC 服务从注册中心的服务列表中删除掉，然后观察 RPC 服务端没有未处理的请求之后，再将服务端停掉。有了优雅关闭之后，RPC 服务端再重启的时候，就会减少对客户端的影响。 服务状态管理 一般有两种解决思路： 主动探测； 心跳模式； 主动探测 思路：RPC 服务打开一个端口，由注册中心每隔一段时间（比如 30 秒）探测这些端口是否可用，如果可用就认为服务仍然是正常的，否则就可以认为服务不可用，那么注册中心就可以把服务从列表里面删除了。 缺陷： 所有的 RPC 服务端都需要开放一个统一的端口给注册中心探测，但需要开放的端口很可能已经被占用，这样会造成 RPC 服务启动失败； 如果 RPC 服务实例比较多，那么每次探测的成本也会比较高，探测的时间也比较长，这样当一个服务不可用时，可能会有一段时间的延迟，才会被注册中心探测到。 因此，改进成了心跳模式。 心跳模式 大部分注册中心都采用心跳模式检测 RPC 服务是否存活。 思路： 首先，注册中心为每一个连接上来的 RPC 服务节点，记录最近续约的时间； 同时，注册中心会启动一个定时器，检测 RPC 服务节点的租约是否到期，租约到期就认为这个服务节点不可用 RPC 服务节点可以按照一定的时间间隔(比如 30 秒)，向注册中心发送心跳包续约； 注册中心收到心跳包之后，会更新这个节点的最近续约时间。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:3","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"分布式 Trace 慢请求问题如何排查？ 单体架构中的慢请求排查 为了应对多线程同时请求造成的日志混乱，可以在记录打点日志时，使用 requestId 将日志串起来，这样方便比较一次请求中的多个步骤的耗时情况； 使用静态代理的方式做切面编程，避免在业务代码中，加入大量打印耗时的日志的代码，减少了对于代码的侵入性，同时编译期的代码注入可以减少； 增加日志采样率，避免全量日志的打印； 为了避免在排查问题时，需要到多台服务器上搜索日志，可以使用消息队列，将日志集中起来放在了 Elasticsearch 中。 分布式 Trace 在单体架构中，单次请求的所有的耗时日志，都被记录在一台服务器上；而在微服务的场景下，单次请求可能跨越多个 RPC 服务，这就造成了，单次的请求的日志会分布在多个服务器上。 可以采用 traceId + spanId 这两个数据维度来记录服务之间的调用关系（这里 traceId 就是 requestId），也就是使用 traceId 串起单次请求，用 spanId 记录每一次 RPC 调用。 比如，请求从用户端过来，先到达 A 服务，A 服务会分别调用 B 和 C 服务，B 服务又会调用 D 和 E 服务。 那么 spanId 是何时生成的，又是如何传递的呢？ 首先，A 服务在发起 RPC 请求服务 B 前，先从线程上下文中获取当前的 traceId 和 spanId，然后，依据上面的逻辑生成本次 RPC 调用的 spanId，再将 spanId 和 traceId 序列化后，装配到请求体中，发送给服务方 B。 服务方 B 获取请求后，从请求体中反序列化出 spanId 和 traceId，同时设置到线程上下文中，以便给下次 RPC 调用使用。在服务 B 调用完成返回响应前，计算出服务 B 的执行时间发送给消息队列。 当然，在服务 B 中，你依然可以使用切面编程的方式，得到所有调用的数据库、缓存、HTTP 服务的响应时间，只是在发送给消息队列的时候，要加上当前线程上下文中的 spanId 和 traceId。 这样，无论是数据库等资源的响应时间，还是 RPC 服务的响应时间就都汇总到了消息队列中，在经过一些处理之后，最终被写入到 Elasticsearch 中以便给开发和运维同学查询使用。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:4","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"负载均衡 负载均衡服务大体上可以分为两大类：一类是代理类的负载均衡服务；另一类是客户端负载均衡服务。 代理类负载均衡服务典型的就是 NGINX 和 LVS，适用于普通的 Web 服务。但对于微服务架构来说，是不合适的。因为微服务架构中的服务节点存储在注册中心里，使用 LVS 就很难和注册中心交互，获取全量的服务节点列表。另外，一般微服务架构中，使用的是 RPC 协议而不是 HTTP 协议，所以 Nginx 也不能满足要求。 在 RPC 中，通常会使用另一类的负载均衡服务，客户端负载均衡服务，也就是把负载均衡的服务内嵌在 RPC 客户端中。 客户端负载均衡 客户端负载均衡服务，一般和客户端应用部署在一个进程中，提供多种选择节点的策略，最终为客户端应用提供一个最佳的，可用的服务端节点。思想：这类服务一般会结合注册中心来使用，注册中心提供服务节点的完整列表，客户端拿到列表之后使用负载均衡服务的策略选取一个合适的节点，然后将请求发到这个节点上。 负载均衡策略 负载均衡策略从大体上来看可以分为两类： 一类是静态策略，也就是说负载均衡服务器在选择服务节点时，不会参考后端服务的实际运行的状态。 一类是动态策略，也就是说负载均衡服务器会依据后端服务的一些负载特性，来决定要选择哪一个服务节点。 静态策略 轮询(RoundRobin，RR)：按照服务列表的顺序，逐个请求后端服务节点； 带权轮询：给节点加上权重值，比如给 8 核 8G 的机器配置权重为 2，那么就会给它分配双倍的流量； 一致性 Hash。 轮询和带有权重的轮询策略，能够将请求尽量平均地分配到后端服务节点上，也就能够做到对于负载的均衡分配，在没有更好的动态策略之前，应该优先使用这两种策略，比如 Nginx 就会优先使用轮询的策略。 动态策略 原理：负载均衡服务器会收集对后端服务节点的调用信息，比如从负载均衡器到服务节点的活跃连接数，或者是请求调用的响应时间，然后从中选择连接数最少的服务节点，或者响应时间最短的服务节点。 在实际开发中，优先考虑使用动态的策略。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:5","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"API 网关 API 网关是一种架构模式，它是将一些服务共有的功能整合在一起，独立部署为单独的一层，用来解决一些服务治理的问题。可以把它看作系统的边界，它可以对出入系统的流量做统一的管控。 网关分类 API 网关可以分为两类：一类叫做入口网关，一类叫做出口网关。 入口网关⭐ 入口网关部署在负载均衡服务器和应用服务器之间，主要有以下作用： 提供给客户端一个统一的请求接入地址，API 网关可以将用户的请求动态路由到不同的业务服务上，并且做一些必要的协议转换工作。比如，部署的微服务对外暴露的协议可能不同，有些还提供的是 HTTP 服务；有些已经完成 RPC 改造，对外暴露 RPC 服务。API 网关可以对客户端屏蔽这些服务的部署地址，以及协议的细节，给客户端的调用带来很大的便捷。 植入一些服务治理的策略，比如服务的熔断、降级，流量控制和分流等； API 网关可以嵌入中间件，比如用户认证和授权的实现等； API 网关可以给请求分配 Request ID，辅助进行日志记录，用于之前讲的分布式 Trace。 出口网关 不是重点。 在系统开发中，会依赖很多外部的第三方系统，出口网关就是负责调用这些外部第三方系统的。比如典型的例子：第三方账户登录、使用第三方工具支付等等。我们可以在应用服务器和第三方系统之间，部署出口网关，在出口网关中，对调用外部的 API 做统一的认证、授权，审计以及访问控制。 如何实现 // TODO：线程池 可以针对不同的服务使用不同的线程池，在线程池内部针对不同的接口设置配额 Tyk 是一种 Go 语言实现的轻量级 API 网关，有着丰富的插件资源，对于 Go 语言栈的团队来说，也是一种不错的选择。 引入网关 在服务层和客户端之间建立一层薄薄的 Web 层，主要做两件事： 聚合服务层接口数据。比如，商品详情页的接口，可能会聚合服务层中，获取商品信息、用户信息、店铺信息以及用户评论等多个服务接口的数据； 负责协议转换、限流、黑白名单等。比如将 HTTP 请求转换为 RPC 请求，并且对前端的流量做一些限制，对于某些请求添加设备 ID 的黑名单等等。 聚合服务接口数据，一般有两种解决思路： 独立出一组网关专门做服务聚合、超时控制方面的事情，我们一般把前一种网关叫做流量网关，后一种可以叫做业务网关； 抽取独立的服务层，专门做接口聚合的操作。这样服务层就大概分为原子服务层和聚合服务层。 接口数据聚合是业务操作，与其放在通用的网关层来实现，不如放在更贴近业务的服务层来实现，所以，我更倾向于第二种方案。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:6","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"跨地域分布式系统 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:5:7","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"六、维护 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:6:0","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"降级熔断 雪崩是如何发生的 雪崩：局部故障最终导致全局故障。 那么，为什么会发生雪崩呢？我们知道，系统在运行的时候是需要消耗一些资源的，包括 CPU、内存等系统资源，也包括执行业务逻辑的时候，需要的线程资源。 举个例子，一般在业务执行的容器内，都会定义一些线程池来分配执行任务的线程，比如在 Tomcat 这种 Web 容器的内部，定义了线程池来处理 HTTP 请求；RPC 框架也给 RPC 服务端初始化了线程池来处理 RPC 请求。 这些线程池中的线程资源是有限的，如果这些线程资源被耗尽，那么服务自然也就无法处理新的请求，服务提供方也就宕机了。比如，你的垂直电商系统有四个服务 A、B、C、D，A 调用 B，B 调用 C 和 D。其中，A、B、D 服务是系统的核心服务（像是电商系统中的订单服务、支付服务等等），C 是非核心服务（像反垃圾服务、审核服务）。 所以，一旦作为入口的 A 流量增加，你可能会考虑把 A、B 和 D 服务扩容，忽略 C。那么 C 就有可能因为无法承担这么大的流量，导致请求处理缓慢，进一步会让 B 在调用 C 的时候，B 中的请求被阻塞，等待 C 返回响应结果。这样一来，B 服务中被占用的线程资源就不能释放。 久而久之，B 就会因为线程资源被占满，无法处理后续的请求。那么从 A 发往 B 的请求，就会被放入 B 服务线程池的队列中，然后 A 调用 B 响应时间变长，进而拖垮 A 服务。你看，仅仅因为非核心服务 C 的响应时间变长，就可以导致整体服务宕机，这就是我们经常遇到的一种服务雪崩情况。 那么我们要如何避免出现上面这种情况呢？从刚刚的介绍中可以看到，因为服务调用方等待服务提供方的响应时间过长，它的资源被耗尽，才引发了级联反应，发生雪崩。 所以在分布式环境下，系统最怕的反而不是某一个服务或者组件宕机，而是最怕它响应缓慢，因为，某一个服务或者组件宕机也许只会影响系统的部分功能，但它响应一慢，就会出现雪崩拖垮整个系统。 解决的思路就是在检测到某一个服务的响应时间出现异常时，切断调用它的服务与它之间的联系，让服务的调用快速返回失败，从而释放这次请求持有的资源。这个思路也就是我们经常提到的降级和熔断机制。 熔断机制 服务治理中的熔断机制指的是在发起服务调用时，如果返回错误或者超时的次数超过一定阈值，则后续的请求不再发向远程服务而是暂时返回错误。 服务调用方为每一个调用的服务维护一个有限状态机，在这个状态机中会有三种状态：关闭（调用远程服务）、半打开（尝试调用远程服务）和打开（直接返回错误）： 当调用失败的次数累积到一定的阈值时，熔断状态从关闭态切换到打开态。一般在实现时，如果调用成功一次，就会重置调用失败次数。 当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时后，状态切换到半打开态。你也可以通过设置一个定时器，定期地探测服务是否恢复。 在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定的成功次数后，状态切换到关闭态；如果出现调用失败的情况，则切换到打开态。 降级机制 相比熔断来说，降级是一个更大的概念。因为它是站在整体系统负载的角度上，放弃部分非核心功能或者服务，保证整体的可用性的方法，是一种有损的系统容错方式。这样看来，熔断也是降级的一种，除此之外还有限流降级、开关降级等。 此处先介绍开关降级，限流降级单独讲。 开关降级指的是在代码中预先埋设一些开关，用来控制服务调用的返回值。比方说，开关关闭的时候正常调用远程服务，开关打开时则执行降级的策略。这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要通过配置中心动态更改开关的值，就可以实现不重启服务快速地降级远程服务了。 在设计开关降级预案的时候，首先要区分哪些是核心服务，哪些是非核心服务。因为我们只能针对非核心服务来做降级处理，然后就可以针对具体的业务，制定不同的降级策略了。列举一些常见场景下的降级策略： 针对读取数据的场景，我们一般采用的策略是直接返回降级数据。比如，如果数据库的压力比较大，我们在降级的时候，可以考虑只读取缓存的数据，而不再读取数据库中的数据；如果非核心接口出现问题，可以直接返回服务繁忙或者返回固定的降级数据。 对于一些轮询查询数据的场景，比如每隔 30 秒轮询获取未读数，可以降低获取数据的频率（将获取频率下降到 10 分钟一次）。 而对于写数据的场景，一般会考虑把同步写转换成异步写，这样可以牺牲一些数据一致性和实效性来保证系统的可用性。 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:6:1","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"限流 什么是限流？ 限流，也称流量控制。是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定性。限流会导致部分用户请求处理不及时或者被拒，这就影响了用户体验。所以一般需要在系统稳定和用户体验之间平衡一下。 限流算法 固定窗口算法 首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。 当次数少于限流阀值，就允许访问，并且计数器+1 当次数大于限流阀值，就拒绝访问。 当前的时间窗口过去之后，计数器清零。 假设单位时间是1秒，限流阀值为3。在单位时间1秒内，每来一个请求,计数器就加1，如果计数器累加的次数超过限流阀值3，后续的请求全部拒绝。等到1s结束后，计数器清0，重新开始计数。如下图： 缺陷：假设限流阀值为5个请求，单位时间窗口是1s，如果我们在单位时间内的前0.8-1s和1-1.2s，分别并发5个请求。虽然都没有超过阀值，但是如果算0.8-1.2s，则并发数高达10，已经超过单位时间1s不超过5阀值的定义啦。 滑动窗口算法 滑动窗口算法解决固定窗口临界值的问题。它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。 假设单位时间还是1s，滑动窗口算法把它划分为5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子。每格表示0.2s。每过0.2s，时间窗口就会往右滑动一格。然后呢，每个小周期，都有自己独立的计数器，如果请求是0.83s到达的，0.8~1.0s对应的计数器就会加1。 那滑动窗口是如何解决临界问题的？ 假设我们1s内的限流阀值还是5个请求，0.8~1.0s内（比如0.9s的时候）来了5个请求，落在黄色格子里。时间过了1.0s这个点之后，又来5个请求，落在紫色格子里。如果是固定窗口算法，是不会被限流的；但是滑动窗口的话，每过一个小周期，它会右移一个小格。过了1.0s这个点后，会右移一小格，当前的单位时间段是0.2~1.2s，这个区域的请求已经超过限定的5了，已触发限流啦，实际上，紫色格子的请求都被拒绝啦。 TIPS: 当滑动窗口的格子周期划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 缺陷：滑动窗口算法虽然解决了固定窗口的临界问题，但是一旦到达限流后，请求都会直接暴力被拒绝。酱紫我们会损失一部分请求，这其实对于产品来说，并不太友好。 漏桶算法 漏桶算法面对限流，就更加的柔性，不存在直接的粗暴拒绝。 它的原理很简单，可以认为就是注水漏水的过程：往漏桶中以任意速率流入水，以固定的速率流出水。当水超过桶的容量时，会被溢出，也就是被丢弃。因为桶容量是不变的，保证了整体的速率。 流入的水滴，可以看作是访问系统的请求，这个流入速率是不确定的。 桶的容量一般表示系统所能处理的请求数。 如果桶的容量满了，就达到限流的阀值，就会丢弃水滴（拒绝请求） 流出的水滴，是恒定过滤的，对应服务按照固定的速率处理请求。 在正常流量的时候，系统按照固定的速率处理请求，是我们想要的。但是面对突发流量的时候，漏桶算法还是循规蹈矩地处理请求，这就不是我们想看到的啦。流量变突发时，我们肯定希望系统尽量快点处理请求，提升用户体验嘛。 令牌桶算法 面对突发流量的时候，我们可以使用令牌桶算法限流。相比漏桶算法，可以调节速率。 令牌桶算法原理： 有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。 如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。 系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑； 如果拿不到令牌，就直接拒绝这个请求。 如果令牌发放的策略正确，这个系统即不会被拖垮，也能提高机器的利用率。 参考文章： 面试必备：4种经典限流算法讲解 参考文章： 高并发系统设计 40 问 字节三面：如何设计一个高并发系统 ","date":"0001-01-01","objectID":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/:6:2","tags":null,"title":"","uri":"/17-%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"[toc] 被迫营业Java的第一天 [2023/05/09] 一、集合 ","date":"0001-01-01","objectID":"/18-java/:0:0","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"Collection ","date":"0001-01-01","objectID":"/18-java/:1:0","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"List ArrayList 问：ArrayList底层的实现原理是什么？ ArrayList 底层是用动态数组实现的； 若不指定初始化容量，ArrayList 初始容量为 0，当第一次添加数据的时候才会初始化容量为 10；若指定初始容量，那么就直接分配该容量大小的数组，不进行扩容； ArrayList 再进行扩容的时候是原来容量的 1.5 倍，每次扩容都需要拷贝数组； ArrayList 再添加数据的时候： 确保数组已使用长度(size)+1后足够存下下一个数据； 计算数组的容量，如果当前数组已使用长度+1后 \u003e 当前数组长度，则调用 grow 方法扩容(原来的1.5倍)； 确保新增的数据有地方存储后，则将新元素添加到位于 size 的位置上； 返回添加成功的布尔值。 ","date":"0001-01-01","objectID":"/18-java/:1:1","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"Map ","date":"0001-01-01","objectID":"/18-java/:2:0","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"HashMap 底层实现 和 Go 也大差不差，记几个关键词即可： 拉链法； 扰动函数减少 hash冲突； 与运算(因此数组长度只能是2的整数次幂，JavaGuide 解释的非常不好。。) 转换红黑树。 static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^：按位异或 // \u003e\u003e\u003e:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16); } JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，会判断是否要将链表转化为红黑树： 当前数组的长度小于 64，那么会选择先进行数组扩容； 否则，转成红黑树，以减少搜索时间。 ","date":"0001-01-01","objectID":"/18-java/:2:1","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"HashMap 有哪些遍历方式? 先说结论：存在阻塞时 parallelStream 性能最高, 非阻塞时 parallelStream 性能最低 。 懒得记了，看链接：HashMap 的 7 种遍历方式与性能分析！ HashMap 遍历从大的方向来说，可分为以下 4 类： 迭代器（Iterator）方式遍历； For Each 方式遍历； Lambda 表达式遍历（JDK 1.8+）; Streams API 遍历（JDK 1.8+）。 但每种类型下又有不同的实现方式，因此具体的遍历方式又可以分为以下 7 种： 使用迭代器（Iterator）EntrySet 的方式进行遍历； 使用迭代器（Iterator）KeySet 的方式进行遍历； 使用 For Each EntrySet 的方式进行遍历； 使用 For Each KeySet 的方式进行遍历； 使用 Lambda 表达式的方式进行遍历； 使用 Streams API 单线程的方式进行遍历； 使用 Streams API 多线程的方式进行遍历。 ","date":"0001-01-01","objectID":"/18-java/:2:2","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"ConcurrentHashMap 和 Hashtable 的区别 底层数据结构：JDK1.7 的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。 实现线程安全的方式⭐： 在 JDK1.7 的时候，ConcurrentHashMap 对整个桶数组进行了分割分段(Segment，分段锁)，每一把锁只锁容器其中一部分数据（下面有示意图），多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率； 到了 JDK1.8 的时候，ConcurrentHashMap 已经摒弃了 Segment 的概念，而是直接用 Node数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本； Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 ","date":"0001-01-01","objectID":"/18-java/:2:3","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"ConcurrentHashMap 线程安全的具体实现方式/底层具体实现 JDK1.8 之前 首先将数据分为一段一段（这个“段”就是 Segment）的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的个数一旦初始化就不能改变。Segment 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。 Segment 的结构和 HashMap 类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 的锁。也就是说，对同一 Segment 的并发写入会被阻塞，不同 Segment 的写入是可以并发执行的。 JDK1.8 之后 Java 8 几乎完全重写了 ConcurrentHashMap，代码量从原来 Java 7 中的 1000 多行，变成了现在的 6000 多行。 ConcurrentHashMap 取消了 Segment 分段锁，采用 Node + CAS + synchronized 来保证并发安全。数据结构跟 HashMap 1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。 Java 8 中，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。 ","date":"0001-01-01","objectID":"/18-java/:2:4","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现有什么不同？ 其实主要就是把段分的更细了。 线程安全实现方式：JDK 1.7 采用 Segment 分段锁来保证安全， Segment 是继承自 ReentrantLock。JDK1.8 放弃了 Segment 分段锁的设计，采用 Node + CAS + synchronized 保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点。 Hash 碰撞解决方法 : JDK 1.7 采用拉链法，JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。 并发度⭐：JDK 1.7 最大并发度是 Segment 的个数，默认是 16。JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。 ","date":"0001-01-01","objectID":"/18-java/:2:5","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"HashMap 和 HashTable 的区别？ 线程是否安全：HashMap 是非线程安全的，Hashtable 是线程安全的,因为 Hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率：因为线程安全的问题，HashMap 要比 Hashtable 效率高一点。另外，Hashtable 基本被淘汰，不要在代码中使用它； Key是否能为null：HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。 初始容量与扩容： 创建时如果不指定容量初始值：Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1；HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。 创建时如果给定了容量初始值：那么 Hashtable 会直接使用给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小。 底层数据结构：HashMap中，当链表长度大于阈值（默认为 8）时，会判断是否要将链表转化为红黑树(Hashtable 没有这样的机制)： 当前数组的长度小于 64，那么会选择先进行数组扩容； 否则，转成红黑树，以减少搜索时间。 ","date":"0001-01-01","objectID":"/18-java/:2:6","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"HashMap 和 HashSet 的区别？ HashSet 底层就是基于 HashMap 实现的。 HashMap HashSet 实现了 Map 接口 实现 Set 接口 存储键值对 仅存储对象 调用 put()向 map 中添加元素 调用 add()方法向 Set 中添加元素 HashMap 使用键（Key）计算 hashcode HashSet 使用成员对象来计算 hashcode 值，对于两个对象来说 hashcode 可能相同，所以equals()方法用来判断对象的相等性 ","date":"0001-01-01","objectID":"/18-java/:2:7","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"HashMap 和 TreeMap 的区别？ TreeMap 实现SortedMap接口，可以对集合中的元素根据键排序。 ","date":"0001-01-01","objectID":"/18-java/:2:8","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"HashSet 如何检查重复？ 当通过add()把对象加入HashSet时： HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较； 如果没有相等的 hashcode，HashSet 会假设对象没有重复出现； 但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。（注意，这是不对的。） HashSet的add()方法只是简单的调用了HashMap的put()方法，并且判断了一下返回值以确保是否有重复元素。 private static final Object PRESENT = new Object(); // PRESENT 其实就是个空 Object // Returns: true if this set did not already contain the specified element // 返回值：当 set 中没有包含 add 的元素时返回真 public boolean add(E e) { return map.put(e, PRESENT)==null; // HashSet 并非没有 Val，其实也是 Key-Val，Val 默认为 PRESENT } // Returns : previous value, or null if none // 返回值：如果插入位置没有元素返回null，否则返回上一个元素 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { ... } 上面的代码可以看出，HashSet 插入时，调用的是 HashMap 的 put()，把 Val 置为默认的 PRESENT； 重复插入的时候，也会像 HashMap 一样操作：对于已存在的 Key，就会更新它的 Val，并返回旧的 Val。对于 HashSet来说，插入重复的 Key，也就是会返回 PRESENT，然后判定其不为 null，返回 false，**“相当于”**插入失败。 也就是说，在 JDK1.8 中，实际上无论HashSet中是否已经存在了某元素，HashSet都会直接插入，只是会在add()方法的返回值处告诉我们插入前是否存在相同元素。 二、并发编程 ","date":"0001-01-01","objectID":"/18-java/:2:9","tags":null,"title":"","uri":"/18-java/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/19-6.824/:0:0","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"一、Introduction ","date":"0001-01-01","objectID":"/19-6.824/:1:0","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"Lab 课程总共有 4 个 Lab： Lab 1：MapReduce Lab 2：Raft Lab 3：K/V Server Lab 4：Shared K/V Service ","date":"0001-01-01","objectID":"/19-6.824/:1:1","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"分布式系统特性 可扩展性 两台计算机构成的系统如果有两倍性能或者吞吐量，就具备很好的可扩展性； 可用性 容错性、可恢复性 两种解决方法：持久化、复制 一致性 主要是从成本考虑，强一致性太昂贵了，可能需要做很多的通信，比如访问所有的节点，找到最新的信息。 强一致性 弱一致性 ","date":"0001-01-01","objectID":"/19-6.824/:1:2","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"实验环境 需要在Linux下： # 安装 Go 环境 wget -qO- https://go.dev/dl/go1.18.linux-amd64.tar.gz | sudo tar xz -C /usr/local # 添加环境变量 export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin export GOPATH=$HOME/Project/Go go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.cn,direct 尝试运行示例： cd 6.824 cd src/main # 构建 MR APP 的动态链接库 go build -race -buildmode=plugin ../mrapps/wc.go # 运行 MR rm mr-out* go run -race mrsequential.go wc.so pg*.txt # 查看结果 more mr-out-0 ","date":"0001-01-01","objectID":"/19-6.824/:1:3","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"二、MapReduce ","date":"0001-01-01","objectID":"/19-6.824/:2:0","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"相关背景 在 20 世纪初，包括本文作者在内的 Google 的很多程序员，为了处理海量的原始数据，已经实现了数以百计的、专用的计算方法。这些计算方法用来处理大量的原始数据，比如，文档抓取（类似网络爬虫的程序）、Web 请求日志等等；也为了计算处理各种类型的衍生数据，比如倒排索引、Web 文档的图结构的各种表示形势、每台主机上网络爬虫抓取的页面数量的汇总、每天被请求的最多的查询的集合等等。 ","date":"0001-01-01","objectID":"/19-6.824/:2:1","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"要解决的问题 大多数以上提到的数据处理运算在概念上很容易理解。然而由于输入的数据量巨大，因此要想在可接受的时间内完成运算，只有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理。 ","date":"0001-01-01","objectID":"/19-6.824/:2:2","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"解决方法 模型 为了解决上述复杂的问题，本文设计一个新的抽象模型，使用这个抽象模型，用户只要表述想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在了一个库里面：利用一个输入 key/value pair 集合来产生一个输出的 key/value pair 集合。 MapReduce 库的用户可以用两个函数表达这个计算：Map 和 Reduce。 用户自定义的 Map 函数接受一个输入的 key/value pair 值，然后产生一个中间 key/value pair 值的集合。MapReduce 库把所有具有相同中间 key 值 I 的中间 value 值集合在一起后传递给 reduce 函数。 用户自定义的 Reduce 函数接受一个中间 key 的值 I 和相关的一个 value 值的集合。Reduce 函数合并这些 value 值，形成一个较小的 value 值的集合。一般的，每次 Reduce 函数调用只产生 0 或 1 个输出 value 值。通常 Map 通过一个迭代器把中间 value 值提供给 Reduce 函数，这样 Reduce Worker 就可以处理无法全部放入内存中的大量的 value 值的集合。 在概念上，用户定义的 Map 和 Reduce 函数都有相关联的类型： map(k1, v1) -\u003e list(k2, v2) reduce(k2, list(v2)) -\u003e list(v2) 比如，输入的 key 和 value 值与输出的 key 和 value 值在类型上推导的域不同。此外，中间 key 和 value 值与输出 key 和 value 值在类型上推导的域相同。 执行流程 通过将 Map 调用的输入数据自动分割为 M 个数据片段的集合，Map 调用被分布到多台机器上执行。输入的数据片段能够在不同的机器上并行处理。使用分区函数将 Map 调用产生的中间 key 值分成 R 个不同分区（例如，hash(key) mod R），Reduce 调用也被分布到多台机器上执行。分区数量（R）和分区函数由用户来指定。 上图展示了 MapReduce 实现中操作的全部流程。当用户调用 MapReduce 函数时，将发生下面的一系列动作： 用户程序首先调用的 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16MB 到 64MB（可以通过可选的参数来控制每个数据片段的大小）。然后用户程序在机群中创建大量的程序副本。 这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是 worker 程序，由 master 分配任务。有 M 个 Map 任务和 R 个 Reduce 任务将被分配，master 将一个 Map 任务或 Reduce 任务分配给一个空闲的 worker。 被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key/value pair，然后把 key/value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出的中间 key/value pair，并缓存在内存中。 缓存中的 key/value pair 通过分区函数分成 R 个区域，之后周期性的写入到本地磁盘上。缓存的 key/value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker 当 Reduce worker 程序接收到 master 程序发来的数据存储位置信息后，使用 RPC 从 Map worker 所在主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据后，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。由于许多不同的 key 值会映射到相同的 Reduce 任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。 Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这个 key 值和它相关的中间 value 值的集合传递给用户自定义的 Reduce 函数。Reduce 函数的输出被追加到所属分区的输出文件。 当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序。在这个时候，在用户程序里的对 MapReduce 调用才返回。 ","date":"0001-01-01","objectID":"/19-6.824/:2:3","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"任务分析 在 main/mrsequential.go 中我们可以找到初始代码预先提供的 单进程串行 的 MapReduce 参考实现，而我们的任务是实现一个 单机多进程并行 的版本。 通过阅读 Lab 文档 http://nil.csail.mit.edu/6.824/2021/labs/lab-mr.html 以及初始代码，可知信息如下： 整个 MR 框架由一个 Coordinator 进程及若干个 Worker 进程构成 Coordinator 进程与 Worker 进程间通过本地 Socket 进行 Golang RPC 通信 由 Coordinator 协调整个 MR 计算的推进，并分配 Task 到 Worker 上运行 在启动 Coordinator 进程时指定 输入文件名 及 Reduce Task 数量 在启动 Worker 进程时指定所用的 MR APP 动态链接库文件 Coordinator 需要留意 Worker 可能无法在合理时间内完成收到的任务（Worker 卡死或宕机），在遇到此类问题时需要重新派发任务 Coordinator 进程的入口文件为 main/mrcoordinator.go Worker 进程的入口文件为 main/mrworker.go 我们需要补充实现 mr/coordinator.go、mr/worker.go、mr/rpc.go 这三个文件 基于此，我们不难设计出，Coordinator 需要有以下功能： 在启动时根据指定的输入文件数及 Reduce Task 数，生成 Map Task 及 Reduce Task 响应 Worker 的 Task 申请 RPC 请求，分配可用的 Task 给到 Worker 处理 追踪 Task 的完成情况，在所有 Map Task 完成后进入 Reduce 阶段，开始派发 Reduce Task；在所有 Reduce Task 完成后标记作业已完成并退出 ","date":"0001-01-01","objectID":"/19-6.824/:2:4","tags":null,"title":"","uri":"/19-6.824/"},{"categories":null,"content":"[toc] ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:0:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"一、基本流程 拉取最新代码——创建分支——提交分支至云端——分支代码完成后查看状态——将代码添加至暂存区——本地提交代码——推送至云端——切换为主分支——合并子分支代码——推送至云端——删除分支 ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:1:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"二、执行命令 在主分支拉取最新代码：git pull 基于主分支创建并且切换到新的子分支（没有这个分支就会新建）：git checkout -b 分支名 先把新的子分支推送到云端仓库，因为此时云端没有这个分支。如果有则忽略此步骤：git push -u origin 分支名 然后创建对应文件，开始写代码 将修改过的文件全部添加到暂存区：git add . 将代码保存到本地仓库：git commit -m \"完成了分类功能开发\" 将本地代码推送到云端：git push 切换到主分支：git checkout master 拉取最新代码：git pull 如果上一步骤存在更新，则进行变基操作即处理冲突（第四步），如果没有，则进行下一步 切换到主分支，合并代码：git merge 分支名 把主分支推送到云端: git push 删除本地的分支：git branch -d 分支名 删除云端的分支：git push origin --delete 分支名 ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:2:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"三、常用 git 命令 初始化一个 git 仓库：git init 查看状态：git status 添加所有修改：git add -A 提交修改：git commit -m \"提交说明\" 查看提交历史，按字母 q(uit) 退出：git log 查看没 add 的不同：git diff(erence) 查看本地分支：git branch 查看所有分支：git branch -a 删除未合并代码分支：git branch -D 分支名 拉取本地不存在的远程分支：git checkout -b 本地分支名 origin/远程分支名 与远程仓库关联：git remote add origin 地址 ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:3:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"四、解决冲突 pre-1: 在基准分支（主分支）上接取最新的代码 git pull pre-2: 切换到自己的分支上 git checkout 分支名 git rebase dev 解决冲突（需要和团队之间商量） git add -A git rebase --continue 重复 2，3，4 直到 reabase 完成,会出现 applying 字样 有可能本地自己的分支和远程分支还有冲突，这时候需要 git pull origin qh/home 之后，解决冲突再 push 即可 ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:4:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"五、git 的语义化 commit chore：add Oyster build script（其他修改, 比如构建流程, 依赖管理） docs：explain hat wobble（更改文档） feat：add beta sequence（新增了一个功能） fix：remove broken confirmation message（修复了一个 bug） refactor：share logic between 4d3d3d3 and flarhgunnstow（代码重构，既不修复错误也不添加功能） style：convert tabs to spaces（不影响代码含义的变化（空白、格式化、缺少分号等，注意不是 css 修改）） test：ensure Tayne retains clothing（测试用例修改） ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:5:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"六、git merge 和 git rebase 的区别 ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:6:0","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"merge merge 特点：⾃动创建⼀个新的 commit 如果合并的时候遇到冲突，仅需要修改后重新 commit 优点：记录了真实的 commit 情况，包括每个分⽀的详情 缺点：因为每次 merge 会⾃动产⽣⼀个 merge commit，所以在使⽤⼀些 git 的 GUI tools，特别是 commit ⽐较频繁时，看到分支很杂乱。 ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:6:1","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":"rebase rebase 特点：会合并之前的 commit 历史 优点：得到更简洁的项目历史，去掉了 merge commit 缺点：如果合并出现代码问题不容易定位，因为 re-write 了 history 总结：因此，当需要保留详细的合并信息的时候建议使⽤ git merge，特别是需要将分支合并进入 master 分支时；当发现自己修改某个功能时，频繁进⾏了 git commit 提交时，发现其实过多的提交信息没有必要时，可以尝试 git rebase. ","date":"0001-01-01","objectID":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/:6:2","tags":null,"title":"","uri":"/20-%E4%BB%A3%E7%A0%81%E5%86%B2%E7%AA%81/"},{"categories":null,"content":" **前言：**本节描述正向代理和反向代理，及其之间的对比。 ","date":"0001-01-01","objectID":"/%E4%BB%A3%E7%90%86/:0:0","tags":null,"title":"","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":null,"content":"一、正向代理 1.1 概念 **正向代理（forward proxy）：**是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。 这种代理其实在生活中是比较常见的，比如访问外国网站技术，其用到的就是代理技术。 有时候，用户想要访问某国外网站，该网站无法在国内直接访问，但是我们可以访问到一个代理服务器，这个代理服务器可以访问到这个国外网站。这样呢，用户对该国外网站的访问就需要通过代理服务器来转发请求，并且该代理服务器也会将请求的响应再返回给用户。这个上网的过程就是用到了正向代理。 所以，正向代理，其实是\"代理服务器\"代理了\"客户端\"，去和\"目标服务器\"进行交互。 通过正向代理服务器访问目标服务器，目标服务器是不知道真正的客户端是谁的，甚至不知道访问自己的是一个代理 1.2 作用 突破访问限制 通过代理服务器，可以突破自身IP访问限制，访问国外网站，教育网等。 提高访问速度 通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。 隐藏客户端真实IP 上网者也可以通过这种方法隐藏自己的IP，免受攻击。 ","date":"0001-01-01","objectID":"/%E4%BB%A3%E7%90%86/:0:1","tags":null,"title":"","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":null,"content":"二、反向代理 2.1 概念 反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 所以，反向代理，其实是\"代理服务器\"代理了\"目标服务器\"，去和\"客户端\"进行交互。 通过反向代理服务器访问目标服务器时，客户端是不知道真正的目标服务器是谁的，甚至不知道自己访问的是一个代理。 2.2 作用 隐藏服务器真实IP 使用反向代理，可以对客户端隐藏服务器的IP地址。 负载均衡 反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上。 提高访问速度 反向代理服务器可以对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度。 提供安全保障 反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。 ","date":"0001-01-01","objectID":"/%E4%BB%A3%E7%90%86/:0:2","tags":null,"title":"","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":null,"content":"三、正向代理和反向代理的区别 虽然正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。 1、正向代理其实是客户端的代理，帮助客户端访问其无法访问的服务器资源。反向代理则是服务器的代理，帮助服务器做负载均衡，安全防护等。 2、正向代理一般是客户端架设的，比如在自己的机器上安装一个代理软件。而反向代理一般是服务器架设的，比如在自己的机器集群中部署一个反向代理服务器。 3、正向代理中，服务器不知道真正的客户端到底是谁，以为访问自己的就是真实的客户端。而在反向代理中，客户端不知道真正的服务器是谁，以为自己访问的就是真实的服务器。 4、正向代理和反向代理的作用和目的不同。正向代理主要是用来解决访问限制问题；而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。 ","date":"0001-01-01","objectID":"/%E4%BB%A3%E7%90%86/:0:3","tags":null,"title":"","uri":"/%E4%BB%A3%E7%90%86/"},{"categories":null,"content":"本文记录常见的负载均衡算法。 ","date":"0001-01-01","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:0","tags":null,"title":"","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":null,"content":"1. ","date":"0001-01-01","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:1","tags":null,"title":"","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":null,"content":"2. Power of 2 random choice P2C算法是一种工业中运用较多的负载均衡算法，它的原理很简单，它有两条基本定律： 若请求IP为空，P2C均衡器将随机选择两个代理主机节点，最后选择其中负载量较小的节点； 若请求IP不为空，P2C均衡器通过对IP地址以及对IP地址加盐进行CRC32哈希计算，则会得到两个32bit的值，将其对主机数量进行取模，即CRC32(IP) % len(hosts) 、CRC32(IP + salt) % len(hosts)， 最后选择其中负载量较小的节点； ","date":"0001-01-01","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:2","tags":null,"title":"","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":null,"content":"3. Least Load Least Load也就是最小负载算法，也是非常经典的负载均衡算法，在最小负载算法中，负载均衡器将请求定向到负载最小的目标主机中； 对于最小负载算法而言，如果把所有主机的负载值动态存入动态数组中，寻找负载最小节点的时间复杂度为O(N)，如果把主机的负载值维护成一个红黑树，那么寻找负载最小节点的时间复杂度为O(logN)，我们这里利用的数据结构叫做 斐波那契堆 ，寻找负载最小节点的时间复杂度为O(1)，感兴趣的小伙伴可以看看斐波那契堆的原理！ ","date":"0001-01-01","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:3","tags":null,"title":"","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":null,"content":"4. 传统一致性哈希 一致性哈希算法是一种特殊的哈希算法，当哈希表改变大小时，平均只需要重新映射n/m个键值，其中n为哈希表键值的数量，m为哈希表槽的数量。 在一致性哈希负载均衡器中，一个集群由多个代理节点所组成，通过CRC32散列算法对代理主机节点的UUID或节点的IP地址进行计算，即**CRC32(IP)或CRC32(UUID)，**则会得到一组散列值，而这组散列值连成的环，称为哈希环。 当收到请求时，负载均衡器将请求的IP进行CRC32哈希计算进而得到一个散列值。如图所示，将代理主机节点和请求IP的哈希值映射到哈希环后，沿着哈希环顺时针方向查找，找到的第一个节点，即请求所被调度的代理节点。 通过对代理节点的哈希值按升序建立动态数组，即可在O(logN)时间复杂度的情况下通过二分搜索可以找到被调度的代理节点。 当代理节点数量越少时，越容易出现节点的哈希值在哈希环上分布不均匀的情况。而通过引入虚拟节点的方式可以解决一致性哈希算法负载不平衡的问题 。通过对代理主机的IP外加虚拟序号的形式作哈希计算。 如192.168.1.1的虚拟节点可能是192.168.1.1#1、192.168.1.1#2、192.168.1.1#3，我们需要把虚拟节点计算得到的CRC32值也映射到哈希环中。 下图的三个节点H1、H2、H3均匀两个虚拟节点： ","date":"0001-01-01","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:4","tags":null,"title":"","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":null,"content":"5. 有界负载一致性哈希 Google提出的有界负载一致性哈希通过限制节点负载上限的方式解决了工作节点负载过高的问题。当节点负载过高时，有界负载一致性哈希算法通过转移热点的方式来提升集群整体的负载平衡性。 在有界负载一致性哈希算法中R 表示代理主机节点的总负载量，Tw 表示代理主机节点的数量，L 表示当前所有代理主机的平均负载量，即： α 表示代理主机所能执行的额外上限系数，M 则表示每个代理主机所能承受的最大负载量，即： 当α趋于0时，有界负载一致性哈希算法将会退化成最小负载算法 当α趋于正无穷时，算法会退化成普通性质的一致性哈希算法。 当请求IP的哈希值所调度的代理主机节点超过所能承受的最大负载量M 时，负载均衡器则会按顺时针选择第一个负载量小于M 值的代理主机节点： ","date":"0001-01-01","objectID":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:5","tags":null,"title":"","uri":"/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"}]